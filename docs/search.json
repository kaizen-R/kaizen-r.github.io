[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "others/RLCS_documentation.html#an-issue-with-ai-explainability",
    "href": "others/RLCS_documentation.html#an-issue-with-ai-explainability",
    "title": "RLCS: An Introduction",
    "section": "An issue with ‚ÄúAI‚Äù: explainability",
    "text": "An issue with ‚ÄúAI‚Äù: explainability\nLet‚Äôs call it Machine Learning. As of today:\n\nMostly Neural networks\nAnd mostly, that means it‚Äôs all black boxes\n\nThere are ways around that. (e.g.¬†Trees and other ‚Äúopen book‚Äù algorithms‚Ä¶)\n\nJohn H. Holland proposed an algorithm with the Cognitive System One program (1976). Later, people came up with variations‚Ä¶ Today we focus on Michigan-style LCS.\n\nActually‚Ä¶ That‚Äôs it. No time to dive deeper here.\nToday, we‚Äôll be discussing one such explainable Machine Learning algorithm."
  },
  {
    "objectID": "others/RLCS_documentation.html#learning-rules-as-models",
    "href": "others/RLCS_documentation.html#learning-rules-as-models",
    "title": "RLCS: An Introduction",
    "section": "Learning rules as model(s)",
    "text": "Learning rules as model(s)\n\nif A & NOT(B) then Class=X\nif D then Class=Y\n\n\n‚ÄúHuman-readable‚Äù, ‚Äúinterpretable‚Äù, good for:\n\nMitigating bias(es) (in training data, at least)\nIncreased trust (justifying decisions)\n\n\n\nLearning about the data (data mining), better decisions, regulatory compliance, ethical/legal matters, possible adversarial attack robustness‚Ä¶"
  },
  {
    "objectID": "others/RLCS_documentation.html#a-new-r-package",
    "href": "others/RLCS_documentation.html#a-new-r-package",
    "title": "RLCS: An Introduction",
    "section": "A new R package",
    "text": "A new R package\n\n\nHave you ever found something that no one else has done?\n\nI found such a thing last November 2024. But let‚Äôs go back for a minute."
  },
  {
    "objectID": "others/RLCS_documentation.html#can-you-guess-the-rule",
    "href": "others/RLCS_documentation.html#can-you-guess-the-rule",
    "title": "RLCS: An Introduction",
    "section": "Can you guess the ‚Äúrule‚Äù?",
    "text": "Can you guess the ‚Äúrule‚Äù?\n&gt; library(RLCS)\n&gt; demo_env1 &lt;- rlcs_example_secret1()\n&gt; sample_of_rows &lt;- sample(1:nrow(demo_env1), 10, replace=F)\n&gt; print(demo_env1[sample_of_rows,], row.names = F)\n state class\n 01010     0\n 00111     0\n 11010     0\n 10001     1\n 00010     0\n 00100     1\n 10100     1\n 01111     0\n 01100     1\n 00001     1"
  },
  {
    "objectID": "others/RLCS_documentation.html#did-you-guess-right",
    "href": "others/RLCS_documentation.html#did-you-guess-right",
    "title": "RLCS: An Introduction",
    "section": "Did you guess right?",
    "text": "Did you guess right?\n&gt; demo_params &lt;- RLCS_hyperparameters(n_epochs = 280, deletion_trigger = 40, deletion_threshold = 0.9)\n&gt; rlcs_model1 &lt;- rlcs_train_sl(demo_env1, demo_params, NULL, F)\n[1] \"Epoch: 40 Progress Exposure: 1280 Classifiers Count: 14\"\n[1] \"Epoch: 80 Progress Exposure: 2560 Classifiers Count: 8\"\n[1] \"Epoch: 120 Progress Exposure: 3840 Classifiers Count: 2\"\n[1] \"Epoch: 160 Progress Exposure: 5120 Classifiers Count: 2\"\n[1] \"Epoch: 200 Progress Exposure: 6400 Classifiers Count: 2\"\n[1] \"Epoch: 240 Progress Exposure: 7680 Classifiers Count: 2\"\n[1] \"Epoch: 280 Progress Exposure: 8960 Classifiers Count: 2\"\n\n\n&gt; print(rlcs_model1)\n  condition action match_count correct_count accuracy numerosity reward first_seen\n1     ###1#      0        3560          3560        1        122      5       1843\n2     ###0#      1        2770          2770        1         94      5       3421\nThe model expresses: ‚ÄúNot bit 4‚Äù"
  },
  {
    "objectID": "others/RLCS_documentation.html#the-model-the-ternary-alphabet",
    "href": "others/RLCS_documentation.html#the-model-the-ternary-alphabet",
    "title": "RLCS: An Introduction",
    "section": "The model: the Ternary Alphabet",
    "text": "The model: the Ternary Alphabet\nA Population of Classifiers is produced.\nThis is how to read that output model:\nEach classifier includes a rule that encodes a match for states that can be read as:\n\n\n\n0\nNo/False/not present\n\n\n1\nYes/True/present\n\n\n#\n‚ÄúDon‚Äôt care‚Äù"
  },
  {
    "objectID": "others/RLCS_documentation.html#the-input",
    "href": "others/RLCS_documentation.html#the-input",
    "title": "RLCS: An Introduction",
    "section": "The input",
    "text": "The input\nBefore we dive in:\nNeural Networks accept numerical vectors for inputs.\nOther algorithms accept factors, or mixed-input.\nWell‚Ä¶\n\nThe RLCS package (specific/current implementation) expects binary strings for its input."
  },
  {
    "objectID": "others/RLCS_documentation.html#the-input-binary-encoding",
    "href": "others/RLCS_documentation.html#the-input-binary-encoding",
    "title": "RLCS: An Introduction",
    "section": "The input: Binary encoding",
    "text": "The input: Binary encoding\nNOTE: This is NOT part of the LCS algorithm per-se.\nWith the input data, we will encode the data as:\n\n\n\n0\nNo/False/not present/0\n\n\n1\nYes/True/present/1\n\n\n\nA ‚Äústate‚Äù of the environment will then be encoded as a string of zeros and ones."
  },
  {
    "objectID": "others/RLCS_documentation.html#binary-input-do-not-worry",
    "href": "others/RLCS_documentation.html#binary-input-do-not-worry",
    "title": "RLCS: An Introduction",
    "section": "Binary input?! DO NOT WORRY",
    "text": "Binary input?! DO NOT WORRY\nAny data point can be encoded into binary strings.\n\n\nrlcs_rosetta_stone()\nA (simplistic) function is actually provided to make this a bit more transparent. Not necessarily the best approach! Just an ‚Äúillustration‚Äù, really.\n(for numerical data, for now‚Ä¶ work-in-progress :))"
  },
  {
    "objectID": "others/RLCS_documentation.html#binary-input-example",
    "href": "others/RLCS_documentation.html#binary-input-example",
    "title": "RLCS: An Introduction",
    "section": "Binary input: Example",
    "text": "Binary input: Example\n\nRosetta Stone ‚Äúbinning‚Äù for numerical variables (2 bits explanation)"
  },
  {
    "objectID": "others/RLCS_documentation.html#binary-input-example-1",
    "href": "others/RLCS_documentation.html#binary-input-example-1",
    "title": "RLCS: An Introduction",
    "section": "Binary input: Example",
    "text": "Binary input: Example\nRosetta Stone: 16 values, 4-bits, ‚Äúdouble-quartiles‚Äù w/ Gray-binary encoding, per variable:\n&gt; head(iris, n=3)\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n&gt; rlcs_iris &lt;- rlcs_rosetta_stone(iris, class_col=5) ## NOT part of LCS\n&gt; head(rlcs_iris$model, n=3)\n  rlcs_Sepal.Length rlcs_Sepal.Width rlcs_Petal.Length rlcs_Petal.Width  class            state\n1              0010             1111              0011             0010 setosa 0010111100110010\n2              0011             0101              0011             0010 setosa 0011010100110010\n3              0000             1101              0000             0010 setosa 0000110100000010\nNote: with some data loss :S"
  },
  {
    "objectID": "others/RLCS_documentation.html#download-and-install-rlcs",
    "href": "others/RLCS_documentation.html#download-and-install-rlcs",
    "title": "RLCS: An Introduction",
    "section": "Download and install RLCS",
    "text": "Download and install RLCS\nTo get the package from GitHub:\nlibrary(devtools)\ninstall_github(\"kaizen-R/RLCS\")"
  },
  {
    "objectID": "others/RLCS_documentation.html#run-your-first-tests-of-rlcs",
    "href": "others/RLCS_documentation.html#run-your-first-tests-of-rlcs",
    "title": "RLCS: An Introduction",
    "section": "Run your first tests of RLCS",
    "text": "Run your first tests of RLCS\nlibrary(RLCS)\ndemo_params &lt;- RLCS_hyperparameters(n_epochs = 400, deletion_trigger = 40, deletion_threshold = 0.9)\ndemo_env2 &lt;- rlcs_example_secret2()\nprint(demo_env2, row.names = F)\nrlcs_model2 &lt;- rlcs_train_sl(demo_env2, demo_params, NULL, F)\nprint(rlcs_model2)\nplot(rlcs_model2)"
  },
  {
    "objectID": "others/RLCS_documentation.html#keywords",
    "href": "others/RLCS_documentation.html#keywords",
    "title": "RLCS: An Introduction",
    "section": "Keywords",
    "text": "Keywords"
  },
  {
    "objectID": "others/RLCS_documentation.html#covering",
    "href": "others/RLCS_documentation.html#covering",
    "title": "RLCS: An Introduction",
    "section": "1 - Covering",
    "text": "1 - Covering\n\n\nThe key: ‚Äú#‚Äù means ‚ÄúI don‚Äôt care‚Äù\n\nCovering a state with a probability of ‚Äú#‚Äù values means making a rule that matches the input state and class/action.\nSomething that could match other (partially) similar input:\n&gt; generate_cover_rule_for_unmatched_instance('010001', 0.2)\n[1] \"0#0001\"\n&gt; generate_cover_rule_for_unmatched_instance('010001', 0.8)\n[1] \"##0###\"\nYou receive an instance of the environment (a binary string state and a class).\nThe class here is defined already."
  },
  {
    "objectID": "others/RLCS_documentation.html#matching",
    "href": "others/RLCS_documentation.html#matching",
    "title": "RLCS: An Introduction",
    "section": "2 - Matching",
    "text": "2 - Matching\n\nWhen you see a new environment instance that does not match any rule in your population yet -&gt; generate a new rule.\n\n\n\nIf one(+) rule(s) in your population matches your new instance state -&gt; increase the match count of the corresponding classifier.\nIf one(+) rule(s) in your population matches your new instance state && class/action ‚Äì&gt; increase the correct count.\n\nincluding their corresponding actions"
  },
  {
    "objectID": "others/RLCS_documentation.html#rule-discovery",
    "href": "others/RLCS_documentation.html#rule-discovery",
    "title": "RLCS: An Introduction",
    "section": "3 - Rule Discovery",
    "text": "3 - Rule Discovery\nAfter a few epochs of exposing the LCS to your environment, you will have a few rules that match correctly a given instance, the ‚Äúcorrect‚Äù set.\nMatch and Correct count are indicators of how good each rule is. But are there other better possibilities?\n\nTake all the correct set, and apply a Genetic Algorithm to that set, to generate new rules!"
  },
  {
    "objectID": "others/RLCS_documentation.html#rule-discovery-ga",
    "href": "others/RLCS_documentation.html#rule-discovery-ga",
    "title": "RLCS: An Introduction",
    "section": "3 - Rule Discovery (GA)",
    "text": "3 - Rule Discovery (GA)\n\nmut_point &lt;- which(runif(nchar(t_instance_state)) &lt; mut_prob)"
  },
  {
    "objectID": "others/RLCS_documentation.html#population-size",
    "href": "others/RLCS_documentation.html#population-size",
    "title": "RLCS: An Introduction",
    "section": "4 - Population Size",
    "text": "4 - Population Size\nMatching must go through all the population every time an environment instance is presented to the LCS.\n\\[O(match) = epochs*N(environment)*N(population)\\]\nWhere \\(N()\\) means ‚Äúsize of‚Äù.\n\\[e.g. 1.000 * 5.000 * 1.000 = 5.000.000.000\\]\n\nOne option: Reduce the population of rules."
  },
  {
    "objectID": "others/RLCS_documentation.html#population-size-1",
    "href": "others/RLCS_documentation.html#population-size-1",
    "title": "RLCS: An Introduction",
    "section": "4 - Population Size",
    "text": "4 - Population Size\n\n\nSubsumption: A ‚Äúperfect‚Äù classifier that has 100% accuracy might be simpler (more # characters) than other classifiers in the population with same classification. Keep only the best classifiers. (Implemented: Accuracy-based subsumption)\nCompaction: You can keep all classifiers that have e.g.¬†60%+ accuracy after a number of epochs.\nDeletion: But you can also cap the population size, keeping only e.g.¬†10.000 best classifiers."
  },
  {
    "objectID": "others/RLCS_documentation.html#prediction",
    "href": "others/RLCS_documentation.html#prediction",
    "title": "RLCS: An Introduction",
    "section": "5 - Prediction",
    "text": "5 - Prediction\nImagine a new sample/instance, never seen before. (Test environment)\nPrediction is about returning the match set for that new instance.\nRLCS::get_match_set(sample_state, population_of_classifiers)\n\nThe prediction will be the majority (possibly weighted by numerosity, accuracy‚Ä¶) of the proposed class/action. That‚Äôs it! It also means, this is natively an ensemble learning algorithm."
  },
  {
    "objectID": "others/RLCS_documentation.html#other-uses",
    "href": "others/RLCS_documentation.html#other-uses",
    "title": "RLCS: An Introduction",
    "section": "6 - Other uses!",
    "text": "6 - Other uses!\n\nWhy talk about ‚Äúenvironment‚Äù and ‚Äúaction‚Äù? This comes from the world of Reinforcement Learning.\n\n\nAnd because one can read the rules, and ‚Äúunderstand‚Äù the population, you can also use the LCS to interpret the results and thus do data mining!\nAll with the same algorithm!"
  },
  {
    "objectID": "others/RLCS_documentation.html#supervised-learning-iris",
    "href": "others/RLCS_documentation.html#supervised-learning-iris",
    "title": "RLCS: An Introduction",
    "section": "Supervised Learning: Iris",
    "text": "Supervised Learning: Iris\n\n\n\n\n\n\nIris Setosa (https://commons.wikimedia.org/w/index.php?curid=57593826)\n\n\n\n\n\n\n\nIris Sample Dataset\n\n\n\n\n\nTime difference of 13.13619 secs ## Training Runtime.\n            predicted\nclass        setosa versicolor virginica\n  setosa         13          0         0\n  versicolor      0          5         3\n  virginica       0          0         9"
  },
  {
    "objectID": "others/RLCS_documentation.html#supervised-learning-iris-1",
    "href": "others/RLCS_documentation.html#supervised-learning-iris-1",
    "title": "RLCS: An Introduction",
    "section": "Supervised Learning: Iris",
    "text": "Supervised Learning: Iris\n\nvisualizing one classifier - iris"
  },
  {
    "objectID": "others/RLCS_documentation.html#supervised-learning-images-classifier",
    "href": "others/RLCS_documentation.html#supervised-learning-images-classifier",
    "title": "RLCS: An Introduction",
    "section": "Supervised Learning: Images Classifier",
    "text": "Supervised Learning: Images Classifier\n[1] \"Accuracy: 0.98\"\n&gt; table(test_mnist_bin01_49b[, c(\"class\", \"predicted\")])\n     predicted\nclass    0    1 rlcs_no_match\n    0 1716   65             5\n    1    5 2008             0\n&gt;\n&gt; ## Training time on 800 samples:\n&gt; print(t_end - t_start)\nTime difference of 1.937979 mins\n\n\n!! Magic Trick: Parallelism: By splitting training data, and then consolidating sub-models! (Take that, Neural network :D)"
  },
  {
    "objectID": "others/RLCS_documentation.html#supervised-learning-images-classifier-1",
    "href": "others/RLCS_documentation.html#supervised-learning-images-classifier-1",
    "title": "RLCS: An Introduction",
    "section": "Supervised Learning: Images Classifier",
    "text": "Supervised Learning: Images Classifier"
  },
  {
    "objectID": "others/RLCS_documentation.html#data-mining",
    "href": "others/RLCS_documentation.html#data-mining",
    "title": "RLCS: An Introduction",
    "section": "Data Mining",
    "text": "Data Mining\nGiven that the rules are ‚Äúexpressive‚Äù, sometimes you can ask the LCS to find rules that appear in your data:\n\nNot necessarily to classify future samples\nTo identify what is important for different classes of your data\n\n\nREAL WORLD anecdote: inventory of 10K rows with 20 columns, each duly binary encoded. I learnt something about my inventory!"
  },
  {
    "objectID": "others/RLCS_documentation.html#epistasis",
    "href": "others/RLCS_documentation.html#epistasis",
    "title": "RLCS: An Introduction",
    "section": "Epistasis",
    "text": "Epistasis\nLCS can somehow recognize how two different parts interact. Aptly‚Ä¶ The term comes from of genetics (genes modified by other genes‚Ä¶). (e.g.¬†XOR‚Ä¶)\n\n  condition action match_count correct_count accuracy numerosity first_seen\n     10##1#      1       15913         15913        1        324        688\n     000###      0       15575         15575        1        357       3394\n     001###      1       14842         14842        1        298       9231\n     11###0      0       13149         13149        1        263      22839\n     ..."
  },
  {
    "objectID": "others/RLCS_documentation.html#rl-too",
    "href": "others/RLCS_documentation.html#rl-too",
    "title": "RLCS: An Introduction",
    "section": "RL, TOO!",
    "text": "RL, TOO!\n\nFirst self-brain-storm on RL with LCS"
  },
  {
    "objectID": "others/RLCS_documentation.html#rl-video",
    "href": "others/RLCS_documentation.html#rl-video",
    "title": "RLCS: An Introduction",
    "section": "RL Video",
    "text": "RL Video"
  },
  {
    "objectID": "others/RLCS_documentation.html#an-r-package",
    "href": "others/RLCS_documentation.html#an-r-package",
    "title": "RLCS: An Introduction",
    "section": "An R package",
    "text": "An R package\nA package to implement a simple version of the Learning Classifier System algorithm:\n\nBinary Alphabet, tournament/one-point crossover GA with mutation, accuracy based, Michigan-style LCS\nWith examples, demonstrating the implementation for:\n\nData Mining\nSupervised Learning\nReinforcement Learning"
  },
  {
    "objectID": "others/RLCS_documentation.html#how-did-i-approach-the-thing",
    "href": "others/RLCS_documentation.html#how-did-i-approach-the-thing",
    "title": "RLCS: An Introduction",
    "section": "How did I approach the thing?",
    "text": "How did I approach the thing?\n\nLists. Lists, everywhere. Which might have been a bad idea‚Ä¶ (data.table?)\nfrom there, lapply() & al.¬†is then my best friend\n‚ÄúStart small, grow fast‚Äù (‚Äúfast‚Äù‚Ä¶ for a hobby, that is)\nthen clean it (then clean it some more)\nFinally publishing on GitHub\nNext steps? CRAN"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples",
    "href": "others/RLCS_documentation.html#examples",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nBefore\nlcs_res &lt;- rlcs_meta_train(train_environment,\n                           1, ## Warmup with just one epoch\n                           wildcard_prob,\n                           rd_trigger,\n                           parents_selection_mode,\n                           mutation_probability,\n                           tournament_pressure,\n                           deletion_trigger) ## Deletion won't be triggered\n\nToo many parameters! (Uncle Bob wouldn‚Äôt like it)"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-1",
    "href": "others/RLCS_documentation.html#examples-1",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nAfter, using an object (reference class, ‚ÄúR5‚Äù, in this case)\ndefault_lcs_hyperparameters &lt;- RLCS_hyperparameters()\nexample_lcs &lt;- rlcs_train_sl(train_environment, default_lcs_hyperparameters)"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-2",
    "href": "others/RLCS_documentation.html#examples-2",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nOr, you know‚Ä¶\nsource(\"run_params/datamining_examples_recommended_hyperparameters_v001.R\")\nbasic_hyperparameters &lt;- RLCS_hyperparameters(\n  wildcard_prob = wildcard_prob,\n  ## defaults for rd_trigger, mutation_probability,\n  ## parents_selection_mode && tournament_pressure\n  n_epochs = n_epochs,\n  deletion_trigger = deletion_trigger,\n  deletion_threshold = deletion_threshold\n)\n\n## It makes it more readable here:\nexample_lcs &lt;- rlcs_train(train_environment, basic_hyperparameters)"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-3",
    "href": "others/RLCS_documentation.html#examples-3",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nBefore\ninc_match_count &lt;- function(M_pop) { ## All versions\n  lapply(M_pop, \\(x) {\n    x$match_count &lt;- x$match_count + 1\n    x\n  })\n}\n\ninc_correct_count &lt;- function(C_pop) { ## SL Specific\n  lapply(C_pop, \\(x) {\n    x$correct_count &lt;- x$correct_count + 1\n    x\n  })\n}\n\ninc_action_count &lt;- function(A_pop) { ## RL Specific\n  lapply(A_pop, \\(x) {\n    x$action_count &lt;- x$action_count + 1\n    x\n  })\n}"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-4",
    "href": "others/RLCS_documentation.html#examples-4",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nAfter, using a function factory\n## Function factory to increase parameter counts\ninc_param_count &lt;- function(param) {\n  param &lt;- as.name(param)\n  function(pop) {\n    lapply(pop, \\(x) {\n      x[[param]] &lt;- x[[param]] + 1\n      x\n    })\n  }\n}\n\ninc_match_count &lt;- inc_param_count(\"match_count\")\ninc_correct_count &lt;- inc_param_count(\"correct_count\")\ninc_action_count &lt;- inc_param_count(\"action_count\")"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-5",
    "href": "others/RLCS_documentation.html#examples-5",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nBefore\n## Support function for human-compatible printing:\nmake_pop_printable &lt;- function(classifier) {\n    \n    df &lt;- plyr::rbind.fill(lapply(1:length(classifier), \\(i) {\n        t_c &lt;- classifier[[i]]\n        data.frame(id = t_c$id,\n                   condition = t_c$condition_string,\n                   action = t_c$action,\n                   match_count = t_c$match_count,\n                   correct_count = t_c$correct_count,\n                   accuracy = t_c$accuracy,\n                   numerosity = t_c$numerosity,\n                   first_seen = t_c$first_seen)\n    }))\n    df[order(df$accuracy, df$numerosity, decreasing = T),]\n}\n\n(Even the parameter name is wrong‚Ä¶)"
  },
  {
    "objectID": "others/RLCS_documentation.html#examples-6",
    "href": "others/RLCS_documentation.html#examples-6",
    "title": "RLCS: An Introduction",
    "section": "Examples",
    "text": "Examples\nAfter - S3 object\nprint.rlcs_population &lt;- function(x, ...) {\n  if(length(x) == 0) return(NULL)\n  x &lt;- .lcs_best_sort_sl(x)\n  x &lt;- unclass(x)\n  l &lt;- lapply(1:length(x), \\(i) {\n    t_c &lt;- x[[i]]\n    data.frame(condition = t_c$condition_string, action = t_c$action,\n               match_count = t_c$match_count, correct_count = t_c$correct_count,\n               accuracy = t_c$accuracy, numerosity = t_c$numerosity,\n               reward = t_c$total_reward, first_seen = t_c$first_seen)\n  })\n  # plyr::rbind.fill(l) ## Faster, but adds plyr dependency :(\n  ## Slower, but no dependency:\n  df &lt;- data.frame(matrix(unlist(l), nrow=length(l), byrow=TRUE))\n  names(df) &lt;- c(\"condition\", \"action\", \"match_count\", \"correct_count\", \"accuracy\", \"numerosity\", \"reward\", \"first_seeen\")\n  df\n}\n\nprint(example_lcs_population)"
  },
  {
    "objectID": "others/RLCS_documentation.html#then-again",
    "href": "others/RLCS_documentation.html#then-again",
    "title": "RLCS: An Introduction",
    "section": "Then again",
    "text": "Then again\nThis is all work in progress.\n\nI plan to make it into a CRAN Package.\nSo: document more, write more tests, reorganize functions‚Ä¶"
  },
  {
    "objectID": "others/RLCS_documentation.html#why-nobody-has-done-it-yet",
    "href": "others/RLCS_documentation.html#why-nobody-has-done-it-yet",
    "title": "RLCS: An Introduction",
    "section": "Why nobody has done it yet?",
    "text": "Why nobody has done it yet?\nIt‚Äôs not fast\n\nThere are many sequential steps, rather unavoidable ones at that\nNot ideal to compete with a world of GPUs and parallel processing (yet ;))\n\n\nIt‚Äôs ‚Äúcomplex‚Äù\n\nOr so does the Wikipedia entry say‚Ä¶\nWhen it comes to ‚Äúalphabets‚Äù, it does get messy, I‚Äôll admit"
  },
  {
    "objectID": "others/RLCS_documentation.html#execution-speed",
    "href": "others/RLCS_documentation.html#execution-speed",
    "title": "RLCS: An Introduction",
    "section": "Execution Speed",
    "text": "Execution Speed\nFor instance, this is a ‚Äúslow‚Äù algorithm. Option: Rcpp for Matching\n\nprofviz"
  },
  {
    "objectID": "others/RLCS_documentation.html#parallel-computing",
    "href": "others/RLCS_documentation.html#parallel-computing",
    "title": "RLCS: An Introduction",
    "section": "Parallel Computing",
    "text": "Parallel Computing\nParallel computing? %dopar%, mirai were tested (it all works, but‚Ä¶)\n\nvertical and horizontal partitioning\n\nBreak data set (vertical). Two options\n\ninstances subsets (reduce population covered per thread/core)\nSubstrings of states (reduce search space)\nboth are ‚Äúrisky‚Äù!\n\nrun fewer iterations (epochs) on full dataset, but on several cores in parallel"
  },
  {
    "objectID": "others/RLCS_documentation.html#parallel-computing-1",
    "href": "others/RLCS_documentation.html#parallel-computing-1",
    "title": "RLCS: An Introduction",
    "section": "Parallel Computing",
    "text": "Parallel Computing\nDepending on the dataset, it can be done‚Ä¶ Or not‚Ä¶"
  },
  {
    "objectID": "others/RLCS_documentation.html#reinforcement-learning-conundrum",
    "href": "others/RLCS_documentation.html#reinforcement-learning-conundrum",
    "title": "RLCS: An Introduction",
    "section": "Reinforcement Learning Conundrum",
    "text": "Reinforcement Learning Conundrum\nWe‚Äôve seen it works, but‚Ä¶ How do you package an RL algorithm?\n\nYou must make assumptions about the ‚Äúworld‚Äù your agent is going to interact with. This makes things complicated:\n\nWhat to include inside the package? What not?\nWhat to expose from the package? What not?\n\nAnd a few other such questions slow me down a bit‚Ä¶"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#an-issue-with-ai-explainability",
    "href": "others/RLCS_documentation_15.html#an-issue-with-ai-explainability",
    "title": "RLCS: A (shorter) Introduction",
    "section": "An issue with ‚ÄúAI‚Äù: explainability",
    "text": "An issue with ‚ÄúAI‚Äù: explainability\nLet‚Äôs call it Machine Learning. As of today:\n\nMostly Neural networks, DNN, and that‚Äôs all black boxes\n\nThere are ways around that."
  },
  {
    "objectID": "others/RLCS_documentation_15.html#an-issue-with-ai-explainability-1",
    "href": "others/RLCS_documentation_15.html#an-issue-with-ai-explainability-1",
    "title": "RLCS: A (shorter) Introduction",
    "section": "An issue with ‚ÄúAI‚Äù: explainability",
    "text": "An issue with ‚ÄúAI‚Äù: explainability\nInterpretability/Explainability:\n\nModel-specific Methods (‚Ä¶)\nLocal Model-Agnostic Methods: Counterfactuals, Local Surrogate Model (LIME), Shapley Value, Shapley Additive exPlanation (SHAP)‚Ä¶\nGlobal Model-Agnostic Methods: Partial Dependence Plot (PDP), Accumulated Local Effects (ALE), H-Statistic, Surrogate Models‚Ä¶\nInterpretable Models: Trees, LM/GLM, KNN, and rule-based\n\nRecommended reading: Molnar C. (2022) ‚ÄúInterpretable Machine Learning‚Äù"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#a-new-r-package",
    "href": "others/RLCS_documentation_15.html#a-new-r-package",
    "title": "RLCS: A (shorter) Introduction",
    "section": "A new R package",
    "text": "A new R package\n\nJohn H. Holland proposed an algorithm with the Cognitive System One program (1976). Later, people came up with variations‚Ä¶ Today we focus on Michigan-style LCS."
  },
  {
    "objectID": "others/RLCS_documentation_15.html#can-you-guess-the-rule",
    "href": "others/RLCS_documentation_15.html#can-you-guess-the-rule",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Can you guess the ‚Äúrule‚Äù?",
    "text": "Can you guess the ‚Äúrule‚Äù?\n\nA Data Mining Exercise with RLCS\n&gt; library(RLCS)\n&gt; demo_env1 &lt;- rlcs_example_secret1()\n&gt; sample_of_rows &lt;- sample(1:nrow(demo_env1), 10, replace=F)\n&gt; print(demo_env1[sample_of_rows,], row.names = F)\n state class\n 01010     0\n 00111     0\n 11010     0\n 10001     1\n 00010     0\n 00100     1\n 10100     1\n 01111     0\n 01100     1\n 00001     1"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#did-you-guess-right",
    "href": "others/RLCS_documentation_15.html#did-you-guess-right",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Did you guess right?",
    "text": "Did you guess right?\n&gt; demo_params &lt;- RLCS_hyperparameters(n_epochs = 280, deletion_trigger = 40, deletion_threshold = 0.9)\n&gt; rlcs_model1 &lt;- rlcs_train_sl(demo_env1, demo_params, NULL, F)\n[1] \"Epoch: 40 Progress Exposure: 1280 Classifiers Count: 14\"\n[1] \"Epoch: 80 Progress Exposure: 2560 Classifiers Count: 8\"\n(...)\n[1] \"Epoch: 280 Progress Exposure: 8960 Classifiers Count: 2\"\n\n Condition/Action is the rule (the rest are quality metrics)\n&gt; print(rlcs_model1)\n  condition action match_count correct_count accuracy numerosity reward first_seen\n1     ###1#      0        3560          3560        1        122      5       1843\n2     ###0#      1        2770          2770        1         94      5       3421\nThis model expresses: ‚ÄúAction/Class is Not bit 4‚Äù"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#learning-rules-as-models",
    "href": "others/RLCS_documentation_15.html#learning-rules-as-models",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Learning rules as model(s)",
    "text": "Learning rules as model(s)\n\nif A & NOT(B) then Class=X\nif D then Class=Y\n\n\n‚ÄúHuman-readable‚Äù, ‚Äúinterpretable‚Äù, good for:\n\nMitigating bias(es) (in training data, at least)\nIncreased trust (justifying decisions)\n\n\n\nLearning about the data (data mining), better decisions, regulatory compliance, ethical/legal matters, possible adversarial attack robustness‚Ä¶"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#download-and-install-rlcs",
    "href": "others/RLCS_documentation_15.html#download-and-install-rlcs",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Download and install RLCS",
    "text": "Download and install RLCS\nhttps://github.com/kaizen-R/RLCS\n\nTo get the package from GitHub:\nlibrary(devtools)\ninstall_github(\"kaizen-R/RLCS\")\n\nRun your first test\nlibrary(RLCS)\ndemo_params &lt;- RLCS_hyperparameters(n_epochs = 400, deletion_trigger = 40, deletion_threshold = 0.9)\ndemo_env2 &lt;- rlcs_example_secret2()\nprint(demo_env2, row.names = F)\nrlcs_model2 &lt;- rlcs_train_sl(demo_env2, demo_params, NULL, F)\nprint(rlcs_model2)\nplot(rlcs_model2)"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#binary-input-example",
    "href": "others/RLCS_documentation_15.html#binary-input-example",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Binary input: Example",
    "text": "Binary input: Example\nNeural Networks accept numerical input. Currently, RLCS accepts Binary strings.\n\nRosetta Stone ‚Äúbinning‚Äù for numerical variables (2 bits explanation)"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#data-mining",
    "href": "others/RLCS_documentation_15.html#data-mining",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Data Mining",
    "text": "Data Mining\n\nWe‚Äôve seen simple examples. A few more are included with the package, have a look at the demos."
  },
  {
    "objectID": "others/RLCS_documentation_15.html#supervised-learning-iris",
    "href": "others/RLCS_documentation_15.html#supervised-learning-iris",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Supervised Learning: Iris",
    "text": "Supervised Learning: Iris\n\n\n\n\n\n\nIris Setosa (https://commons.wikimedia.org/w/index.php?curid=57593826)\n\n\n\n\n\n\n\nIris Sample Dataset\n\n\n\n\n\nTime difference of 13.13619 secs ## Training Runtime.\n            predicted\nclass        setosa versicolor virginica\n  setosa         13          0         0\n  versicolor      0          5         3\n  virginica       0          0         9"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#supervised-learning-iris-1",
    "href": "others/RLCS_documentation_15.html#supervised-learning-iris-1",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Supervised Learning: Iris",
    "text": "Supervised Learning: Iris\n\nvisualizing one classifier - iris"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#supervised-learning-images-classifier",
    "href": "others/RLCS_documentation_15.html#supervised-learning-images-classifier",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Supervised Learning: Images Classifier",
    "text": "Supervised Learning: Images Classifier\n[1] \"Accuracy: 0.98\"\n&gt; table(test_mnist_bin01_49b[, c(\"class\", \"predicted\")])\n     predicted\nclass    0    1 rlcs_no_match\n    0 1716   65             5\n    1    5 2008             0\n&gt;\n&gt; ## Training time on 800 samples:\n&gt; print(t_end - t_start)\nTime difference of 1.937979 mins\n\n\n!! Magic Trick: Parallelism: By splitting training data, and then consolidating sub-models! (Take that, Neural network :D)"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#supervised-learning-images-classifier-1",
    "href": "others/RLCS_documentation_15.html#supervised-learning-images-classifier-1",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Supervised Learning: Images Classifier",
    "text": "Supervised Learning: Images Classifier"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#reinforcement-learning-too",
    "href": "others/RLCS_documentation_15.html#reinforcement-learning-too",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Reinforcement Learning, TOO!",
    "text": "Reinforcement Learning, TOO!\nThis example is in fact not learning probability distributions. And it uses reward-shaping. But it works!"
  },
  {
    "objectID": "others/RLCS_documentation_15.html#then-again",
    "href": "others/RLCS_documentation_15.html#then-again",
    "title": "RLCS: A (shorter) Introduction",
    "section": "Then again",
    "text": "Then again\nHyperparameters tuning is not easy, and impacts performance. Large Populations of rules are in fact hard to interpret, in spite of being readable.\nThis is all work in progress. I plan to try and make it into a CRAN Package. (So: document more, write more tests, reorganize functions‚Ä¶) I will keep working on better mechanics (fitness sharing, deletion, etc.), parallel processing, help with encoding/decoding, etc."
  },
  {
    "objectID": "posts/2021-06-20_OnContainers/index.html",
    "href": "posts/2021-06-20_OnContainers/index.html",
    "title": "Testing Containers",
    "section": "",
    "text": "Now this Post is a tiny bit different, although still about working with data, and with a focus on security.\nBut this time around, if you‚Äôve followed a bit the Blog, we have a few ‚ÄúDocker‚Äù containers running on different machines, to work on security data. That‚Äôs very cool, but‚Ä¶ What about the security OF these containers?¬†\n\n\nOK so the other day (weeks ago actually) a colleague showed me his Debian container was found to be insecure, and in doing so, he showed me about ‚ÄúTrivy‚Äù. So this (free) Aquasec tool is supposed to be able to detect, in seconds, some vulnerabilities in Containers images. And that‚Äôs‚Ä¶ Interesting to say the least.\nIn looking into it, I also came across the ‚Äúnative‚Äù alternative (well, not so native, but almost):\ndocker scan\nFunction, so we might want to try that too. Docker scan however requires a Docker account and a connection, while trivy, once installed, can be run locally as far as I have been able to check.\nsudo docker pull aquasec/trivy\nmkdir trivy_cache\ncd trivy_cache\n\n\n\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy caffix/amass\n\nNote to self: NO detection in ANY test involving Alpine containers so far‚Ä¶ Weird? Or even cooler than before (Alpine is already very lightweight‚Ä¶ Now if it also seems generally secure‚Ä¶). CVE-based detections is apparently tricky. Another colleague explained to me a bit about it, and it seems it is far from perfect. It can be prone to false-positives, and/or false-negatives, so a quick reminder: This Blog post is about ONE kind of checks, but it is NOT about EXHAUSTIVE security checks üòâ\nLet‚Äôs test our latest container (upcoming posts on the subject of Postgres):\nsudo docker run --rm -v $PWD:/root/.cache/ aquasec/trivy postgres\nNow that gives 130, 19, 32 high & 2 Critical‚Ä¶ Not cool.\nSo let‚Äôs try to upgrade the OS maybe? In a Dockerfile:\nFROM postgres\nRUN apt-get update\nRUN apt-get dist-upgrade -y\nLet‚Äôs build that:\nsudo docker build -t local/postgres_update .\nThen we run the command locally (using docker.sock):\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy local/postgres_update\nDoesn‚Äôt make any difference at all, unfortunately‚Ä¶ (And postgres was indeed upgraded, which is good, but apparently not enough‚Ä¶). Maybe I‚Äôll need to remove something from that container to improve things a bit? I don‚Äôt know. Let‚Äôs keep going\n\n\n\nSo first here we need to login to Docker Hub:\ndocker login\nThen\ndocker scan postgres\n(If you see a warning about Snyk and you are CERTAIN there is nothing sensitive in your docker image, I guess it‚Äôs safe to go ahead‚Ä¶)\nAnd indeed, a loooong output:\n\nThe output finishes with what I consider rather bad news:¬†\n\nNow, with such results (and it seems to be pretty common among debian-based images out there, although I‚Äôm not certain why‚Ä¶), one would have to consider seriously whether or not to use such a container. Again, keep in mind, CVE-based detection might not be perfect.\nPros- & Cons-? Pro: Clearly, having a container working from a simple ‚Äúdocker pull‚Äù is great. Cons: Well, are we reaaaally exposed here?\nLet‚Äôs see:\nMy containers run in a machine (the ‚ÄúHome Lab Server‚Äù) that is creating its own home-only small wifi network, uses a firewall (iptables) so that only ‚Äúinternal‚Äù machines correctly logged onto that Wifi can see those containers, and also‚Ä¶ Almost all that is on the Home Lab Server I actually publish on the Internet in one way or another.\nSo? I can still play around with this container at home. But should I need to use something similar in a different setup, I‚Äôd definitely would need to ensure it is in a controlled environment‚Ä¶ And then I looked a bit more into it. It turns out someone at the Postgres community thought it‚Äôd be cool to have an Alpine-based container‚Ä¶ Could this be the answer?\nWe already know Alpine-based containers are generally smaller‚Ä¶ Let‚Äôs go for it then:\ndocker pull postgres:alpine\nUp front, it‚Äôs 160 MB in size compared to 314MB‚Ä¶ Good.\nBut even better:¬†\n\nI feel (somewhat) relieved‚Ä¶ That I could use at work. (Good, I was starting to worry ;))\nAlso, trivy seems to agree with Docker Scan:\n\n\n\n\nWhat about our RStudio Env:\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy rocker_base003\n3 Highs, no Critical‚Ä¶ And from Docker Scan:¬†\n\nThat‚Äôs not perfect, but with no high vulnerabilities & more dependencies checked, I‚Äôd say that‚Äôs much better than the postgres container üôÇ\n\n\n\nUsing Docker is great. I am a big fan (I know, it‚Äôs obvious, if you‚Äôre a reader of the Blog). But then one needs to think of the security aspects of it all.\nOne (DEFINITELY NOT complete nor perfect) way to go about it is to look for more secure images. To do so, you need to be able to check whether an image has any red-flags. In CI, you would probably not want to deploy anything with known critical vulnerabilities, and so you would add a check upon deployments and stop anything looking really bad.\nOnce you know where you stand, you‚Äôre better off.\nAnd now you can actually look for alternative images when you think you need to."
  },
  {
    "objectID": "posts/2021-06-20_OnContainers/index.html#intro",
    "href": "posts/2021-06-20_OnContainers/index.html#intro",
    "title": "Testing Containers",
    "section": "",
    "text": "Now this Post is a tiny bit different, although still about working with data, and with a focus on security.\nBut this time around, if you‚Äôve followed a bit the Blog, we have a few ‚ÄúDocker‚Äù containers running on different machines, to work on security data. That‚Äôs very cool, but‚Ä¶ What about the security OF these containers?¬†\n\n\nOK so the other day (weeks ago actually) a colleague showed me his Debian container was found to be insecure, and in doing so, he showed me about ‚ÄúTrivy‚Äù. So this (free) Aquasec tool is supposed to be able to detect, in seconds, some vulnerabilities in Containers images. And that‚Äôs‚Ä¶ Interesting to say the least.\nIn looking into it, I also came across the ‚Äúnative‚Äù alternative (well, not so native, but almost):\ndocker scan\nFunction, so we might want to try that too. Docker scan however requires a Docker account and a connection, while trivy, once installed, can be run locally as far as I have been able to check.\nsudo docker pull aquasec/trivy\nmkdir trivy_cache\ncd trivy_cache\n\n\n\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy caffix/amass\n\nNote to self: NO detection in ANY test involving Alpine containers so far‚Ä¶ Weird? Or even cooler than before (Alpine is already very lightweight‚Ä¶ Now if it also seems generally secure‚Ä¶). CVE-based detections is apparently tricky. Another colleague explained to me a bit about it, and it seems it is far from perfect. It can be prone to false-positives, and/or false-negatives, so a quick reminder: This Blog post is about ONE kind of checks, but it is NOT about EXHAUSTIVE security checks üòâ\nLet‚Äôs test our latest container (upcoming posts on the subject of Postgres):\nsudo docker run --rm -v $PWD:/root/.cache/ aquasec/trivy postgres\nNow that gives 130, 19, 32 high & 2 Critical‚Ä¶ Not cool.\nSo let‚Äôs try to upgrade the OS maybe? In a Dockerfile:\nFROM postgres\nRUN apt-get update\nRUN apt-get dist-upgrade -y\nLet‚Äôs build that:\nsudo docker build -t local/postgres_update .\nThen we run the command locally (using docker.sock):\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy local/postgres_update\nDoesn‚Äôt make any difference at all, unfortunately‚Ä¶ (And postgres was indeed upgraded, which is good, but apparently not enough‚Ä¶). Maybe I‚Äôll need to remove something from that container to improve things a bit? I don‚Äôt know. Let‚Äôs keep going\n\n\n\nSo first here we need to login to Docker Hub:\ndocker login\nThen\ndocker scan postgres\n(If you see a warning about Snyk and you are CERTAIN there is nothing sensitive in your docker image, I guess it‚Äôs safe to go ahead‚Ä¶)\nAnd indeed, a loooong output:\n\nThe output finishes with what I consider rather bad news:¬†\n\nNow, with such results (and it seems to be pretty common among debian-based images out there, although I‚Äôm not certain why‚Ä¶), one would have to consider seriously whether or not to use such a container. Again, keep in mind, CVE-based detection might not be perfect.\nPros- & Cons-? Pro: Clearly, having a container working from a simple ‚Äúdocker pull‚Äù is great. Cons: Well, are we reaaaally exposed here?\nLet‚Äôs see:\nMy containers run in a machine (the ‚ÄúHome Lab Server‚Äù) that is creating its own home-only small wifi network, uses a firewall (iptables) so that only ‚Äúinternal‚Äù machines correctly logged onto that Wifi can see those containers, and also‚Ä¶ Almost all that is on the Home Lab Server I actually publish on the Internet in one way or another.\nSo? I can still play around with this container at home. But should I need to use something similar in a different setup, I‚Äôd definitely would need to ensure it is in a controlled environment‚Ä¶ And then I looked a bit more into it. It turns out someone at the Postgres community thought it‚Äôd be cool to have an Alpine-based container‚Ä¶ Could this be the answer?\nWe already know Alpine-based containers are generally smaller‚Ä¶ Let‚Äôs go for it then:\ndocker pull postgres:alpine\nUp front, it‚Äôs 160 MB in size compared to 314MB‚Ä¶ Good.\nBut even better:¬†\n\nI feel (somewhat) relieved‚Ä¶ That I could use at work. (Good, I was starting to worry ;))\nAlso, trivy seems to agree with Docker Scan:\n\n\n\n\nWhat about our RStudio Env:\nsudo docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $PWD:/root/.cache/ aquasec/trivy rocker_base003\n3 Highs, no Critical‚Ä¶ And from Docker Scan:¬†\n\nThat‚Äôs not perfect, but with no high vulnerabilities & more dependencies checked, I‚Äôd say that‚Äôs much better than the postgres container üôÇ\n\n\n\nUsing Docker is great. I am a big fan (I know, it‚Äôs obvious, if you‚Äôre a reader of the Blog). But then one needs to think of the security aspects of it all.\nOne (DEFINITELY NOT complete nor perfect) way to go about it is to look for more secure images. To do so, you need to be able to check whether an image has any red-flags. In CI, you would probably not want to deploy anything with known critical vulnerabilities, and so you would add a check upon deployments and stop anything looking really bad.\nOnce you know where you stand, you‚Äôre better off.\nAnd now you can actually look for alternative images when you think you need to."
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "",
    "text": "This entry is a bit‚Ä¶ Different. I just acquired a new MacBook Air M1. And some things worried me and indeed I faced a couple of issues, so here is the story about that. In case someone has doubts, like I did.\nI personally like Apple stuff. It‚Äôs a choice (not always a popular one, I‚Äôm aware ‚Äì and that‚Äôs OK, each one their opinion :)). For me, the main argument was initially the battery life (at the time, I came from a rather bad experience with an ageing HP laptop, which battery would hardly survive for 15 minutes away from a plug); and then once you get used to the Apple ecosystem, the different things just ‚Äúwork‚Äù together ‚Äì and that‚Äôs convenient.\nSo when Apple announced the M1 chip more than a year ago, the first thing I searched was whether Docker was supported on the new chip. It wasn‚Äôt. Indeed, it took some time, and so I didn‚Äôt think any further about it back then.\nCome this year‚Äôs announcement of new Macbook Pro devices and new M1 Pro, M1 Max chips‚Ä¶ And I‚Äôll admit, Apple marketing must be working: I started wondering again about it all."
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#intro",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#intro",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "",
    "text": "This entry is a bit‚Ä¶ Different. I just acquired a new MacBook Air M1. And some things worried me and indeed I faced a couple of issues, so here is the story about that. In case someone has doubts, like I did.\nI personally like Apple stuff. It‚Äôs a choice (not always a popular one, I‚Äôm aware ‚Äì and that‚Äôs OK, each one their opinion :)). For me, the main argument was initially the battery life (at the time, I came from a rather bad experience with an ageing HP laptop, which battery would hardly survive for 15 minutes away from a plug); and then once you get used to the Apple ecosystem, the different things just ‚Äúwork‚Äù together ‚Äì and that‚Äôs convenient.\nSo when Apple announced the M1 chip more than a year ago, the first thing I searched was whether Docker was supported on the new chip. It wasn‚Äôt. Indeed, it took some time, and so I didn‚Äôt think any further about it back then.\nCome this year‚Äôs announcement of new Macbook Pro devices and new M1 Pro, M1 Max chips‚Ä¶ And I‚Äôll admit, Apple marketing must be working: I started wondering again about it all."
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#decision",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#decision",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Decision",
    "text": "Decision\nNow it‚Äôs not that I wouldn‚Äôt like the power of the newest thing (I‚Äôm certain I would :D). I‚Äôve actually had a look and went to the store to see it ‚Äúlive‚Äù, and yes, the Macbook Pro 14‚Ä≥ with the M1 Pro chip is indeed nice. But maybe it‚Äôs too expensive for my taste. I mean yes, Apple devices will be never really be considered cheap anyway, so if price is a factor‚Ä¶ But then there is pricey and pricey. I just wouldn‚Äôt do it.\nIn the end, I settled for the one-year-old model Macbook Air M1. It‚Äôs (quite a bit) more reasonable in price (though not cheap), and if I‚Äôm being honest with myself, it covers my needs. I was already using a Macbook Air, albeit a somewhat older version (6.5 years old by now), and I was mostly OK, so I knew the new version would be ‚Äúsufficient‚Äù. (Sure, the 14‚Ä≥ screen Pro with 64GB of RAM and its gazillion GPUs (that I wouldn‚Äôt really use) sounds very nice, and yes, more power could in theory be useful in some very specific situations).\nBut in this case, I came from an Early 2015 Macbook Air with 8GB of RAM, and moved to the 2020 Air M1 with 16GB, and well, let‚Äôs just say I can definitely tell the difference!\n\nSo the 16GB of RAM was important ‚Äì actually, increasing the RAM was a main decision factor for me, as I wanted to be able to run different containers AND VMs all at the same time (yes, 32GB would be nice, too, but that was still a stretch, and I couldn‚Äôt come up with a use-case that would justify the expense). Last time I switched devices (from an older Macbook Air, actually) it was because I actually needed more than the 4GB I had settled on before, so I moved to an 8GB version. This time around, more RAM is also a reason for the change. Incidentally, more RAM means less disk access too, so longer life for the Disk ‚Äì at least in theory (see below: Swap usage at 0 :)).\n\nIn the end, the change meant for me:\n\nTwice the RAM,\ntwice the disk size,\ntwice the disk speed (at least that‚Äôs what I read ‚Äì didn‚Äôt check),\ntwice the number of CPU threads (actually, 8 Cores instead of two ‚Äì and better/faster ones, the older Mac is sporting 1.6GHz i5 dual core‚Ä¶)\n\nAnd it costed me about half of the Macbook Pro 14‚Ä≥ version I also (really) considered. Granted, it‚Äôs not the same. But all in all, I‚Äôm very happy with the computing power gains (I don‚Äôt do any video or photo editing for instance), and it hurts the pocket a little less‚Ä¶"
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#caveats",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#caveats",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Caveats",
    "text": "Caveats\nI don‚Äôt use it much, but as I was forced to run a Windows (to test the Simio simulation software), I recently re-installed Oracle VirtualBox on the older Mac. That‚Äôs not an option anymore. So I‚Äôm testing Parallels, and actually had to create a Windows Insider Account to be able to download the Windows 11 ARM preview. In the end, it works, so that‚Äôs good. But Parallels costs money where Oracle VirtualBox didn‚Äôt. I‚Äôll have to check whether I can get a discount through the University maybe, for the Parallels license. (After all, I wouldn‚Äôt need it if it wasn‚Äôt for them :P).¬†\nThe other thing that was bothering me the first night was the Docker image for RStudio Server: The base images I‚Äôm used to for R on Docker (including RStudio) just won‚Äôt ‚Äúsimply‚Äù work, they‚Äôre meant for AMD64 (and actually, the container boots, but then RStudio won‚Äôt get pass the login, not to mention I couldn‚Äôt get R to install packages from command line either) and unfortunately I needed an alternative, fast (I have some homework to do). I guess the great people behind the ‚ÄúRocker‚Äù images haven‚Äôt had the time yet to prepare it for ARM64v8 support. I hope this will change, but otherwise, I‚Äôll keep going with other options‚Ä¶\nThe good news is some people have been working on that M1 compatibility thing already (thank them! see references), and so on DockerHub one can find the ‚Äúamoselb/rstudio-m1‚Äù image, which does work. The only thing is, it‚Äôs big. After adding some libraries, it‚Äôs above 5.5GB (I‚Äôm used to seeing 3.5GB images with the libraries I usually use, so I‚Äôll need to work on maybe shrinking that thing at some point). Maybe the easiest will be (for now) to trim down the image itself by removing some unnecessary Ubuntu packages. But all in all the important (and urgent) thing is, it works. A couple more packages were needed to get the LaTeX generation to work, but that wasn‚Äôt too hard either. I‚Äôll make sure to create a Dockerfile for it and post it on my GitHub account when I get the chance. (Note that Docker required Rosetta2, in its current version.)"
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#other-things",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#other-things",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Other things",
    "text": "Other things\nOne of the main reasons for me to use Docker is that I can do stuff without installing much on the Mac itself. In my mind, that way I‚Äôm keeping my laptop clean üòÄ I do use different browsers, and faced no real issue on that front.\nFor the University, I‚Äôm also using MatLab, and as I was in a hurry I installed it directly on the Mac, that worked flawlessly too, thankfully. However at some point I‚Äôll have to look into getting it to run from a container, instead of on the Mac itself ‚Äì but then I‚Äôll have to look how to go about the X11 for the GUI (it seems XQuartz will do the trick), and see if the ARM64 thing will be a bother or not (it seems it will for that particular container image)‚Ä¶\nAnd as a note, I use from time to time ActivePresenter, which also seems to be working OK out of the box.\nOtherwise, moving from the old to the new Macbook Air was REALLY easy: there is this ‚ÄúMigration Assistant‚Äù, and even though it‚Äôs not fast (but then again I migrated quite a few GBs), it just works. To my point: the Apple ecosystem all works together nicely."
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#conclusion",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#conclusion",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Conclusion",
    "text": "Conclusion\nThe above is a screenshot of the M1 CPU usage, while using two browsers, Docker with the mentioned image for RStudio & Matlab. Battery-wise, I have been using it a bit for 3 days, done the data movement from the older Mac, updated the OS to the latest version, installed the few things I needed, and done some (rather simple) tests, and I‚Äôm still above 20% battery, while I have not yet ever switched it off. And that‚Äôs just great for me.\nWhether or not one can/should justify to oneself the cost of a new Apple device, that‚Äôs for each person to pounder. But although it wasn‚Äôt straightforward and I‚Äôm still a bit worried about the Docker+RStudio Server container setup, the good news is that it wasn‚Äôt too bad either to migrate to the ARM chip.\nAll in all, this new laptop is MUCH faster, and I‚Äôm very happy with it (for now :))."
  },
  {
    "objectID": "posts/2021-11-27_migratingM1DockerRStudio/index.html#resources",
    "href": "posts/2021-11-27_migratingM1DockerRStudio/index.html#resources",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Resources",
    "text": "Resources\nGetting Windows 11 Preview to work, step-by-step with Parallels\nDocker image with RStudio Server and M1 compatible (basic tests OK)\nMore info on the topic of Docker, RStudio Server, M1 on GitHub"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html",
    "href": "posts/2025-03-19_ExplainableAI/index.html",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "I have been open about some of my worries with GenAI (and in fact Deep Learning with Neural Networks).\nOne of these worries had to do with the fact that DeepLearning outputs, while very precise in the immense majority of cases, are never easily interpreted. In other words, one cannot easily understand why a (deep) neural network (in the supervised learning case, for instance) makes the choices it makes.\nThey say ‚ÄúIf you talk the talk‚Ä¶ Walk the walk‚Äù. Well, here goes my own personal attempt at just that.\n\n\n\nI‚Äôve shown in the past, how for data mining the rules themselves are showing how a classifier (separately, each of the classifier systems) actually ‚Äúshows‚Äù where to put our attention (see https://kaizen-r.github.io/posts/2025-01-25_RLCS_4_DataMining/ for instance).\nWell, today we‚Äôll see how using LCS outcome can be used itself directly to help interpret the algorithm‚Äôs own choices.\nAnd how that can be important.\nAnd to be perfectly clear, this was one of the key reasons why I got interested in LCS as a family of algorithms in the first place!\n\n\n\nIf you use a neural network trained to classify numbers, say on MNIST dataset, it will work. Most assuredly!\nAnd training it can be faster than with the LCS (although, that is‚Ä¶ not that clear. More on that some other time).\nBut more importantly: although the neural network output will work, you will have a hard time understanding why it chose one class or another. (At least, without SHAP, LIME, etc.)\nWell, I present to you, interpreting LCS output as images classifier:\n\n\n\nLCS are expressive in their choices!\n\n\nA few things happen here: First, I take MNIST, but as explained in the past, to contain the processing needs, I compress the input image first (that‚Äôs not part of the LCS algorithm üòÅ). Once I‚Äôm down to a 7x7 binary image, I use that as my state and I train the LCS with an environment of several such ‚Äústates‚Äù (i.e.¬†compressed pictures).\nDifferent from a Neural Network, I do not need to train on that many examples (also already clarified in the past). So I train on only 500 samples, chosen randomly, and here I train for quite some time (almost 7 minutes, but single-thread, mind you) on said 500 samples.\nAs an output, I get a set of a few thousand ‚Äúclassifiers‚Äù (&lt; 2500 in today‚Äôs example), all of which I have presented in the past also and won‚Äôt explain here again. Together, they form the System of classifiers.\nBut just for reference, I got a 99% correctly classified testing samples (out of 3799 of them, none of which had been seen for training).\n\n\n\nQuality of generated classifier\n\n\nNow on to the explainable part!\n\n\n\nNow tell me: Does the following set of visuals help in actually interpreting the LCS recommendation? (hint: I think it does!)\nI‚Äôve been trying to visualize why the LCS choices are indeed explainable. Of course, matching several rules makes it more confusing‚Ä¶ But each rule that matches is a vote. If you can visualize the ‚Äúensemble‚Äù of rules/classifiers, all of which must have matched the sample, in our case hopefully you can see what the LCS is using as subset of reference for a given image.\nHere an example, whereby a Zero image is correctly classified, among other reasons because it needs to have ‚Äúlines around‚Äù and one ‚Äúempty pixel‚Äù in the center! That‚Äôs enough for the LCS to decide that was a zero, and probably very few of the 156 rules that matched that test sample (all of which agreed on the correct class) would have been sufficient to explain the choice!\nIn other words, I try to show the ensemble and its choice in such a way that you see why the LCS decided on class 0 for that sample.\nGood luck doing that with a Neural network!\n\n\n\nClass 0 - Visualized\n\n\n\n\n\nExplainable AI is important for many reasons.\nBecause of the very nature of ML (in that sense different from other approaches), sometimes (as rarely as it might be, 1% of the cases in today‚Äôs exercise) it makes a classification mistake. There are several possible reasons for that, but often it has to do with problems with generalization (overfitting).\nRemember we used 500 samples for training, and have tested with 99% correct results on 3800 test samples!\n(Note that part of the trick here is that my compressing the original images has removed more subtle differences that might have otherwise required better generalization‚Ä¶ Fair enough!)\nBut I do hope in the exercise for today, the visualization of the LCS choices is helpful and indeed explainable.\nAt the very least, I feel it‚Äôs important to know, when an error is detected.\n\n\n\nResistance to Adversarial attacks!\nOne important issue with some CNNs for instance for images classification is that they are sensible to a type of attack whereby someone can add noise to a picture, invisible to the human eye, and force the classifier to err the classification.\nThis will not happen with LCS, as I hope the visuals I introduced today clearly show. And that‚Äôs pretty cool, too.\n\n\n\nFor our exercise today, a few (1%) of the examples were wrongly classified, and in all cases the confidence of the proposed classification was below 65%.\nAs the LCS output is a ‚Äúsystem of classifiers‚Äù, whereby a new sample matches several ‚Äúrules‚Äù, and given in our exercise the high level of compression with loss of information, it was no surprise that some examples were difficult based on the compressed image (I wouldn‚Äôt have been able to do any better myself, without the original image).\n\n\n\nLook at the compressed sample used, you‚Äôll understand the confusion of the LCS\n\n\nIn summary, they matched several classifiers, some of which were voting for one class, while the rest for the other‚Ä¶ Which is reflected in the low confidence of the outcome!\nAnd overall, my code for LCS did a great job, given what they see as (compressed) input.\n\n\n\n\n\n\nClass 0 - other example\n\n\nIt doesn‚Äôt always happen, but here again a central empty cell is quite self-explanatory. Moreover, one can tell the line needs to spread horizontally for the set of classifiers to agree on a Zero class, here. (That happens more often indeed)\n\n\n\nClass 1 - an example\n\n\nYou can see in the above, how the width of the line is constrained by the ‚Äúempty cells‚Äù recommendations (‚ÄúPixel=0‚Äù). Clearly the line for the one is apparent (‚ÄúPixel=1‚Äù). And the resulting visual shows (green) empty cells surrounding (maroon) full cells, indeed.\n\n\n\nLast example for today\n\n\n\n\n\nLook, I‚Äôm not kidding myself. I will not magically shift the focus of the whole AI community towards the LCS algorithm, overnight.\nPlus, it‚Äôs not a perfect algorithm. Many hyper-parameters to consider, not particularly fast (although‚Ä¶ to be discussed)‚Ä¶\nBut it does work, requires (at least in today‚Äôs example) relatively few (ideally well chosen) samples for training, and is clear in why it makes the decisions it makes, which as explained is (at least from my perspective) very important.\nI do hope, however, that maybe it shows there are alternatives to neural networks, and if nothing else, I would expect this exercise might be considered useful, as a complementary approach: Keep using your neural networks, deep learning and what-not, but maybe you can use an LCS on the side, to confirm (with a level of confidence included, and visuals that express the why) the neural net choices‚Ä¶\nAnd although I still have a lot to do, I hope when it‚Äôs ready, my RLCS package will participate in making that a reality :)"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#foreword",
    "href": "posts/2025-03-19_ExplainableAI/index.html#foreword",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "I have been open about some of my worries with GenAI (and in fact Deep Learning with Neural Networks).\nOne of these worries had to do with the fact that DeepLearning outputs, while very precise in the immense majority of cases, are never easily interpreted. In other words, one cannot easily understand why a (deep) neural network (in the supervised learning case, for instance) makes the choices it makes.\nThey say ‚ÄúIf you talk the talk‚Ä¶ Walk the walk‚Äù. Well, here goes my own personal attempt at just that."
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#lcs-outputs-can-be-interpreted",
    "href": "posts/2025-03-19_ExplainableAI/index.html#lcs-outputs-can-be-interpreted",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "I‚Äôve shown in the past, how for data mining the rules themselves are showing how a classifier (separately, each of the classifier systems) actually ‚Äúshows‚Äù where to put our attention (see https://kaizen-r.github.io/posts/2025-01-25_RLCS_4_DataMining/ for instance).\nWell, today we‚Äôll see how using LCS outcome can be used itself directly to help interpret the algorithm‚Äôs own choices.\nAnd how that can be important.\nAnd to be perfectly clear, this was one of the key reasons why I got interested in LCS as a family of algorithms in the first place!"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#explainable-ai",
    "href": "posts/2025-03-19_ExplainableAI/index.html#explainable-ai",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "If you use a neural network trained to classify numbers, say on MNIST dataset, it will work. Most assuredly!\nAnd training it can be faster than with the LCS (although, that is‚Ä¶ not that clear. More on that some other time).\nBut more importantly: although the neural network output will work, you will have a hard time understanding why it chose one class or another. (At least, without SHAP, LIME, etc.)\nWell, I present to you, interpreting LCS output as images classifier:\n\n\n\nLCS are expressive in their choices!\n\n\nA few things happen here: First, I take MNIST, but as explained in the past, to contain the processing needs, I compress the input image first (that‚Äôs not part of the LCS algorithm üòÅ). Once I‚Äôm down to a 7x7 binary image, I use that as my state and I train the LCS with an environment of several such ‚Äústates‚Äù (i.e.¬†compressed pictures).\nDifferent from a Neural Network, I do not need to train on that many examples (also already clarified in the past). So I train on only 500 samples, chosen randomly, and here I train for quite some time (almost 7 minutes, but single-thread, mind you) on said 500 samples.\nAs an output, I get a set of a few thousand ‚Äúclassifiers‚Äù (&lt; 2500 in today‚Äôs example), all of which I have presented in the past also and won‚Äôt explain here again. Together, they form the System of classifiers.\nBut just for reference, I got a 99% correctly classified testing samples (out of 3799 of them, none of which had been seen for training).\n\n\n\nQuality of generated classifier\n\n\nNow on to the explainable part!"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#the-visuals",
    "href": "posts/2025-03-19_ExplainableAI/index.html#the-visuals",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "Now tell me: Does the following set of visuals help in actually interpreting the LCS recommendation? (hint: I think it does!)\nI‚Äôve been trying to visualize why the LCS choices are indeed explainable. Of course, matching several rules makes it more confusing‚Ä¶ But each rule that matches is a vote. If you can visualize the ‚Äúensemble‚Äù of rules/classifiers, all of which must have matched the sample, in our case hopefully you can see what the LCS is using as subset of reference for a given image.\nHere an example, whereby a Zero image is correctly classified, among other reasons because it needs to have ‚Äúlines around‚Äù and one ‚Äúempty pixel‚Äù in the center! That‚Äôs enough for the LCS to decide that was a zero, and probably very few of the 156 rules that matched that test sample (all of which agreed on the correct class) would have been sufficient to explain the choice!\nIn other words, I try to show the ensemble and its choice in such a way that you see why the LCS decided on class 0 for that sample.\nGood luck doing that with a Neural network!\n\n\n\nClass 0 - Visualized"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#why-is-this-good-12",
    "href": "posts/2025-03-19_ExplainableAI/index.html#why-is-this-good-12",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "Explainable AI is important for many reasons.\nBecause of the very nature of ML (in that sense different from other approaches), sometimes (as rarely as it might be, 1% of the cases in today‚Äôs exercise) it makes a classification mistake. There are several possible reasons for that, but often it has to do with problems with generalization (overfitting).\nRemember we used 500 samples for training, and have tested with 99% correct results on 3800 test samples!\n(Note that part of the trick here is that my compressing the original images has removed more subtle differences that might have otherwise required better generalization‚Ä¶ Fair enough!)\nBut I do hope in the exercise for today, the visualization of the LCS choices is helpful and indeed explainable.\nAt the very least, I feel it‚Äôs important to know, when an error is detected."
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#why-is-it-good-22",
    "href": "posts/2025-03-19_ExplainableAI/index.html#why-is-it-good-22",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "Resistance to Adversarial attacks!\nOne important issue with some CNNs for instance for images classification is that they are sensible to a type of attack whereby someone can add noise to a picture, invisible to the human eye, and force the classifier to err the classification.\nThis will not happen with LCS, as I hope the visuals I introduced today clearly show. And that‚Äôs pretty cool, too."
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#locating-errors",
    "href": "posts/2025-03-19_ExplainableAI/index.html#locating-errors",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "For our exercise today, a few (1%) of the examples were wrongly classified, and in all cases the confidence of the proposed classification was below 65%.\nAs the LCS output is a ‚Äúsystem of classifiers‚Äù, whereby a new sample matches several ‚Äúrules‚Äù, and given in our exercise the high level of compression with loss of information, it was no surprise that some examples were difficult based on the compressed image (I wouldn‚Äôt have been able to do any better myself, without the original image).\n\n\n\nLook at the compressed sample used, you‚Äôll understand the confusion of the LCS\n\n\nIn summary, they matched several classifiers, some of which were voting for one class, while the rest for the other‚Ä¶ Which is reflected in the low confidence of the outcome!\nAnd overall, my code for LCS did a great job, given what they see as (compressed) input."
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#a-few-more-examples-for-no-reason",
    "href": "posts/2025-03-19_ExplainableAI/index.html#a-few-more-examples-for-no-reason",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "Class 0 - other example\n\n\nIt doesn‚Äôt always happen, but here again a central empty cell is quite self-explanatory. Moreover, one can tell the line needs to spread horizontally for the set of classifiers to agree on a Zero class, here. (That happens more often indeed)\n\n\n\nClass 1 - an example\n\n\nYou can see in the above, how the width of the line is constrained by the ‚Äúempty cells‚Äù recommendations (‚ÄúPixel=0‚Äù). Clearly the line for the one is apparent (‚ÄúPixel=1‚Äù). And the resulting visual shows (green) empty cells surrounding (maroon) full cells, indeed.\n\n\n\nLast example for today"
  },
  {
    "objectID": "posts/2025-03-19_ExplainableAI/index.html#conclusions",
    "href": "posts/2025-03-19_ExplainableAI/index.html#conclusions",
    "title": "RLCS & Explainable AI",
    "section": "",
    "text": "Look, I‚Äôm not kidding myself. I will not magically shift the focus of the whole AI community towards the LCS algorithm, overnight.\nPlus, it‚Äôs not a perfect algorithm. Many hyper-parameters to consider, not particularly fast (although‚Ä¶ to be discussed)‚Ä¶\nBut it does work, requires (at least in today‚Äôs example) relatively few (ideally well chosen) samples for training, and is clear in why it makes the decisions it makes, which as explained is (at least from my perspective) very important.\nI do hope, however, that maybe it shows there are alternatives to neural networks, and if nothing else, I would expect this exercise might be considered useful, as a complementary approach: Keep using your neural networks, deep learning and what-not, but maybe you can use an LCS on the side, to confirm (with a level of confidence included, and visuals that express the why) the neural net choices‚Ä¶\nAnd although I still have a lot to do, I hope when it‚Äôs ready, my RLCS package will participate in making that a reality :)"
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html",
    "href": "posts/2024-11-02_WordEmbeddings/index.html",
    "title": "ML Concepts: Word Embeddings",
    "section": "",
    "text": "I discussed an unsupervised clustering algorithm, DBScan. We used multi-dimensional points (coordinates) in space. But what if our data is text? That‚Äôs common in ‚Äúgeneral‚Äù, but also in Cybersecurity. So the question becomes: Can we treat ‚Äútext‚Äù as points on which to apply such (or similar) algorithms?\nEnters the concept of embedding."
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#continuing-on-text-for-cybersecurity-ml",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#continuing-on-text-for-cybersecurity-ml",
    "title": "ML Concepts: Word Embeddings",
    "section": "",
    "text": "I discussed an unsupervised clustering algorithm, DBScan. We used multi-dimensional points (coordinates) in space. But what if our data is text? That‚Äôs common in ‚Äúgeneral‚Äù, but also in Cybersecurity. So the question becomes: Can we treat ‚Äútext‚Äù as points on which to apply such (or similar) algorithms?\nEnters the concept of embedding."
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#conceptual-understanding",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#conceptual-understanding",
    "title": "ML Concepts: Word Embeddings",
    "section": "Conceptual understanding",
    "text": "Conceptual understanding\nOnce again, who am I to ‚Äúteach‚Äù you what an embedding is, hu? It‚Äôs probably better to go to the definition, which hopefully, thanks to the context provided in the last entry, can help intuit where we‚Äôre going with all this:\n‚ÄúIn¬†natural language processing, a¬†word embedding¬†is a representation of a word. The embedding is used in text analysis. Typically, the representation is a¬†real-valued¬†vector that encodes the meaning of the word in such a way that the words that are closer in the vector space are expected to be similar in meaning.‚Äù\nSo two things: Today is actually about Natural Language Processing, or NLP in short. Not a new topic in this Blog, but hey.\nSecond, we‚Äôre looking for a representation of a word as a ‚Äúreal-valued vector‚Äù. So think of it like so: A ‚Äúvector‚Äù can represent many things, but today we‚Äôre going to consider it a set of coordinates.\nSo in 3 dimensions (3D), a word embedding would represent a word as 3 numbers, representing each a coordinate of the (x, y, z) space. Sounds familiar? Check again the entry on Clustering if not, please, it makes more sense to consider both entries together‚Ä¶\nYou‚Äôre back?\nOK. For very large text, maybe the information of a word with only 3 dimensions is not enough to ‚Äúencode‚Äù its relationship to other words. So you would go into higher dimensions, say 15, 30 or 1000 dimensions (again, why not? You and I can‚Äôt visualize 30 dimensions in our heads, but it‚Äôs easy for a computer‚Ä¶ Fun, ain‚Äôt it?)\nAnd so with a set of vectors, each representing a word, we get in fact a set of points in an N-dimensional space. And then‚Ä¶\nWhy not use algorithms on these ‚Äúembeddings‚Äù, say the DBScan algorithm?"
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#in-practice-embedding-from-texts",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#in-practice-embedding-from-texts",
    "title": "ML Concepts: Word Embeddings",
    "section": "In practice: Embedding from text(s)",
    "text": "In practice: Embedding from text(s)\nWe‚Äôre not going to discuss the current algorithms for embeddings in detail. They use‚Ä¶ Neural Networks, of all things. The general accepted version of Word2Vec for instance in essence takes pairs of words (out of ‚Äútraining text‚Äù) and transforms the ‚Äúwords‚Äù into vectors of 300 dimensions (if I remember correctly). Better even, you can get the embeddings, so you need not train anything yourself (thanks Google AI!).\nBut for today, we might just want to go ahead and actually train our own embeddings. Let‚Äôs go for it!\nBy the way: Here the code for today.\nNow one important concept for Machine Learning: ‚ÄúGarbage IN? Garbage OUT!‚Äù So IF I use cra*py (pardon my french) text as input, I shouldn‚Äôt expect much of a result as an output.¬†\nLet‚Äôs say I consider the Wikipedia to hold ‚Äúgood‚Äù text about some IT and Cybersecurity concepts. If so, I could use for instance the R Package wikipediR. (At least that‚Äôs the one I used for today)\nlibrary(WikipediR) # Get Wiki data\n## Simple wrapper\nmy_page_content &lt;- function(keywords) {\n  page_content(language = \"en\",\n    project = \"wikipedia\",\n    page_name = keywords,\n    as_wikitext = FALSE,\n    clean_response = TRUE) |&gt;\n  clean_text_set()\n}\n## Explicitly for explanation:\nfirewall_wiki &lt;- my_page_content(\"firewall (computing)\")\nfirewall_wiki &lt;- firewall_wiki[1:82]\nswitch_wiki &lt;- my_page_content(\"network switch\")\nswitch_wiki &lt;- switch_wiki[2:96]\nAnd it goes on, with a few other keywords of interest (say ‚Äúrouter‚Äù, ‚Äúhacker‚Äù‚Ä¶). You have the details of this example in the code.\nWhy I filter and keep only 82 paragraphs of the Firewall entry? Just a matter of cleaner stuff, the way I parse the Wiki entries (which is detailed in ‚Äúclean_text_set()‚Äù function), some lines contain a bit of only pairs of words, others a few references with proper Names, etc.¬† Consider this a manual process in this case because I‚Äôm lazy. In the real world, I would look for the key words that mark the section of the Wiki Entry that do not interest me, and keep the ones above that only. And clean those. Like it or not, in this case, I needed to extract meaningful sentences of some HTML pages. It requires a bit of work (my ‚Äúcleant_text_set()‚Äù function, created for today‚Äôs exercise specifically, hopefully can show how one has to work, it‚Äôs not always as simple as running a function call‚Ä¶). All in all, after pre-processing, I‚Äôll end up with 692 sentences. In traditional ML, a good part of the work is about getting the right data in the right format. And that‚Äôs all I say about that today. Moving on.\nThe next step will be to use our data. Here I‚Äôm not going to implement anything myself, it‚Äôs beyond my point. Suffice to say I‚Äôm going to use the ‚ÄúContinuous Bag of Words‚Äù, that looks at words AROUND one word to assign positions in space. In concept and simplifying a lot, we‚Äôre seeing if ‚Äúblock‚Äù and ‚Äúfirewall‚Äù appear in the training text near one another more often than ‚Äúrestaurant‚Äù and ‚Äúfirewall‚Äù. (I‚Äôd guess that‚Äôs about right :D)\nNow we can use R to train our own Word2Vec Neural Network, with Bag Of Words, on our sample text (692 small blocks of text) and ask it to come up with vectors of 30 dimensions as embeddings for the main keywords found in the text.\n## Lets' move on to something more... Substantial:\nfull_text &lt;- c(\n  switch_wiki,\n  router_wiki,\n  firewall_wiki,\n  hacker_wiki,\n  computer_wiki,\n  cpu_wiki,\n  virus_wiki\n)\n\nmodel &lt;- word2vec(full_text, type=\"cbow\", dim=30, iter = 50)\nembeddings &lt;- as.matrix(model)\nembeddings\nAnd yes, it requires a few things (the ‚Äúword2vec‚Äù R package, for one), a bit of understanding (or trial and error, but understanding is better!). But if all goes as planned you‚Äôll get something like this:\n\n\n\nSo 970 words have been transformed into their corresponding 30-dimensional vectors! Good!\n30 dimensions is going to be hard to ‚Äúlook at‚Äù, but let‚Äôs do it anyway. What we really want is to understand the similarity of things here. So for instance, FROM OUR SELECTED WIKI text (very small sample, if you ask me, and yet‚Ä¶):\n\nNow I wouldn‚Äôt necessarily agree that ‚Äúpix‚Äù is the best nearest word for ‚Äúfirewall‚Äù but‚Ä¶ That‚Äôs what our sample text says, it would seem. Anyhow, it doesn‚Äôt sound completely crazy either. (e.g.¬†‚ÄúRestaurant‚Äù, had it been in the sample text, hopefully wouldn‚Äôt appear in the top 5 ‚Äúnearest‚Äù terms for Firewall‚Ä¶)\n30 dimensions is going to be hard to ‚Äúlook at‚Äù, but let‚Äôs do it anyway. What we really want is to understand the similarity of things here. So for instance, FROM OUR SELECTED WIKI text (very small sample, if you ask me, and yet‚Ä¶):\nNow I wouldn‚Äôt necessarily agree that ‚Äúpix‚Äù is the best nearest word for ‚Äúfirewall‚Äù but‚Ä¶ That‚Äôs what our sample text says, it would seem. Anyhow, it doesn‚Äôt sound completely crazy either. (e.g.¬†‚ÄúRestaurant‚Äù, had it been in the sample text, hopefully wouldn‚Äôt appear in the top 5 ‚Äúnearest‚Äù terms for Firewall‚Ä¶)"
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#going-2d-and-hint-for-the-future",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#going-2d-and-hint-for-the-future",
    "title": "ML Concepts: Word Embeddings",
    "section": "Going 2D and hint for the future",
    "text": "Going 2D and hint for the future\nI‚Äôm going to finish this with one visualization, and then hopefully everything will come together. Now I‚Äôll say this first: I know you can bring 30 dimensions into 2, yes. I was going to try ‚Äúmulti-dimensional scaling‚Äù (as PCA is probably too lossy for such a reduction), or look into some algorithm for that. But then I came across examples here, and heck, dimensionality reduction was beyond the point for today, and so I skipped doing it myself. (To this day, I haven‚Äôt looked at how the umap() function works. I know, shame on me.)\nBut here is the key of all the conversation for today:\n\n\n\nProjecting Embeddings onto 2D plot\n\n\nWe‚Äôve done it! We have visualized our words, not without first creating embeddings for them, and then projecting into 2 Dimensions.\nAnd let‚Äôs have a look at what is where‚Ä¶\nNot bad, ‚Äúfirewalls‚Äù is near ‚Äúfirewall‚Äù (pfiu!). So are filter, traffic‚Ä¶ And maybe the rest is not great, but that‚Äôs what we came up with from (again) very little sample text."
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#mixing-things-up",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#mixing-things-up",
    "title": "ML Concepts: Word Embeddings",
    "section": "Mixing things up!",
    "text": "Mixing things up!\nLast week, I published a (simplistic) entry about DBScan as an algorithm to cluster things. WHY NOT apply that here?!\n\nCould we have a look at one cluster, maybe one that contains the word ‚ÄúVirus‚Äù?\n\nThings like ‚Äúinfection‚Äù, ‚Äúexecutable‚Äù, ‚Äúscanner‚Äù, ‚Äúmalicious‚Äù are all in the area‚Ä¶ And with the same color!\nWith more text and better cleanup‚Ä¶ I‚Äôm convinced the approach has its merits üôÇ\nAs per 3D visuals, this time using Multi-dimensional Scaling (another algorithm that uses distances!) to project onto 3 dimensions, well it works, but there is a bit too much data, and maybe it‚Äôs not super super useful‚Ä¶ Still:"
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#applications",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#applications",
    "title": "ML Concepts: Word Embeddings",
    "section": "Applications",
    "text": "Applications\nWhat if instead of Wiki entries from the internet, we had taken CVE text (maybe along with their CVSS (or whatever scoring system you prefer))? We could probably do some sort of regression once we encode the text (maybe even mixing things up with other algorithms) and maybe estimate the score?\nHow about classifying threat alerts into groups?\nWhat if we had taken logs from a machine. Could we maybe use all this and find specially anomalous logs, from the complete log file? (Imagine thousands of lines reviewed in seconds by your laptop like so‚Ä¶)\nAnd consider this: Over this and the last Blog entry, we‚Äôve discussed enough to do some basic ML. But there is much more than Clustering applied to text. I just hope this helps give a hint of the possibilities. üôÇ"
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#conclusion",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#conclusion",
    "title": "ML Concepts: Word Embeddings",
    "section": "Conclusion",
    "text": "Conclusion\nAt this stage, I truly hope we understand what it means for us to be able to put words (or texts, they could be each files‚Ä¶ why not!) into vectors (i.e.¬†points in N-dimensional space), to be projected (or not) and for which distances can be calculated to other words/texts.\nWith that, we open a world of possibilities: Topic Modelling, Sentiment Analysis, etc. can all be done using distances between points üôÇ (There is more to NLP, though, and NOT only LLMs, please. More simple/traditional stuff is out there! One example I wrote about forever ago was part of speech tagging, for instance. Another time I used TF-IDF to model a classifier of log files with supervised learning‚Ä¶) Maybe in a future post I‚Äôll discuss more of these concepts, but I‚Äôd be very happy for now if somehow I helped someone out there understand a bit better how these things could actually work.\nBy the by: GenAI essentially does self-supervised learning on word embeddings. (WOW! What a bomb to leave at the end of a blog entry, ‚Äúself-supervised‚Äù???)."
  },
  {
    "objectID": "posts/2024-11-02_WordEmbeddings/index.html#bonus-a-word-about-genai",
    "href": "posts/2024-11-02_WordEmbeddings/index.html#bonus-a-word-about-genai",
    "title": "ML Concepts: Word Embeddings",
    "section": "Bonus: A word about GenAI",
    "text": "Bonus: A word about GenAI\nOK, OK, OK‚Ä¶ But real quick then.\nFirst: I don‚Äôt particularly like GenAI as a topic because ‚Äì mostly ‚Äì of the hype, misunderstanding, risks‚Ä¶ but otherwise is undoubtedly incredibly powerful and I‚Äôll admit it must have some cool applications‚Ä¶ For expert users! And although very slowly, I myself am considering using it as an assistant R-coder‚Ä¶ I have done tests and it‚Äôs not bad at all, and it WOULD make me much faster‚Ä¶ But I‚Äôm mostly resisting for now: Coding and thinking how to approach a problem is what I like, so why externalize that‚Ä¶ Unless I really HAVE to‚Ä¶\nThat said‚Ä¶ What the heck is ‚Äúself-supervised‚Äù learning?¬†\nSupervised learning needs to have a means of knowing whether it‚Äôs doing a good job to rectify its own behaviour while in training.\nIf your job is to predict the best next word for a given text‚Ä¶ All you need is to try to predict it, and then read the next word (or ‚Äútoken‚Äù). If you guessed wrong, you rectify your behaviour for your next guess. Then you read the next word‚Ä¶ And iterate. And in the above scenario, nobody needs to ‚Äútag‚Äù anything, the information is self-contained! So you just ingest text one ‚Äútoken‚Äù at a time (don‚Äôt worry, say ‚Äúone word at a time‚Äù, and more or less you‚Äôre good). All you need is text (and ‚Äúattention‚Äù, but that‚Äôs WAY beyond today‚Äôs objectives :D).\nThe more text, the more training examples you get üôÇ\nAnd yes: Your words/tokens, are presented to your GenAI (well, LLMs, really) as‚Ä¶ Embbedings."
  },
  {
    "objectID": "posts/2022-11-12_HavelHakimi/index.html",
    "href": "posts/2022-11-12_HavelHakimi/index.html",
    "title": "Graph Theory: Havel-Hakimi algorithm (and a twist)",
    "section": "",
    "text": "As is now common, I use the courses of the master as inspiration. I have recently started studying (again, from scratch) graph theory. This time around, it goes deeper into the theory and math background though, compared to past courses I have taken on the subject.\nFor this instance, I came across some pseudo-code in the book and I thought: Why not implement it (in R, of course).\nAnd so I did. This will be a short post üôÇ"
  },
  {
    "objectID": "posts/2022-11-12_HavelHakimi/index.html#intro",
    "href": "posts/2022-11-12_HavelHakimi/index.html#intro",
    "title": "Graph Theory: Havel-Hakimi algorithm (and a twist)",
    "section": "",
    "text": "As is now common, I use the courses of the master as inspiration. I have recently started studying (again, from scratch) graph theory. This time around, it goes deeper into the theory and math background though, compared to past courses I have taken on the subject.\nFor this instance, I came across some pseudo-code in the book and I thought: Why not implement it (in R, of course).\nAnd so I did. This will be a short post üôÇ"
  },
  {
    "objectID": "posts/2022-11-12_HavelHakimi/index.html#a-summary",
    "href": "posts/2022-11-12_HavelHakimi/index.html#a-summary",
    "title": "Graph Theory: Havel-Hakimi algorithm (and a twist)",
    "section": "A summary",
    "text": "A summary\nSo I haven‚Äôt come across this situation in ‚Äúreal life‚Äù just yet, but supposing someone hands me a list of ‚Äúdegrees‚Äù (degree: number of ‚Äúconnections‚Äù of a vertex) of a set of vertices (or I come up with such a list on my own for some need), there is an algorithm that will tell whether you can use those to create a legit‚Äô graph.\nThere is some background behind the algorithm, for sure, and you can check all about it in Wikipedia.\nBut at the very least, it‚Äôs clearly recursive: (From Wikipedia) ‚ÄúLet ¬†be a finite list of nonnegative integers that is¬†nonincreasing. Let be a second finite list of nonnegative integers that is rearranged to be nonincreasing. List¬†¬†is graphic if and only if list¬†¬†is graphic.‚Äù\nAnd well, that‚Äôs it. The code is really the thing for today. In this case, I add a ‚Äúverbose‚Äù option to the function so that one can follow what the algorithm actually does with the degrees sequence."
  },
  {
    "objectID": "posts/2022-11-12_HavelHakimi/index.html#the-twist",
    "href": "posts/2022-11-12_HavelHakimi/index.html#the-twist",
    "title": "Graph Theory: Havel-Hakimi algorithm (and a twist)",
    "section": "The Twist",
    "text": "The Twist\nSo the issue with the above is, it will tell you WHETHER a graph CAN be created with that list of degrees. It won‚Äôt show you what it looks like. And after playing around with the concept for a couple of days, I found out it is (to me at least) quite hard to come up with a graph that follows a simple sequence of degrees ‚Äújust like that‚Äù.\nSo instead, I started thinking about programming something to feed the igraph library for it to plot a graph for me, out of a valid ‚Äúgraphic‚Äù sequence of degrees‚Ä¶ And I did give it some thought, until I realized‚Ä¶ Someone must have done it‚Ä¶ Duh! It was right there, in the igraph library, in fact. With different algorithms (option ‚Äúmethod‚Äù) to generate the graph (one sequence of degrees can allow for multiple valid graphs, with or without loops, multi-graphs‚Ä¶).\nHere it was, very simple (the ‚Äúvl‚Äù method was the best alternative for my objectives so I stick with it for now):\nlibrary(igraph)\ntest_degrees_seq &lt;- c(6,3,3,3,3,2,2,2,2,1,1) # Example from Wikipedia\nplot(sample_degseq(test_degrees_seq, method=\"vl\"))\n¬†\n\n¬†\n\nConclusions\nNot much today, as the code was the objective.\nBut it‚Äôs still fun to take pseudo-code, and have it help me solve the book‚Äôs exercises, while getting better acquainted with the algorithm üôÇ\nAnd being able to visualize the graphs helps me understand better what certain degree sequences can look like üôÇ\nReferences\nBook: ‚ÄúGraph Theory and its applications‚Äù, J.L. Gross, J. Yellen, M. Anderson ‚Äì Ed. CRC (3rd ed.)\nMy code for today on my Github\nhttps://igraph.org/r/doc/sample_degseq.html\nhttps://en.wikipedia.org/wiki/Havel%E2%80%93Hakimi_algorithm"
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html",
    "href": "posts/2025-06-21_RLCS_for_text/index.html",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "",
    "text": "Alright so this a bit of a crazy idea.\nAt work, these past few weeks, when I had the time, I had this side project, whereby I would try to create a model to classify texts in two categories, like ‚Äúimportant vs not-important‚Äù. Sounded easy enough upfront, in my mind even a basic Na√Øve-Bayes (i.e.¬†supervised learning) classifier would easily do the trick‚Ä¶\nHow wrong I was. After some testing, and several more or less complex algorithms all failing with similarly low accuracy (and that was enough for me, I needed not check other metrics)‚Ä¶ I dug further, and I finally found some texts that were repeated across both classes. That is, yes: same identical complete text but present in the two classes. You know what they say: ‚ÄúGarbage-in, Garbage-out‚Äù. Now, to be fair, there was a reason for it, through no fault of the original/historical manual tagging! The thing just wasn‚Äôt originally meant to be used as a training dataset for a future Supervised Learning classifier, and the tags used were in fact a mess - from the perspective of this exercise, although they made sense in their original context. Anyhow‚Ä¶\nSo we went back and started a fresh new (manual) classification system (well, my colleagues did) and right away the newly classified data allowed for a 10% accuracy increase across all models/algorithms tested with it as training/testing set. And that, with a much smaller new dataset. So we were onto something, for sure.\nAnd yet, none of the algorithms still provided very good results. Part of the issue is, some of the texts in both classes are very similar. Me, I‚Äôd have a hard time deciding for some of the entries which class should apply (I‚Äôve tried, and failed, so maybe I shouldn‚Äôt ask my machine to do something I can‚Äôt manually do myself on a small sample‚Ä¶).\nAs a note, part of that classification exercise is in fact a bit of an art, maybe, and somewhat tacit information is required, experience: Hard to explain, and hence hard to manually write down in rules, which is why the ML approach was suggested in the first place (otherwise, simple rules could have worked?).\nAn example: My company works in Healthcare, so mentions of hospitals and patients would be an easy give-away, compared to news about say fashion, or transportation‚Ä¶. But most of it isn‚Äôt as clear-cut‚Ä¶"
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html#i-have-been-busy-with-something-for-work-lately",
    "href": "posts/2025-06-21_RLCS_for_text/index.html#i-have-been-busy-with-something-for-work-lately",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "",
    "text": "Alright so this a bit of a crazy idea.\nAt work, these past few weeks, when I had the time, I had this side project, whereby I would try to create a model to classify texts in two categories, like ‚Äúimportant vs not-important‚Äù. Sounded easy enough upfront, in my mind even a basic Na√Øve-Bayes (i.e.¬†supervised learning) classifier would easily do the trick‚Ä¶\nHow wrong I was. After some testing, and several more or less complex algorithms all failing with similarly low accuracy (and that was enough for me, I needed not check other metrics)‚Ä¶ I dug further, and I finally found some texts that were repeated across both classes. That is, yes: same identical complete text but present in the two classes. You know what they say: ‚ÄúGarbage-in, Garbage-out‚Äù. Now, to be fair, there was a reason for it, through no fault of the original/historical manual tagging! The thing just wasn‚Äôt originally meant to be used as a training dataset for a future Supervised Learning classifier, and the tags used were in fact a mess - from the perspective of this exercise, although they made sense in their original context. Anyhow‚Ä¶\nSo we went back and started a fresh new (manual) classification system (well, my colleagues did) and right away the newly classified data allowed for a 10% accuracy increase across all models/algorithms tested with it as training/testing set. And that, with a much smaller new dataset. So we were onto something, for sure.\nAnd yet, none of the algorithms still provided very good results. Part of the issue is, some of the texts in both classes are very similar. Me, I‚Äôd have a hard time deciding for some of the entries which class should apply (I‚Äôve tried, and failed, so maybe I shouldn‚Äôt ask my machine to do something I can‚Äôt manually do myself on a small sample‚Ä¶).\nAs a note, part of that classification exercise is in fact a bit of an art, maybe, and somewhat tacit information is required, experience: Hard to explain, and hence hard to manually write down in rules, which is why the ML approach was suggested in the first place (otherwise, simple rules could have worked?).\nAn example: My company works in Healthcare, so mentions of hospitals and patients would be an easy give-away, compared to news about say fashion, or transportation‚Ä¶. But most of it isn‚Äôt as clear-cut‚Ä¶"
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html#rlcs-for-text-then",
    "href": "posts/2025-06-21_RLCS_for_text/index.html#rlcs-for-text-then",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "RLCS for text, then?",
    "text": "RLCS for text, then?\nAs we (you, my reader, and myself) have learnt over the past few months, the RLCS implementation has a few shortcomings, and today two of them are of particular interest:\n\nThe binary input string format issue is going to be a bother\nThe very high importance, for performance, of the length of said binary input strings, is another one.\n\nWhy so?\nWell, free text is not great to transform to binary strings. I am however willing to do a simplified test: Generate a TF-IDF (done) of the input texts, keep the main keywords, say top‚Ä¶ 100 (rather easy), and instead of real numbers, just encode in binary (i.e.¬†a keyword (stemmed and all, cleaned up) appears or doesn‚Äôt, for a particular entry of text). That seems simple enough: just ‚Äúgrep‚Äù over new text and look for a particular keyword, and that encodes one variable, and repeat with all 100 top keywords. Here you go: Binary string of length 100.\nBut 100 variables from a TD-IDF is a brutal simplification, when the original matrix might well have 3 or 4 thousand distinct stemmed-keywords‚Ä¶ That‚Äôs a big information loss right there. (And I don‚Äôt mean to go the way of PCA and such, I could, but explainability of the results would be quite impacted, and so no, not today).\nAlso, going from real number to binary true/false is another brutal information loss. More on this one in a moment.\n‚Äú100‚Äù here is just an idea, but come to think of it, I don‚Äôt think I can do much more than, say, 300? That is, without crawling to a halt in terms of processing time. I haven‚Äôt tried yet, and with the improvements in speed of a few weeks back, who knows‚Ä¶ :D"
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html#testing-the-idea",
    "href": "posts/2025-06-21_RLCS_for_text/index.html#testing-the-idea",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "Testing the idea",
    "text": "Testing the idea\nSo I am willing to work on this approach starting this very weekend. (Maybe that will spill over the beginning of next week, but since this is actually ‚Äúfor work‚Äù, well, I don‚Äôt see an issue with merging my personal- and work-time for a few days here‚Ä¶)\nWhat I am hoping is, I can get some machine-provided rules to help with the automated classification of future texts. The texts at work are about Cybersecurity news (but that detail is not in fact important for this post). I just want to create something that will help the analysts in choosing what to worry about and what they can safely discard as noise/irrelevant pieces of news.\nOne important aspect here will be the False-Positive vs False-Negative ratio, among other things. I am also worried about data-drift, as one keyword in the overall exercise is ‚Äúnews‚Äù, which, you know, change over time.\nBut heck, this is all future issues, the first thing is to get a good enough classifier, that we shall later refine.\nAnd if I make the RLCS package (code) part of the final solution, if I actually show it can be useful for such a practical, real-world scenario, well‚Ä¶ But that‚Äôs a big ‚Äúif‚Äù."
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html#my-own-rosetta-stone",
    "href": "posts/2025-06-21_RLCS_for_text/index.html#my-own-rosetta-stone",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "My own Rosetta Stone",
    "text": "My own Rosetta Stone\nActually, this is one excuse for this entry:\n\n\n\na rosetta stone to use with RLCS\n\n\nI have been meaning to do something about the limitation with the binary input strings issue. But instead of changing the code of the RLCS (for now), what if instead I facilitated the future data scientists‚Äô efforts by offering a sort of translation engine?\nI could in fact create a function that:\n\ntakes a data frame as input (say), or even a matrix.\nencodes factors or texts into variables with binary strings. Length of said variables would depend on the number of distinct values (i.e.¬†levels of factors). Now that won‚Äôt work for pure free text, but it just might for short tags received as text columns in the DF.\nand using the function I demonstrated for the Iris dataset a few weeks back, I can ‚Äúeasily‚Äù encode real numbers into ‚Äúbins‚Äù that I can then encode with binary strings. See this entry about how that could work.\nKeep track of the above transformations and offer a ‚Äútranslator‚Äù to translate back the resulting rules learnt by the RLCS into the original format, or a readable version of it anyway.\n\nI call this the Rosetta Stone for (what I believe are) obvious reasons.\nAnd I shall create such a Rosetta Stone function (or maybe an object?) as part of the RLCS package, for sure. That should help with adoption, or so I would hope.\nBut maybe for now I focus on the simpler application. Direct binary encoding of top TF-IDF keywords, a simple binary present-or-not encoding. Simplistic, maybe too much so, but until I try‚Ä¶ I won‚Äôt know, now will I?"
  },
  {
    "objectID": "posts/2025-06-21_RLCS_for_text/index.html#conclusions",
    "href": "posts/2025-06-21_RLCS_for_text/index.html#conclusions",
    "title": "RLCS for text? And a new idea‚Ä¶",
    "section": "Conclusions",
    "text": "Conclusions\nNa√Øve-Bayes, SVM, Random-Forest, Lasso, heck even DNN, you name it: If the data is not good, and two classes are in fact not ‚Äúsomewhat clearly‚Äù separable (or no generalized rule will stand), then no amount of processing will create great models. I have tried (thanks to suggestion by other colleagues) more modern approaches, such as full-text embeddings (maybe my approach was simplistic: I used word2vec, with say 200 dimensions, and then averaged full entries vectors‚Ä¶ obtaining simple encodings of texts in 200-dimensional vectors, each text one point‚Ä¶ It actually kind‚Äôa worked, but still wasn‚Äôt great, and aside from clustering approaches, well, results would be harder to explain‚Ä¶ Anyhow, I digress: This wasn‚Äôt a solution. Yet :D)\nThat said, maybe a subset of good, understandable rules, while not always useful, can make a dent into the problem. And that‚Äôs what I‚Äôm hoping the application of RLCS to this text classification problem might offer: Find us some rules that will classify perfectly some of the new texts, so that an analyst can skip reading through them, and maybe move on to other news.\nThen, where the rule-set won‚Äôt actually work, the RLCS output will hopefully tell you it‚Äôs not confident (mixed subset of recommended classes) in the proposed classification, and so as an analyst you can go back to other approaches (or say manually review, tag, and save for future improvements), but at least you will have received help for the clear-cut cases, in reviewing some of the news pieces.\nSo I am hoping I can at the very least reduce the size of the problem, in the short term. And I do believe, this is something the RLCS can help with :)"
  },
  {
    "objectID": "posts/2022-03-20_OnReduce/index.html",
    "href": "posts/2022-03-20_OnReduce/index.html",
    "title": "Iterative function calls with Reduce",
    "section": "",
    "text": "In many instances, the ‚ÄúNumerical Methods‚Äù will imply recurrent function calls. We demonstrated how to go about this using loops here. But I wasn‚Äôt satisfied with this¬† approach (I did mention, I prefer the apply() family of functions over for loops‚Ä¶).\nThe apply() wasn‚Äôt fit for it, but while digging a bit deeper into how to go about recurrent functions in R, well‚Ä¶ Here comes a lesser-known approach (and I‚Äôm not saying it‚Äôs better‚Ä¶ Although it does seem to be faster :))."
  },
  {
    "objectID": "posts/2022-03-20_OnReduce/index.html#intro",
    "href": "posts/2022-03-20_OnReduce/index.html#intro",
    "title": "Iterative function calls with Reduce",
    "section": "",
    "text": "In many instances, the ‚ÄúNumerical Methods‚Äù will imply recurrent function calls. We demonstrated how to go about this using loops here. But I wasn‚Äôt satisfied with this¬† approach (I did mention, I prefer the apply() family of functions over for loops‚Ä¶).\nThe apply() wasn‚Äôt fit for it, but while digging a bit deeper into how to go about recurrent functions in R, well‚Ä¶ Here comes a lesser-known approach (and I‚Äôm not saying it‚Äôs better‚Ä¶ Although it does seem to be faster :))."
  },
  {
    "objectID": "posts/2022-03-20_OnReduce/index.html#reduce",
    "href": "posts/2022-03-20_OnReduce/index.html#reduce",
    "title": "Iterative function calls with Reduce",
    "section": "Reduce()",
    "text": "Reduce()\nIt turns out (of course!) that the base R package has that covered for us. Probably in certain cases of pure recurrence, that won‚Äôt be the way (I still have to understand better this Reduce() function, really). But for our purposes, it turns out, it works as intended.\nSo here, we tricked it a bit, and the comparison of efficiency might be imperfect‚Ä¶ But it should overall be valid.\nWe basically compare two approaches:\nmy_logistic_map2 &lt;- function(my_r, x) {\n  my_r * x * (1-x)\n}\n(...)\nfor(my_r in 1:length(my_growth_rates)) { # I'm not a fan of for loops, but here...\n  for(my_gen in 2:n_gens) {\n    res_mat[my_r, my_gen] &lt;- my_logistic_map2(my_growth_rates[my_r], res_mat[my_r, my_gen-1])\n  }\n}\nYou‚Äôll notice the double loop there‚Ä¶ Now let‚Äôs see a functionally equivalent code with the base Reduce() function:\nfor(my_r in 1:(length(my_growth_rates)-1)) { # I'm not a fan of for loops, but here...\n  res_mat[my_r, ] &lt;- Reduce(function(x, y) my_growth_rates[my_r] * x * (1-x), \n    x = 1:(n_gens-1), \n    init = 0.5, \n    accumulate = TRUE)\n}\nNow one for loop, and one Reduce() call.\nA quick comparison of both does show a rather clear improvement, although I am not content with the potential issues of this comparison:\n expr      min       lq     mean   median       uq      max neval\n v1() 4.913179 4.921944 4.941147 4.936691 4.937704 4.996217     5\n v2() 2.129384 2.141234 2.161598 2.147729 2.188960 2.200683     5\nBut still, it seems to work and we seem to have a rather clear improvement."
  },
  {
    "objectID": "posts/2022-03-20_OnReduce/index.html#notes",
    "href": "posts/2022-03-20_OnReduce/index.html#notes",
    "title": "Iterative function calls with Reduce",
    "section": "Notes",
    "text": "Notes\nThis time around, the ‚Äúbest‚Äù reference I found was nowhere near the actual documentation. It‚Äôs also a bit counter-intuitive to set an initial vector of values that will in fact‚Ä¶ Not really be used.\nAnd why the y in there?\nWell, the ‚Äúy‚Äù in the ‚Äúfunction(x, y)‚Äù call definition (inside the Reduce() call), actually refers to ‚Äúthe next value of the input vector‚Äù, but as our recurrence equation does NOT depend on the next entry at all (i.e.¬†in our case, we define our calculation only as a function of the former value), in our case the x in the ‚Äúfunction(x, y)‚Äù call, it only ensures in our case that the iteration repeats for a certain number of times, the length of our initial x = ‚Äú1:(n_gens-1)‚Äù vector.\nBut in fact, after the initial value (‚Äúinit = 0.5‚Äù), we do not use the vector values for any calculation per-se.\nSo in our case, we will in fact be Reducing something like this, (‚Äì&gt; is not actual code here, just indicating what‚Äôs happening):\nfunction(x0, 1) my_growth_rates[my_r] * x0 * (1-x0) --&gt; x1\nThen, more or less, this is what we‚Äôre doing with the Reduce() call (note how we do NOT use the second parameter at all‚Ä¶ but to limit iterations):\nfunction(x0, y=1) my_growth_rates[my_r] * x0 * (1-x0) --&gt; x1\nfunction(x1, y=2) my_growth_rates[my_r] * x1 * (1-x1) --&gt; x2\nfunction(x2, y=3) my_growth_rates[my_r] * x2 * (1-x2) --&gt; x3\n(...)\nfunction(xn-1, y=(n_gens-1)) my_growth_rates[my_r] * xn-1 * (1-xn-1) --&gt; xn\nSo it might be LESS intuitive, as a code to be read by someone else, than using the for loops, indeed.\nBut it is, however, faster.\nThe best reference for the actual code use what here on StackOverflow in this case."
  },
  {
    "objectID": "posts/2022-03-20_OnReduce/index.html#references",
    "href": "posts/2022-03-20_OnReduce/index.html#references",
    "title": "Iterative function calls with Reduce",
    "section": "References",
    "text": "References\nHere my code to compare both approaches\nThe reference I¬† used to create the new code\nHadley‚Äôs Advanced R reference on Functionals"
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "This is quite literally my first Reinforcement Learning exercise ever. Coded from scratch. With no Neural Network whatsoever, but instead, using my own implementation of the Learning Classifier System(s) I have been discussing lately.\nAnd the point is this: It works!\nHere I present the first actual working results.\n\n\n\nSo we have an agent (blue dot) that can move in any of {up, down, right, left} direction.\nWe have a simulated world, with walls (black dots), some rewarding food (green dots) and some hurting enemies/poison (red dots).\nIndeed the aestetics of this demo are not marvelous, but I‚Äôve never cared much about look&feel, I care about what happens under the hood here.\n\n\n\nmonitoring the learning process\n\n\nSo our agent moves, and gets a reward as informed by our world. For instance:\n\nNo reward if moving to an empty cell\nSmall negative reward if moving backwards (to the cell it was in at immediately anterior step)\nsomewhat larger negative reward if ‚Äúbumping‚Äù into a wall\nlarge positive reward if finding food (obviously)\nand large negative reward if moving onto an enemy/poison cell (duh!)\n\nThe trick is: We do NOT tell the agent what to do! It must learn how to behave on its own, just by maximizing its reward.\nAnd here, the agent will use my implementation of a Learning Classifier System. No neural network or deep learning or anything fancy like that :D\nOh, and every line of code is in R.\n\n\n\nSo there is a bit more to it. I will not explain today in detail my whole implementation of an LCS algorithm to do RL. But some of the logic available to the agent is important to understand current results:\n\nI chose to implement a ‚Äúsmall memory‚Äù for my agent, so that a reward will inform the current step and be ‚Äúpassed onto‚Äù the last action, divided by 2.\nThe reason to do that is the following: the agent only sees one cell in all 8 directions (inlcuding diagonals), and it can move in 4 main directions. The idea of the small memory was to allow the machine to learn rules to choose to ‚Äúmove diagonally‚Äù. I haven‚Äôt validated exactly if this is the result. But it seems the agent does work better with that little bit of ‚Äúmemory‚Äù.\n\nI‚Äôll discuss the complete algorithm later on, but today let‚Äôs look at the result in a short video!\n\n\n\nHere is a small video I made of the current results‚Ä¶\n\n\n\n\nI am unclear at this point about whether I just implemented a version ‚Äì or a mix ‚Äì of TD, Q-Learning, XCS, CS01‚Ä¶ That‚Äôs the theory part, and I‚Äôll need to dig deeper into that now, to frame better what I just created.\n(Also, the code is very‚Ä¶ messy, right now :D I just wanted to see if I could get it to work‚Ä¶)\nBut from an experimental perspective, this was very satisfying already."
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#reinforcement-learning-with-lcs",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#reinforcement-learning-with-lcs",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "This is quite literally my first Reinforcement Learning exercise ever. Coded from scratch. With no Neural Network whatsoever, but instead, using my own implementation of the Learning Classifier System(s) I have been discussing lately.\nAnd the point is this: It works!\nHere I present the first actual working results."
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#limited-agent-simple-rules",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#limited-agent-simple-rules",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "So we have an agent (blue dot) that can move in any of {up, down, right, left} direction.\nWe have a simulated world, with walls (black dots), some rewarding food (green dots) and some hurting enemies/poison (red dots).\nIndeed the aestetics of this demo are not marvelous, but I‚Äôve never cared much about look&feel, I care about what happens under the hood here.\n\n\n\nmonitoring the learning process\n\n\nSo our agent moves, and gets a reward as informed by our world. For instance:\n\nNo reward if moving to an empty cell\nSmall negative reward if moving backwards (to the cell it was in at immediately anterior step)\nsomewhat larger negative reward if ‚Äúbumping‚Äù into a wall\nlarge positive reward if finding food (obviously)\nand large negative reward if moving onto an enemy/poison cell (duh!)\n\nThe trick is: We do NOT tell the agent what to do! It must learn how to behave on its own, just by maximizing its reward.\nAnd here, the agent will use my implementation of a Learning Classifier System. No neural network or deep learning or anything fancy like that :D\nOh, and every line of code is in R."
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#a-few-more-details",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#a-few-more-details",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "So there is a bit more to it. I will not explain today in detail my whole implementation of an LCS algorithm to do RL. But some of the logic available to the agent is important to understand current results:\n\nI chose to implement a ‚Äúsmall memory‚Äù for my agent, so that a reward will inform the current step and be ‚Äúpassed onto‚Äù the last action, divided by 2.\nThe reason to do that is the following: the agent only sees one cell in all 8 directions (inlcuding diagonals), and it can move in 4 main directions. The idea of the small memory was to allow the machine to learn rules to choose to ‚Äúmove diagonally‚Äù. I haven‚Äôt validated exactly if this is the result. But it seems the agent does work better with that little bit of ‚Äúmemory‚Äù.\n\nI‚Äôll discuss the complete algorithm later on, but today let‚Äôs look at the result in a short video!"
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#the-result",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#the-result",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "Here is a small video I made of the current results‚Ä¶"
  },
  {
    "objectID": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#conclusions",
    "href": "posts/2025-02-16_RLCS_World_Explorer_v001/index.html#conclusions",
    "title": "RLCS: Reinforcement Learning: World Explorer v1",
    "section": "",
    "text": "I am unclear at this point about whether I just implemented a version ‚Äì or a mix ‚Äì of TD, Q-Learning, XCS, CS01‚Ä¶ That‚Äôs the theory part, and I‚Äôll need to dig deeper into that now, to frame better what I just created.\n(Also, the code is very‚Ä¶ messy, right now :D I just wanted to see if I could get it to work‚Ä¶)\nBut from an experimental perspective, this was very satisfying already."
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "Recently, I had ‚Äúbroken‚Äù my Reinforcement Learning implementation, in the sense that it would learn at first, and then it would get worse with more experience, instead of better.\nWith so many hyper-parameters to consider, I knew I had touched too many levers while trying to improve‚Ä¶\nOne key thing was my exploration prevalence. But I didn‚Äôt know that. I start training with high exploration (1 step in each 2). That‚Äôs meant to expose to the maximum possible situations at first. In the smaller worlds, that should cover more environment states, and so reward of different actions would be learnt early on. That was the idea behind my choice, anyway. It kind of made sense‚Ä¶\nBut then I knew of course that too much exploration would mean‚Ä¶ Worse rewards.\nThat was correct, but a few more things were happening‚Ä¶ The short list here:\n\nmy reward update function per classifier of the LCS was not great\nand my choosing of best classifiers (influencing the algorithm step of going from match-set to action-set) was in fact all wrong too ü§¶‚Äç‚ôÇÔ∏è\n\nTheory to the rescue!\n\n\n\nI bought the ‚Äúbible of RL‚Äù (see Resources below) and recently received it at home. And it‚Äôs already making a difference! (Actually, having a physical copy was a great choice for me.)\nI have now corrected the above issues, but inspired by only the first two chapters (the second one really, as I had glanced at the first one earlier‚Ä¶) I was able to implement 2 different reward-update functions that (along with exploration pressure increase) made all the difference.\nPlus I now have initialized my rewards with a high positive value to foment more exploration at the earlier stages.\n\n\n\nTo emit a judgement on the quality of my implementation, along with the right mix of hyper-parameters (then again, I‚Äôm not saying they‚Äôre optimal, I‚Äôm saying they‚Äôre OK)‚Ä¶\nI had to sit down and choose what would demonstrate ‚Äúlearning‚Äù in my small scenario.\nSo I kept things very simple:\n\n1 agent\n4 actions corresponding to the 4 directions (horizontal and vertical only)\nAt all steps, the agent can see empty cells, wall cells, food cells, enemy cells and where it came from (allocentric perception forced me to do that), 1 cell in any direction (including diagonals).\n\nIn a simple scenario, 5x5 world, there are at any point: 16 wall cells, 5 empty cells, 1 food, 1 enemy, 1 walk-back.\n\n\n\na simple world to study learning quality\n\n\nGiven that, I think this demonstrates how good the agent is after some training:\n\n\n\nlearning with sample average reward update\n\n\nThe above is using a ‚Äúsample average‚Äù reward update function, whereby the reward contribution gets smaller and smaller with time.\nThis learns the best exploitation policy in certain scenarios where there is a unique perfect policy. However, in our case, given the limited agent perception, one could consider that it would be best to keep learning over time.\nThat is because the ‚Äúfood‚Äù and the ‚Äúenemy‚Äù positions change once the agent collides with them. Although in the longer run that is probably incorrect, there are many possible perceived states even in this very small scenario (and in spite of the LCS and its GA pressuring to learn of each scenario only the relevant part of the states‚Ä¶), we could think that with limited learning steps, an option that ensures the agent keeps learning in a non-stationary environment will be better off.\nWell, so I implemented the equations with fixed alpha (set to 0.1).\nNote that in all the above, I keep starting training with one exploratory step in each 2, then reduce exploration every 2000 time-steps, until I get to 1 in 6. That forces exploration too, with more pressure at the beginning.\nWith the new rules this might be in fact unnecessary, I am aware, but I still haven‚Äôt tested with fixed exploration pressure (say always 1 in 6 in my example). It should work!\nAnyhow, the results with fixed alpha are almost identical in my simple scenario:\n\n\n\nlearning with fixed alpha\n\n\n\n\n\nWell, we‚Äôve seen there are:\n\nMore wall cells (16) than empty cells (5)\nmore empty cells (5) than enemy, food and ‚Äúwalk-back‚Äù cell (of which there is one)\n\nAnd yet, after some training, the agent averages, over 1000 most recent steps taken:\n\n275 food eaten (most rewarding)\n3 enemy encounters (most penalized)\nless than 100 wall bumps (heavily penalized)\nabout 150 walk-backs (slightly penalized)\nand well, quite a bit of walking around in empty cells\n\nI haven‚Äôt done the math, but in some of the perceived states:\n\nCorner: 5 walls/8 total cells. There are 4 corners. 62.5%\nSide: 3 walls/8. 37.5%\nThe above account for 8 of 9 possible agent positions (exceptuating center cell)\n\nAnd yet, only 10% of the time the agent bumps into a wall on average (and that‚Äôs with a 17% chance of exploratory move!).\nAs the agent has very limited state perception, I believe this is proof right there that it has indeed learnt something.\nI‚Äôd have to run many more numbers (4 moves possible, 9 locations, 5 different possible cells-status per cell, in different combinations‚Ä¶ I‚Äôm not doing that until someone asks me to do a PhD on the topic üòÅ)\nSimilar numbers could demonstrate that there are lots of food-related actions compared to white cell prevalence‚Ä¶\nAnd indeed, supposing the identical probability of encountering food or enemy at any stage, the fact that our agent has chosen the right action when faced with both possibilities, choosing food 275 times for only 3 times the enemy (again, exploration step 1 in 6 in all described statistics above), well‚Ä¶\nI‚Äôm sold.\n\n\n\nI‚Äôm very happy about it all. The Reinforcement Learning example I chose is working nicely! And it makes sense, based on the little theory I have studied thus far.\n(Note: I shall actually post a short entry on real-world application of data mining with my LCS implementation. Any day now, it has happened already‚Ä¶).\n\n\n\n‚ÄúReinforcement Learning, An introduction.‚Äù, 2nd Ed. Bradford Books, by R. S. Sutton & A. G. Bardo."
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#using-theory-is-proving-useful-indeed",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#using-theory-is-proving-useful-indeed",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "Recently, I had ‚Äúbroken‚Äù my Reinforcement Learning implementation, in the sense that it would learn at first, and then it would get worse with more experience, instead of better.\nWith so many hyper-parameters to consider, I knew I had touched too many levers while trying to improve‚Ä¶\nOne key thing was my exploration prevalence. But I didn‚Äôt know that. I start training with high exploration (1 step in each 2). That‚Äôs meant to expose to the maximum possible situations at first. In the smaller worlds, that should cover more environment states, and so reward of different actions would be learnt early on. That was the idea behind my choice, anyway. It kind of made sense‚Ä¶\nBut then I knew of course that too much exploration would mean‚Ä¶ Worse rewards.\nThat was correct, but a few more things were happening‚Ä¶ The short list here:\n\nmy reward update function per classifier of the LCS was not great\nand my choosing of best classifiers (influencing the algorithm step of going from match-set to action-set) was in fact all wrong too ü§¶‚Äç‚ôÇÔ∏è\n\nTheory to the rescue!"
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#i-only-have-gone-through-chapter-1-2-and-already",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#i-only-have-gone-through-chapter-1-2-and-already",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "I bought the ‚Äúbible of RL‚Äù (see Resources below) and recently received it at home. And it‚Äôs already making a difference! (Actually, having a physical copy was a great choice for me.)\nI have now corrected the above issues, but inspired by only the first two chapters (the second one really, as I had glanced at the first one earlier‚Ä¶) I was able to implement 2 different reward-update functions that (along with exploration pressure increase) made all the difference.\nPlus I now have initialized my rewards with a high positive value to foment more exploration at the earlier stages."
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#results",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#results",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "To emit a judgement on the quality of my implementation, along with the right mix of hyper-parameters (then again, I‚Äôm not saying they‚Äôre optimal, I‚Äôm saying they‚Äôre OK)‚Ä¶\nI had to sit down and choose what would demonstrate ‚Äúlearning‚Äù in my small scenario.\nSo I kept things very simple:\n\n1 agent\n4 actions corresponding to the 4 directions (horizontal and vertical only)\nAt all steps, the agent can see empty cells, wall cells, food cells, enemy cells and where it came from (allocentric perception forced me to do that), 1 cell in any direction (including diagonals).\n\nIn a simple scenario, 5x5 world, there are at any point: 16 wall cells, 5 empty cells, 1 food, 1 enemy, 1 walk-back.\n\n\n\na simple world to study learning quality\n\n\nGiven that, I think this demonstrates how good the agent is after some training:\n\n\n\nlearning with sample average reward update\n\n\nThe above is using a ‚Äúsample average‚Äù reward update function, whereby the reward contribution gets smaller and smaller with time.\nThis learns the best exploitation policy in certain scenarios where there is a unique perfect policy. However, in our case, given the limited agent perception, one could consider that it would be best to keep learning over time.\nThat is because the ‚Äúfood‚Äù and the ‚Äúenemy‚Äù positions change once the agent collides with them. Although in the longer run that is probably incorrect, there are many possible perceived states even in this very small scenario (and in spite of the LCS and its GA pressuring to learn of each scenario only the relevant part of the states‚Ä¶), we could think that with limited learning steps, an option that ensures the agent keeps learning in a non-stationary environment will be better off.\nWell, so I implemented the equations with fixed alpha (set to 0.1).\nNote that in all the above, I keep starting training with one exploratory step in each 2, then reduce exploration every 2000 time-steps, until I get to 1 in 6. That forces exploration too, with more pressure at the beginning.\nWith the new rules this might be in fact unnecessary, I am aware, but I still haven‚Äôt tested with fixed exploration pressure (say always 1 in 6 in my example). It should work!\nAnyhow, the results with fixed alpha are almost identical in my simple scenario:\n\n\n\nlearning with fixed alpha"
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#what-do-the-above-screenshot-say",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#what-do-the-above-screenshot-say",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "Well, we‚Äôve seen there are:\n\nMore wall cells (16) than empty cells (5)\nmore empty cells (5) than enemy, food and ‚Äúwalk-back‚Äù cell (of which there is one)\n\nAnd yet, after some training, the agent averages, over 1000 most recent steps taken:\n\n275 food eaten (most rewarding)\n3 enemy encounters (most penalized)\nless than 100 wall bumps (heavily penalized)\nabout 150 walk-backs (slightly penalized)\nand well, quite a bit of walking around in empty cells\n\nI haven‚Äôt done the math, but in some of the perceived states:\n\nCorner: 5 walls/8 total cells. There are 4 corners. 62.5%\nSide: 3 walls/8. 37.5%\nThe above account for 8 of 9 possible agent positions (exceptuating center cell)\n\nAnd yet, only 10% of the time the agent bumps into a wall on average (and that‚Äôs with a 17% chance of exploratory move!).\nAs the agent has very limited state perception, I believe this is proof right there that it has indeed learnt something.\nI‚Äôd have to run many more numbers (4 moves possible, 9 locations, 5 different possible cells-status per cell, in different combinations‚Ä¶ I‚Äôm not doing that until someone asks me to do a PhD on the topic üòÅ)\nSimilar numbers could demonstrate that there are lots of food-related actions compared to white cell prevalence‚Ä¶\nAnd indeed, supposing the identical probability of encountering food or enemy at any stage, the fact that our agent has chosen the right action when faced with both possibilities, choosing food 275 times for only 3 times the enemy (again, exploration step 1 in 6 in all described statistics above), well‚Ä¶\nI‚Äôm sold."
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#conclusions",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#conclusions",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "I‚Äôm very happy about it all. The Reinforcement Learning example I chose is working nicely! And it makes sense, based on the little theory I have studied thus far.\n(Note: I shall actually post a short entry on real-world application of data mining with my LCS implementation. Any day now, it has happened already‚Ä¶)."
  },
  {
    "objectID": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#resources",
    "href": "posts/2025-03-16_RLCS_RL_WorksAgain/index.html#resources",
    "title": "RLCS for RL: It works again (using books helps)",
    "section": "",
    "text": "‚ÄúReinforcement Learning, An introduction.‚Äù, 2nd Ed. Bradford Books, by R. S. Sutton & A. G. Bardo."
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "",
    "text": "Math. More specifically, Ordinary Differential Equations. More specifically, in fact, probably things related with evolution in time. Although not only.\nI just want to really understand mathematical models used for simulating things.\nAnd ODEs are just the thing.\nPhysics, Chemistry, etc. maybe are beyond the point. Simulating interactions of‚Ä¶ Well, agents, that‚Äôs what got me curious. Or populations growth (i.e.¬†the Logistic Model‚Ä¶). That kind of things.\nAnyhow, that‚Äôs the why for today‚Äôs post."
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#i-really-want-to-understand",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#i-really-want-to-understand",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "",
    "text": "Math. More specifically, Ordinary Differential Equations. More specifically, in fact, probably things related with evolution in time. Although not only.\nI just want to really understand mathematical models used for simulating things.\nAnd ODEs are just the thing.\nPhysics, Chemistry, etc. maybe are beyond the point. Simulating interactions of‚Ä¶ Well, agents, that‚Äôs what got me curious. Or populations growth (i.e.¬†the Logistic Model‚Ä¶). That kind of things.\nAnyhow, that‚Äôs the why for today‚Äôs post."
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#the-book",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#the-book",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "The book",
    "text": "The book\nI have done exercises about ODE in the past, but being able to follow the math, and being able to understand the math, are, to me, two different things. My goal here is to understand, not just copy and paste.\nAfter reading some comments online, I came across this book, highly recommended in its approach to the topic:\n\n\n\nThe reference book that I hope will change things"
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#day-1",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#day-1",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "‚ÄúDay 1‚Äù",
    "text": "‚ÄúDay 1‚Äù\nActually, Day 2. Day 1, I went through Chapter 1 (Overview) which confirmed this looked promising.\nSo Day 2. Chapter 2. Well, that took me the whole day, yesterday. And a hard day of thinking about the math, too. And that didn‚Äôt even include none of the whole section of exercises, either. But no one said it would be easy, hu?\nSo I did go through the whole theory of the chapter in the end, but in the middle, I made a detour of sorts, when reaching ‚Äúexample 2.2.1‚Äù. This was the provided information:\n\\[\n\\dot{x} = x^2-1\n\\]\nThat seemed innocuous enough, right? You would look for roots, fair enough: (-1, 1). Then where \\(\\dot{x} &gt; 0\\), you know the ‚Äúflow‚Äù will move to the right, and to the left when negative, so you can draw the vector field.\nObviating the ‚Äúarrows‚Äù of the vector field, I just put a ‚Äúfull dot‚Äù for stable equilibrium, and ‚Äúempty dot‚Äù for unstable equilibrium.\nIt looks like so (and that was not the part that got me stumbling). One thing I did, is code the whole thing (in R, obviously) and so here I am generating a phase portrait for that scenario:\n\n\n\n\n\n\n\n\n\nBut then something came up. See, one argument of the methods presented in the book (thus far, anyway) is to get a ‚Äúgeometric‚Äù sense of what happens with nonlinear equations that are hard to solve analytically.\nThis one example ODE was easy to ‚Äúintegrate‚Äù, so I could visualize the ‚Äúpotential function‚Äù that leads to this. That‚Äôs where I made a conceptual mistake that got me wondering what was wrong‚Ä¶\n\nJust integrate?\nWell, if you integrate the above, you get:\n\\[f(x) = x^3/3-x+C\\]\nBut when you draw that, you get quite exactly the opposite of what you‚Äôd expect. Why? Why is it, when I integrate the ODE directly, I get the opposite function of what I‚Äôd expect?\nI could see that what you want for this example, what fits nicely with the ODE, is in fact the following:\n\n\n\n\n\n\n\n\n\nThat is the same thing, but multiplied by -1.\n\n\nThe Key\n\n‚ÄúA first order ODE can be understood as gradient descent of its potential function.‚Äù\n\nThat‚Äôs what clicked for me and fixed a conceptual problem that got me worried for‚Ä¶ Hours? Until I asked a friend (thanks Omar) and at long last, it all made sense.\nSo here is the concept of the whole exercise. Let‚Äôs go back and go step-by-step. So, again, this:\n\ndraw_phase_portrait(dot_x, x_min, x_max)\n\n\n\n\n\n\n\n\nHow I can make an intuition of that phase portrait and the vector field for it is:\nWith the passing of time:\n\na particle ‚Äòlanding‚Äô near x=-1 will tend to move towards, and then stay, at x=-1.\na particle ‚Äòlanding‚Äô between x=-1 and x=1 will tend to go to the left until it stabilizes at x=-1.\na particle ‚Äòlanding‚Äô on the right of x=1 will move away from 1, and it will move ever faster.\na particle ‚Äòlanding‚Äô precisely at x=1 will stay there, but any perturbation to it, however small, will push it away from that ‚Äúequilibrium‚Äù.\n\nI could see that here: The concept I understand is, if you consider some sort of a particle (ball? flow? no matter) that falls vertically onto this next curve, see below (which you have to imagine is ‚Äúcovered in some dense fluid, say honey or similar‚Äù, thereby eliminating the possibility of overshooting a stable equilibrium because of previous horizontal inertia‚Ä¶), it will indeed behave as described above, right?\n\nplot(orig_points, type=\"l\", main=\"original function (C=0)\")\n\n\n\n\n\n\n\n\nRight? Now I had missed a step in the logic of the ODE. Because what I just described is the ‚Äúgradient descent‚Äù.\nHeck! But I know that one! Why could I not ‚Äúsee‚Äù the solution?\nGradient descent is, by definition, the negated derivative!!\nSo if I am given:\n\\[\n\\dot{x} = x^2-1\n\\]\nI should have known (!!) that the potential function corresponding to that ODE, the one that negates the gradient hereby represented, is in fact:\n\\[\n\\int -(x^2-1) = -(x^3/3-x+C)\n\\]\nThat was ALL I needed to understand to see where I had made a (conceptual) mistake.\nAnd it finally clicked when that friend gave me that key. Sometimes, you need help. I‚Äôm just glad I know a few people that can answer such questions.\nEdit: I kept getting confused by trying to ‚Äúsolve the ODE‚Äù and getting to the potential function.\nHere is the clarification I need to keep in mind, for first order ODE.\nSolving the ODE analytically means solving:\n\\[\n\\dot{x} = f(x) = dx/dt \\rightarrow\\int{{1\\over{f(x)}} dx}=\\int{dt}\n\\]\nWhich should lead to an expression \\(x(t)\\), which is related to \\(t\\) for a specifically given \\(x(0)\\).\nWhereas the potential function is given by:\n\\[\n\\dot{x} = f(x) = {-dV\\over{}dx}\n\\]\nWhich is where one can ‚Äúsee‚Äù the negative of the derivative‚Ä¶ Which was the gradient descent all along. I just didn‚Äôt grab the distinction :(\nActually, that also makes it clear that ‚Äúsolving‚Äù analytically what looked like a simple ODE is in fact a real pain‚Ä¶ And why one would prefer to use geometric approaches.\nAnyhow, I‚Äôm still not 100% clear on what the ‚Äúsolving analytically the ODE‚Äù means: I can understand how the first order ODE itself expresses a change over time for a given initial condition. Which is why I can understand the next section. But I guess I still need to wrap my head conceptually around what ‚Äúsolving it‚Äù means."
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#slopes-field",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#slopes-field",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "Slopes Field",
    "text": "Slopes Field\nOn to the last piece of the puzzle, visualizing the ‚Äúfield‚Äù of that equation.\nOne ‚Äúcool thing‚Äù about this whole concept is you can visualize ‚Äúall‚Äù initial positions and effect of the passing of time for the above ‚Äúpotential‚Äù equation, that is, all the possible behaviours of a ‚Äúparticle falling onto the curve‚Äù. That‚Äôs called a slopes field.\nAnd you only need the ODE (here, first order) for that!\nThe only real difficulty I had there was to draw the ‚Äúarrows‚Äù. I know it shows the ‚Äúslopes‚Äù at some given points. Which, well, is the definition of the derivative, so yes, the ODE is the key. As per each \\(x0\\), that‚Äôs easy too. And generating the positions over time, well‚Ä¶\nI used the (simple, far from ideal but sufficient for today) Euler method for getting a numerical solution for each \\(x0\\), iterating with small \\(\\Delta t\\). Then I extract a subset of each possible \\(t\\) positions, and thereby space a bit the arrows so that it can be visualized.\nOne thing I still don‚Äôt quite understand: the cos, tan, and all that trigonometry stuff required to draw the arrows. So yeah, I‚Äôll admit: I just copied that part of the code from here.\nAside from that slight difficulty of the drawing of the arrows, I‚Äôm quite happy with the outcome!\n\n\n\n\n\n\n\n\n\nYou can see what the vector field predicted!"
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#this-makes-me-happy",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#this-makes-me-happy",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "This makes me happy",
    "text": "This makes me happy\nAt long last, I have a conceptual understanding of what a given (simple, first order) ODE represents, in a mathematical sense, but also as an intuition.\nThis book, I will say, is very promising‚Ä¶ But it‚Äôs also very dense with concepts to be understood. Here is me ‚Äúreading‚Äù chapter 2:\n\n\n\nDoes it make sense to underline EVERYTHING? :D\n\n\n\n\n\nWrapping my head around vector fields"
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#conclusions",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#conclusions",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "Conclusions",
    "text": "Conclusions\nWell, that was‚Ä¶ Challenging.\nAt the rythm of one full day of work per chapter, just to read the theory, and 13 such chapters, notwithstanding that doing some exercises might very well add another day or two for each of the chapters (at least), and considering this is not something I can do on a workday (no way, this requires waaaaay too much focus of me), so considering one such effective day per week, we‚Äôre looking at‚Ä¶ 26 weeks, at best?\nHalf a year. For this one book.\nAnd that is, if I keep the focus on that one book (that‚Äôs something I do wrong: I jump from book to book, all the time. Too many interesting things to learn, what can I say‚Ä¶)\nI should really consider reading short novels, instead :D\nOn the other hand: The satisfaction of getting the intuition behind the math is incredibly fulfilling. So maybe it‚Äôs worth it, after all‚Ä¶"
  },
  {
    "objectID": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#references",
    "href": "posts/2025-07-13_Studying_NonLinear_Dynamics_FirstDay/index.html#references",
    "title": "Studying Nonlinear Dynamics: Day 1",
    "section": "References",
    "text": "References\n‚ÄúNonlinear Dynamics and Chaos (‚Ä¶)‚Äù, by S. Strogatz (CRC Press)\nDrawing the Slopes Field, I was initially not sure about how to draw the arrows, this helped."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Version ‚Äú0‚Äù is done and working. And I will say this, it is already showing some of its power. Let me show you.\n\n\n\nAlright so this is what I have so far:\n\nA basic, fully functional, Michigan-style LCS for Supervised Learning\nA wrapper makes it easier to call the thing for training\nGA (tournament-based parents selection, one-point cross over reproduction, simple mutation) and Covering for rules discovery\nDeletion was somewhat fixed\nAccuracy and other stats work\nPrinting support functions\nNew: It includes subsumption. But calling subsumption affects performance ‚Äì both ways ‚Äì depending on the when/where/how, a known fact. But when used ‚Äì and that‚Äôs an important running decision, by the way ‚Äì, it condensates the relevant information encoded in the system‚Ä¶ Making it, when applicable, much better!\n\n\n\nsubsumption and deletion are costly, but effective to contain the size of the system\n\n\nNew too: Testing can be called now too, which is very helpful to validate the value of the LCS\nThis LCS for SL accepts an environment that, importantly, currently supports only:\n\nBinary classes/actions (so 0 or 1)\nBinary strings as input/states (no more no less) (and I mean, strings)\nAll states must be of equal length (whatever that is)\n\n\nThat‚Äôs on the plus side. On the not-so-great, well:\n\nLittle-to-no error control in there yet\nNext-to-zero documentation so far\nAnd I‚Äôll make a note on performance later in this post.\nImperfect/still-a-bit-disorganized code is probably an understatement.\n\nBut that‚Äôs just what needs to happen next, I guess. Now on to what you can do with this thing.\n\n\n\nSo I‚Äôve already shown that one, but it wasn‚Äôt ‚Äúperfect‚Äù. Here the new version and a few tricks allow me to show how the LCS can be used for data mining.\nSo I give it 70% of the sample space, and it comes up with the following ‚ÄúClassifiers Set‚Äù:\n\n\n\nUsing LCS to discover the hidden rules in the dataset\n\n\nNotice how this is quite exactly what the LCS was supposed to try and discover. And also how it indeed tells us what that particular ‚Äúenvironment‚Äù (dataset and its classes) is all about.\n(Oh, and in this particular exercise, I really did not need to run so many epochs, it‚Äôs just my default hyperparameter setting, but after a hundred or so epochs, it was already done.)\nLet‚Äôs move to a more interesting example.\n\n\n\nThe ‚ÄúIntroduction to Learning Classifier Systems‚Äù book ‚Äì referenced in my first post on LCS ‚Äì explains the algorithm with (among much more explanations) one particular example, called a ‚Äú6-bit multiplexer‚Äù.\nThe rules of that particular example are like so:\n\nyou get a string of 6 bits as input\nthe first two bits point to an address in the resting 4 bits\nthe ‚Äúclass‚Äù of your classifier should be whatever the bit is at the designated address.\n\nA couple of examples:\n\n‚Äú010000‚Äù says ‚ÄúBit 2 of the last 4 bits is the class, so 0‚Äù\n‚Äú110001‚Äù says ‚ÄúBit 4 of the last 4 bits is the class, so 1‚Äù\n‚Äú101101‚Äù says ‚ÄúBit 3 of the last 4 bits is the class, so 0‚Äù\n‚Ä¶\n\nYou get the idea. One aspect of this is meant to show that the LCS SL can somehow recognize things that are interrelated in the data, here how two different parts interact. They call this ‚Äúepistasis‚Äù. For now, suffice to say, it‚Äôs a bit more interesting use-case and we hope our LCS can discover relevant rules.\nAgain, with 70% of the whole dataset (64 entries total, for 6 bits), we train our LCS and hope to identify important rules (ideally, up to 8 perfect rules in this case ‚Äì but that‚Äôs not guaranteed). Here I show one such trained Classifier Set (aka ‚ÄúLCS‚Äù or ‚ÄúLearning Classifier System‚Äù, where the S stands for ‚ÄúSystem‚Äù, implying more than one classifier working together‚Ä¶ but I digress) that gets it almost perfect:\n\n\n\nAlmost perfect MUX6 LCS\n\n\nYou have to look somewhat carefully but you should find 7 of the 8 ‚Äúperfect‚Äù classifiers in there. And I haven‚Äôt checked for this particular example, but if the training set (randomly selected) did contain all the needed cases (probably did), this LCS should also almost cover for the missing classifier (11###0 0). Hint, the following would be the only one that would match for that missing classifier, so they would participate to recommend the action/class, and see how they all recommend class 0 (‚Ä¶):\n\n1####0 0\n#1#0#0 0\n##00#0 0\n##0#10 0\n\nSo in spite of missing one perfect rule (and that‚Äôs also depending on the random environment and non-deterministic nature of the LCS training‚Ä¶), it would work in all testing cases.\nLet‚Äôs move on to a (much) harder use-case.\n\n\n\nNow this was a stretch. the MNIST dataset is nothing like the dummy tests above, for sure. First, I don‚Äôt know how to manually write a perfect program manually for it (the above cases were trivial, comparatively).\nSecond, many trained neural nets on the MNIST dataset don‚Äôt get perfect record (but that‚Äôs understandable, if you spend enough time with that dataset).\nThird, and quite important, the ‚Äústates‚Äù here are numerical strings representing the shade (black-white) of 784 pixels (28*28) integers between 0 and 255. With a simple binary transformation I could end up with my states represented each as 6272 binary strings (8 bits per pixel).\nAnd there are a few thousand entries (samples) per represented number.\nI knew upfront, doing thousands of exposures per sample to get anywhere would take forever.\nFair enough, and so I simplified the problem first. Here is what I did:\n\nCompress the data, from shades to 0-1 values per pixel. I used a threshold to ‚Äúsharpen‚Äù the dataset, so only if the value was &gt; 100 (out of 255) I would set my new pixel to 1, otherwise I set it to 0.\nCompress further, from 28*28 to 7*7 pixels. Each original 4-pixels-square is encoded as only 1 pixel, with value 1 if any of the 4*4 subsquare was one, 0 otherwise.\nThe above gives me 7*7 binary strings, so my states are now 49 bits long.\n\n\n\nI ‚Äúcompress‚Äù the MNIST data before training my LCS\n\n\nClass stays the same, but I also will do a simpler exercise. My LCS should distinguish between classes 0 and 1 only. (This is not an issue, it‚Äôs a choice. I just choose to keep things simple, that‚Äôs all, but the value of the approach is the same, think of it as a one-versus-rest approach if you want). This is in part to make things faster, and in (big) part because the code so far only allows two-classes-output only.\n\nLet me skip directly to the results here:\n\n\n\nShowing a couple of runs of an LCS SL on MNIST simplified dataset\n\n\n(BTW, I meant to write ‚Äúconfusion matrix‚Äù, not ‚Äúcontention table‚Äù above, obviously‚Ä¶ Apologies, I hadn‚Äôt slept much yesterday‚Ä¶)\nI just want to make this clear:\n\nTraining on a total 500 random (sampled) training inputs only (that‚Äôs the size of my environment here), so roughly 250 examples of pictures of Zero and 250 of One\nTraining on these 500 examples takes me between 7.4 and 9.3 minutes (in the above example)\nIt generalizes very well: I end up with an LCS that correctly classified 96 to 97+% of the 3799 sample tests.\n\n\n\nJust FYI, I worked a bit more (31/12) on this and reduced the running times for better results in just above 20 seconds for the mono-thread version:\n\n\n\nBetter speed AND accuracy after slight code update\n\n\nThis gives us in fact 98.6+% of correctly classified test samples after 20s training (still on only 500 training samples)!\n\n\n\n\nOne thing that has worried me the past few days, something I actually knew was a concern with LCS, was performance. I mean speed, here. (SEE EDIT ABOVE before you continue)\nTraining requires exposing the LCS to sufficient training instances to ‚Äúrepresent‚Äù the overall data. Here I believe, in LCS in particular, too many training instances would hinder training because of the speed of processing power needed. I truly believe better chosen training instances are more important than more training instances. Kinda contrary of what Deep Learning would have you think. Although, this belief is, right now, just that: A belief.\nLCS on the other hand, for each training instance, require a lot of ‚Äúepochs‚Äù, so seeing the same data quite a few times. That is because after covering, the GA kicks in and that happens with choosing what best rules are available, which are evolved over time and where ‚Äúbest‚Äù depends on how many matches, how general but specific enough a rule is, whether a rule not only matches but also returns the correct action‚Ä¶ The point is, ideally, you want to train your LCS on a dataset, but circle over that dataset many times. I‚Äôm talking, thousands of times ideally - for each entry.\nThe other aspect of it is, of course, choosing R as a programming language. As much as I am comfortable with it, it is a slow language, if you consider compiled alternatives and such.\nI wanted to dive a bit into the details of what in my current (basic) implementation I could do, and so I ran the thing through ‚Äúprofvis‚Äù quite a few times, separate functions at separate times, then overall, with larger problems, etc.\nOne thing I do a lot, because I‚Äôm using lists for everything right now, is use ‚Äúlapply()‚Äù (and al.). I have tried as much as I could to not use dependencies if I could avoid it. So much so, I believe the only actual dependency I have is the plyr package for the rbind() function, and that‚Äôs for printing stuff‚Ä¶\nNot having too many dependencies is partly motivated by my end goal of producing a package, which I‚Äôd like to make ‚Äúlight‚Äù as much as possible.\nAnyhow, so I use lapply() a lot, but I have also used %in% quite a few times. And in some cases, I mix both and check quite a few instances, quite a few times!\nMatching, which happens a lot, for instance, can have an impact:\n\n\n\nProfiling run-times of mono-thread R interpreted code with LOTS of iterations in there‚Ä¶\n\n\n\n\n\nYou might know this by now: I like to parallelize stuff over my CPU cores/threads. It‚Äôs just a thing I think about when I see my processing times are‚Ä¶ Long. Even if long is a few seconds. And here, we‚Äôre talking many iterations, which on bigger datasets/longer states means minutes.\n(Actually, before I decided to simplify to 49 bits the states of the MNIST exercise, I was working with 784 bits states, and well, it would NOT converge after several minutes‚Ä¶)\nWell, I have to keep working on this, but the cool thing is, an LCS can be pre-trained, and then re-trained.\nSo the LCS (in supervised learning setting for now) is nothing but a set of classifiers, which are rules learnt from examples. You can improve it by exposing it, simply, to more examples. Or let it run more iterations over the same examples!\nEither are valid approaches.\nNow‚Ä¶ What if I ‚Äúsharded‚Äù my data? Say, if I have 7 CPU cores‚Ä¶\nI could do one shorter run over all the data to generate a first ruleset. I could then use at the same time that pretrained LCS, and what if I trained 7 sub-LCS on 7 subsets of the data for more iterations (quite a few more epochs now, but in parallel, each on smaller data samples)?\nWhat if then I loop over that, with some sort of ‚Äúcompaction‚Äù of the 7 newly re-trained sub-LCS and generate a new single base LCS, to then re-distribute to 7 sub processes.\nWhat if I did that a few times?\nI still have to think (seriously, and hard) through all the implications of the simple ‚Äúalgorithm‚Äù I just proposed above. I came up with it quite independently, mind you. And maybe it‚Äôs a very bad idea. (not showing all the training examples hinders the selection and then generalization of classifiers, for one‚Ä¶ So maybe it‚Äôs a stupid idea‚Ä¶ I just haven‚Äôt thought it through yet. For now I do think maybe it does in fact kinda make sense.)\nBUT, I have done it already! One version of my code allows for parallel processing like just described.\nAnd well, in (quite a few) tests with the MNIST example above, for roughly the same overall runtimes (and ‚Äúcompaction‚Äù is costly!) I get a gain of 1-2% of correctly classified samples.\nFrom 96% to 97+%. (It might sound marginal, and indeed I‚Äôm talking about a LOT more processing, but the same runtimes with marginal gains in such near-100% ranges, sounds like potentially valuable).\nWell, indeed, I‚Äôve done that too:\n\n\n\nCPU-based parallel training of my LCS\n\n\n\n\n\nSo I‚Äôve got all the pieces of the puzzle. And it works. And I have validated some marvellous (to me) results. All in a few days.\nWell, not a ‚Äúfew days‚Äù. See, I‚Äôve coded for only a few hours maybe, but I‚Äôve been thinking about this for a long time. And I also think it‚Äôd be unfair to say I was fast: Coding time per-se doesn‚Äôt account for waking up in the middle of the night coming up with my own design to approach the MNIST example. Waking up in the middle of the night, when I have a project like this, somehow happens more often. I have a bit of insomnia, but these projects make it worse, although they also make me more‚Ä¶ Productive.\nI guess what I‚Äôm saying is: coding time might not have been too many hours. But thinking time, or ‚Äúobsessing‚Äù (rather) did account for much more than 4 or 5 days (in 4 to 8h/day). I mean, I have designed everything in between the days of coding, and that started long before.\nAnyhow, to the next step: Moving from a few functions and examples to an actual Package!\nThat‚Äôs what I‚Äôll be up to when I next have time to dedicate to this.\n\n\n\nWell, that is, indeed, when I next have the time. I‚Äôll be disconnecting for a couple of weeks during January. I simply have other personal priorities (all great).\nSo I‚Äôll take this where I left it maybe a bit later. No matter. I have gone through half the book of packages, and I actually am more convinced than ever that this is the perfect opportunity to create a package for me.\n\n\n\nWell, I am just so‚Ä¶ Proud of this thing already!\nSee I had only ever read about the idea until‚Ä¶ Well, basically a week ago. Thanks to the holiday season, and long week-end hours, I can now say I have a working LCS in R.\nNot only that:\n\nI know it‚Äôs already not too bad in terms of what you could expect about performance. I know (from profiling) where I could try to go RCpp. I also have ideas to run it in more ‚Äúhighly‚Äù parallel setups. With more cores on a machine, or‚Ä¶ More machines! (plumbeR, here I come‚Ä¶ Well, later though, that‚Äôs not urgent)\nBut I also know, if I can ‚Äúencode‚Äù a problem into a binary string for binary classification, it turns out LCS are a very valid idea to consider! Just as good as a Neural Network! Heck, in some cases, better!\nI have done some testthat() already, I have several separate functions, very few (almost none) dependencies, the thing is somewhat organized‚Ä¶ So the next step comes rather naturally.\n\nAnyhow, overall, I am happy to report, I do believe this (future) package can prove very valuable to the community!\nAnd at this stage, I already hope I can explain that in future forums - I will convince people, I‚Äôm sure of it.\nSo this is turning out to be as great a project as I had (unreasonably) imagined already a long time ago. Which, let me tell you, is very satisfying at a very personal level.\n\n\n\nAgain, if some keywords above are confusing, the how of the algorithm is neatly explained in this 12‚Äô video, which I highly recommend."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#intro-imperfect-but-very-cool",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#intro-imperfect-but-very-cool",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Version ‚Äú0‚Äù is done and working. And I will say this, it is already showing some of its power. Let me show you."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#whats-in-it",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#whats-in-it",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Alright so this is what I have so far:\n\nA basic, fully functional, Michigan-style LCS for Supervised Learning\nA wrapper makes it easier to call the thing for training\nGA (tournament-based parents selection, one-point cross over reproduction, simple mutation) and Covering for rules discovery\nDeletion was somewhat fixed\nAccuracy and other stats work\nPrinting support functions\nNew: It includes subsumption. But calling subsumption affects performance ‚Äì both ways ‚Äì depending on the when/where/how, a known fact. But when used ‚Äì and that‚Äôs an important running decision, by the way ‚Äì, it condensates the relevant information encoded in the system‚Ä¶ Making it, when applicable, much better!\n\n\n\nsubsumption and deletion are costly, but effective to contain the size of the system\n\n\nNew too: Testing can be called now too, which is very helpful to validate the value of the LCS\nThis LCS for SL accepts an environment that, importantly, currently supports only:\n\nBinary classes/actions (so 0 or 1)\nBinary strings as input/states (no more no less) (and I mean, strings)\nAll states must be of equal length (whatever that is)\n\n\nThat‚Äôs on the plus side. On the not-so-great, well:\n\nLittle-to-no error control in there yet\nNext-to-zero documentation so far\nAnd I‚Äôll make a note on performance later in this post.\nImperfect/still-a-bit-disorganized code is probably an understatement.\n\nBut that‚Äôs just what needs to happen next, I guess. Now on to what you can do with this thing."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-1-not-bit-4",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-1-not-bit-4",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "So I‚Äôve already shown that one, but it wasn‚Äôt ‚Äúperfect‚Äù. Here the new version and a few tricks allow me to show how the LCS can be used for data mining.\nSo I give it 70% of the sample space, and it comes up with the following ‚ÄúClassifiers Set‚Äù:\n\n\n\nUsing LCS to discover the hidden rules in the dataset\n\n\nNotice how this is quite exactly what the LCS was supposed to try and discover. And also how it indeed tells us what that particular ‚Äúenvironment‚Äù (dataset and its classes) is all about.\n(Oh, and in this particular exercise, I really did not need to run so many epochs, it‚Äôs just my default hyperparameter setting, but after a hundred or so epochs, it was already done.)\nLet‚Äôs move to a more interesting example."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-2-mux6",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-2-mux6",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "The ‚ÄúIntroduction to Learning Classifier Systems‚Äù book ‚Äì referenced in my first post on LCS ‚Äì explains the algorithm with (among much more explanations) one particular example, called a ‚Äú6-bit multiplexer‚Äù.\nThe rules of that particular example are like so:\n\nyou get a string of 6 bits as input\nthe first two bits point to an address in the resting 4 bits\nthe ‚Äúclass‚Äù of your classifier should be whatever the bit is at the designated address.\n\nA couple of examples:\n\n‚Äú010000‚Äù says ‚ÄúBit 2 of the last 4 bits is the class, so 0‚Äù\n‚Äú110001‚Äù says ‚ÄúBit 4 of the last 4 bits is the class, so 1‚Äù\n‚Äú101101‚Äù says ‚ÄúBit 3 of the last 4 bits is the class, so 0‚Äù\n‚Ä¶\n\nYou get the idea. One aspect of this is meant to show that the LCS SL can somehow recognize things that are interrelated in the data, here how two different parts interact. They call this ‚Äúepistasis‚Äù. For now, suffice to say, it‚Äôs a bit more interesting use-case and we hope our LCS can discover relevant rules.\nAgain, with 70% of the whole dataset (64 entries total, for 6 bits), we train our LCS and hope to identify important rules (ideally, up to 8 perfect rules in this case ‚Äì but that‚Äôs not guaranteed). Here I show one such trained Classifier Set (aka ‚ÄúLCS‚Äù or ‚ÄúLearning Classifier System‚Äù, where the S stands for ‚ÄúSystem‚Äù, implying more than one classifier working together‚Ä¶ but I digress) that gets it almost perfect:\n\n\n\nAlmost perfect MUX6 LCS\n\n\nYou have to look somewhat carefully but you should find 7 of the 8 ‚Äúperfect‚Äù classifiers in there. And I haven‚Äôt checked for this particular example, but if the training set (randomly selected) did contain all the needed cases (probably did), this LCS should also almost cover for the missing classifier (11###0 0). Hint, the following would be the only one that would match for that missing classifier, so they would participate to recommend the action/class, and see how they all recommend class 0 (‚Ä¶):\n\n1####0 0\n#1#0#0 0\n##00#0 0\n##0#10 0\n\nSo in spite of missing one perfect rule (and that‚Äôs also depending on the random environment and non-deterministic nature of the LCS training‚Ä¶), it would work in all testing cases.\nLet‚Äôs move on to a (much) harder use-case."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-3-mnist-with-tricks",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-3-mnist-with-tricks",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Now this was a stretch. the MNIST dataset is nothing like the dummy tests above, for sure. First, I don‚Äôt know how to manually write a perfect program manually for it (the above cases were trivial, comparatively).\nSecond, many trained neural nets on the MNIST dataset don‚Äôt get perfect record (but that‚Äôs understandable, if you spend enough time with that dataset).\nThird, and quite important, the ‚Äústates‚Äù here are numerical strings representing the shade (black-white) of 784 pixels (28*28) integers between 0 and 255. With a simple binary transformation I could end up with my states represented each as 6272 binary strings (8 bits per pixel).\nAnd there are a few thousand entries (samples) per represented number.\nI knew upfront, doing thousands of exposures per sample to get anywhere would take forever.\nFair enough, and so I simplified the problem first. Here is what I did:\n\nCompress the data, from shades to 0-1 values per pixel. I used a threshold to ‚Äúsharpen‚Äù the dataset, so only if the value was &gt; 100 (out of 255) I would set my new pixel to 1, otherwise I set it to 0.\nCompress further, from 28*28 to 7*7 pixels. Each original 4-pixels-square is encoded as only 1 pixel, with value 1 if any of the 4*4 subsquare was one, 0 otherwise.\nThe above gives me 7*7 binary strings, so my states are now 49 bits long.\n\n\n\nI ‚Äúcompress‚Äù the MNIST data before training my LCS\n\n\nClass stays the same, but I also will do a simpler exercise. My LCS should distinguish between classes 0 and 1 only. (This is not an issue, it‚Äôs a choice. I just choose to keep things simple, that‚Äôs all, but the value of the approach is the same, think of it as a one-versus-rest approach if you want). This is in part to make things faster, and in (big) part because the code so far only allows two-classes-output only.\n\nLet me skip directly to the results here:\n\n\n\nShowing a couple of runs of an LCS SL on MNIST simplified dataset\n\n\n(BTW, I meant to write ‚Äúconfusion matrix‚Äù, not ‚Äúcontention table‚Äù above, obviously‚Ä¶ Apologies, I hadn‚Äôt slept much yesterday‚Ä¶)\nI just want to make this clear:\n\nTraining on a total 500 random (sampled) training inputs only (that‚Äôs the size of my environment here), so roughly 250 examples of pictures of Zero and 250 of One\nTraining on these 500 examples takes me between 7.4 and 9.3 minutes (in the above example)\nIt generalizes very well: I end up with an LCS that correctly classified 96 to 97+% of the 3799 sample tests.\n\n\n\nJust FYI, I worked a bit more (31/12) on this and reduced the running times for better results in just above 20 seconds for the mono-thread version:\n\n\n\nBetter speed AND accuracy after slight code update\n\n\nThis gives us in fact 98.6+% of correctly classified test samples after 20s training (still on only 500 training samples)!"
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#performance",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#performance",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "One thing that has worried me the past few days, something I actually knew was a concern with LCS, was performance. I mean speed, here. (SEE EDIT ABOVE before you continue)\nTraining requires exposing the LCS to sufficient training instances to ‚Äúrepresent‚Äù the overall data. Here I believe, in LCS in particular, too many training instances would hinder training because of the speed of processing power needed. I truly believe better chosen training instances are more important than more training instances. Kinda contrary of what Deep Learning would have you think. Although, this belief is, right now, just that: A belief.\nLCS on the other hand, for each training instance, require a lot of ‚Äúepochs‚Äù, so seeing the same data quite a few times. That is because after covering, the GA kicks in and that happens with choosing what best rules are available, which are evolved over time and where ‚Äúbest‚Äù depends on how many matches, how general but specific enough a rule is, whether a rule not only matches but also returns the correct action‚Ä¶ The point is, ideally, you want to train your LCS on a dataset, but circle over that dataset many times. I‚Äôm talking, thousands of times ideally - for each entry.\nThe other aspect of it is, of course, choosing R as a programming language. As much as I am comfortable with it, it is a slow language, if you consider compiled alternatives and such.\nI wanted to dive a bit into the details of what in my current (basic) implementation I could do, and so I ran the thing through ‚Äúprofvis‚Äù quite a few times, separate functions at separate times, then overall, with larger problems, etc.\nOne thing I do a lot, because I‚Äôm using lists for everything right now, is use ‚Äúlapply()‚Äù (and al.). I have tried as much as I could to not use dependencies if I could avoid it. So much so, I believe the only actual dependency I have is the plyr package for the rbind() function, and that‚Äôs for printing stuff‚Ä¶\nNot having too many dependencies is partly motivated by my end goal of producing a package, which I‚Äôd like to make ‚Äúlight‚Äù as much as possible.\nAnyhow, so I use lapply() a lot, but I have also used %in% quite a few times. And in some cases, I mix both and check quite a few instances, quite a few times!\nMatching, which happens a lot, for instance, can have an impact:\n\n\n\nProfiling run-times of mono-thread R interpreted code with LOTS of iterations in there‚Ä¶"
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#nicos-trick-parallelizing",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#nicos-trick-parallelizing",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "You might know this by now: I like to parallelize stuff over my CPU cores/threads. It‚Äôs just a thing I think about when I see my processing times are‚Ä¶ Long. Even if long is a few seconds. And here, we‚Äôre talking many iterations, which on bigger datasets/longer states means minutes.\n(Actually, before I decided to simplify to 49 bits the states of the MNIST exercise, I was working with 784 bits states, and well, it would NOT converge after several minutes‚Ä¶)\nWell, I have to keep working on this, but the cool thing is, an LCS can be pre-trained, and then re-trained.\nSo the LCS (in supervised learning setting for now) is nothing but a set of classifiers, which are rules learnt from examples. You can improve it by exposing it, simply, to more examples. Or let it run more iterations over the same examples!\nEither are valid approaches.\nNow‚Ä¶ What if I ‚Äúsharded‚Äù my data? Say, if I have 7 CPU cores‚Ä¶\nI could do one shorter run over all the data to generate a first ruleset. I could then use at the same time that pretrained LCS, and what if I trained 7 sub-LCS on 7 subsets of the data for more iterations (quite a few more epochs now, but in parallel, each on smaller data samples)?\nWhat if then I loop over that, with some sort of ‚Äúcompaction‚Äù of the 7 newly re-trained sub-LCS and generate a new single base LCS, to then re-distribute to 7 sub processes.\nWhat if I did that a few times?\nI still have to think (seriously, and hard) through all the implications of the simple ‚Äúalgorithm‚Äù I just proposed above. I came up with it quite independently, mind you. And maybe it‚Äôs a very bad idea. (not showing all the training examples hinders the selection and then generalization of classifiers, for one‚Ä¶ So maybe it‚Äôs a stupid idea‚Ä¶ I just haven‚Äôt thought it through yet. For now I do think maybe it does in fact kinda make sense.)\nBUT, I have done it already! One version of my code allows for parallel processing like just described.\nAnd well, in (quite a few) tests with the MNIST example above, for roughly the same overall runtimes (and ‚Äúcompaction‚Äù is costly!) I get a gain of 1-2% of correctly classified samples.\nFrom 96% to 97+%. (It might sound marginal, and indeed I‚Äôm talking about a LOT more processing, but the same runtimes with marginal gains in such near-100% ranges, sounds like potentially valuable).\nWell, indeed, I‚Äôve done that too:\n\n\n\nCPU-based parallel training of my LCS"
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#next-steps-packaging",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#next-steps-packaging",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "So I‚Äôve got all the pieces of the puzzle. And it works. And I have validated some marvellous (to me) results. All in a few days.\nWell, not a ‚Äúfew days‚Äù. See, I‚Äôve coded for only a few hours maybe, but I‚Äôve been thinking about this for a long time. And I also think it‚Äôd be unfair to say I was fast: Coding time per-se doesn‚Äôt account for waking up in the middle of the night coming up with my own design to approach the MNIST example. Waking up in the middle of the night, when I have a project like this, somehow happens more often. I have a bit of insomnia, but these projects make it worse, although they also make me more‚Ä¶ Productive.\nI guess what I‚Äôm saying is: coding time might not have been too many hours. But thinking time, or ‚Äúobsessing‚Äù (rather) did account for much more than 4 or 5 days (in 4 to 8h/day). I mean, I have designed everything in between the days of coding, and that started long before.\nAnyhow, to the next step: Moving from a few functions and examples to an actual Package!\nThat‚Äôs what I‚Äôll be up to when I next have time to dedicate to this."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#a-few-days-off",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#a-few-days-off",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Well, that is, indeed, when I next have the time. I‚Äôll be disconnecting for a couple of weeks during January. I simply have other personal priorities (all great).\nSo I‚Äôll take this where I left it maybe a bit later. No matter. I have gone through half the book of packages, and I actually am more convinced than ever that this is the perfect opportunity to create a package for me."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#conclusion",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#conclusion",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Well, I am just so‚Ä¶ Proud of this thing already!\nSee I had only ever read about the idea until‚Ä¶ Well, basically a week ago. Thanks to the holiday season, and long week-end hours, I can now say I have a working LCS in R.\nNot only that:\n\nI know it‚Äôs already not too bad in terms of what you could expect about performance. I know (from profiling) where I could try to go RCpp. I also have ideas to run it in more ‚Äúhighly‚Äù parallel setups. With more cores on a machine, or‚Ä¶ More machines! (plumbeR, here I come‚Ä¶ Well, later though, that‚Äôs not urgent)\nBut I also know, if I can ‚Äúencode‚Äù a problem into a binary string for binary classification, it turns out LCS are a very valid idea to consider! Just as good as a Neural Network! Heck, in some cases, better!\nI have done some testthat() already, I have several separate functions, very few (almost none) dependencies, the thing is somewhat organized‚Ä¶ So the next step comes rather naturally.\n\nAnyhow, overall, I am happy to report, I do believe this (future) package can prove very valuable to the community!\nAnd at this stage, I already hope I can explain that in future forums - I will convince people, I‚Äôm sure of it.\nSo this is turning out to be as great a project as I had (unreasonably) imagined already a long time ago. Which, let me tell you, is very satisfying at a very personal level."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#references",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#references",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Again, if some keywords above are confusing, the how of the algorithm is neatly explained in this 12‚Äô video, which I highly recommend."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "So I wasn‚Äôt kidding. I really like this ‚ÄúLearning Classifier System‚Äù (aka LCS) idea, and I really want to develop the R package for it, which I will call ‚ÄúRLCS‚Äù (clever, hu?).\nNow I have to start somewhere, and so I will keep it simple for now. I will first focus on an LCS that does supervised learning only (that means, no reinforcement learning for now.)\nAlso, I will focus on the simplest binary environments. In LCS lingo, for supervised classification, environment is equivalent to saying dataset. Each entry to classify is presented as binary strings, and the class (aka action) is, for simplicity, also a simple 0 or 1.\nSo binary classification of binary strings.\nThis might sound simplistic (and it is somewhat, yes) but the feature engineering and codificatioin into GA-compatible individuals is often harder than the actual training of a ML algorithm.\nAnyhow. I will forego some details for now, but suffice to say I‚Äôm working right now towards a Michigan-style LCS.\n\n\n\nNow we will receive an environment/dataset as input that has ‚Äústates‚Äù in binary format, and actions/classes as either 0 or 1.\n## Suppose test data is:\ntest_environment &lt;- data.frame(state = c('00011', '10010', '01110', '00001'),\n                               class = c(0, 0, 0, 1))\n(It‚Äôs not enough info to conclude that, but these examples all agree with a classifier that would say, in human readable format: ‚ÄúThe Class is the negated bit 4 of the input‚Äù.)\nOne of the key aspects of an LCS, is that it will produce rules. A rule is a pair of a condition and an action.\nA condition in turn is written (in our current approach) as a string of a ternary alphabet, namely characters from the set {0, 1, #}, where # means wildcard and matches either 0 or 1.\nNow for each input of the environment (each entry of the dataset), for today‚Äôs purposes, we will want to know which rules it matches (regardless of the action). In other words, we want to match an input to condition(s). That will tell us the ‚ÄúMatch set‚Äù.\nMatching is one key aspect of the LCS overall algorithm, one that will be run a lot, and therefore I worry that it could be slow.\nA couple more keywords: A classifier is a rule and its statistics. (We will skip the statistics part for today.) And a population is our set of classifiers.\nShort of going the way of C++, I have coded one first simplistic function that takes a classifier set as a dataframe, and another one that uses a list of lists instead.\nConditions can easily be written as strings:\nconditions &lt;- c('#001#', '10#10', '##110', '###0#')\nactions &lt;- c(0, 0, 0, 1)\nFor the first approach, it was quite straightforward:\nlcs_classifier1 &lt;- data.frame(id = 1:4,\n                      condition_string = conditions,\n                      action = actions, #simplest is binary for supervised\n                      accuracy = 1,\n                      numerosity = 1,\n                      first_seen = c(1, 2, 3, 4) ## I'm inventing a coverage trigger\n                      )\n\n## Find Matching Rules\nget_match_set_v001 &lt;- function(ti_condition, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- unlist(strsplit(ti_condition, \"\"))\n    pop &lt;- pop[, c(\"id\", \"condition_string\")] # Same\n\n    which(sapply(1:nrow(pop), function(i) {\n\n        t_cond &lt;- unlist(strsplit(pop$condition_string[i], \"\"))\n        relevant_positions &lt;- which(t_cond %in% c(\"0\", \"1\"))\n        \n        all(t_cond[relevant_positions] == ti_cond[relevant_positions])\n    }))\n}\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v001(test_environment$state[1], lcs_classifier1), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v001(test_environment$state[2], lcs_classifier1),\n        c(1, 2)\n    )\n})\n\n(OUTPUT:) Test passed ü•≥\nFor the second approach, I needed some more supporting functions:\n######\n## Option 2: Use list instead of Data.frame and pre-calculate match sets\n\n## Function to create a new rule from a condition string and an action\n## THIS IS VALID FOR CLASSIFICATION, NOT FOR Reinforcement Learning!!!\n## In our case, a new rule has: A condition string, an (correct!) action\n## Since action is correct, this is useful for future \"covering\"\n## AND we set accuracy to 1\nnew_supervised_rule &lt;- function(condition_string, action) {\n    list(id = 1,\n         condition_string = condition_string,\n         condition_length = nchar(condition_string),\n         condition_list = list(\"0\" = which(unlist(strsplit(condition_string, \"\")) == \"0\"),\n                               \"1\" = which(unlist(strsplit(condition_string, \"\")) == \"1\")),\n         action = action,\n         accuracy = 1,\n         numerosity = 1,\n         first_seen = 1)\n}\n\n## Function to return max id from a classifier set in list format\nmax_id_in_classifier &lt;- function(pop) {\n    max(sapply(pop, function(x) x$id))\n}\n\n## Function to add rule to a population.\n## date_rule_born will be useful stat for future, setting as parameter for now.\nadd_valid_rule_to_pop &lt;- function(pop, condition_string, action, date_rule_born = 1) {\n    \n    t_rule &lt;- new_supervised_rule(condition_string, action)\n    t_rule$id &lt;- max_id_in_classifier(pop)+1\n    t_rule$first_seen &lt;- date_rule_born\n    \n    pop[[length(pop)+1]] &lt;- t_rule\n    \n    pop\n}\n\n## Support function for human-compatible printing:\nmake_pop_printable &lt;- function(classifier) {\n    data.frame\n    rbind.fill(lapply(1:length(classifier), function(i) {\n        t_c &lt;- classifier[[i]]\n        data.frame(id = t_c$id,\n                   condition = t_c$condition_string,\n                   action = t_c$action,\n                   accuracy = t_c$accuracy,\n                   numerosity = t_c$numerosity,\n                   first_seen = t_c$first_seen)\n    }))\n}\n\n## Matching with list formatted population.\nget_match_set_v002 &lt;- function(input_state, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- as.integer(unlist(strsplit(input_state, \"\")))\n    \n    which(sapply(1:length(pop), function(i) {\n        rule &lt;- pop[[i]]$condition_list\n        all(ti_cond[rule$'0'] == 0, ti_cond[rule$'1'] == 1)\n    }))\n}\n\nlcs_classifier2 &lt;- list(new_supervised_rule(conditions[1], actions[1]))\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[2], actions[2])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[3], actions[3])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[4], actions[4])\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v002(test_environment$state[1], lcs_classifier2), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v002(test_environment$state[2], lcs_classifier2),\n        c(1, 2)\n    )\n})\n\n\n\nAn example population\n\n\n\n\n\nmicrobenchmark(\n    sapply(test_environment$state, function(x) { get_match_set_v001(x, lcs_classifier1)}),\n    sapply(test_environment$state, function(x) { get_match_set_v002(x, lcs_classifier2)}),\n    times = 10000L\n)\n\n\n\nlists and pre-calculated match positions is faster\n\n\nLists are more flexible and data.frames are not the fastest option out there anyway. Here the pre-calculations in the second format also helps doing faster matching.\nHowever I know this choice might have an impact, particularly when time will come to implement deletion, subsumption and compaction (all useful for better LCS performance/value). And another idea I have in mind will require further lists management (but it‚Äôs too early to discuss that).\nBut that‚Äôs a problem for future me (and nothing that hasn‚Äôt been solved already).\n\n\n\nWell well: Day 1, and we have covered concepts of environment, states, actions, conditions, rules, classifiers, population and matching/match set.\nAlong with developping a functional (basic) list for storing classifiers, and a matching function.\nNot too bad (albeit all too simplistic and not going for ‚Äúfull-power‚Äù flexible LCS implementation).\n\n\n\nI‚Äôll keep referring to this video (although the book is better to get acquainted with the vocabulary and concepts): intro explaining the algorithm ."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#intro",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#intro",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "So I wasn‚Äôt kidding. I really like this ‚ÄúLearning Classifier System‚Äù (aka LCS) idea, and I really want to develop the R package for it, which I will call ‚ÄúRLCS‚Äù (clever, hu?).\nNow I have to start somewhere, and so I will keep it simple for now. I will first focus on an LCS that does supervised learning only (that means, no reinforcement learning for now.)\nAlso, I will focus on the simplest binary environments. In LCS lingo, for supervised classification, environment is equivalent to saying dataset. Each entry to classify is presented as binary strings, and the class (aka action) is, for simplicity, also a simple 0 or 1.\nSo binary classification of binary strings.\nThis might sound simplistic (and it is somewhat, yes) but the feature engineering and codificatioin into GA-compatible individuals is often harder than the actual training of a ML algorithm.\nAnyhow. I will forego some details for now, but suffice to say I‚Äôm working right now towards a Michigan-style LCS."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#the-ternary-alphabet-for-conditions",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#the-ternary-alphabet-for-conditions",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "Now we will receive an environment/dataset as input that has ‚Äústates‚Äù in binary format, and actions/classes as either 0 or 1.\n## Suppose test data is:\ntest_environment &lt;- data.frame(state = c('00011', '10010', '01110', '00001'),\n                               class = c(0, 0, 0, 1))\n(It‚Äôs not enough info to conclude that, but these examples all agree with a classifier that would say, in human readable format: ‚ÄúThe Class is the negated bit 4 of the input‚Äù.)\nOne of the key aspects of an LCS, is that it will produce rules. A rule is a pair of a condition and an action.\nA condition in turn is written (in our current approach) as a string of a ternary alphabet, namely characters from the set {0, 1, #}, where # means wildcard and matches either 0 or 1.\nNow for each input of the environment (each entry of the dataset), for today‚Äôs purposes, we will want to know which rules it matches (regardless of the action). In other words, we want to match an input to condition(s). That will tell us the ‚ÄúMatch set‚Äù.\nMatching is one key aspect of the LCS overall algorithm, one that will be run a lot, and therefore I worry that it could be slow.\nA couple more keywords: A classifier is a rule and its statistics. (We will skip the statistics part for today.) And a population is our set of classifiers.\nShort of going the way of C++, I have coded one first simplistic function that takes a classifier set as a dataframe, and another one that uses a list of lists instead.\nConditions can easily be written as strings:\nconditions &lt;- c('#001#', '10#10', '##110', '###0#')\nactions &lt;- c(0, 0, 0, 1)\nFor the first approach, it was quite straightforward:\nlcs_classifier1 &lt;- data.frame(id = 1:4,\n                      condition_string = conditions,\n                      action = actions, #simplest is binary for supervised\n                      accuracy = 1,\n                      numerosity = 1,\n                      first_seen = c(1, 2, 3, 4) ## I'm inventing a coverage trigger\n                      )\n\n## Find Matching Rules\nget_match_set_v001 &lt;- function(ti_condition, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- unlist(strsplit(ti_condition, \"\"))\n    pop &lt;- pop[, c(\"id\", \"condition_string\")] # Same\n\n    which(sapply(1:nrow(pop), function(i) {\n\n        t_cond &lt;- unlist(strsplit(pop$condition_string[i], \"\"))\n        relevant_positions &lt;- which(t_cond %in% c(\"0\", \"1\"))\n        \n        all(t_cond[relevant_positions] == ti_cond[relevant_positions])\n    }))\n}\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v001(test_environment$state[1], lcs_classifier1), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v001(test_environment$state[2], lcs_classifier1),\n        c(1, 2)\n    )\n})\n\n(OUTPUT:) Test passed ü•≥\nFor the second approach, I needed some more supporting functions:\n######\n## Option 2: Use list instead of Data.frame and pre-calculate match sets\n\n## Function to create a new rule from a condition string and an action\n## THIS IS VALID FOR CLASSIFICATION, NOT FOR Reinforcement Learning!!!\n## In our case, a new rule has: A condition string, an (correct!) action\n## Since action is correct, this is useful for future \"covering\"\n## AND we set accuracy to 1\nnew_supervised_rule &lt;- function(condition_string, action) {\n    list(id = 1,\n         condition_string = condition_string,\n         condition_length = nchar(condition_string),\n         condition_list = list(\"0\" = which(unlist(strsplit(condition_string, \"\")) == \"0\"),\n                               \"1\" = which(unlist(strsplit(condition_string, \"\")) == \"1\")),\n         action = action,\n         accuracy = 1,\n         numerosity = 1,\n         first_seen = 1)\n}\n\n## Function to return max id from a classifier set in list format\nmax_id_in_classifier &lt;- function(pop) {\n    max(sapply(pop, function(x) x$id))\n}\n\n## Function to add rule to a population.\n## date_rule_born will be useful stat for future, setting as parameter for now.\nadd_valid_rule_to_pop &lt;- function(pop, condition_string, action, date_rule_born = 1) {\n    \n    t_rule &lt;- new_supervised_rule(condition_string, action)\n    t_rule$id &lt;- max_id_in_classifier(pop)+1\n    t_rule$first_seen &lt;- date_rule_born\n    \n    pop[[length(pop)+1]] &lt;- t_rule\n    \n    pop\n}\n\n## Support function for human-compatible printing:\nmake_pop_printable &lt;- function(classifier) {\n    data.frame\n    rbind.fill(lapply(1:length(classifier), function(i) {\n        t_c &lt;- classifier[[i]]\n        data.frame(id = t_c$id,\n                   condition = t_c$condition_string,\n                   action = t_c$action,\n                   accuracy = t_c$accuracy,\n                   numerosity = t_c$numerosity,\n                   first_seen = t_c$first_seen)\n    }))\n}\n\n## Matching with list formatted population.\nget_match_set_v002 &lt;- function(input_state, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- as.integer(unlist(strsplit(input_state, \"\")))\n    \n    which(sapply(1:length(pop), function(i) {\n        rule &lt;- pop[[i]]$condition_list\n        all(ti_cond[rule$'0'] == 0, ti_cond[rule$'1'] == 1)\n    }))\n}\n\nlcs_classifier2 &lt;- list(new_supervised_rule(conditions[1], actions[1]))\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[2], actions[2])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[3], actions[3])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[4], actions[4])\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v002(test_environment$state[1], lcs_classifier2), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v002(test_environment$state[2], lcs_classifier2),\n        c(1, 2)\n    )\n})\n\n\n\nAn example population"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#well-keep-the-list-format-for-now",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#well-keep-the-list-format-for-now",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "microbenchmark(\n    sapply(test_environment$state, function(x) { get_match_set_v001(x, lcs_classifier1)}),\n    sapply(test_environment$state, function(x) { get_match_set_v002(x, lcs_classifier2)}),\n    times = 10000L\n)\n\n\n\nlists and pre-calculated match positions is faster\n\n\nLists are more flexible and data.frames are not the fastest option out there anyway. Here the pre-calculations in the second format also helps doing faster matching.\nHowever I know this choice might have an impact, particularly when time will come to implement deletion, subsumption and compaction (all useful for better LCS performance/value). And another idea I have in mind will require further lists management (but it‚Äôs too early to discuss that).\nBut that‚Äôs a problem for future me (and nothing that hasn‚Äôt been solved already)."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#conclusions",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#conclusions",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "Well well: Day 1, and we have covered concepts of environment, states, actions, conditions, rules, classifiers, population and matching/match set.\nAlong with developping a functional (basic) list for storing classifiers, and a matching function.\nNot too bad (albeit all too simplistic and not going for ‚Äúfull-power‚Äù flexible LCS implementation)."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#references",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#references",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "I‚Äôll keep referring to this video (although the book is better to get acquainted with the vocabulary and concepts): intro explaining the algorithm ."
  },
  {
    "objectID": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html",
    "href": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html",
    "title": "Multi-Agent RL",
    "section": "",
    "text": "Really all I did here, is modify the simple World I created a few months back to support multiple agents (blue-dots).\nThen I simply loop through each agent in turn (which means, they act sequentially), which is a simplification indeed, but sufficient for a quick demo.\nFinally, I train them, 16K steps for good measure, to look for green dots (food) and avoid the rest (red enemies, walls, etc.).\nHere is what it looks like (I even added an audio track :D)"
  },
  {
    "objectID": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#simplistic-while-functional-2d-multi-agent-rl",
    "href": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#simplistic-while-functional-2d-multi-agent-rl",
    "title": "Multi-Agent RL",
    "section": "",
    "text": "Really all I did here, is modify the simple World I created a few months back to support multiple agents (blue-dots).\nThen I simply loop through each agent in turn (which means, they act sequentially), which is a simplification indeed, but sufficient for a quick demo.\nFinally, I train them, 16K steps for good measure, to look for green dots (food) and avoid the rest (red enemies, walls, etc.).\nHere is what it looks like (I even added an audio track :D)"
  },
  {
    "objectID": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#what-for",
    "href": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#what-for",
    "title": "Multi-Agent RL",
    "section": "What for?",
    "text": "What for?\nGood question. Because I can? Nah‚Ä¶\nBut also, consider this: Each of these 5 agents here have learnt independently their own set of rules with the LCS algorithm. And they seem to do a pretty good job.\nIn terms of Applications, I don‚Äôt know, but maybe a non-centrally coordinated, fully distributed behaviour, for a cleaning team of robots would be a kind of application here.\nAnd no, that‚Äôs not a great idea (it would be easy to teach the robots what to do in this particular scenario) here. But in a more complex setting, maybe writing down behaviour rules would be harder, and then the LCS approach might make sense."
  },
  {
    "objectID": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#conclusions",
    "href": "posts/2025-06-05_RLCS_MultiAgent_RL/index.html#conclusions",
    "title": "Multi-Agent RL",
    "section": "Conclusions",
    "text": "Conclusions\nI don‚Äôt kid myself, but I was half-hoping to see some kind of ‚Äúemergent‚Äù behaviour :D Obviously, that didn‚Äôt happen.\nThen again, there is much more to that, and my agents are pretty simple‚Ä¶ Oh well.\nIt works. That counts.\nNext up: I think I want to look into ‚ÄúComplex Adaptive Systems‚Äù. I have found a book that explains them pretty good, and provides some examples in prose, that I might want to transform into actual computer models‚Ä¶ If, you know, I make the time for it."
  },
  {
    "objectID": "posts/2025-03-14_Migrating_Contents_Slowly/index.html",
    "href": "posts/2025-03-14_Migrating_Contents_Slowly/index.html",
    "title": "Migrating Contents (slowly)",
    "section": "",
    "text": "I‚Äôve had my own kaizen-r.com blog for some time, and I relaunched on github.io in November last year.\nOne issue I‚Äôm facing is I need to migrate all the old contents, which were not on the same platform‚Ä¶ And so I need to manually migrate the contents of the older blog.\n\n\n\nSo one thing that happens is I have made many publications about my last MSc project. As the project is published already, it makes little sense for me to re-produce all those entries.\nSome, I might, but the majority will disappear.\nAnd some more of the old contents is probably‚Ä¶ Well, I might be better off if it disappears. Saves me the effort.\n\n\n\nText is just copy-paste, almost.\nThe issue is to re-organize the multimedia (mostly images‚Ä¶ And a few videos). That, unfortunately, will not be fast‚Ä¶\n\n\n\nIn short, I‚Äôll need to slowly move contents from the old blog, with some criteria hopefully."
  },
  {
    "objectID": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#migrating-more-of-the-old-contents",
    "href": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#migrating-more-of-the-old-contents",
    "title": "Migrating Contents (slowly)",
    "section": "",
    "text": "I‚Äôve had my own kaizen-r.com blog for some time, and I relaunched on github.io in November last year.\nOne issue I‚Äôm facing is I need to migrate all the old contents, which were not on the same platform‚Ä¶ And so I need to manually migrate the contents of the older blog."
  },
  {
    "objectID": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#not-everything-goes",
    "href": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#not-everything-goes",
    "title": "Migrating Contents (slowly)",
    "section": "",
    "text": "So one thing that happens is I have made many publications about my last MSc project. As the project is published already, it makes little sense for me to re-produce all those entries.\nSome, I might, but the majority will disappear.\nAnd some more of the old contents is probably‚Ä¶ Well, I might be better off if it disappears. Saves me the effort."
  },
  {
    "objectID": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#easy-and-slow",
    "href": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#easy-and-slow",
    "title": "Migrating Contents (slowly)",
    "section": "",
    "text": "Text is just copy-paste, almost.\nThe issue is to re-organize the multimedia (mostly images‚Ä¶ And a few videos). That, unfortunately, will not be fast‚Ä¶"
  },
  {
    "objectID": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#conclusions",
    "href": "posts/2025-03-14_Migrating_Contents_Slowly/index.html#conclusions",
    "title": "Migrating Contents (slowly)",
    "section": "",
    "text": "In short, I‚Äôll need to slowly move contents from the old blog, with some criteria hopefully."
  },
  {
    "objectID": "posts/2021-08-01_FunctionAndClosures/index.html",
    "href": "posts/2021-08-01_FunctionAndClosures/index.html",
    "title": "Parts of Speech Tagging",
    "section": "",
    "text": "So I‚Äôve mentioned the concepts of Functional Programming in R a couple of times (here & here) already. I‚Äôve also played a bit with OOP (Object Oriented Programming) in R.\nBut I needed to explain it to others. There are MANY resources on the topic, but I wanted to SHOW it with a reasonably short amount of code as a demo, albeit in an incomplete/imperfect way.\n\n\n\nSo I put together the following function:\nsetup_env &lt;- function(x) {\n  local_var &lt;- x # Parent environment for Child Function(s)\n\n  save_and_add_one &lt;- function(y) {\n    assign(\"local_var\", y, envir = parent.env(environment()))\n    # write to the parent environment of this function.\n    y + 1 # Implicit return\n  }\n\n  add_5 &lt;- function() {\n    local_var + 5 # Will look for variable going up the environments tree until found\n  }\n\n  add_origin_5 &lt;- function() { # Overwriting \"local_var\" does not affect calling env's parameter values\n    x + 5 # x is not lost, it is part of the setup_env() context\n  }\n\n  show_local_env_x &lt;- function() {\n    x &lt;- 1 # This x is the first found\n    x # when looking for the x object. It is NOT the parent function's parameter, in this case\n  }\n\n  # implicit return: The list will contain functions, which names we can change if needed:\n  list(save_and_add_one = save_and_add_one,\n    add_five = add_5,\n    add_5_to_setup_call_param = add_origin_5,\n    show_internal_function_env_x = show_local_env_x)\n}\nThis should do. Let‚Äôs go through it.\nEach function is an R object. A function assigned to a variable, when called and while needed, will hold on to its calling parameters. So in the example:\ntest_env &lt;- setup_env(2) # so x will be two at first\nWe have an assigned calling variable x = 2. This will stay true as long as we don‚Äôt overwrite ‚Äúx‚Äù in the context of the variable ‚Äútest_env‚Äù.\nThe function will assigned that value to ‚Äúlocal_var‚Äù\nlocal_var &lt;- x\nThe ‚Äútest_env‚Äù var contains a function that returned a named list. So we can call on the names of that list, functions in this case, like so:\ntest_env$add_five() # So we expect 7\nHere, the ‚Äúlocal_var‚Äù still is equal to 2. the ‚Äúadd_five()‚Äù is a function within a function.\nIt will first try to locate ‚Äúlocal_var‚Äù from its own environment (created upon calling it). As it is not found, it will go ‚Äúup‚Äù the branch to locate it in its parent environment. This time it will find it, and hence use it to return the value of the operation.\nWhat if we try to overwrite local_var from within a function (that is a nested function)? We need to point to the parent.env() of our current environment(), and assign() the value there. This way we actually choose the environment in which we assign it. ‚Äú&lt;&lt;-‚Äù is similar in this case, but not exactly the same, though, as you don‚Äôt get to choose which environment to use for the assignement.\ntest_env$save_and_add_one(4)\nOnce we‚Äôve done that, ‚Äúlocal_var‚Äù should have been updated to 4. Which means, calling a function that depends on it‚Ä¶\ntest_env$add_five() # Now we have 4 in local_var, so that's a 9\nHere we read (again) local_var from our parent environment (add_five‚Äôs parent environment is ‚Äì still ‚Äì test_env, an instantiation of setup_env()).\nlocal_var was changed after being assigned the value of x, upon calling the first time to setup_env(). But x, the calling parameter, hasn‚Äôt changed. So the following will do ‚Äú2+5‚Äù:\ntest_env$add_5_to_setup_call_param() # We called setup_env with 2, so that should be a 7\nWhich is expected.\nIn yet a different function within setup_env(), we COULD use x as local variable for the corresponding child environment. If we do so, assign a value to x say from within ‚Äúshow_internal_function_env_x()‚Äù, it will NOT change the value of the parameter x used when calling setup_env() at the beginning:\ntest_env$show_internal_function_env_x() # Careful, we use a DIFFERENT x here, which we set to one.\ntest_env$add_5_to_setup_call_param() # But in fact the calling parameter x was untouched\nAnd that‚Äôs about it.\n\n\n\nSo what thing this example shows, is that the calling parameter (x = 2) in:\ntest_env &lt;- setup_env(2)\nSurvives, as long as ‚Äútest_env‚Äù (the variable) survives. IF one passes a big object (say a dataframe with tens of thousands of rows and hundreds of colums) to an equivalent of setup_env(), then ‚Äútest_env‚Äù would hold it‚Äôs environment with that variable in memory. In other words, it will add a copy of the parameter to the memory, until the function‚Äôs environment can be cleaned (either by the gc() or through a forced call).\nSo I guess a note of warning is in order: Careful, you can duplicate data in memory when you use closures. And that‚Äôs in spite of the ‚Äúmodification in place‚Äù trick used by the R interpreter. Maybe you want to call your functions/closures with the smallest amount of data needed for them to work. It‚Äôs a small optimisation right there.\n\n\n\nI am unsure about whether or not this helped or made things more confusing. This code I am convinced I can use to explain ‚Äúlive‚Äù about the nuances of functions and environments (and even of ‚Äúclosures‚Äù), but without an explanation‚Ä¶\nTo those not accustomed to closures and environments, but familiar with R, I am still convinced it should be helpful, and it all fits in a rather short amount of code.\nOn the other hand, one could use such closures to store functions and variables together, making those variables local to the instantiation of the closure (sort of private variables in an Object). In effect, we would have something similar to an object, for which we could use the equivalent of ‚Äúmethods‚Äù (our functions inside the function).\nIt‚Äôs not a perfect analogy, but it‚Äôs interesting regardless.\n\n\n\nA nice example with explanation using folder trees to explain environments\nThe always great resource Advanced R\nMy own code for today"
  },
  {
    "objectID": "posts/2021-08-01_FunctionAndClosures/index.html#intro",
    "href": "posts/2021-08-01_FunctionAndClosures/index.html#intro",
    "title": "Parts of Speech Tagging",
    "section": "",
    "text": "So I‚Äôve mentioned the concepts of Functional Programming in R a couple of times (here & here) already. I‚Äôve also played a bit with OOP (Object Oriented Programming) in R.\nBut I needed to explain it to others. There are MANY resources on the topic, but I wanted to SHOW it with a reasonably short amount of code as a demo, albeit in an incomplete/imperfect way.\n\n\n\nSo I put together the following function:\nsetup_env &lt;- function(x) {\n  local_var &lt;- x # Parent environment for Child Function(s)\n\n  save_and_add_one &lt;- function(y) {\n    assign(\"local_var\", y, envir = parent.env(environment()))\n    # write to the parent environment of this function.\n    y + 1 # Implicit return\n  }\n\n  add_5 &lt;- function() {\n    local_var + 5 # Will look for variable going up the environments tree until found\n  }\n\n  add_origin_5 &lt;- function() { # Overwriting \"local_var\" does not affect calling env's parameter values\n    x + 5 # x is not lost, it is part of the setup_env() context\n  }\n\n  show_local_env_x &lt;- function() {\n    x &lt;- 1 # This x is the first found\n    x # when looking for the x object. It is NOT the parent function's parameter, in this case\n  }\n\n  # implicit return: The list will contain functions, which names we can change if needed:\n  list(save_and_add_one = save_and_add_one,\n    add_five = add_5,\n    add_5_to_setup_call_param = add_origin_5,\n    show_internal_function_env_x = show_local_env_x)\n}\nThis should do. Let‚Äôs go through it.\nEach function is an R object. A function assigned to a variable, when called and while needed, will hold on to its calling parameters. So in the example:\ntest_env &lt;- setup_env(2) # so x will be two at first\nWe have an assigned calling variable x = 2. This will stay true as long as we don‚Äôt overwrite ‚Äúx‚Äù in the context of the variable ‚Äútest_env‚Äù.\nThe function will assigned that value to ‚Äúlocal_var‚Äù\nlocal_var &lt;- x\nThe ‚Äútest_env‚Äù var contains a function that returned a named list. So we can call on the names of that list, functions in this case, like so:\ntest_env$add_five() # So we expect 7\nHere, the ‚Äúlocal_var‚Äù still is equal to 2. the ‚Äúadd_five()‚Äù is a function within a function.\nIt will first try to locate ‚Äúlocal_var‚Äù from its own environment (created upon calling it). As it is not found, it will go ‚Äúup‚Äù the branch to locate it in its parent environment. This time it will find it, and hence use it to return the value of the operation.\nWhat if we try to overwrite local_var from within a function (that is a nested function)? We need to point to the parent.env() of our current environment(), and assign() the value there. This way we actually choose the environment in which we assign it. ‚Äú&lt;&lt;-‚Äù is similar in this case, but not exactly the same, though, as you don‚Äôt get to choose which environment to use for the assignement.\ntest_env$save_and_add_one(4)\nOnce we‚Äôve done that, ‚Äúlocal_var‚Äù should have been updated to 4. Which means, calling a function that depends on it‚Ä¶\ntest_env$add_five() # Now we have 4 in local_var, so that's a 9\nHere we read (again) local_var from our parent environment (add_five‚Äôs parent environment is ‚Äì still ‚Äì test_env, an instantiation of setup_env()).\nlocal_var was changed after being assigned the value of x, upon calling the first time to setup_env(). But x, the calling parameter, hasn‚Äôt changed. So the following will do ‚Äú2+5‚Äù:\ntest_env$add_5_to_setup_call_param() # We called setup_env with 2, so that should be a 7\nWhich is expected.\nIn yet a different function within setup_env(), we COULD use x as local variable for the corresponding child environment. If we do so, assign a value to x say from within ‚Äúshow_internal_function_env_x()‚Äù, it will NOT change the value of the parameter x used when calling setup_env() at the beginning:\ntest_env$show_internal_function_env_x() # Careful, we use a DIFFERENT x here, which we set to one.\ntest_env$add_5_to_setup_call_param() # But in fact the calling parameter x was untouched\nAnd that‚Äôs about it.\n\n\n\nSo what thing this example shows, is that the calling parameter (x = 2) in:\ntest_env &lt;- setup_env(2)\nSurvives, as long as ‚Äútest_env‚Äù (the variable) survives. IF one passes a big object (say a dataframe with tens of thousands of rows and hundreds of colums) to an equivalent of setup_env(), then ‚Äútest_env‚Äù would hold it‚Äôs environment with that variable in memory. In other words, it will add a copy of the parameter to the memory, until the function‚Äôs environment can be cleaned (either by the gc() or through a forced call).\nSo I guess a note of warning is in order: Careful, you can duplicate data in memory when you use closures. And that‚Äôs in spite of the ‚Äúmodification in place‚Äù trick used by the R interpreter. Maybe you want to call your functions/closures with the smallest amount of data needed for them to work. It‚Äôs a small optimisation right there.\n\n\n\nI am unsure about whether or not this helped or made things more confusing. This code I am convinced I can use to explain ‚Äúlive‚Äù about the nuances of functions and environments (and even of ‚Äúclosures‚Äù), but without an explanation‚Ä¶\nTo those not accustomed to closures and environments, but familiar with R, I am still convinced it should be helpful, and it all fits in a rather short amount of code.\nOn the other hand, one could use such closures to store functions and variables together, making those variables local to the instantiation of the closure (sort of private variables in an Object). In effect, we would have something similar to an object, for which we could use the equivalent of ‚Äúmethods‚Äù (our functions inside the function).\nIt‚Äôs not a perfect analogy, but it‚Äôs interesting regardless.\n\n\n\nA nice example with explanation using folder trees to explain environments\nThe always great resource Advanced R\nMy own code for today"
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html",
    "href": "posts/2021-07-24_ShinyServer1/index.html",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "",
    "text": "Let me step aside from the NLP topic for a moment. It‚Äôs unfortunate that I want to do so many things, and I don‚Äôt really have all the time I wish I had, but as long as I am learning as I go, well, all is good.\nI just wanted to make quick entry to mention that I finally tested ‚ÄúShiny Server‚Äù.\nI recently was faced more directly with the need to actually share my work, beyond slides and PPTs.\nFor now, IOSlides in RStudio did the trick. I have also used Tableau, QlikView and a bit of PowerBI, all great tools (and reasonably easy to get to a basic level!) but for those of us that use R & RStudio, we are often drawn into Shiny.\nShiny is simply‚Ä¶ Great. Not as easy as these other tools, that‚Äôs true (it is not the same learning curve, at least from my experience), but arguably it is more powerful. Instead of a Dashboard, you can run code (ML, for example) AND show it, updated on the go. So you present an application, not ‚Äúsimply‚Äù a dataset. I‚Äôll have to look into the alternatives, I know some do try to do the same, but that‚Äôs not for today.\nAnd insisting on the learning curve (I‚Äôll repeat myself about that today): I keep learning about Shiny, the same way I keep learning about Docker & R stuff, packages, RStudio capacities‚Ä¶ Heck, a lot to keep me busy for the upcoming months (or years :S). Let‚Äôs just hope this Blog doesn‚Äôt die along the way‚Ä¶\nSide note: I am also looking into many other things lately (git, more plumbeR, docker-compose & Swarm, Shiny modules (wow that‚Äôs going to help make the Shiny bits of code cleaner), closures & environments (which I know a bit about, but clearly there is more to it), RStudio Projects (and the much commented ‚Äúdon‚Äôt use setwd()‚Äù mantra), and how to use all that‚Ä¶). But that will amount to another few posts. For now: back to Shiny Server‚Ä¶\nShiny was already an excellent excellent package, very powerful. Well: Shiny Server makes it even better!\nToday we‚Äôll get to provide two applications over a Web interface from a Shiny Server:\n\n\n\nbasic_tree_view_shiny_server"
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#intro",
    "href": "posts/2021-07-24_ShinyServer1/index.html#intro",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "",
    "text": "Let me step aside from the NLP topic for a moment. It‚Äôs unfortunate that I want to do so many things, and I don‚Äôt really have all the time I wish I had, but as long as I am learning as I go, well, all is good.\nI just wanted to make quick entry to mention that I finally tested ‚ÄúShiny Server‚Äù.\nI recently was faced more directly with the need to actually share my work, beyond slides and PPTs.\nFor now, IOSlides in RStudio did the trick. I have also used Tableau, QlikView and a bit of PowerBI, all great tools (and reasonably easy to get to a basic level!) but for those of us that use R & RStudio, we are often drawn into Shiny.\nShiny is simply‚Ä¶ Great. Not as easy as these other tools, that‚Äôs true (it is not the same learning curve, at least from my experience), but arguably it is more powerful. Instead of a Dashboard, you can run code (ML, for example) AND show it, updated on the go. So you present an application, not ‚Äúsimply‚Äù a dataset. I‚Äôll have to look into the alternatives, I know some do try to do the same, but that‚Äôs not for today.\nAnd insisting on the learning curve (I‚Äôll repeat myself about that today): I keep learning about Shiny, the same way I keep learning about Docker & R stuff, packages, RStudio capacities‚Ä¶ Heck, a lot to keep me busy for the upcoming months (or years :S). Let‚Äôs just hope this Blog doesn‚Äôt die along the way‚Ä¶\nSide note: I am also looking into many other things lately (git, more plumbeR, docker-compose & Swarm, Shiny modules (wow that‚Äôs going to help make the Shiny bits of code cleaner), closures & environments (which I know a bit about, but clearly there is more to it), RStudio Projects (and the much commented ‚Äúdon‚Äôt use setwd()‚Äù mantra), and how to use all that‚Ä¶). But that will amount to another few posts. For now: back to Shiny Server‚Ä¶\nShiny was already an excellent excellent package, very powerful. Well: Shiny Server makes it even better!\nToday we‚Äôll get to provide two applications over a Web interface from a Shiny Server:\n\n\n\nbasic_tree_view_shiny_server"
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#getting-up-and-running",
    "href": "posts/2021-07-24_ShinyServer1/index.html#getting-up-and-running",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "Getting up and running",
    "text": "Getting up and running\nAs usual, thanks to the community out there, it was VERY easy.\ndocker pull rocker/shiny\ndocker run -p 3838:3838 --rm rocker/shiny\nAnd that‚Äôs about it. As usual, it takes a minute or two (depending on connection speed) to get the base image. Maybe l need to also look into ‚Äúlighter‚Äù images, as they pile up."
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#mapping-our-own-applications",
    "href": "posts/2021-07-24_ShinyServer1/index.html#mapping-our-own-applications",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "Mapping our own applications¬†",
    "text": "Mapping our own applications¬†\nCreate a folder, say ‚Äúshiny_apps‚Äù. Then inside it create different folders for different Shiny applications.\nFor instance, let‚Äôs copy the example of KMeans (from the Shiny Gallery). A great thing about this demo, that shows a bit of the power of Shiny: You run an ML algorithm each time you tweak something in the interface. I‚Äôve heard PowerBI now supports R, but‚Ä¶ This is more ‚Äúnative‚Äù, and also I am unsure about how much of R PowerBI actually supports (I‚Äôll look into it soon enough).\nLet‚Äôs re-create our ‚ÄúRisks Visualization‚Äù demo from a few months back. This time we move that script into one ‚Äúapp.R‚Äù file, in the corresponding folder. Shiny Server will look (I believe) for either a pair of ‚Äúui.R + server.R‚Äù or an ‚Äúapp.R‚Äù file(s), so that should work.\nI‚Äôm not convinced this is a best practice, but then you can map the ‚Äúshiny_apps‚Äù folder to the container‚Äôs ‚Äú/srv/shiny-server/‚Äú. From there you‚Äôll see your different applications (see the first image above).\nIn order to get today‚Äôs demo to work, we‚Äôll need some packages (our risks visualization demo depends on those), so let‚Äôs also make a Dockerfile and build that, so that our image has all the required dependencies pre-installed.\nThe Dockerfile, first (rather simplistic):\nFROM rocker/shiny\n\nRUN R -e \"utils::install.packages(c('data.table', 'lubridate', 'dplyr',\\\n    'ggplot2', 'ggthemes'))\"\nOne advantage of this approach of a different container for Shiny Server (instead of re-using our RStudio container, which we did until today, and was good enough to server Shiny Apps and many other things), aside from abstracting from the RStudio interface itself for the end-users, is to be able to load only packages actually used across the applications you want to share, instead of all packages we might ever need when programming. (You could even think about having different containers, with different applications, and hence only the different packages needed in each container.) This is just a small optimization.\nLet‚Äôs move to the correct directory (the one with the newly created Dockerfile), and build it. Now remember the Dockerfile should be in a folder of its own (one best-practice, I believe). Then again, we could have it somewhere else (well, we should!) but for this demo ‚Äì and just for that purpose -, that‚Äôll do:\ndocker build -t local_shiny .\nSo we have our directory of ‚Äúshiny_apps‚Äù as follows:\n\nFinally, let‚Äôs move up to get to our directory of shiny_apps, and launch our new container:\ndocker run --name shiny_server -p 3838:3838 -v `pwd`:/srv/shiny-server/ local_shiny\nAs seen in the first screenshot, we can now see the different applications by connecting to our Shiny server, listening on port 3838.\nThe difference being (compared to using our laptop‚Äôs traditional files browser): if we click on an application‚Äôs link (and note: it won‚Äôt work for the folder containing the Dockerfile, for obvious reasons), Shiny will THEN launch the application:\n\nSo here: We‚Äôve downloaded a new container image prepared with Shiny Server (free), then created a version of it with our own Dockerfile to have all required packages. We launched that, and all applications we pointed to are now being served by our very own Shiny Server.\nYes: This was ‚ÄúQuick & Dirty‚Äù. But still, it worked."
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#note-more-to-be-done.-so-much-more",
    "href": "posts/2021-07-24_ShinyServer1/index.html#note-more-to-be-done.-so-much-more",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "Note: More to be done. So much more!",
    "text": "Note: More to be done. So much more!\nThere is plenty more to do, but the above is a start. Now at some point I‚Äôll have to test some of the many options I found out there to add ‚Äúlogin pages‚Äù to my apps. Shiny Server Pro does this better, for sure, but I‚Äôm using the free version of it. If I go there, I might just as well consider also putting up another container in between with NGINX, for TLS support (otherwise I‚Äôll be login with username and password over an unencrypted channel, which is not horrible while working locally on my laptop, but isn‚Äôt good in an actual client-server setup).\nOnce there, using the NGINX to also front our RStudio container will make sense.\nAt that point I might want to look a bit more into docker-compose to bring it all up and down at will, along with our Database container too.\nMeanwhile there is some space to improve on other fronts, like using a lighter container (maybe alpine-based) to run simple R scripts with a limited set of packages, tied to crontabs‚Ä¶ Or keep working on code quality (logging, projects, environments, and a long etc.).\nEven Shiny applications require some time to learn how to better code them (for instance I‚Äôve been reading up on ‚ÄúShiny Modules‚Äù lately, which I wasn‚Äôt aware of‚Ä¶ More proof of my actual ignorance, which keeps growing as I learn more and more about R‚Ä¶)\nBut that will make for contents for future entries."
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#conclusions",
    "href": "posts/2021-07-24_ShinyServer1/index.html#conclusions",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "Conclusions",
    "text": "Conclusions\nGetting a basic/demo Shiny Server up and running in a new Docker container took, literally, 3 minutes.\nGetting our own application(s) into the container wasn‚Äôt too painful either. Do look into further settings and better ways to do it though (e.g.¬†do not run the Shiny service as root, which apparently is the default for the rocker/shiny container‚Ä¶)\nI‚Äôm putting together quite a few containers, and many other potential candidates (using plumbeR, for instance), which pushes me to start thinking about a more ‚Äúoperational‚Äù setup. I‚Äôll work on that in upcoming entries (ALTHOUGH I‚Äôm also far from done one the NLP front‚Ä¶ ‚ÄúThings-to-learn‚Äù keep adding up, which is good, although frustrating at times).\nI hope you liked it!"
  },
  {
    "objectID": "posts/2021-07-24_ShinyServer1/index.html#some-external-resources",
    "href": "posts/2021-07-24_ShinyServer1/index.html#some-external-resources",
    "title": "Sharing Results: Shiny Server (beginnings)",
    "section": "Some External Resources",
    "text": "Some External Resources\nShiny Server Intro\nThe Shiny Gallery: KMeans demo\nThe Rocker/Shiny Container Base Image\nShiny Apps Formats"
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html",
    "href": "posts/2025-09-30_various_updates/index.html",
    "title": "Miscelanea week of sorts",
    "section": "",
    "text": "So, for one: Last weekend I basically spent it unlocking a very-well locked laptop. More precisely, a BitLocker protected Windows would refuse to boot. The HP partition to re-install wouldn‚Äôt even see the ciphered partition. Neither would a Windows Repair or Windows Install USB.\nFinally, a Live-Ubuntu pendrive gave me hopes when I saw the disk using\nfdisk -l\nBut then, that was only the beginning. Next, I needed the BitLocker recovery password. I had to wait for a few weeks for the (anonymous, for this post) user to give it to me.\nWhen I got it at last, I spent the weekend trying to open the ciphered partition."
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#this-last-few-days-were-different",
    "href": "posts/2025-09-30_various_updates/index.html#this-last-few-days-were-different",
    "title": "Miscelanea week of sorts",
    "section": "",
    "text": "So, for one: Last weekend I basically spent it unlocking a very-well locked laptop. More precisely, a BitLocker protected Windows would refuse to boot. The HP partition to re-install wouldn‚Äôt even see the ciphered partition. Neither would a Windows Repair or Windows Install USB.\nFinally, a Live-Ubuntu pendrive gave me hopes when I saw the disk using\nfdisk -l\nBut then, that was only the beginning. Next, I needed the BitLocker recovery password. I had to wait for a few weeks for the (anonymous, for this post) user to give it to me.\nWhen I got it at last, I spent the weekend trying to open the ciphered partition."
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#remember-backup-backup-and-backup",
    "href": "posts/2025-09-30_various_updates/index.html#remember-backup-backup-and-backup",
    "title": "Miscelanea week of sorts",
    "section": "Remember: Backup, Backup and‚Ä¶ Backup",
    "text": "Remember: Backup, Backup and‚Ä¶ Backup\nYep. That‚Äôs like the first 3 rules of Cybersecurity.\nAnd I should have done that in the first place: Do a ‚Äúdd‚Äù of that disk the moment I saw it. But then I needed a spare 1TB disk which‚Ä¶ I didn‚Äôt have. Fair enough: I could have bought one. I should have. I didn‚Äôt.\nAnd so, when the time came to actually try to access the data, every single step of the way was stressful: One wrong move anywhere, I could corrupt the thing. And then forget about recovering data.\nWell, that‚Äôs why I took my sweet time with it. Long hours went into this ‚Äútask‚Äù. So many more that I care to admit. Oh well.\nIt‚Äôs done, we got the data back.\n\nSide note\nAlmost all of it was already in a separate backup, so the effort was worth a measly few files‚Ä¶ But that I didn‚Äôt know upfront‚Ä¶ Plus, it‚Äôs been a good exercise.\nI realized after the fact, Sunday afternoon, it had been about 20 years I hadn‚Äôt ‚Äúdug‚Äù so deep into SysAdmin stuff.\nAlso: Praise to ‚Äúdislocker‚Äù. Really great stuff.\nAnd also: Ubuntu wouldn‚Äôt cut it (almost! but then no); neither did SystemRescue. Kali was the distro that would have the up-to-date-enough version of dislocker in the end. Without which, there was no opening the f$*#‚Äù disk‚Ä¶ (A few hours lost right there‚Ä¶)"
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#so-whats-next",
    "href": "posts/2025-09-30_various_updates/index.html#so-whats-next",
    "title": "Miscelanea week of sorts",
    "section": "So what‚Äôs next?",
    "text": "So what‚Äôs next?\nWell, a few other things happened.\nI have a presentation ready‚Ä¶ To do a 1h+ stint. It turns out, I will only get 15‚Äô. I should have asked earlier, this one is on me.\nSo first, I need to make my RLCS presentation comprehensible and useful for a 15‚Äô (tops!) session. Which, for who knows me, is difficult. I have a much easier time talking more, than I have talking less!\n‚ÄúIt‚Äôs long because I didn‚Äôt have the time to make it shorter‚Äù is a saying (no idea of the source). It applies, here. I have a month ahead of me to squeeze the valuable stuff of the RLCS package into a 10 to 15‚Äô presentation. Alright, it‚Äôs not that bad, feasible.\nAnd then, for no reason whatsoever, I got reminded (thanks random LinkedIn posts) about the ARC-AGI1 challenge. And it got my head spinning."
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#arc-agi-as-a-new-blog-topic",
    "href": "posts/2025-09-30_various_updates/index.html#arc-agi-as-a-new-blog-topic",
    "title": "Miscelanea week of sorts",
    "section": "ARC-AGI as a new Blog topic",
    "text": "ARC-AGI as a new Blog topic\nWell, it‚Äôs ambitious indeed. But heck, why not? So it‚Äôs official, I‚Äôll look into it. Even if I finally decide I can‚Äôt barely start tackling the challenge, I‚Äôm somehow certain I will learn stuff along the way.\nHeck, a few initial outcomes of simply thinking about it:\n\nAfter a few hours giving it some thought, it‚Äôs clear almost none of what I have done thus far will help me with this challenge. (Link in resources, if you don‚Äôt know it).\nI think one key aspect of this ‚Äúfew shots learning‚Äù approach, after trying some examples myself, is about finding what changes. So I‚Äôm thinking XOR right there. But XOR what?\nI think I need to somehow‚Ä¶ Represent knowledge? IDK! Oh, and this reminisces of course some ‚ÄúKnowledge Graphs‚Äù concepts, which I was not a big fan of, but maybe now I‚Äôll give them a thought.\nTalking about graphs!\n\nOne aspect of the ARC AGI thing that isn‚Äôt helpful is‚Ä¶ It‚Äôs a rather ‚Äúvisual‚Äù challenge, and I‚Äôm more of a tabular-data or, sometimes, text-only-data person. So this is a challenge a bit. But I already learnt I can do ‚Äúkernels‚Äù and understand them a bit‚Ä¶\nWell, I found something else that is interesting for this challenge, and uses graphs! It‚Äôs an algorithm called ‚ÄúConnected Components Labelling‚Äù and I found it marvelous, well because it uses graphs :)\n\nI won‚Äôt go into details, but it turns out it‚Äôs just so very similar in my mind to the Bongard problems (which I discovered in the ‚Äúbible‚Äù GEB‚Ä¶)"
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#various-notes",
    "href": "posts/2025-09-30_various_updates/index.html#various-notes",
    "title": "Miscelanea week of sorts",
    "section": "Various notes",
    "text": "Various notes\nI have yet to finish Hofstadter‚Äôs ‚ÄúG√∂del, Escher, Bach‚Äù. I just don‚Äôt fathom reading it with anything less than 100% of attention, and no more than one chapter at a time. And I read quite a few books at the same time, and so this one is taking me forever! But I definitely intend to finish it in due time.\nOh, and yes, there is an ARC AGI2. But let‚Äôs not even get there yet. It‚Äôs not the goal."
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#conclusion",
    "href": "posts/2025-09-30_various_updates/index.html#conclusion",
    "title": "Miscelanea week of sorts",
    "section": "Conclusion",
    "text": "Conclusion\nFor my anonymous person, good results: We got her data back.\nFor me? Not so tangibly-productive a week, I guess, but I have had time to think about innovation (oh, that‚Äôs right: I‚Äôm also reading ‚ÄúThe Idea Factory‚Äù, about Bell Labs, by J. Gertner, and enjoying it inmensely, although here again, I‚Äôm taking my sweet time, maybe getting a couple of chapters out of the way each week‚Ä¶ Still!). Right, so, thinking about ARC AGI, innovation, but also about Cybersecurity, as I have drifted a bit away from my ‚Äúcore topic‚Äù by following my various curiosities‚Ä¶\nSometimes, not doing, thinking, is good too."
  },
  {
    "objectID": "posts/2025-09-30_various_updates/index.html#resources",
    "href": "posts/2025-09-30_various_updates/index.html#resources",
    "title": "Miscelanea week of sorts",
    "section": "Resources",
    "text": "Resources\nhttp://github.com/Aorimn/dislocker -&gt; VERY USEFUL.\nhttps://arcprize.org/arc-agi/1/ -&gt; VERY INTERESTING.\nhttps://en.wikipedia.org/wiki/Bongard_problem -&gt; Maybe inspiration for Chollet‚Äôs ARC AGI?\nhttps://en.wikipedia.org/wiki/G%C3%B6del%2C_Escher%2C_Bach -&gt; THE ‚ÄúGEB‚Äù, no two books like this one.\nhttps://en.wikipedia.org/wiki/Connected-component_labeling -&gt; I definitely will take this as part of my work on the ARC AGI challenge!"
  },
  {
    "objectID": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html",
    "href": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html",
    "title": "RLCS is now published!",
    "section": "",
    "text": "About a year ago (my first post on this topic was published in December 2024) I decided to look into developing my first R package for an (almost) unknown Machine Learning algorithm, John H. Holland‚Äôs ‚ÄúLearning Classifier System‚Äù.\nWell, it is now a real thing. The project is published and available on my GitHub.\n\n\n\nFirst Description of the Help for RLCS\n\n\nNow this means a few things for me:\n\nI am now ‚Äúcapable‚Äù of coding an R Package, and share it. (Granted, there is still some work to be done, but heck, it‚Äôs a milestone for me regardless).\nI took a description of an algorithm, and made it into an R Package from scratch.\nI am making a dent in the World of ML in the sense that this particular algorithm is symbolic and interpretable/explainable. I feel rather strongly about this aspect.\n\nYes, I am a bit proud. Even though this thing is very ‚Äúniche‚Äù.\nAlso, publishing the package was a pre-requisite for the upcoming November presentation, where the audience is meant to be able to test it themselves, and I was worried anything would go wrong on the road to making the code available. It didn‚Äôt. I have tested the whole process from the GitHub a couple of times, from Windows and from MacOSX. Provided you have the right version of Rcpp, things are working fine.\nI can now demo the thing and get the (R enthusiasts) audience to follow along. So yeah, I‚Äôm good with this right now."
  },
  {
    "objectID": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#a-milestone-for-this-project",
    "href": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#a-milestone-for-this-project",
    "title": "RLCS is now published!",
    "section": "",
    "text": "About a year ago (my first post on this topic was published in December 2024) I decided to look into developing my first R package for an (almost) unknown Machine Learning algorithm, John H. Holland‚Äôs ‚ÄúLearning Classifier System‚Äù.\nWell, it is now a real thing. The project is published and available on my GitHub.\n\n\n\nFirst Description of the Help for RLCS\n\n\nNow this means a few things for me:\n\nI am now ‚Äúcapable‚Äù of coding an R Package, and share it. (Granted, there is still some work to be done, but heck, it‚Äôs a milestone for me regardless).\nI took a description of an algorithm, and made it into an R Package from scratch.\nI am making a dent in the World of ML in the sense that this particular algorithm is symbolic and interpretable/explainable. I feel rather strongly about this aspect.\n\nYes, I am a bit proud. Even though this thing is very ‚Äúniche‚Äù.\nAlso, publishing the package was a pre-requisite for the upcoming November presentation, where the audience is meant to be able to test it themselves, and I was worried anything would go wrong on the road to making the code available. It didn‚Äôt. I have tested the whole process from the GitHub a couple of times, from Windows and from MacOSX. Provided you have the right version of Rcpp, things are working fine.\nI can now demo the thing and get the (R enthusiasts) audience to follow along. So yeah, I‚Äôm good with this right now."
  },
  {
    "objectID": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#status-summary",
    "href": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#status-summary",
    "title": "RLCS is now published!",
    "section": "Status summary",
    "text": "Status summary\nIt is still a simple version:\n\nIn practice, I still only accept ‚Äúbinary strings‚Äù for the input states. I will keep working on the ‚ÄúRosetta Stone‚Äù function to get everyone to see this is just a ‚Äúconceptual‚Äù limitation.\nThe more important limitation is that of speed, when comparing with other algorithms. This is alright, I consider it a trade-off for the interpretability of the output. That said, I have done some tests to make it work in parallel processing settings (and it does work). But that‚Äôs really making it more ‚Äúcomplex‚Äù and I do not include the parallel stuff in the Package quite on purpose, mainly because of additional dependencies that I want to avoid. I will probably make some demos available. Maybe in the future I create a separate package that adds the dependencies and wraps things so that parallel processing is made more transparent. But not for now.\nSimple demos included only, for now. I will make sure to share three examples in the end: Binary rules ‚Äúdata mining‚Äù (the simplest example), some numerical dataset supervised classification (e.g.¬†iris), and some image stuff (my working example of MNIST 0-1 classifier would suffice, but I need to make it easier to try out).\nReinforcement Learning. This is something I dedicated quite some effort to. And I want to show it to the World. I am just struggling with the how to ‚Äúwrap‚Äù it into the package so that the interaction with a theoretical environment can be shown while not making the user worry about every step. This might take a bit."
  },
  {
    "objectID": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#conclusion",
    "href": "posts/2025-09-21_RLCS_Now_available_on_GitHub/index.html#conclusion",
    "title": "RLCS is now published!",
    "section": "Conclusion",
    "text": "Conclusion\nIt is not ‚Äúfinished‚Äù. It might well never be‚Ä¶\nBut right now, I need to shift focus to re-working the presentation explaining the whole thing.\nI want to make sure it is a bit easier to follow, less confusing, namely about the ‚Äúbinary input‚Äù: this is an implementation limitation, somehow people focus a lot on it, while it is not part of the LCS algorithm and not a real issue. The ‚Äúrosetta stone‚Äù function is there just for that, but is too simplistic and poorly put together one morning‚Ä¶ So I‚Äôll give it a bit more of my time.\nBut I am confident this will now all turn out fine. The milestone is there. Now I need to make sure I communicate more about it. See if I can get people to give it a little bit of attention, as the message (‚Äúpractical symbolic ML‚Äù) is important.\nActually‚Ä¶ Even if my implementation is not the best way to go, that‚Äôs no matter: the message is what counts, in the end."
  },
  {
    "objectID": "posts/2020-06-20_FirstEntry_orig/index.html#note-first-post-ever-reproduced",
    "href": "posts/2020-06-20_FirstEntry_orig/index.html#note-first-post-ever-reproduced",
    "title": "First Entry: Variables",
    "section": "NOTE: First post ever, reproduced",
    "text": "NOTE: First post ever, reproduced\nThis one was my first-ever Blog post on the original kaizen-r.com site. I‚Äôm just reproducing it here out of‚Ä¶ Nostalgia, I guess.\nAnyway‚Ä¶ Onward!"
  },
  {
    "objectID": "posts/2020-06-20_FirstEntry_orig/index.html#variables",
    "href": "posts/2020-06-20_FirstEntry_orig/index.html#variables",
    "title": "First Entry: Variables",
    "section": "Variables",
    "text": "Variables\nVariables are sometimes overseen as ‚Äúobvious‚Äù. Or at least, ‚Äúhow to name them‚Äù.\nBut after some time programming on your own, particularly in languages like R (from my experience at least), you find you could make mistakes. And after a while, you kind of re-use the same variable names, not necessarily for a reason.\nFor me, it was:\nmydf\nThat I read in a book one day (some years ago now) when I was beginning my programming in R, and it just stuck, from the very first few exercises onwards. There is nothing particularly wrong with that‚Ä¶ Or is there?\nIt‚Äôs also easy to use a variable called ‚Äúa‚Äù for a quick script. Then obviously you end up using: ‚Äúb‚Äù, ‚Äúc‚Äù‚Ä¶\na &lt;- 1\nb &lt;- 2\nc &lt;- \"a string\"\nBut wait. c() is actually a function in R (a pretty important one at that). You actually CAN use ‚Äúc‚Äù as a variable name, but maybe you shouldn‚Äôt‚Ä¶\nYes, this is a basic concept, but even then, you must be careful. I created a ‚Äúfactorial‚Äù variable not long ago to demo how to program a factorial calculation using a while loop‚Ä¶ Only to find out later on that, duh!, factorial() is also a function in R‚Ä¶ (One that wasn‚Äôt useful in that particular case as the goal was to demo while loops, but‚Ä¶ I had never used ‚Äúfactorial(n)‚Äù before in R, I simply never had had the need‚Ä¶ Anyway!)"
  },
  {
    "objectID": "posts/2020-06-20_FirstEntry_orig/index.html#so-how-do-i-name-a-variable-and-a-function-and-why-not-a-file",
    "href": "posts/2020-06-20_FirstEntry_orig/index.html#so-how-do-i-name-a-variable-and-a-function-and-why-not-a-file",
    "title": "First Entry: Variables",
    "section": "So how DO I name a variable? And a function? And (why not) a file?",
    "text": "So how DO I name a variable? And a function? And (why not) a file?\nLet‚Äôs try to answer the first one for now.\nVariables can be named almost anything in R. Well, mostly, alfa-numerics, plus dot(.) and underscore are allowed. Some exceptions apply:\n.1myvariable\nThat would not work. More to the point, I would not recommend it üôÇ\nOther considerations, besides what‚Äôs permitted or not, might be:\n\nLong variable names end up being heavy on the eye, particularly when you do things like (in R):\n\nmylongdataframename[mylongdataframename$somevariablenameinthedataframe == 1,]\nThat happens a lot. Yes, it did happen to me (more than I care to admit).\n\nYou also might want to consider that others might want to read your code, and so variables like ‚Äúx‚Äù, or ‚Äútdffwd‚Äù might not be too good either.\nThen you come across recommendations out there: camelCase, dot (.) separator, underscores‚Ä¶ Each of which have pros and cons. Too much literature on the topic to be convinced ‚Äì one way or another, with good arguments for or against any of these.\nVariable names might include object information: Is it a string, so I can end my variable name with _s? a data frame, _df? But then this goes against the idea of making variables ‚Äúshort‚Äù, or, at least, ‚Äúconcise‚Äù.\nMoreover, you might want to choose one way to go for ALL the coding languages you use (or, well, as many as possible). So in Python (usually Python is ‚Äúright there‚Äù when you talk about R), calling an object‚Äôs method uses the dot (.), which in turn might push you away from it for your day-to-day variable naming conventions.\n\nAt the end of the day, I chose the following:\n\nI use underscore (_), to separate words in the variable names. This is subject to debate out there, but that‚Äôs just my choice üôÇ\nI use all lower-case for all variable names, and for functions. This is not a recommendation, you can come up with your own system of course. I can differentiate simply because if I‚Äôm calling a function, there will be a () after it (duh!)\nI try to use real complete words, or ‚Äústems‚Äù where it makes sense, to keep it short.\nI agree with the concept of ‚Äúnouns‚Äù for variable names, and ‚Äúverbs‚Äù for functions.\nI have ‚Äúshortcuts‚Äù: For example, I use ‚Äún‚Äù for a number, usually a quantity/count."
  },
  {
    "objectID": "posts/2020-06-20_FirstEntry_orig/index.html#conclusion",
    "href": "posts/2020-06-20_FirstEntry_orig/index.html#conclusion",
    "title": "First Entry: Variables",
    "section": "Conclusion",
    "text": "Conclusion\nAs you can see, this post is extremely ‚Äúbasic‚Äù in concept.¬†\nBut I found that this kind of details, overtime, can impact your code, how readable it is, how fast you can program‚Ä¶ How much you have to think about how to name a variable is surprisingly full of impact on the resulting code. And maybe it is, partly at least, an art, more than science. Either way, every programmer has had these concepts in mind at some point. Those that have thought about it might be, arguably, one step ahead. ‚ÄúThe devil lies in the details‚Äù, or so they say.\nTO BE CONTINUED‚Ä¶"
  },
  {
    "objectID": "posts/2020-06-20_FirstEntry_orig/index.html#references",
    "href": "posts/2020-06-20_FirstEntry_orig/index.html#references",
    "title": "First Entry: Variables",
    "section": "References",
    "text": "References\nhttps://www.r-bloggers.com/r-code-best-practices/\nhttps://style.tidyverse.org/syntax.html#object-names\nhttps://stackoverflow.com/questions/1944910/what-is-your-preferred-style-for-naming-variables-in-r\nSomewhat related references:\nhttps://www.r-bloggers.com/r-best-practices-r-you-writing-the-r-way/\nhttps://google.github.io/styleguide/Rguide.html"
  },
  {
    "objectID": "posts/2024-10-12_Testing_LLM_Apple/index.html",
    "href": "posts/2024-10-12_Testing_LLM_Apple/index.html",
    "title": "Testing LLMs locally on basic Apple Silicon",
    "section": "",
    "text": "I have learned since. But back in October 2024, I did run the following test.\nNowadays, I prefer Meta‚Äôs OLlama for its simplicity - although I still haven‚Äôt tested it on Apple Silicon, that‚Äôs true too. (And I‚Äôm no fan of Meta, but OLlama is easy to use, runs locally, and my tests thus far were quite good. You have to admit the good, sometimes, too).\nThis entry is reproduced from the ‚Äúold‚Äù blog."
  },
  {
    "objectID": "posts/2024-10-12_Testing_LLM_Apple/index.html#new-intro",
    "href": "posts/2024-10-12_Testing_LLM_Apple/index.html#new-intro",
    "title": "Testing LLMs locally on basic Apple Silicon",
    "section": "",
    "text": "I have learned since. But back in October 2024, I did run the following test.\nNowadays, I prefer Meta‚Äôs OLlama for its simplicity - although I still haven‚Äôt tested it on Apple Silicon, that‚Äôs true too. (And I‚Äôm no fan of Meta, but OLlama is easy to use, runs locally, and my tests thus far were quite good. You have to admit the good, sometimes, too).\nThis entry is reproduced from the ‚Äúold‚Äù blog."
  },
  {
    "objectID": "posts/2024-10-12_Testing_LLM_Apple/index.html#old-intro",
    "href": "posts/2024-10-12_Testing_LLM_Apple/index.html#old-intro",
    "title": "Testing LLMs locally on basic Apple Silicon",
    "section": "OLD Intro",
    "text": "OLD Intro\nFair enough, I keep criticizing the GenAI hype. But in order to criticize something, I guess I believe I have to have SOME kind of understanding of what happens (silly me I guess for thinking like that).\nAfter brushing up on AI these past few weeks, mostly through readings, including what others might consider the ‚Äúless fun stuff‚Äù (which I personally find fascinating, though) such as ‚Äúwords embeddings‚Äù, transformers architecture (still not 100% clear on these), Recurrent NeuralNets, ‚ÄúWord2Vec‚Äù (very cool!), it was time I moved on to the actual fun: Testing an LLM.\nAnd I have had a worry: Being a MacBook (Air, M1) user, is there any way I can test using an LLM and make it work locally?\nThere sure is. I did it the other day."
  },
  {
    "objectID": "posts/2024-10-12_Testing_LLM_Apple/index.html#mlx-lm",
    "href": "posts/2024-10-12_Testing_LLM_Apple/index.html#mlx-lm",
    "title": "Testing LLMs locally on basic Apple Silicon",
    "section": "MLX-LM",
    "text": "MLX-LM\nThat‚Äôs the name for it. Think Apple‚Äôs version of things to use its GPU for (in this case) GenAI (more generally: MLX is for ML‚Ä¶ Duh!).\nJust a few things to set up. This post is not about me being clever or coding much, instead I‚Äôm just testing the thing. I just want to KNOW it works. No NVidia GPU, no crazy resources, no Internet connection‚Ä¶\nAnd to achieve that, I only had to follow a mix of a couple of resources (see Resources section).\nWith a Python3 venv, some pip, the mlx-ml, a HuggingFace account (for login, and then to download Mistral-7B), and of course a MacBook Air (M1, in my case), I just was able to generate 100 tokens out of a simple prompt, WHILE OFFLINE:\n\n\n\nAsking a local LLM to answer a simple question\n\n\nAnd that‚Äôs about it!"
  },
  {
    "objectID": "posts/2024-10-12_Testing_LLM_Apple/index.html#conclusion",
    "href": "posts/2024-10-12_Testing_LLM_Apple/index.html#conclusion",
    "title": "Testing LLMs locally on basic Apple Silicon",
    "section": "Conclusion",
    "text": "Conclusion\nAll that is not to say my laptop is well suited for any of this. I‚Äôd have to consider training things a bit to learn more, just ‚Äúgenerating answers‚Äù is not a use-case that would justify worrying so much. But I really wanted to try it for myself, and make it work OFFLINE (which to me is very important, go figure). There would be much more to this, but it‚Äôs a good start, and I‚Äôll leave it at that for now.\n\nResources\nIt started here (But then me signing licenses for this one test was silly, so I moved away from Llama-3-8B‚Ä¶)\nThis resource made the day\nAnd HuggingFace is COOL. I read a bit through this, for instance."
  },
  {
    "objectID": "posts/2022-11-06_Optimization_gettingStarted/index.html",
    "href": "posts/2022-11-06_Optimization_gettingStarted/index.html",
    "title": "Getting Started with Optimization",
    "section": "",
    "text": "Intro\nI‚Äôve mentioned I‚Äôm looking for a subject for my project, and that one of the concepts I‚Äôd like to leverage is what‚Äôs commonly called ‚ÄúOperations Research‚Äù, also known more generally as ‚ÄúOptimization‚Äù.\nOf course, I want to use R for it üôÇ\nAnd so I chose a course about that. The course has started, and there are some initial exercises to be delivered (for now, rather introductory, it will get harder‚Ä¶). Now ‚ÄúR‚Äù is not a chosen alternative officially for the course, but I am authorized to use it. And so I shall.\nThis here is a sample of one of the initial exercises. As the exercise is mostly about reproducing something that already is detailed, I feel I am breaking no rule by creating an alternative solution (it‚Äôs really a very mainstream example), plus I‚Äôm doing it here in another programming language.\nSo here goes.\n\n\nThe exercise\n‚ÄúA manager has to decide how much time to allocate between radio and TV advertising.\n\nAt least 70% of the time should be allocated to TV.\nThe audience exposure per minute is 150 users for radio and 800 users for TV.\nThe cost per minute is 400 ‚Ç¨ for radio and 2,000‚Ç¨ for TV.\nThere is an available budget of 25,000‚Ç¨.\nHow many minutes should the manager allocate to each medium if she wants to maximize audience exposure?‚Äù\n\n\n\nThe math\nThe only difficulty of the above exercise is how to express that ‚Äú70% of the time‚Äù should be allocated to TV.\nIf ‚Äúx1‚Äù is Radio time, and x2 is TV time, we want to make sure that \\(x2 &gt;= 0.7 (x1+x2)\\)\nOne trick we will use is to change a ‚Äúgreater than‚Äù constraint into its negated version, thereby getting to a ‚Äúlower than‚Äù constraint. With some re-work, we can get to the second of the inequalities shown below:\n\n\n\nThe code\nSo now we‚Äôre about ready to implement this in R. This time around, we will test the boot package, and its implementation of the simplex() function.\na&lt;-c(150,800) # Objective function's Coefs.\n\n# m1*n coefs (lhs) &lt;= constraints\n#A1&lt;-rbind(c(400, 2000),c(0.7, -0.3)) # Alternative\nA1&lt;-matrix(c(400, 2000, 0.7, -0.3),nrow = 2, ncol=2, byrow=TRUE) \nb1 &lt;- c(25000,0) # Vector m1 (rhs) &lt;= constraints.\n\nA2 &lt;- NULL # m2*n coefs (lhs) &gt;= constraints\nb2 &lt;- NULL # Vector m2 (rhs) &gt;= constraints.\n\nadv_alloc_simplex_res &lt;- simplex(a=a, A1=A1, b1=b1, A2=A2, b2=b2, maxi=\"TRUE\") # Maximize Objective.\nadv_alloc_simplex_res\nOne of the reasons to set all the inequalities with ‚Äúlower than‚Äù configurations was because certain R packages do not accept ‚Äúgreater than‚Äù comparisons. As they are in fact equivalent with a simple multiplication by ‚Äú-1‚Äù, all is good for us here. Here the corresponding output (it is the right answer with the selected conditions):\n\nSo you should really choose to go all in with the TV budget, with 12.5 minutes in total, for a maximized audience of 10K viewers.\nVisually, the matlib package includes some alternative for simple scenarios like this one to visualize the result:\n\n\n\nConclusions\nThis concludes our first tentative at doing Operations Research in R üôÇ\nIt‚Äôs not too difficult. Really as it often happens in these cases, making sure you get the equations and inequalities right will be key, as the code itself is not too complex.\n\n\nReferences\nThe above code on my GitHub"
  },
  {
    "objectID": "posts/2021-07-18_NLP_partII/index.html",
    "href": "posts/2021-07-18_NLP_partII/index.html",
    "title": "Tokens of Text",
    "section": "",
    "text": "It‚Äôs all great: We‚Äôre able to collect all our blog entries, or well, the text thereof. We are even able to crawl a bit faster, provided we have a multi-core setup. (Worst case scenario, we‚Äôre limited in the crawling by the speed of our website‚Äôs, mostly).\nNow that we have that, let‚Äôs do a very simple first exercise: Let‚Äôs look at the distribution of ‚Äútokens‚Äù in our text.\nFor now, we‚Äôll focus on the ‚Äúfirst‚Äù article in the list (as it turns out‚Ä¶ The last one published, before this one). We won‚Äôt go into too much detail, as this NLP topic is a very wide subject matter to cover, so allow me to go ‚Äústep by step‚Äù."
  },
  {
    "objectID": "posts/2021-07-18_NLP_partII/index.html#a-first-basic-look-at-the-collected-text-tokens",
    "href": "posts/2021-07-18_NLP_partII/index.html#a-first-basic-look-at-the-collected-text-tokens",
    "title": "Tokens of Text",
    "section": "",
    "text": "It‚Äôs all great: We‚Äôre able to collect all our blog entries, or well, the text thereof. We are even able to crawl a bit faster, provided we have a multi-core setup. (Worst case scenario, we‚Äôre limited in the crawling by the speed of our website‚Äôs, mostly).\nNow that we have that, let‚Äôs do a very simple first exercise: Let‚Äôs look at the distribution of ‚Äútokens‚Äù in our text.\nFor now, we‚Äôll focus on the ‚Äúfirst‚Äù article in the list (as it turns out‚Ä¶ The last one published, before this one). We won‚Äôt go into too much detail, as this NLP topic is a very wide subject matter to cover, so allow me to go ‚Äústep by step‚Äù."
  },
  {
    "objectID": "posts/2021-07-18_NLP_partII/index.html#tokenization-stemming",
    "href": "posts/2021-07-18_NLP_partII/index.html#tokenization-stemming",
    "title": "Tokens of Text",
    "section": "Tokenization & Stemming",
    "text": "Tokenization & Stemming\nSo let‚Äôs see if we‚Äôre able to extract unique ‚Äúwords‚Äù from the article contents. We‚Äôll use the generally accepted ‚ÄúMC_tokenizer‚Äù function from the tm package here.\ntokens_art_1 &lt;- MC_tokenizer(all_articles_df_vfuture[1, \"article_content\"])\nWe get 964 tokens (or words, in this case)! For one rather short article‚Ä¶\nBut then again, this is noisy. And also, these are all the tokens. To get an idea of my vocabulary in English (which incidentally is not my mother tongue, far from it‚Ä¶), let‚Äôs count unique tokens, after some cleaning up:\n# There'll probably some noise, let's clean that a bit:\ntokens_art_1 &lt;- sapply(tokens_art_1, tolower)\ntokens_art_1 &lt;- as.character(removeWords(tokens_art_1, stopwords(\"english\")))\ntokens_art_1 &lt;- tokens_art_1[tokens_art_1 != \"\"]\ntokens_art_1 &lt;- wordStem(tokens_art_1)\nSo as for our computer upper-case and lower-case matter, we put everything into lower-case. Then we remove the english ‚Äústop-words‚Äù as provided by the tm package. Here is the complete list of these:\n\nOnce we removed these, we clean up the list of tokens from the article (removing stop-words has left empty entries‚Ä¶).\nBut then here we go further down the road of concepts, as we introduce ‚ÄúStemming‚Äú. So stemming is, well, looking for the stem of a word. So for example, ‚Äúrunning‚Äù, ‚Äúrunner‚Äù and ‚Äúrun‚Äù are all derived from their stem ‚Äúrun‚Äù. We use the ‚ÄúwordStem‚Äù function from the SnowBallC package in this instance.\nLong story short, we can look for the most common words in the article, after some clean-up and stemming:\n\nMmmmm‚Ä¶ So I mention ‚Äúpage‚Äù almost twenty times? And ‚Äúarticl‚Äù 8 times? Let‚Äôs do a quick check, just in case:\n\nWell that seems about right. Although I‚Äôll have to get myself a Thesaurus, I guess.\n\nConclusions\nEnough for today. We got our quick review of Tokens and Stemming. We counted unique words in our document and did some basic cleaning.\nMore on NLP soon."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html",
    "href": "posts/2024-12-08_A_new_project/index.html",
    "title": "A new project",
    "section": "",
    "text": "Ever since I read about the concept in M. Mitchell‚Äôs book ‚ÄúComplexity The emerging science at the edge of order and chaos‚Äù some time last year (I think around this time of the year‚Ä¶), I have been thinking about this, in the background of my head.\n\n\n\nWhat piqued me curiosity\n\n\nThe weird strings above, the 11##10### thing, might mean nothing to most right now (you have to look a bit further into it all, and I‚Äôll probably try and explain some of it in the future), but it was a revelation to me when I first read it.\nSo yes, I‚Äôve had other fish to fry for some time, but now it feels like I might just have the mental space to shift my focus a bit‚Ä¶\n\n\nSo here is my upcoming project, explained in one picture:\n\n\n\nMy new project in one picture\n\n\n(By the way, a personal note here: buying that left book in physical format from Springer was one ‚Äútough cookie‚Äù, thank goodness I‚Äôm motivated, it‚Äôs quite possibly the priciest book I ever bought from my own pocket, in ‚Ç¨-per-page‚Ä¶ Oh well: It looks it still was the right call for me :D)\n\n\n\nAs I said, I‚Äôve been a bit busy. Full-time job, MSc paper (success!), then summer, learning other stuff, (did I mention full-time job? :D)‚Ä¶ But it is time.\nI also have been thinking for quite some time I should try my hand eventually at creating my own R Package. This was all the more true after the last R conferences I attended recently, where it looks like ‚Äúeveryone is doing it‚Äù in the R (mostly academic) community‚Ä¶ So why not me?\nPlus, I have an idea or two. So what if I‚Äôm not the greatest coder out there? I still do have some tricks in my sleeves ;) I have proved (at least to myself) I can do highly distributed processing using (among other things) R and create my own thing. (My very own algorithm, that was.)\nPlus, I‚Äôm into ML just as much as the next person, but I‚Äôve also played quite a bit with Genetic Algorithms recently. And I believe I have all it takes to put that to good use here. (I‚Äôm just a bit sad this will not involve Network Graphs, the way I have it designed (yet, anyway :D).) I believe I understand how the LCS algorithms might be particularly useful in their own specific way. I can see in my head how they must work, what makes them different, all in spite of not having written one line of code yet.\nNow, it might take a while, indeed. Why, with the Holiday season coming, the day job and all. But I have a sort of a plan in mind, already an architecture (in my head, for now), examples of how I would want to validate the implementation (that last thing, one example with application to cybersecurity and logs classification, in particular, woke me up in the middle of the night a couple of weeks back).\nAnd R packages, from what I have read thus far, are not ‚Äúmagic‚Äù. It‚Äôs going to be work, for sure, but I don‚Äôt see anything I can‚Äôt manage. If anything, it‚Äôs less complicated than I thought. I‚Äôve already played with testthat, microbenchmark, I‚Äôve always separated my code in functions, separated R and C++ code, all that‚Ä¶ So yeah, I think I‚Äôm up to the task.\nAnd finally, a note about the ‚Äúwhy now‚Äù: I can‚Äôt find it done yet!! Which to me is quite incredible. I have found this niche, that nobody (in the R community) has deemed relevant enough thus far, and I am willing to put the work towards filling that niche!\n\n\n\nThis here today is me announcing, basically, my intention to create and (hopefully) get my future new RLCS package onto CRAN. I know, I know, I‚Äôm getting WAAAAY ahead of myself here.\nAnd I realize me publishing this entry might very well mean someone beats me to it. If that happens, well‚Ä¶ I‚Äôm already convinced my implementation will be ‚Äúcompetitive‚Äù, so‚Ä¶ let‚Äôem!\n(Plus, why would anyone decide to go for this now? It would just make no sense whatsoever - if not to bother me. If that‚Äôs you: Just give me a few months, and you‚Äôll save yourself the trouble :D)\n\n\n\nIt turns out, for some reason, I know I will. Obviously, I don‚Äôt ‚Äúknow know‚Äù, it‚Äôs more of a feeling.\nI am enthused, to begin with. I have the knowledge. Time is not an issue, although it will take me probably a few months (my best estimate right now, given my current known agenda, is 3-4 months for a functional package, plus whatever time it takes for submission to CRAN of a ‚Äúv001‚Äù).\nMoreover, I somehow needed a new, rather difficult, interesting long-term personal objective. I feel this will help me get in the ‚Äúflow‚Äù, which is a great feeling (but hard to come by).\nAlso, I have this crazy idea that, once the thing works, I can dive further into it and study it towards a bigger goal, maybe research, ideally even (who knows) a PhD‚Ä¶?\n\n\n\nI‚Äôve done my first (of two) presentation about ‚ÄúBackground of ML for Cybersecurity‚Äù. I actually had trouble with some of the demos during the first session :S But not because of the demos themselves, just, ‚Äúheat of the moment‚Äù, computer resources, demo effect, and so on. Nothing major.\nThankfully, I get a second chance, as there is a second session coming. And I have time to prepare some more examples, so that‚Äôs good too, the second session will be all-the-more interesting.\nBut because I have some time, I‚Äôm making a pause there and re-focusing on this new project of mine as a personal interest thing.\n\n\n\nI realize nobody cares, but heck: I do. I need to ‚Äúmigrate‚Äù, move everything (while reviewing each thing) from the old blog to this new setup, because.. Well, because this platform is more convenient, and ‚Äì let‚Äôs be honest ‚Äì cheaper‚Ä¶ After all, it‚Äôs one thing to write for one own‚Äôs pleasure, and quite another to spend money with no return year after year just to maintain it.\nSo yes, I need to organize myself to minimize future costs a bit (it just is the sensible thing to do, economically).\n\n\n\n**This is important: I still don‚Äôt really know why this family of algorithms have received sooo little attention**, beyond the fact that ‚ÄúConnectionism‚Äù has received a lot of said attention (deservingly, for sure).\nBut I‚Äôm curious about whether LCS can be made (ideally equally) valuable. And I have the personal conviction that I am in the right position to dig further into it.\nAnd so it is time, I‚Äôm in an ideal position, and I‚Äôm motivated.\nNow all I have to do is‚Ä¶ Start!\n(To start hear means also put thoughts to paper, design, code, test, document‚Ä¶ Don‚Äôt expect lots of news too soon, either! I‚Äôm not in a hurry, nobody should be: this thing has been known since the 70‚Äôs and it looks like few - aside from noted exceptions - have cared about it thus far‚Ä¶)\n\n\n\nThis is the best intro explaining the algorithm that I found thus far - and if anything it confirmed I was on the right path. It just makes a lot of sense to me!"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#the-new-project",
    "href": "posts/2024-12-08_A_new_project/index.html#the-new-project",
    "title": "A new project",
    "section": "",
    "text": "So here is my upcoming project, explained in one picture:\n\n\n\nMy new project in one picture\n\n\n(By the way, a personal note here: buying that left book in physical format from Springer was one ‚Äútough cookie‚Äù, thank goodness I‚Äôm motivated, it‚Äôs quite possibly the priciest book I ever bought from my own pocket, in ‚Ç¨-per-page‚Ä¶ Oh well: It looks it still was the right call for me :D)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#why-now-why-me",
    "href": "posts/2024-12-08_A_new_project/index.html#why-now-why-me",
    "title": "A new project",
    "section": "",
    "text": "As I said, I‚Äôve been a bit busy. Full-time job, MSc paper (success!), then summer, learning other stuff, (did I mention full-time job? :D)‚Ä¶ But it is time.\nI also have been thinking for quite some time I should try my hand eventually at creating my own R Package. This was all the more true after the last R conferences I attended recently, where it looks like ‚Äúeveryone is doing it‚Äù in the R (mostly academic) community‚Ä¶ So why not me?\nPlus, I have an idea or two. So what if I‚Äôm not the greatest coder out there? I still do have some tricks in my sleeves ;) I have proved (at least to myself) I can do highly distributed processing using (among other things) R and create my own thing. (My very own algorithm, that was.)\nPlus, I‚Äôm into ML just as much as the next person, but I‚Äôve also played quite a bit with Genetic Algorithms recently. And I believe I have all it takes to put that to good use here. (I‚Äôm just a bit sad this will not involve Network Graphs, the way I have it designed (yet, anyway :D).) I believe I understand how the LCS algorithms might be particularly useful in their own specific way. I can see in my head how they must work, what makes them different, all in spite of not having written one line of code yet.\nNow, it might take a while, indeed. Why, with the Holiday season coming, the day job and all. But I have a sort of a plan in mind, already an architecture (in my head, for now), examples of how I would want to validate the implementation (that last thing, one example with application to cybersecurity and logs classification, in particular, woke me up in the middle of the night a couple of weeks back).\nAnd R packages, from what I have read thus far, are not ‚Äúmagic‚Äù. It‚Äôs going to be work, for sure, but I don‚Äôt see anything I can‚Äôt manage. If anything, it‚Äôs less complicated than I thought. I‚Äôve already played with testthat, microbenchmark, I‚Äôve always separated my code in functions, separated R and C++ code, all that‚Ä¶ So yeah, I think I‚Äôm up to the task.\nAnd finally, a note about the ‚Äúwhy now‚Äù: I can‚Äôt find it done yet!! Which to me is quite incredible. I have found this niche, that nobody (in the R community) has deemed relevant enough thus far, and I am willing to put the work towards filling that niche!"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#the-outcome",
    "href": "posts/2024-12-08_A_new_project/index.html#the-outcome",
    "title": "A new project",
    "section": "",
    "text": "This here today is me announcing, basically, my intention to create and (hopefully) get my future new RLCS package onto CRAN. I know, I know, I‚Äôm getting WAAAAY ahead of myself here.\nAnd I realize me publishing this entry might very well mean someone beats me to it. If that happens, well‚Ä¶ I‚Äôm already convinced my implementation will be ‚Äúcompetitive‚Äù, so‚Ä¶ let‚Äôem!\n(Plus, why would anyone decide to go for this now? It would just make no sense whatsoever - if not to bother me. If that‚Äôs you: Just give me a few months, and you‚Äôll save yourself the trouble :D)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#will-i-manage",
    "href": "posts/2024-12-08_A_new_project/index.html#will-i-manage",
    "title": "A new project",
    "section": "",
    "text": "It turns out, for some reason, I know I will. Obviously, I don‚Äôt ‚Äúknow know‚Äù, it‚Äôs more of a feeling.\nI am enthused, to begin with. I have the knowledge. Time is not an issue, although it will take me probably a few months (my best estimate right now, given my current known agenda, is 3-4 months for a functional package, plus whatever time it takes for submission to CRAN of a ‚Äúv001‚Äù).\nMoreover, I somehow needed a new, rather difficult, interesting long-term personal objective. I feel this will help me get in the ‚Äúflow‚Äù, which is a great feeling (but hard to come by).\nAlso, I have this crazy idea that, once the thing works, I can dive further into it and study it towards a bigger goal, maybe research, ideally even (who knows) a PhD‚Ä¶?"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#what-about-the-sessions-on-ml",
    "href": "posts/2024-12-08_A_new_project/index.html#what-about-the-sessions-on-ml",
    "title": "A new project",
    "section": "",
    "text": "I‚Äôve done my first (of two) presentation about ‚ÄúBackground of ML for Cybersecurity‚Äù. I actually had trouble with some of the demos during the first session :S But not because of the demos themselves, just, ‚Äúheat of the moment‚Äù, computer resources, demo effect, and so on. Nothing major.\nThankfully, I get a second chance, as there is a second session coming. And I have time to prepare some more examples, so that‚Äôs good too, the second session will be all-the-more interesting.\nBut because I have some time, I‚Äôm making a pause there and re-focusing on this new project of mine as a personal interest thing."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#and-what-about-the-migration-of-the-old-blog",
    "href": "posts/2024-12-08_A_new_project/index.html#and-what-about-the-migration-of-the-old-blog",
    "title": "A new project",
    "section": "",
    "text": "I realize nobody cares, but heck: I do. I need to ‚Äúmigrate‚Äù, move everything (while reviewing each thing) from the old blog to this new setup, because.. Well, because this platform is more convenient, and ‚Äì let‚Äôs be honest ‚Äì cheaper‚Ä¶ After all, it‚Äôs one thing to write for one own‚Äôs pleasure, and quite another to spend money with no return year after year just to maintain it.\nSo yes, I need to organize myself to minimize future costs a bit (it just is the sensible thing to do, economically)."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#conclusions",
    "href": "posts/2024-12-08_A_new_project/index.html#conclusions",
    "title": "A new project",
    "section": "",
    "text": "**This is important: I still don‚Äôt really know why this family of algorithms have received sooo little attention**, beyond the fact that ‚ÄúConnectionism‚Äù has received a lot of said attention (deservingly, for sure).\nBut I‚Äôm curious about whether LCS can be made (ideally equally) valuable. And I have the personal conviction that I am in the right position to dig further into it.\nAnd so it is time, I‚Äôm in an ideal position, and I‚Äôm motivated.\nNow all I have to do is‚Ä¶ Start!\n(To start hear means also put thoughts to paper, design, code, test, document‚Ä¶ Don‚Äôt expect lots of news too soon, either! I‚Äôm not in a hurry, nobody should be: this thing has been known since the 70‚Äôs and it looks like few - aside from noted exceptions - have cared about it thus far‚Ä¶)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#references",
    "href": "posts/2024-12-08_A_new_project/index.html#references",
    "title": "A new project",
    "section": "",
    "text": "This is the best intro explaining the algorithm that I found thus far - and if anything it confirmed I was on the right path. It just makes a lot of sense to me!"
  },
  {
    "objectID": "posts/2021-04-17_GoingAutoML/index.html",
    "href": "posts/2021-04-17_GoingAutoML/index.html",
    "title": "Going AutoML ‚Äì Clustering Example",
    "section": "",
    "text": "Now I‚Äôm probably NOT a good reference for this, but the ‚Äúlow-code‚Äù trend does make sense‚Ä¶ Up to a point. As long as you understand what you‚Äôre doing, it‚Äôs probably an OK approach.\nAfter all, one doesn‚Äôt need to be a mechanic to drive a car‚Ä¶ Although I‚Äôm certain there is a plus side if you actually are a mechanic. Bad example üôÇ\n\nIntro\nSo a few days ago (at the time of writing) a colleague asked me if I would be able to come up with a way of finding ‚Äúsimilar things‚Äù within a dataset‚Ä¶ And obviously I thought: ‚ÄúSure, that‚Äôs unsupervised ML, let‚Äôs do some clustering‚Äù. And so I started on the path to program a dashboard that would allow for applying some ‚ÄúK-Means‚Äù magic to data from a specific CSV file. Relevant detail: the data was text based, not numeric.\nI used some of the NLP concepts I already used in this blog post a few weeks back, to get to a numeric matrix first; then instead of doing ‚Äúsupervised‚Äù ML, I would do K-Means on the resulting matrix.\n\n\nOne way to go\nSay you receive a CSV (aka a dataframe for our objectives). Say you want to see how one variable (column) of entries can group together (or not). Say you call that the X entries. You could say column X has ‚Äúpersons‚Äù (John Doe, Jane Smith, etc.)\nNow this is NOT ideal (actually it‚Äôs a pretty dirty approach), but it IS one way to go and it does work in some cases at least:\nUse the resting variables (columns that DO NOT include Column X) as text entries, put them together as one column of text (so all text for each row becomes one cell of text). Then create one cell putting together ALL THE RESULTING text PER PERSON (column X) in yet another cell.\nNow you end up with one row per person, with all text from the original dataframe as one ‚Äútext cell‚Äù for each person. There will be repeated words, it will be messy as hell‚Ä¶ But then you can consider that NEW data frame as having documents per person (one row == one document).\n\n\nSo what would happen then?\nWhat if you applied TF-IDF on the resulting new data.frame?\nYou could then apply K-Means (or other Clustering algorithms) on the resulting dataset.\nNow that doesn‚Äôt sound like much but if you have followed, essentially in the above we have treated our ‚Äúpersons‚Äù as ‚Äúauthors‚Äù of ‚Äúbooks‚Äù.\nWe have then characterized their writing by applying TF-IDF on their ‚Äútext‚Äù (loosely extracted directly from the original data frame, which is NOT a great way to go, but it is a trick)‚Ä¶ For instance the original data frame might contain text variables that are not words‚Ä¶\nAnd then we have tried to see if there was any ‚Äúclustering‚Äù around our ‚Äúauthors‚Äù, in other words: maybe some ‚Äúauthors‚Äù would write with similar ‚Äúwords‚Äù (or frequency thereof) as others?\n\n\nDoes it actually work?\nJudge by yourself: I posted here my demo code for the above. (I‚Äôm not proud of that code, there is plenty of room for improvement, but for demo purposes that‚Äôs about enough.)\nFirst I create a dataframe with 5 rows, describing 4 theoretical persons (see below). So can we expect to identify some groups out of these four persons? Say 3 groups?\n(3 groups: 3 here is the ‚ÄúK‚Äù in K-Means, and it must be set ahead of time. Discussing ‚ÄúElbow-method‚Äù and the likes for optimal K selection is beyond our point for today, sorry, but let‚Äôs just say there is an easy visual way of identifying a ‚Äúgood number of clusters‚Äù ‚Äì there are plenty of resources out there about K-Means, so I won‚Äôt enter much into how it works today).\nVisually, we can tell we have separations between the persons in our dataframe:\n\nBut no clear choice for 3 groups, is there?\nThen let‚Äôs see what K-Means does for us (I just ran the function):\n\nOne could discuss long and large about whether this makes sense. First, entries for Nick were counted as one per our TF-IDF approach, so no surprise they‚Äôre in the same cluster.\nSecond, well, Nick set apart, we get one group with persons who like apples and cars, and a separate third group for‚Ä¶ Well, for good measure, as there were only four possible groups in our dataset.\nAgain: NOT A GREAT APPROACH. But the thing is, I do think it can be practical to call this function from time to time on data.frames for which I want to see if there is any kind of structure hidden inside.\nA better approach (obviously) ‚Äì and the usual way to go about K-Means ‚Äì is to test for different numbers of clusters, but that‚Äôs for an actual more serious deployment, which is beyond the point of this Blog entry.\nMaybe a couple of warnings: For high dimensionality (many unique words or rather strings in the dataset) the tf-idf matrix grows rapidly so trimming it is of clear value. That‚Äôs because we assumed the dataframe contained text, but it might contain coded info, dirty text strings, etc. Our assumptions are probably too simplistic so once again, use the approach with care. Numeric data should be set aside from the TF-IDF steps and then put back in for K-Means steps. And as usual, for too many dimensions or points to cluster, K-Means can slow down (as it calculates the distance from each point on our n dimensions (the unique strings in the data) to each cluster center at each iteration, and well albeit simple math, run it on sufficiently big number of distances and it will slow down‚Ä¶).\nAlso, if you have non-informative stuff (say words that are unique to each entry by which you are trying to cluster), get rid of that, they don‚Äôt help our algorithm.\n\n\nConclusions\nI explained the initial concept in the above. Now, think about it further: in theory one could call that clustering function basically on any dataframe.\nThis is not quite ‚ÄúAutoML‚Äù, but definitely a bit more ‚Äúlow-code‚Äù than by programming from scratch every time. And if you put together some Network Graphs and a Shiny Dashboard as an interface (yes, I‚Äôve done that ;)), well‚Ä¶\nLet me tell you, it can be a rather practical a tool for quick and dirty checks üôÇ\n\n\nReferences\nMy code on GitHub"
  },
  {
    "objectID": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html",
    "href": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html",
    "title": "RLCS for Data Mining: Visuals",
    "section": "",
    "text": "I‚Äôve shown quite a few ‚ÄúClassifiers‚Äù and detailed how data mining can be cool with an LCS.\nBut looking at text-like classifiers populations is not fun (easier for the computer, not fun for the human).\nHere is an alternative:\n\n\n\nWhat you need to decide on classification\n\n\nThat‚Äôs the 3D version of it.\nInterpretation: It basically says ‚Äúmost rules will require to know about 3 bits only (out of 6 in this case), and for these, the first two bits are much more important‚Äù.\nIndeed. That was for the MUX6bits of past examples, the very same proposed in the book about LCS I have referenced in past entries.\nI had inspiration from a video by Dr.¬†Will Browne on how one could visualize the attention of an LCS:\n\n\n\nProposed alternative in Dr.¬†Browne‚Äôs youtube video\n\n\nCompared to the past results I have been showing:\n\n\n\nFormer/old presentation‚Ä¶\n\n\nI think the visual is better looking :D\nAs I am not a fan of forcing 3D on what could be 2D and a palette, here goes an alternative visualization. Less fancy, but just as practical, I think:\n\n\n\n2D alternative. Might be the best one"
  },
  {
    "objectID": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#i-keep-at-it-explainable-findings",
    "href": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#i-keep-at-it-explainable-findings",
    "title": "RLCS for Data Mining: Visuals",
    "section": "",
    "text": "I‚Äôve shown quite a few ‚ÄúClassifiers‚Äù and detailed how data mining can be cool with an LCS.\nBut looking at text-like classifiers populations is not fun (easier for the computer, not fun for the human).\nHere is an alternative:\n\n\n\nWhat you need to decide on classification\n\n\nThat‚Äôs the 3D version of it.\nInterpretation: It basically says ‚Äúmost rules will require to know about 3 bits only (out of 6 in this case), and for these, the first two bits are much more important‚Äù.\nIndeed. That was for the MUX6bits of past examples, the very same proposed in the book about LCS I have referenced in past entries.\nI had inspiration from a video by Dr.¬†Will Browne on how one could visualize the attention of an LCS:\n\n\n\nProposed alternative in Dr.¬†Browne‚Äôs youtube video\n\n\nCompared to the past results I have been showing:\n\n\n\nFormer/old presentation‚Ä¶\n\n\nI think the visual is better looking :D\nAs I am not a fan of forcing 3D on what could be 2D and a palette, here goes an alternative visualization. Less fancy, but just as practical, I think:\n\n\n\n2D alternative. Might be the best one"
  },
  {
    "objectID": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#code-improvement",
    "href": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#code-improvement",
    "title": "RLCS for Data Mining: Visuals",
    "section": "Code improvement",
    "text": "Code improvement\nDid you notice the code above?\nplot(lcs_classifier2)\nThat‚Äôs because I am working on doing things a bit better, using in this case S3 objects. I create a class ‚Äúrlcs_population‚Äù and with that I can have dedicated print, plot, etc. functions that are called for these objects!\nStill not great, still work ongoing, but‚Ä¶ Looking better every day :)"
  },
  {
    "objectID": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#conclusions",
    "href": "posts/2025-03-21_RLCS_DataMining_Visuals/index.html#conclusions",
    "title": "RLCS for Data Mining: Visuals",
    "section": "Conclusions",
    "text": "Conclusions\nI‚Äôm not always a fan of 3D visuals.\nBut I have to admit, it beats looking at strings of binary numbers in our tertiary alphabet‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "",
    "text": "OK so I just wrote that ‚ÄúRLCS is more like RF than Partitioning Trees in terms of classification power in SL settings‚Äù.\nBut that was bold! I actually just meant that it is also an ensemble learning model of sort.\nBut since I was at it‚Ä¶ Why not check the assertion?"
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#i-said-it-without-checking",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#i-said-it-without-checking",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "",
    "text": "OK so I just wrote that ‚ÄúRLCS is more like RF than Partitioning Trees in terms of classification power in SL settings‚Äù.\nBut that was bold! I actually just meant that it is also an ensemble learning model of sort.\nBut since I was at it‚Ä¶ Why not check the assertion?"
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#well",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#well",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "Well!",
    "text": "Well!\nAlright, I‚Äôve explained how I go about the Iris dataset with RLCS a few times now. One key aspect maybe is that in encoding states, I do loose precision of the input. (e.g.¬†I force some data loss). That is, in the current state of affairs with the Rosetta Stone.\nI just ran a randomForest model against the Iris dataset too, now, because I wanted to see how much I was lying‚Ä¶\nHere the code: I tuned nothing, it‚Äôs kind-of-defaults here:\n## Running demo_sl_iris.R first to select train_set/test_set, then come here:\nlibrary(randomForest)\niris_rf &lt;- randomForest(Species~.,data=iris[train_set,],ntree=100,proximity=TRUE)\nprint(iris_rf)\nirisPred &lt;- predict(iris_rf, newdata=iris[-train_set,])\ntable(irisPred, iris[-train_set,]$Species)\n## Results in Accuracy:\n25/30\nHere the FIRST results ever of such a check by yours truly:\n\n\n\nAccuracy: RLCS: 93% - RF: 83%\n\n\n10% better Accuracy! (and it‚Äôs on the first test ever)"
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#yes-but",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#yes-but",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "Yes but!",
    "text": "Yes but!\nThis is also unfair, because I fixed a seed to run RLCS, which is stochastic in nature. I just took the one in the demos already included on my GitHub.\nA truly valid test would be to run it a few times and average accuracy, for one.\nSo, believe me or not: I just changed the seed, and RLCS gave back a 97% accuracy. Try it: change the seed in the demo for Iris to 1234‚Ä¶\nBUT the moment I did that, the Random Forest gave back a 100%!\nAlso, I haven‚Äôt thought even a minute about the RF hyperparameters, I‚Äôm sure it can be improved. If you throw in a few more trees, maybe‚Ä¶\nI‚Äôm just saying, it‚Äôs a first test, I haven‚Äôt done anything special, this was a FIRST RUN result, which had me euphoric for just a moment. That is, until I ran a second test :D\nSince then, I also ran an rpart with the exact same results than random forest (facepalm).\nWhich is to say: By pure dumb luck, and without tuning anything specially, RLCS was better for a given seed, and worse overall for the few other seeds I have tested, than RF.\nToo bold, I was. Fair enough."
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#yes-its-also-much-slower-indeed",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#yes-its-also-much-slower-indeed",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "Yes, it‚Äôs also much slower indeed",
    "text": "Yes, it‚Äôs also much slower indeed\nNo questions asked: RLCS as it is today is not fast. And yet: If it was better in the results, and it‚Äôs more interpretable, it would be more of a price to pay for the trade-off."
  },
  {
    "objectID": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#conclusions",
    "href": "posts/2025-11-08_Comparing_RLCS_to_RF_partI/index.html#conclusions",
    "title": "RLCS is not better than Random Forest (until further notice)",
    "section": "Conclusions",
    "text": "Conclusions\nThis one was a first, quick check to assert my own conceptual ideas in comparing RLCS to Random Forest.\nYou should know: I like RF. And RPART. Better than Deep Learning, if anything. But yeah, RLCS is not quite ‚Äúthere yet‚Äù.\nNow I am also aware this was an imperfect validation (to say the least).\nAnyhow: I need to run many (many) more checks and see what‚Äôs what. New question:\nCan RLCS actually be better for certain scenarios? Or is it slower and also worse at classifying than RF?\nUnrelated: This is all ‚Äúpost-Spanish-R-congress‚Äù whereby I was given the chance to present RLCS to the R community more ‚Äúlive‚Äù with a 15‚Äô communication. (The time pressure was a big deal, but I hope I managed to transmit something.)"
  },
  {
    "objectID": "posts/2025-09-15_RLCS_To_Nationals/index.html",
    "href": "posts/2025-09-15_RLCS_To_Nationals/index.html",
    "title": "RLCS goes to the National R Congress!",
    "section": "",
    "text": "I received the news that my proposal to present the RLCS work to the yearly Spanish R congress was accepted!\nAnd so, I am re-shifting my focus onto the RLCS project a bit for the upcoming weeks :)\nFirst off: I‚Äôm re-creating the new ‚ÄúR Package‚Äù from scratch, so that it has the right name, the right files‚Ä¶\nIt will be a simple version:\n\nNo parallel computing stuff\nSimple demos included only\nAnd the Reinforcement Learning will be included, but slightly more hidden than the rest."
  },
  {
    "objectID": "posts/2025-09-15_RLCS_To_Nationals/index.html#i-am-so-happy-about-this",
    "href": "posts/2025-09-15_RLCS_To_Nationals/index.html#i-am-so-happy-about-this",
    "title": "RLCS goes to the National R Congress!",
    "section": "",
    "text": "I received the news that my proposal to present the RLCS work to the yearly Spanish R congress was accepted!\nAnd so, I am re-shifting my focus onto the RLCS project a bit for the upcoming weeks :)\nFirst off: I‚Äôm re-creating the new ‚ÄúR Package‚Äù from scratch, so that it has the right name, the right files‚Ä¶\nIt will be a simple version:\n\nNo parallel computing stuff\nSimple demos included only\nAnd the Reinforcement Learning will be included, but slightly more hidden than the rest."
  },
  {
    "objectID": "posts/2025-09-15_RLCS_To_Nationals/index.html#a-bit-of-cleaning-up-and-testing",
    "href": "posts/2025-09-15_RLCS_To_Nationals/index.html#a-bit-of-cleaning-up-and-testing",
    "title": "RLCS goes to the National R Congress!",
    "section": "A bit of cleaning up and testing‚Ä¶",
    "text": "A bit of cleaning up and testing‚Ä¶\nIn order to make it available on my GitHub (it‚Äôs unfortunate, but I doubt I would get it published on CRAN in the upcoming month and a half, although, who knows‚Ä¶), anyhow, I need to clean it up. Too many prints and too many functions exposed.\nThen I need to test it (once uploaded to my GitHub) from a different environment (say, a Windows).\nThen I need to make sure I document the key parts."
  },
  {
    "objectID": "posts/2025-09-15_RLCS_To_Nationals/index.html#the-presentation-needs-a-review-too",
    "href": "posts/2025-09-15_RLCS_To_Nationals/index.html#the-presentation-needs-a-review-too",
    "title": "RLCS goes to the National R Congress!",
    "section": "The presentation needs a review too",
    "text": "The presentation needs a review too\nI have had the presentation ‚Äúslides‚Äù ready and shown in the past, but the goal now is to allow the audience to ‚Äúfollow along‚Äù while I do the demos.\nI ‚Äúonly‚Äù have about a month left to work on all that, and I won‚Äôt have as many hours as I would like, but I am confident it will all turn out OK."
  },
  {
    "objectID": "posts/2025-09-15_RLCS_To_Nationals/index.html#conclusion",
    "href": "posts/2025-09-15_RLCS_To_Nationals/index.html#conclusion",
    "title": "RLCS goes to the National R Congress!",
    "section": "Conclusion",
    "text": "Conclusion\nLots of work, but a bit more focused now that I have a new deadline.\nAnd although this is a very small audience for sure, being a simple independent enthusiast, I am still quite proud of myself here."
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "At least the XCS version of LCS algorithm is a ‚Äúwell-known‚Äù (in the rather small sub-world of LCS enthusiasts, that is) approach to do Reinforcement Learning.\nThen again, all step-by-steps for RL in LCS seem to be hidden in more or less archane papers which are pay-per-access, and I don‚Äôt know yet if things make enough sense for me to pay for reading said papers. (Until recently, I had access with my University‚Äôs MSc Student account‚Ä¶ No more, it would seem. Fair enough.) We‚Äôll see how I go about that later‚Ä¶\nBut for now‚Ä¶\n\n\n\nWell, what I can do, is try to come up with my own personal version of an RL implementation with my RLCS ‚Äúfuture-package‚Äù, see if I can make it work, without worrying about past work too much for now.\nI do have a general understanding of ideas of LCS and RL, I just haven‚Äôt found a detailed step-by-step for me to copy from pseudo-code. I also have been reading (but I‚Äôm far from done) what I understand is the bible of Reinforcement Learning, i.e.¬†‚ÄúReinforcement Learning - An Introduction‚Äù by R. S. Sutton & A. G. Bardo. The general ideas of TD and Q-Learning I think I somewhat grasp, and I have my own (limited, sure) experience with Monte-Carlo.\nMixing these concepts with what I have implemented thus far of an LCS, adapting my code with concepts of Action Sets instead of Correct Sets, detect/action/effect/reward with an environment, and a split between exploit and explore, I came up with this ‚Äúdesign‚Äù this morning (Saturday and Sunday mornings are often a bit quieter than the rest of the week):\n\n\n\nthinking, thinking‚Ä¶\n\n\nThis is all on my small home-office wall right now, not at all implemented, but it seems it should be feasible, and I am curious as to whether it could work (or be a complete bust).\n\n\n\nWell, truth being told‚Ä¶ I don‚Äôt know.\nIt ‚Äúsounds‚Äù like a cool thing to be able to do. In the above drawing, I suggest I could, using an LCS, implement an ‚Äúagent‚Äù (yes, one of those, but please, I‚Äôm not talking about LLMs) that would learn on its own how to navigate a simple grid-world and look for food.\nI will have to code the whole logic and rules of that world, all aspects of movements in it, rewards, etc. It‚Äôs going to be a bit of work (somehow I think I‚Äôll manage).\nBut yeah, I don‚Äôt know a few things at this point: whether my ‚Äúdesign‚Äù will work (with whatever adjustments I can come up with), or why even program an RL algorithm.\nI just think it would be cool to have this future package be able to do all of data mining, supervised learning and reinforcement learning, with examples of each.\nAs to when I could use it, I know the answer for data mining and SL ‚Äì not so much for RL, for now.\n\n\n\nJust another fun exercise, really. It will take a few weeks, probably.\nBut if (big if at this stage) I manage to make it work, that would mean I actually understand enough of LCS as a concept to implement it from scratch and do data mining, Supervised Learning and Reinforcement learning. In turn that would also imply I know a bit more of what Reinforcement Learning entails.\nWhich in itself ‚Äì for me ‚Äì would already be pretty cool.\n\n\n\nTo be fair, there are a few papers out there I was able to access for free. In no special order and particularly valuable to inspire my future exercise I found these:\nhttps://arxiv.org/abs/2305.09945\nhttps://dl.acm.org/doi/pdf/10.1145/206944.206955\nhttps://www2.cs.uh.edu/~ceick/6367/bull-lcs.pdf"
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#although-i-know-in-theory",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#although-i-know-in-theory",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "At least the XCS version of LCS algorithm is a ‚Äúwell-known‚Äù (in the rather small sub-world of LCS enthusiasts, that is) approach to do Reinforcement Learning.\nThen again, all step-by-steps for RL in LCS seem to be hidden in more or less archane papers which are pay-per-access, and I don‚Äôt know yet if things make enough sense for me to pay for reading said papers. (Until recently, I had access with my University‚Äôs MSc Student account‚Ä¶ No more, it would seem. Fair enough.) We‚Äôll see how I go about that later‚Ä¶\nBut for now‚Ä¶"
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#general-understanding-of-rl-and-lcs-my-own-mix",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#general-understanding-of-rl-and-lcs-my-own-mix",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "Well, what I can do, is try to come up with my own personal version of an RL implementation with my RLCS ‚Äúfuture-package‚Äù, see if I can make it work, without worrying about past work too much for now.\nI do have a general understanding of ideas of LCS and RL, I just haven‚Äôt found a detailed step-by-step for me to copy from pseudo-code. I also have been reading (but I‚Äôm far from done) what I understand is the bible of Reinforcement Learning, i.e.¬†‚ÄúReinforcement Learning - An Introduction‚Äù by R. S. Sutton & A. G. Bardo. The general ideas of TD and Q-Learning I think I somewhat grasp, and I have my own (limited, sure) experience with Monte-Carlo.\nMixing these concepts with what I have implemented thus far of an LCS, adapting my code with concepts of Action Sets instead of Correct Sets, detect/action/effect/reward with an environment, and a split between exploit and explore, I came up with this ‚Äúdesign‚Äù this morning (Saturday and Sunday mornings are often a bit quieter than the rest of the week):\n\n\n\nthinking, thinking‚Ä¶\n\n\nThis is all on my small home-office wall right now, not at all implemented, but it seems it should be feasible, and I am curious as to whether it could work (or be a complete bust)."
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#why-even-consider-rl",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#why-even-consider-rl",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "Well, truth being told‚Ä¶ I don‚Äôt know.\nIt ‚Äúsounds‚Äù like a cool thing to be able to do. In the above drawing, I suggest I could, using an LCS, implement an ‚Äúagent‚Äù (yes, one of those, but please, I‚Äôm not talking about LLMs) that would learn on its own how to navigate a simple grid-world and look for food.\nI will have to code the whole logic and rules of that world, all aspects of movements in it, rewards, etc. It‚Äôs going to be a bit of work (somehow I think I‚Äôll manage).\nBut yeah, I don‚Äôt know a few things at this point: whether my ‚Äúdesign‚Äù will work (with whatever adjustments I can come up with), or why even program an RL algorithm.\nI just think it would be cool to have this future package be able to do all of data mining, supervised learning and reinforcement learning, with examples of each.\nAs to when I could use it, I know the answer for data mining and SL ‚Äì not so much for RL, for now."
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#conclusions",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#conclusions",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "Just another fun exercise, really. It will take a few weeks, probably.\nBut if (big if at this stage) I manage to make it work, that would mean I actually understand enough of LCS as a concept to implement it from scratch and do data mining, Supervised Learning and Reinforcement learning. In turn that would also imply I know a bit more of what Reinforcement Learning entails.\nWhich in itself ‚Äì for me ‚Äì would already be pretty cool."
  },
  {
    "objectID": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#references",
    "href": "posts/2025-02-09_About_Understanding_RL_with_LCS/index.html#references",
    "title": "RLCS: Reinforcement Learning?",
    "section": "",
    "text": "To be fair, there are a few papers out there I was able to access for free. In no special order and particularly valuable to inspire my future exercise I found these:\nhttps://arxiv.org/abs/2305.09945\nhttps://dl.acm.org/doi/pdf/10.1145/206944.206955\nhttps://www2.cs.uh.edu/~ceick/6367/bull-lcs.pdf"
  },
  {
    "objectID": "posts/2023-07-29_GA_1_3/index.html",
    "href": "posts/2023-07-29_GA_1_3/index.html",
    "title": "Optimization: Genetic Algorithm(s) (1/2)",
    "section": "",
    "text": "This time around, I keep going studying and implementing optimization algorithms, based on the already mentioned reference book, and I want to work on a slightly different family of these, now a full blown ‚Äúmetaheuristic‚Äù in fact, called ‚ÄúGenetic Algorithms‚Äù.\nAs this one is a bit different, I will take my time, and go bit by bit. So today is about ‚Äúsetting things up‚Äù (mostly).\n\n\nThis time, we will try to minimize this function (see visualization), which would be quite hard for (say) Gradient Descent (it most probably wouldn‚Äôt find the global minimum at all).\n \n\n\n\nAs usual, I am not inventing anything. Not only am I using a book for reference pseudo-code, but of course these algorithms are documented all over, say for instance in Wikipedia.\nOverall, the idea is to start with a ‚Äúpopulation of individuals‚Äù (each representing a possible solution in the search space). Then individuals are selected as parents, have one or more children, which can also suffer (in theory, rarely) mutations (which allows to explore more of the search space).\nThis leaves us with a bigger population of individuals. At this point, we stop concerning ourselves with parents or childrens and consider them all as individuals.\nA new ‚Äúgeneration‚Äù is then ‚Äúselected‚Äù (in reference to ‚Äúnatural selection‚Äù) using (normally) the fittest individuals (e.g.¬†minimum values) from that bigger pool of individuals, and then the process can start anew.\nThe selection of parents can be done in several ways, the mix of parents ‚Äúgenes‚Äù into each child can follow some process (usually varying say the proportion & redistribution of each progenitor‚Äôs genes), and mutations can happen more or less often (through a parameter, typically).\nThe algorithm stops when it ‚Äúconverges‚Äù (or after a set number of generations), whereby the best individual in the final generation is representing the best found solution (hopefully, a global minimum, in our scenario).\n\n\n\nAlthough there are alternatives, the simplest approach is to use ‚Äúbinary genes‚Äù. As numbers can ‚Äì obviously ‚Äì be binary encoded, all we have to do is encode the search space (min/max ranges for say x, y coordinates) so that given a number of bits per coordinate, any value stays in range, and any individual will be a binary representation of two (in our example) such coordinates.\nAs the fitness corresponds to a real value, we then just need to have a ‚Äúdecoder‚Äù of the binary values to evaluate the objective function to minimize using real numbers.\nAt this stage of the development, I have ensured I can generate the ‚Äúsearch space‚Äù visually (similar to recent blog entries), but also that I can generate such individuals, and maybe even a ‚Äúgeneration‚Äù.\n\n\n\n100 individuals, one generation\n\n\n\n\n\nThis is all provided in my GitHub.\nAs this is a bit ‚Äúmessier‚Äù with more concepts than most recent entries, I chose to create for myself an RStudio Project, whereby I can then source files with relative paths‚Ä¶ And so the code for today requires two files (*_v001.R).\n\n\n\nWell, in upcoming entry/ies, I shall code for selecting parents, generating children, mutation, and iteration across a number of generations, thereby in principle closing the loop on this particular topic of Genetic Algorithms applied to optimization."
  },
  {
    "objectID": "posts/2023-07-29_GA_1_3/index.html#intro",
    "href": "posts/2023-07-29_GA_1_3/index.html#intro",
    "title": "Optimization: Genetic Algorithm(s) (1/2)",
    "section": "",
    "text": "This time around, I keep going studying and implementing optimization algorithms, based on the already mentioned reference book, and I want to work on a slightly different family of these, now a full blown ‚Äúmetaheuristic‚Äù in fact, called ‚ÄúGenetic Algorithms‚Äù.\nAs this one is a bit different, I will take my time, and go bit by bit. So today is about ‚Äúsetting things up‚Äù (mostly).\n\n\nThis time, we will try to minimize this function (see visualization), which would be quite hard for (say) Gradient Descent (it most probably wouldn‚Äôt find the global minimum at all).\n \n\n\n\nAs usual, I am not inventing anything. Not only am I using a book for reference pseudo-code, but of course these algorithms are documented all over, say for instance in Wikipedia.\nOverall, the idea is to start with a ‚Äúpopulation of individuals‚Äù (each representing a possible solution in the search space). Then individuals are selected as parents, have one or more children, which can also suffer (in theory, rarely) mutations (which allows to explore more of the search space).\nThis leaves us with a bigger population of individuals. At this point, we stop concerning ourselves with parents or childrens and consider them all as individuals.\nA new ‚Äúgeneration‚Äù is then ‚Äúselected‚Äù (in reference to ‚Äúnatural selection‚Äù) using (normally) the fittest individuals (e.g.¬†minimum values) from that bigger pool of individuals, and then the process can start anew.\nThe selection of parents can be done in several ways, the mix of parents ‚Äúgenes‚Äù into each child can follow some process (usually varying say the proportion & redistribution of each progenitor‚Äôs genes), and mutations can happen more or less often (through a parameter, typically).\nThe algorithm stops when it ‚Äúconverges‚Äù (or after a set number of generations), whereby the best individual in the final generation is representing the best found solution (hopefully, a global minimum, in our scenario).\n\n\n\nAlthough there are alternatives, the simplest approach is to use ‚Äúbinary genes‚Äù. As numbers can ‚Äì obviously ‚Äì be binary encoded, all we have to do is encode the search space (min/max ranges for say x, y coordinates) so that given a number of bits per coordinate, any value stays in range, and any individual will be a binary representation of two (in our example) such coordinates.\nAs the fitness corresponds to a real value, we then just need to have a ‚Äúdecoder‚Äù of the binary values to evaluate the objective function to minimize using real numbers.\nAt this stage of the development, I have ensured I can generate the ‚Äúsearch space‚Äù visually (similar to recent blog entries), but also that I can generate such individuals, and maybe even a ‚Äúgeneration‚Äù.\n\n\n\n100 individuals, one generation\n\n\n\n\n\nThis is all provided in my GitHub.\nAs this is a bit ‚Äúmessier‚Äù with more concepts than most recent entries, I chose to create for myself an RStudio Project, whereby I can then source files with relative paths‚Ä¶ And so the code for today requires two files (*_v001.R).\n\n\n\nWell, in upcoming entry/ies, I shall code for selecting parents, generating children, mutation, and iteration across a number of generations, thereby in principle closing the loop on this particular topic of Genetic Algorithms applied to optimization."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html",
    "title": "Classifying URLs",
    "section": "",
    "text": "I‚Äôm still working my way through a ‚Äúpractical demos‚Äù session on ML background for Cybersecurity.\nSee I have a ‚Äúplan‚Äù in my head about how to introduce Machine Learning, including demystifying a bit the math behind it. The ‚Äúplan‚Äù goes a bit like this:\n\nWe‚Äôve seen recently a bit of what unsupervised learning can be about. For Cybersecurity, anomaly detection is a clear use-case. We‚Äôve used the concept of distance between points. But there is more to this category (clustering per-se, but also dimensionality reduction is quite useful, for instance).\nML can be about making a line go through points (nicely). That‚Äôs regression. With sufficient data, you‚Äôre compressing information of relationships between dimensions to predict an outcome. In the simplest form, given x, you can estimate y. And the math is quite simple:\n\\[\ny = \\beta_0 + \\beta_1x\n\\]\nSuch a linear regression is then really of the realm of statistics. As such, there is little of practical application of that thing for us in this simplest form, as in Cybersecurity, many things are expected to be black or white. But maybe it‚Äôs not completely crazy to maybe estimate that the more time a machine is connected to the Internet, the higher the risk of infection (all other things being equal, that is). That could be a growing line. Sometimes things can be approximated with the appropriate transformations on the dimensions (say ‚Äúindependent variables‚Äù) and then used in a linear regression (so the ‚Äúmodel is linear on its parameters‚Äù).\n\n\nI‚Äôll make an entry about linear regression soon(-ish), when I have time.\n\n\nML can also be about making a line separate groups of things nicely, i.e.¬†classifying stuff. In its simplest form, we will have input data, and will want to know in which one of two categories a given input should belong too. That‚Äôs our ‚Äúrun of the mill‚Äù Spam classifier.\n\n\nBoth regression (linear or not) and classification are usually considered to be the two most common supervised learning use-cases.\n\n\nThen you have Reinforcement Learning (aka RL). So far, I have yet to personally come across a real-world cybersecurity application of that, although it is pretty cool a concept! (Actually a friend has demonstrated something with Honeypots and such‚Ä¶) But I‚Äôll admit, I have played little with RL myself for now, and it‚Äôs a pending task of mine. It does sound appealing, and there are some papers out there to use RL for optimizing pentesting processes and such.\nAnd then you have Self-Supervised Learning. The first time I read that I was like ‚ÄúWhaaaat?‚Äù. But that‚Äôs LLMs, as noted at the end of one of my most recent posts. You predict next word in a text, and check what actually comes in the‚Ä¶ Rest of the text. So you only need‚Ä¶ The text. Nifty. But I‚Äôm not too fond of it and have yet to think it through enough to come up with something practical beyond LLMs‚Ä¶\n\nThere is plenty more, but this is one way of putting categories to what ML is about.\n\n\n\nAlright, so I‚Äôll skip some of the above, and today jump right onto this:\nHow does Supervised Machine Learning work, as applied to one cybersecurity-relevant classification use-case?\nSomehow I feel it‚Äôs more fun to frame things a little into practical use-cases, instead of pure math (which I suppose is boring/threatening to quite a few).\nEven then, be warned: This entry is pretty long. But hopefully it contains some important things and my wish is, it‚Äôs also understandable."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#i-have-a-plan",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#i-have-a-plan",
    "title": "Classifying URLs",
    "section": "",
    "text": "I‚Äôm still working my way through a ‚Äúpractical demos‚Äù session on ML background for Cybersecurity.\nSee I have a ‚Äúplan‚Äù in my head about how to introduce Machine Learning, including demystifying a bit the math behind it. The ‚Äúplan‚Äù goes a bit like this:\n\nWe‚Äôve seen recently a bit of what unsupervised learning can be about. For Cybersecurity, anomaly detection is a clear use-case. We‚Äôve used the concept of distance between points. But there is more to this category (clustering per-se, but also dimensionality reduction is quite useful, for instance).\nML can be about making a line go through points (nicely). That‚Äôs regression. With sufficient data, you‚Äôre compressing information of relationships between dimensions to predict an outcome. In the simplest form, given x, you can estimate y. And the math is quite simple:\n\\[\ny = \\beta_0 + \\beta_1x\n\\]\nSuch a linear regression is then really of the realm of statistics. As such, there is little of practical application of that thing for us in this simplest form, as in Cybersecurity, many things are expected to be black or white. But maybe it‚Äôs not completely crazy to maybe estimate that the more time a machine is connected to the Internet, the higher the risk of infection (all other things being equal, that is). That could be a growing line. Sometimes things can be approximated with the appropriate transformations on the dimensions (say ‚Äúindependent variables‚Äù) and then used in a linear regression (so the ‚Äúmodel is linear on its parameters‚Äù).\n\n\nI‚Äôll make an entry about linear regression soon(-ish), when I have time.\n\n\nML can also be about making a line separate groups of things nicely, i.e.¬†classifying stuff. In its simplest form, we will have input data, and will want to know in which one of two categories a given input should belong too. That‚Äôs our ‚Äúrun of the mill‚Äù Spam classifier.\n\n\nBoth regression (linear or not) and classification are usually considered to be the two most common supervised learning use-cases.\n\n\nThen you have Reinforcement Learning (aka RL). So far, I have yet to personally come across a real-world cybersecurity application of that, although it is pretty cool a concept! (Actually a friend has demonstrated something with Honeypots and such‚Ä¶) But I‚Äôll admit, I have played little with RL myself for now, and it‚Äôs a pending task of mine. It does sound appealing, and there are some papers out there to use RL for optimizing pentesting processes and such.\nAnd then you have Self-Supervised Learning. The first time I read that I was like ‚ÄúWhaaaat?‚Äù. But that‚Äôs LLMs, as noted at the end of one of my most recent posts. You predict next word in a text, and check what actually comes in the‚Ä¶ Rest of the text. So you only need‚Ä¶ The text. Nifty. But I‚Äôm not too fond of it and have yet to think it through enough to come up with something practical beyond LLMs‚Ä¶\n\nThere is plenty more, but this is one way of putting categories to what ML is about."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#todays-intro",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#todays-intro",
    "title": "Classifying URLs",
    "section": "",
    "text": "Alright, so I‚Äôll skip some of the above, and today jump right onto this:\nHow does Supervised Machine Learning work, as applied to one cybersecurity-relevant classification use-case?\nSomehow I feel it‚Äôs more fun to frame things a little into practical use-cases, instead of pure math (which I suppose is boring/threatening to quite a few).\nEven then, be warned: This entry is pretty long. But hopefully it contains some important things and my wish is, it‚Äôs also understandable."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#classifying-urls-into-two-categories",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#classifying-urls-into-two-categories",
    "title": "Classifying URLs",
    "section": "Classifying URLs into TWO categories",
    "text": "Classifying URLs into TWO categories\n\nThe data\nIn Cybersecurity sometimes getting to interesting datasets can be a bit challenging. After all, certain things are usually done behind closed doors. You can probably understand why. Which is why I like for instance this resource, secrepo.com.\nToday, we‚Äôre gathering a seemingly simple dataset: A list of web URLs, very simply tagged as either good or bad. Nothing else. But, mind you, 420 thousand of‚Äôem.\n\nPoint number one: to do ML, it can help to have lots of data. (It‚Äôs not always necessary, but it‚Äôs usually a good idea.)\n\n\n\nThe objective\nToday is about trying to distinguish (really just trying!) to classify URLs (‚Äúwebpages‚Äù, for most) in two categories: Good or Bad. Why? Applications are for your protection, and can be used to recommend you to avoid certain websites, which in turn can be maybe used as a supplementary control for other security measures, such as detecting Phishing emails.\nCan we make our computer tell us if a given URL is good or bad?\nThat‚Äôs it. That‚Äôs our goal for today. Using Machine Learning, of course. So we‚Äôre aiming to implement one (or more) model(s) to classify URLs. Based on data we already have. That‚Äôs supervised learning, more precisely a classifier.\n\nJust to be very clear: This is all part of a preparation to an introduction on ML background for Cybersecurity. ‚ÄúIntroduction‚Äù is the key here: I‚Äôm not aiming for complete, perfect, not even good, as long as I can convey certain concepts that I believe are relevant to grasp an idea at best of how ML works.\nEven the code I put together is‚Ä¶ Well, lacking. It‚Äôs not meant to be production grade.\n\nThere is nothing in the way of test-driven anything\nSome of the regular expressions are simplistic\nSome stuff will be badly filtered\nThe trained models are not good\nThe data is what it is, and I‚Äôm not trying to complement it\n‚Ä¶\n\nPlease don‚Äôt come saying ‚Äúthis is not great‚Äù. I know. I only have so much spare time. This post is only my way to support with contents an interactive session I plan to give soon. There is a lot of good training on ML, Cybersecurity & al.¬†out there. Go find it, if you want formal and/or good, detailed training.\nIf you‚Äôre fine with simply trying to wrap our heads around concepts, do keep reading.\n\n\n\nThe code\nThe code will be on my Github eventually. But for now, as usual, a few blocks of it:\n\nurls_df &lt;- read.csv(\"https://raw.githubusercontent.com/faizann24/Using-machine-learning-to-detect-malicious-URLs/refs/heads/master/data/data.csv\")\n\nurls_df$url &lt;- tolower(urls_df$url)\n## Let's have a quick look, a.k.a. \"EDA\"\ndim(urls_df)\n&gt; [1] 420464      2\ntable(urls_df$label) ## Imbalance, we might want e.g. to under-sample \"good\"\n&gt;  bad   good \n 75643 344821 \n\n\nPoint number two: Imbalance is often bad. Here we have 4.5 times more good entries than bad entries. Now, why could that be bad? Here we‚Äôre going to try to learn from our data. If we keep the imbalance in the dataset, to make things simple, our model could learn that there is more good than bad. And maybe that‚Äôs what we want, but then that imbalance could affect the outcome of our model. Unless we want to use that imbalance for some reason, it‚Äôs probably best to manage it upfront.\n\nHow to remove imbalance? Well, one way (of surely many out there, only I only know a few), is to ‚Äúunder-sample‚Äù some of the over-represented class. Today we‚Äôre going to take proportionally less entries from good to train our model, making then sure that we have roughly half and half, of each class.\nAs per the class, it‚Äôs a binary choice, good or bad. We‚Äôll create a variable to encode that as 0 or 1 (or the other way around, it‚Äôs irrelevant). That‚Äôs just to make things compatible with certain models, as most will expect numerical data.\nurls_df$label_num &lt;- ifelse(urls_df$label == \"good\", 0, 1)\nurls_df$url_length &lt;- nchar(urls_df$url)\n\n## A bit of domain knowledge helps:\nnrow(urls_df[urls_df$url_length &gt; 300,]) / nrow(urls_df)\n[1] 0.001203432\n\nPoint number 3: Domain Knowledge is important. We‚Äôre going to leverage that today quite a bit. To begin with, we have 0.1% of the entries with URL length superior to 300 characters, and to make things cleaner, we‚Äôll assume today these are‚Ä¶ Irrelevant. So we remove them. Our classifier will hence not be trained with such data. And maybe that‚Äôs a bad idea, depending on your goals. For today, everything is fair game, we want to keep things simple.\n\n\n\nFeature Engineering\nHeck. We only have URLs. And a class. How is a machine suppose to go from there?\nLet‚Äôs try to extract something akin‚Äô to a signal out of that. So we‚Äôve got already the length of each URL. And maybe that‚Äôs helpful. Are longer URLs more often bad than good? Well, for real long URLs, maybe a bit. But it‚Äôs not really definitive, is it?\n\n\n\nComparing densities of URL lengths per class\n\n\n\nPoint number 4: Always look at the data. Don‚Äôt just run into the modelling, it‚Äôs not a good idea. Get a feeling of the data you want to work with. I can‚Äôt stress this enough.\n\nLet‚Äôs keep going then. Again, domain knowledge is key. The good news is, most of us have seen thousands of URLs in our lifetime, so maybe we have a little understanding of what we could look for.\nToo many slashes ‚Äú/‚Äù? Too many ‚Äúdots‚Äù? Maybe. So those could be two new ‚Äúdimensions‚Äù. Although maybe these two are already somewhat expressed through the length of the URL? In other words, it might make sense that the longer the URL, the more dots and slashes.\n\nPoint number 5: That‚Äôs a correlation right there, and depending on how much two variables are correlated, maybe you‚Äôre better off with fewer variables. There is a lot of background statistics on this topic. And for ML algorithms, sometimes too many variables is a bad thing, more so if they don‚Äôt add any useful information.\n\nFor today, we‚Äôll keep it. After all, we have for now only what, 3 variables to work with? We need more. I‚Äôm going to save you the pain of going through it all one by one, and propose my own few variables I thought we might consider for training our model, ALL extracted from the URLs themselves.\n\nIP as host: Humans use ‚ÄúDomain Names‚Äù that are readable. You need a DNS entry for that, and you need to register things as the owner for the DNS entry, for legal reasons. So if you skip the DNS step, you can still have an IP address, but it will look like‚Ä¶ An IP. It‚Äôs a bit far-fetched, but I‚Äôd argue if a URL reflects a Public IP, it‚Äôs either known good (ours or provided by some trusted third party), or - more often than not - it‚Äôs a bad indicator.\nURL readability: So it‚Äôs not direct. A URL can of course contain stuff that‚Äôs purely technical. But we usually make an effort to make things readable: variable names, folder names, etc. Bad actors might want to obfuscate stuff or generate random folder or what-not. And so if a URL is mostly unreadable gibberish, I‚Äôd guess it‚Äôs a bad sign. Which we can ‚Äúencode‚Äù as: How many vowels has the URL relative to its length? Does the URL contain things with 4 consecutive consonants (not usual in written english, although not good an indicator in some other languages‚Ä¶)? Again, both things are probably somewhat related, but not necessarily/completely. So I take both.\nIs a port expressly identified in the URL? After the host, a column and number is usually not required for a normal website, it‚Äôs usually a default (443 or 80). So if you see ‚Äúsomehost.somedomain.com:12345‚Äù, something exotic is going on. Exotic for normal web browsing is weird (well, it‚Äôs exotic :D), and so not expected for good stuff.\nWe can keep going: Domain extension, file extension (a URL ending in .exe is a red flag, for sure :D), or more simply how common is either of these, is probably helpful too.\n\nIt‚Äôs not exhaustive (not in the least) but hopefully it makes some sense. From a URL, we‚Äôve put together 14 different variables that way. All chosen from experience, from ‚Äúdomain knowledge‚Äù. (See point number 3 above if it wasn‚Äôt clear before.)\n\n\n\nWe should keep looking at our data‚Ä¶\n\n\nFrom no variables (except considering the URL itself‚Ä¶) to 14. Not too shabby.\n&gt; names(urls_df)\n [1] \"url\"                       \"label\"                     \"url_length\"               \n [4] \"label_num\"                 \"slashes_count\"             \"dots_count\"               \n [7] \"host_is_ip\"                \"vowels_prev\"               \"ends_in_slash\"            \n[10] \"contains_port\"             \"n_params\"                  \"domain_ext\"               \n[13] \"file_ext\"                  \"is_common_domain_ext\"      \"is_uncommon_domain_ext\"   \n[16] \"is_uncommon_file_ext\"      \"has_4_consonants_straight\"\nThere is sooo much more to consider.\nFor instance if you check out the code (if/when I make it available on my GitHub), you‚Äôll see at one point I ‚Äúscale‚Äù the data. That is, I try to put all the variable in comparable orders of magnitude. This is to avoid one variable overshadowing all the others. Something that varies from 0.5 to 0.6 might otherwise be considered less important than something that varies from 3 to 4000. Which is not always true.\nI also make a BAD thing: I transform extensions to ‚Äúfactors‚Äù, and then I encode the levels of the factors as numerical data. This is not great, I know :D\nNamely, factors are not ordered, while two numbers could be, providing ordinal value at least, and distances could be considered, when here there is clearly no such thing. BAD! BAD Nico!\nLook, this is no excuse, but hopefully, if you order things upfront, and then encode to numerical value, say bad entries as factors first, then good, you end up with ordered levels where by lower ones are for bad, and higher for good (or vice-versa). It will turn out wrong for today. This is tricky and let me insist, NOT good practice. As it turns out, I have so many possible extensions (values) in there, that a better approach - such as one-hot-encoding - makes my dataset explode in size and not fit my RAM memory‚Ä¶ And I am just too lazy to work through this for what was meant to be a simple demo. So‚Ä¶ My apologies, I know, it hurts the eyes to see this. Moving on.\n\n\nTraining Models\nOne last concept, and we‚Äôll dive in actual ‚ÄúLearning‚Äù.\n\nPoint number 6: Save some entries for testing you trained model. So say we have 10K entries, of which 5000 are good and 5000 are bad entries. How do you know your trained model ‚Äúgeneralizes‚Äù correctly? If you were to try and evaluate your model on data you used to train it, you couldn‚Äôt know whether it just learnt exactly that case, or if it would work on future data. To verify how it would work on future data, you‚Ä¶ Validate using data not seen during training. There is more to that, too, but that‚Äôll be enough for conceptual understanding today.\n\nOK. At last. As today has been dense (I know, sorry), I‚Äôll train just ONE model on our dataset.\ngood_urls &lt;- urls_df[urls_df$label == \"good\",]\nbad_urls &lt;- urls_df[urls_df$label == \"bad\",]\n## Undersampling \"good\" vs \"bad\"\nsample_urls_df &lt;- rbind(bad_urls[sample(1:nrow(bad_urls), size = 10000,replace = FALSE),],\n                        good_urls[sample(1:nrow(good_urls), size = 10000,replace = FALSE),])\n\n## ...\n\nseparate_sets &lt;- sample(c(TRUE, FALSE), nrow(sample_urls_df), replace=TRUE, prob=c(0.7,0.3))\nt_train &lt;- sample_urls_df[separate_sets, ]\nt_test &lt;- sample_urls_df[!separate_sets, ] # i.e. Not train set...\n\n\nPartitioning Tree, train and test\nHere is how you train a Partitioning Tree in R:\n## A Partitioning tree but WITHOUT the bad trick of extensions encoding\n## And low depth:\ntree_model &lt;- rpart(label ~ url_length + slashes_count + dots_count +\n                        host_is_ip + vowels_prev + ends_in_slash + contains_port +\n                        n_params + is_common_domain_ext + is_uncommon_domain_ext +\n                        is_uncommon_file_ext + has_4_consonants_straight,\n                    data = t_train,\n                    method = \"class\",\n                    control = rpart.control(cp = 0.05))\nAnd here how you visualize, and ‚Äútest‚Äù it:\n&gt; tree_model ; plot(tree_model); text(tree_model)\nn= 13929 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 13929 6933 good (0.4977385 0.5022615)  \n  2) dots_count&gt;=0.3877992 2846  729 bad (0.7438510 0.2561490) *\n  3) dots_count&lt; 0.3877992 11083 4816 good (0.4345394 0.5654606)  \n    6) vowels_prev&lt; -0.6992319 1877  658 bad (0.6494406 0.3505594) *\n    7) vowels_prev&gt;=-0.6992319 9206 3597 good (0.3907234 0.6092766) *\n&gt; t_test$predicted &lt;- predict(tree_model, t_test, type=\"class\")\n&gt; table(t_test[, c(\"label\", \"predicted\")])\n      predicted\nlabel   bad good\n  bad  1431 1636\n  good  611 2393\nNow to the important part: We‚Äôve tested on 30% of the data our model trained on the other 70% of the data. In the above, we‚Äôve also excluded the factor-level-encoded variables because they‚Äôre a bad thing (but as we‚Äôll see in a second, they contain useful information, unfortunately). And we got some results, as such:\nBased on the data, we have trained a partitioning tree that makes mistakes about 37% of the time. As we have balanced our dataset, we know that randomly choosing one class of the other would have led us to 50% error, approximately. Still, not great.\nLet‚Äôs have a look at this ‚Äútree‚Äù:\n\n\n\nA simplistic partitioning tree\n\n\nLow depth, and still, with only two choices, we get a 63% correct classification on unseen data.\n\nOne thing to note, I‚Äôm not sure that this particular implementation of the model in fact uses Shannon‚Äôs information entropy to select nodes (it could use Gini impurity, typically). But suffice to say it could, and that‚Äôs one way a Partitioning Tree could decide which variable to choose first to make a separation in two branches, and then iterate. And I only mention it because that was the topic of last week‚Äôs entry.\n\nIt does look like the number of ‚Äúdots‚Äù in the URL, and our prevalence of vowels (which I explained a bit earlier) are important to help classify our URLs. Take note! Actually, this is a fair point, Trees are nice because they‚Äôre readable by a human. That is, the decisions of this algorithm are explainable, and that‚Äôs a good thing.\nNow without further ado, what better models I have managed to produce, just increasing depth and/or adding the (badly encoded) extension variables:\n\nWith just more decisions (more branches in the tree, i.e.¬†more depth), I got my classification to a 75% correct classification rate.\nAdding the (incorrectly) encoded extension variables, I go up to 80%.\n\n\n\n\nA somewhat better tree, albeit using bad practices"
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#conclusions",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#conclusions",
    "title": "Classifying URLs",
    "section": "Conclusions",
    "text": "Conclusions\nLots of theory covered. And only a bit of practical outcome, as today we just have a (first) model that is ‚Äúbetter than chance‚Äù, although well, far from perfect.\nIn a future post, we‚Äôll probably circle back to this exercise, to see potentially things related to other classification algorithms such as logistic regression, random forests, neural nets, and maybe SVM. Now that most of the theory is covered, it should be shorter, more to the point. (I have them all working already, I just don‚Äôt want to add content for today, it‚Äôs already too much‚Ä¶)\n\nNote: If I have time, I‚Äôll make a Shiny Application, so that you can test whether or not you can beat this simple (bad) model. Fair warning: I don‚Äôt know how the URLs were originally tagged; but I‚Äôm not much better than my very own simple partitioning tree model :D"
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#references",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#references",
    "title": "Classifying URLs",
    "section": "References",
    "text": "References\nFor today, only the recommended list of potential datasets for Cybersecurity.\nThe rest is of my own doing. Of course, the Internet, Stack Overflow, Wikipedia, etc. as usual."
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html",
    "href": "posts/2021-09-12_SOCSim2/index.html",
    "title": "Simulating a SOC (part II): GUI",
    "section": "",
    "text": "Last week I started a small program to simulate a SOC.\nThis week, I wanted to see if I could make it more‚Ä¶ Visual.\nThis here is the ‚Äúfinal‚Äù result working with the simulator from last week:\n\nBut it wasn‚Äôt easy‚Ä¶\nSo here is the long-story-short about that.\n(No code, as I am not happy with my code right now, I have done so many tests I myself have a hard time following it right now‚Ä¶ And it was meant to be a ‚Äúquick & dirty‚Äù exercise, well, dirty it is, that‚Äôs for sure. So maybe when I settle on a cleaner version, I‚Äôll share that instead.)"
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html#intro",
    "href": "posts/2021-09-12_SOCSim2/index.html#intro",
    "title": "Simulating a SOC (part II): GUI",
    "section": "",
    "text": "Last week I started a small program to simulate a SOC.\nThis week, I wanted to see if I could make it more‚Ä¶ Visual.\nThis here is the ‚Äúfinal‚Äù result working with the simulator from last week:\n\nBut it wasn‚Äôt easy‚Ä¶\nSo here is the long-story-short about that.\n(No code, as I am not happy with my code right now, I have done so many tests I myself have a hard time following it right now‚Ä¶ And it was meant to be a ‚Äúquick & dirty‚Äù exercise, well, dirty it is, that‚Äôs for sure. So maybe when I settle on a cleaner version, I‚Äôll share that instead.)"
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html#enters-shiny",
    "href": "posts/2021-09-12_SOCSim2/index.html#enters-shiny",
    "title": "Simulating a SOC (part II): GUI",
    "section": "Enters Shiny",
    "text": "Enters Shiny\nSo as now usual, I went the way of Shiny to create a Dashboard.\nThe very first version of that was simple, and it worked at the first try:\n\nI did have to learn how to work with a reactiveTimer() in Shiny, and it took some testing, but it wasn‚Äôt horrible.\nThen came the complications‚Ä¶"
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html#one-animated-plot-is-ok-more-not-so-much",
    "href": "posts/2021-09-12_SOCSim2/index.html#one-animated-plot-is-ok-more-not-so-much",
    "title": "Simulating a SOC (part II): GUI",
    "section": "One animated plot is OK‚Ä¶ More, not so much",
    "text": "One animated plot is OK‚Ä¶ More, not so much\nWith just one plot, everything seemed to work upfront. As usual, I chose ggplot, and simply plotted it alongside some numbers, and things went fine.\nHowever, the minute I threw in more plots, something went wrong: Whenever more than one plot needed an update (rendering), things froze, even if only for half a second. But it was perceptible.\nDo note that the dataset is rather simple and small, so ‚Äúloading‚Äù is probably not the issue here.\nI‚Äôm convinced that with a much faster laptop, this could have gone unnoticed. Well, maybe, I‚Äôm not sure.\nBut in summary, it seems that Shiny needs a little time to render several ggplots.\nAnd so I went hunting for a solution. I have played enough with Shiny to know that if you ggsave() a plot somewhere and then load the image, that renders faster. That was the first test, and indeed, it seemed to freeze a little less (it wasn‚Äôt ‚Äúperfect‚Äù, but almost).\nThen I looked into alternatives. I love ggplot(), so it bothers me to admit that, but I needed to see where the problem was.\nI pushed forward, and tested the plot solutions that come bundled with most of R (from the ‚Äúgraphics‚Äù package). That worked better than ggplot() indeed, but then I would need to work all the many details to make those acceptable (presentation-wise). So not cool.\nThen I found the ‚ÄúrenderCachedPlot()‚Äù alternative to ‚ÄúrenderPlot()‚Äù. That seemed VERY promising. Indeed, it would only update a graph if there was something to update for that particular graph. That option helped, but not enough for my taste.\nI also tried to run the Shiny app from a ‚Äúdedicated‚Äù Shiny Server container, as opposed to running it from a full-fledged RStudio container. Maybe the container was too busy? That didn‚Äôt improve things either.\nSomeone in a Telegram group (about R) did point me to a VERY helpful CSS trick, that consists of playing with the opacity of a ‚Äúrecalculating‚Äù object in Shiny, and that made the visualisation MUCH smoother. The only detail is, behind the scenes, one could still tell the laptop was busy recalculating things as the timer still slowed down. Regardless, that CSS trick was a life-saver, visually speaking.\nSo thanks a lot for that, Mister X (I won‚Äôt mention your name, for privacy reasons ‚Äì but that can be changed if the interested party has any interest).\nAs we know, R is mono-core by default. Could there be something with ‚Äúfutures‚Äù? Yes there is. But the solution was worse than the original problem. After all, on a small data frame, launching a new R session for each plot does seem like an overkill. And indeed, that wasn‚Äôt a solution."
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html#final-solution",
    "href": "posts/2021-09-12_SOCSim2/index.html#final-solution",
    "title": "Simulating a SOC (part II): GUI",
    "section": "Final solution",
    "text": "Final solution\nAt the end, although still not perfect, I used plot_ly() instead of ggplot().\nAnd it ‚Äúworked‚Äù. You still clearly notice visually the impact of updating 3 graphs (which, once again, is no issue when working with one, in my tests anyway).\nThe resulting ‚Äúanimated‚Äù dashboard, sporting three plots, is the one shown at the beginning of this entry."
  },
  {
    "objectID": "posts/2021-09-12_SOCSim2/index.html#conclusions",
    "href": "posts/2021-09-12_SOCSim2/index.html#conclusions",
    "title": "Simulating a SOC (part II): GUI",
    "section": "Conclusions",
    "text": "Conclusions\nFirst of all, let‚Äôs be clear: There are certainly MANY things I haven‚Äôt tried. For instance the Plotly package has some built-in animation solutions that I haven‚Äôt tried, and they seem very smooth.\nAnd from what I‚Äôve experienced with more traditional BI solutions, like PowerBI, you wouldn‚Äôt use that to reload a graphs every 0.3 seconds like we do here. I haven‚Äôt tested that, so my perspective is probably VERY biased/wrong‚Ä¶\nOn the other hand, making the Simulations ‚Äúvisual‚Äù in an interactive Dashboard is probably a bad idea anyway. At some point, I might want to run several simulations with different parameters, and see which parameter set gives the best result based on some conditions. Doing that while ‚Äúshowing‚Äù every step is simply not the way to go, and although it would probably be ‚Äúcool‚Äù, we would be wasting LOTS of unnecessary compute power on refreshing some graphs‚Ä¶ And making things all-the-more slow, which is not what you want if you want to simulate many alternative solutions.\nSo here we are.\n\nPlotly seems faster than ggplot. I wouldn‚Äôt have know, had I not tried to do an animated dashboard with more than one plot, really.\nYou can use timers in Shiny to animate things. Although it seems there is an ‚Äúinvalidate‚Äù alternative out there that is preferred to the ‚ÄúreactiveTimer‚Äù option‚Ä¶ I‚Äôll have to look into that.\nAs our simulator was really a set of things bundled together, I used the reactiveValues() function of Shiny to ‚Äútranslate‚Äù the original simulator‚Ä¶\nVisualising a simulation WHILE it‚Äôs running is fun to watch, but not really a good idea. Maybe I could adapt the Dashboard to run simulations in the background and show only results; that‚Äôd make more sense.\n\nI still think this is not too bad for a simple exercise implemented in my spare time‚Ä¶"
  },
  {
    "objectID": "posts/2025-05-18_RLCS_with_Cpp/index.html",
    "href": "posts/2025-05-18_RLCS_with_Cpp/index.html",
    "title": "RLCS: Making things faster where it matters",
    "section": "",
    "text": "This entry was not ‚Äúplanned‚Äù, as I am still working on this last bit, and also I shouldn‚Äôt touch things as I have a presentation coming next week on this, but‚Ä¶\nOne key issue with the LCS algorithm, as repeatedly mentioned thus far, is training speed‚Ä¶ It‚Äôs not great. And after running it many (many many) times, it does work, but I am well aware this will be a problem at some point. We also know R is an interpreted and (thus) slow language. I have done my best to take advantage of SIMD capacity of nowadays CPUs (through the lapply() family of functions).\nAnd so, as also mentioned in the past, I have been profiling the code (using profvis) and I have known for quite a while that the bottleneck in the end is in the matching operation. I won‚Äôt explain what matching entails here, but it is maybe the most used operation of the algorithm, and one that is expensive.\nNow I could (I guess) re-code it all in C++ (or, say, Rust? I was reading up on that‚Ä¶ But that‚Äôs a story for some other time), but let‚Äôs face it‚Ä¶ I don‚Äôt wanna. Also, it‚Äôd be a lousy R Package if it had no R code‚Ä¶\nBut, let‚Äôs face it, sometimes one has no choice but to move beyond R."
  },
  {
    "objectID": "posts/2025-05-18_RLCS_with_Cpp/index.html#rcpp-for-the-win",
    "href": "posts/2025-05-18_RLCS_with_Cpp/index.html#rcpp-for-the-win",
    "title": "RLCS: Making things faster where it matters",
    "section": "",
    "text": "This entry was not ‚Äúplanned‚Äù, as I am still working on this last bit, and also I shouldn‚Äôt touch things as I have a presentation coming next week on this, but‚Ä¶\nOne key issue with the LCS algorithm, as repeatedly mentioned thus far, is training speed‚Ä¶ It‚Äôs not great. And after running it many (many many) times, it does work, but I am well aware this will be a problem at some point. We also know R is an interpreted and (thus) slow language. I have done my best to take advantage of SIMD capacity of nowadays CPUs (through the lapply() family of functions).\nAnd so, as also mentioned in the past, I have been profiling the code (using profvis) and I have known for quite a while that the bottleneck in the end is in the matching operation. I won‚Äôt explain what matching entails here, but it is maybe the most used operation of the algorithm, and one that is expensive.\nNow I could (I guess) re-code it all in C++ (or, say, Rust? I was reading up on that‚Ä¶ But that‚Äôs a story for some other time), but let‚Äôs face it‚Ä¶ I don‚Äôt wanna. Also, it‚Äôd be a lousy R Package if it had no R code‚Ä¶\nBut, let‚Äôs face it, sometimes one has no choice but to move beyond R."
  },
  {
    "objectID": "posts/2025-05-18_RLCS_with_Cpp/index.html#the-results-please",
    "href": "posts/2025-05-18_RLCS_with_Cpp/index.html#the-results-please",
    "title": "RLCS: Making things faster where it matters",
    "section": "The results, please?!",
    "text": "The results, please?!\nAlright alright, I digress, I know.\nHere.\nBEFORE:\n\n\n\nProfile and Guilty code in R\n\n\nNow this is a real, but incomplete test.\nAnd all I did was change the one piece of code like so:\n    ## Inside \"get_match_set()\", a sub-routine gets indices...\n\n    ## BEFORE\n    # match_set &lt;- which(sapply(pop, \\(item, ti_cond) {\n    #   rule &lt;- item$condition_list\n    #   !(any(ti_cond[rule$'0'] != 0) || any(ti_cond[rule$'1'] != 1))\n    # }, ti_cond))\n    \n    ## AFTER\n    match_set &lt;- get_match_set_cpp(pop, ti_cond)\nAnd (although it‚Äôs very basic and probably not great‚Ä¶) here the new version of the same functionality, but in C++ with some RCpp ‚Äúsugar‚Äù:\n#include &lt;Rcpp.h&gt;\nusing namespace Rcpp;\n\nbool element_matches(List element, NumericVector ti_cond) {\n  List temp_conds = element(\"condition_list\");\n  NumericVector temp_conds_0 = temp_conds(\"0\");\n  int j;\n  for(j = 0; j &lt; temp_conds_0.size(); j++) {\n    if(ti_cond[temp_conds_0[j]-1] != 0) { return(false); }\n  }\n  NumericVector temp_conds_1 = temp_conds(\"1\");\n  for(j = 0; j &lt; temp_conds_1.length(); j++) {\n    if(ti_cond[temp_conds_1[j]-1] != 1) { return(false); }\n  }\n  return(true);\n}\n\n// [[Rcpp::export]]\nRcpp::NumericVector get_match_set_cpp(List pop, NumericVector ti_cond) {\n  NumericVector matches_indices;\n  int i;\n  for(i = 0; i &lt; pop.length(); i++) {\n    if(element_matches(pop[i], ti_cond)) {\n      matches_indices.push_back(i+1);\n    }\n  }\n  return(matches_indices);\n}\nAnd AFTER said changes:\n\n\n\n1/3 runtime for that section, &lt; 1/2 overall!\n\n\nNotice the 4 seconds mark vs the 10 seconds (overall)? And that‚Äôs just one test‚Ä¶ That is, in spite of using vectorized operations, I was far from ‚Äúfast enough‚Äù, compared to a compiled version."
  },
  {
    "objectID": "posts/2025-05-18_RLCS_with_Cpp/index.html#the-issue-i-faced",
    "href": "posts/2025-05-18_RLCS_with_Cpp/index.html#the-issue-i-faced",
    "title": "RLCS: Making things faster where it matters",
    "section": "The issue I faced",
    "text": "The issue I faced\nOne problem I had with this‚Ä¶ Is that I need to update my whole MacBook OS and XCode to get RCpp to run on it ü§ï\nAnd I‚Äôm not home, I‚Äôm using Mobile data, and I‚Äôm literally 5 days away from having to demo this thing ‚Äúlive‚Äù, and I just don‚Äôt want to break anything right now!\nSo‚Ä¶ I went back to Docker (which I hadn‚Äôt used for a while‚Ä¶ And the OSX complained it was a ‚Äúpotential malware‚Äù, and I had to re-install that too‚Ä¶), and got myself a new RStudio container, and did all the tests from there‚Ä¶\nSo I‚Äôll do more testing AFTER I have a new full-backup, and I‚Äôm at home to upgrade the whole environment‚Ä¶\nBut regardless (and that‚Äôs what‚Äôs cool with Docker!), this just worked :)"
  },
  {
    "objectID": "posts/2025-05-18_RLCS_with_Cpp/index.html#conclusions",
    "href": "posts/2025-05-18_RLCS_with_Cpp/index.html#conclusions",
    "title": "RLCS: Making things faster where it matters",
    "section": "Conclusions",
    "text": "Conclusions\nSometimes, you have to go down one level (or two)‚Ä¶ But it‚Äôs soooo worth it :)"
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html",
    "href": "posts/2021-05-01_OnFutures/index.html",
    "title": "A revelation: R Futures",
    "section": "",
    "text": "I have been accepting (NOT complaining about) R limitation of being mono-core, monothread. For a long time. Actually, for years. I even went all the way to using Docker to distribute compute load across CPUs of one (or more) physical machine. It was just something I had ‚Äúassumed‚Äù was like that.\nBut what little did I know (as it apparently always is the case). In other words, once again, I was wrong, and as always, the harder I try, the more I learn (thankfully). Well, maybe not exactly wrong: The R interpreter is still mono-core, mono-thread (as far as I understand). That doesn‚Äôt mean nothing can be done about it.\nMore importantly: THIS IS A GAME CHANGER FOR ME. My beloved R programming language was always useful for my goals, but now it‚Äôs also FAST! (I‚Äôm weird because of this, if you ask my colleagues ‚Äì All others seem to have gone the Python way). And it only took me about 6-7 years to find out I could parallelise computing in R (yes: facepalm, right there)."
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html#intro",
    "href": "posts/2021-05-01_OnFutures/index.html#intro",
    "title": "A revelation: R Futures",
    "section": "",
    "text": "I have been accepting (NOT complaining about) R limitation of being mono-core, monothread. For a long time. Actually, for years. I even went all the way to using Docker to distribute compute load across CPUs of one (or more) physical machine. It was just something I had ‚Äúassumed‚Äù was like that.\nBut what little did I know (as it apparently always is the case). In other words, once again, I was wrong, and as always, the harder I try, the more I learn (thankfully). Well, maybe not exactly wrong: The R interpreter is still mono-core, mono-thread (as far as I understand). That doesn‚Äôt mean nothing can be done about it.\nMore importantly: THIS IS A GAME CHANGER FOR ME. My beloved R programming language was always useful for my goals, but now it‚Äôs also FAST! (I‚Äôm weird because of this, if you ask my colleagues ‚Äì All others seem to have gone the Python way). And it only took me about 6-7 years to find out I could parallelise computing in R (yes: facepalm, right there)."
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html#context",
    "href": "posts/2021-05-01_OnFutures/index.html#context",
    "title": "A revelation: R Futures",
    "section": "Context",
    "text": "Context\nThe last few weeks I have been dealing with several-hours-runtimes in some scripts. A big part because of API limits, so not much to tweak there. But for the rest of the code that was no excuse‚Ä¶ And if anything broke (I need to work on my debugging skills), I would have to re-launch much of it‚Ä¶\nAnd then when it comes to hours, although I generally don‚Äôt care about running times (actually: if it‚Äôs during my sleep, machine hours are GREAT: Work being done while I‚Äôm sleeping!), when it comes to slowing me down during the day, well, that‚Äôs another matter. Particularly when the thing slowing me down is an automation (it‚Äôs like an oxymoron or something, don‚Äôt you agree?).\nAnd I was considering this for the past week, I was even about to start going the way of ‚Äúcontainerization‚Äù, plumbeR, etc. After all, distributing the work IS a way to make things faster (if/when applicable).\nBut as I was pondering on this issue, I finally challenged my assumptions: can R be made multi-thread? Or can I make it run stuff in parallel?\nAs introduced earlier, challenging the assumption paid off: As it turns out, there are MORE THAN ONE packages out there (facepalm, once again, really) to help with this particular endeavour. Now I had to choose one of those for testing, and I chose ‚Äúfuture.apply‚Äù (which is actually a wrap around the ‚Äúfuture‚Äù package)."
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html#welcome-to-the-future",
    "href": "posts/2021-05-01_OnFutures/index.html#welcome-to-the-future",
    "title": "A revelation: R Futures",
    "section": "Welcome to the Future",
    "text": "Welcome to the Future\nIt‚Äôs SO easy, I really hate myself for not having found out about this years ago already. But that‚Äôs OK. Within a few years, maybe, I might consider myself something more than an R programming beginner. For now, that‚Äôs actually a good thing.\nAlright so here is the complete code for the test:\n# Testing future package through future.apply\n\nlibrary(future.apply)\nlibrary(Rwhois) # A reasonable slow function\nlibrary(microbenchmark)\n\navailableCores() # 4 on the Home Lab Server\nplan(multisession) # Let's compare a couple of speed tests\n\ndomains_vector &lt;- c(\"google.com\", \"kaizen-r.com\", \"nytimes.com\", \n   \"economist.com\", \"had.co.nz\", \"urlscan.io\",\n   \"towardsdatascience.com\", \"aquasec.com\", \"ipvoid.com\",\n   \"rstudio.com\", \"mitre.org\", \"what2log.com\")\n\nmicrobenchmark(\n   lapply(domains_vector, whois_query), # traditional way\n   future_lapply(domains_vector, whois_query), # using futures\n   times = 5L\n)\nEssentially: One library load, one ‚Äúplan‚Äù command, and a very similar way of doing things (using vectorization).\nHere are the results:\n\nAs always, there is MUCH MORE TO IT. For instance the concept of ‚Äúfuture‚Äù is actually interesting in and of itself, as explained on the Package Owner‚Äôs GitHub:\n‚Äúa future is an abstraction for a value that may be available at some point in the future. The state of a future can either be unresolved or resolved. [‚Ä¶]‚Äù\nThe future package has implicit calls (using %&lt;-% instead of &lt;-) or explicit calls. It has different plans. I actually wanted to test ‚Äúmulticore‚Äù instead of ‚Äúmultisession‚Äù, as it seems this reduces overhead and hence enhances further the gains of speed, but apparently this might clash with RStudio for I-don‚Äôt-really-know-the-reason.\nFrom the comments on GitHub, by Henrik Bengtsson (I didn‚Äôt know him, but because of ‚Äúfuture.apply‚Äù, he now is on my top R guys list):\n‚ÄúFor instance, when running R from within RStudio process forking may resulting in crashed R sessions‚Äù\nMy tests demonstrated that something must be off, because speed was NOT improved at all compared to non-parallelized calls, so the multicore option did not work for me.\nThat‚Äôs OK though, this thing has already changed my life as an R-coding guy. (Not every day does one challenge such an ingrained assumption, just to find I was so wrong for so long‚Ä¶)"
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html#conclusions",
    "href": "posts/2021-05-01_OnFutures/index.html#conclusions",
    "title": "A revelation: R Futures",
    "section": "Conclusions",
    "text": "Conclusions\nThe results are there alright.\nSimply put, we managed to multiply speed by ~3 times, by using better the available resources on the machine. (I am guessing one of the cores cannot be used, it must be busy with Docker, OS, or the session creation overhead is slowing things down‚Ä¶ I‚Äôll have to double check)."
  },
  {
    "objectID": "posts/2021-05-01_OnFutures/index.html#resources",
    "href": "posts/2021-05-01_OnFutures/index.html#resources",
    "title": "A revelation: R Futures",
    "section": "Resources",
    "text": "Resources\nhttps://github.com/HenrikBengtsson/future.apply\nMy own demo code on my GitHub account"
  },
  {
    "objectID": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html",
    "href": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html",
    "title": "Nonlinear Dynamics: on Bifurcations",
    "section": "",
    "text": "It turns out, back in February 2022, I published on the ‚Äúold‚Äù Blog an entry on the Logistic Map.\nAs I was reading through Chapter 2 last week, it was mentioned. This week, I browsed through Chapter 3 (that one will take time to fully follow), which discusses Bifurcations.\nAs the math was getting complicated, with ‚Äúsupercritical pitchfork‚Äù bifurcations, or ‚Äúcusp catastrophe‚Äù including an imperfection parameter and hence play with 2 independent variables (forcing us to look at things as folded surfaces in 3D).\nLong story short, it was a bit overwhelming, and so at one point I disconnected and thought I‚Äôd browse a bit through all the chapters to get a sense of what was ahead, which I did this morning.\nAnd sure enough, chapter 10 is about one-dimensional maps and it comes after the introduction of chaos with the Lorenz equations.\nWell, I‚Äôm not re-writing what I wrote some time ago, so instead I hereby reproduce the old entry, only updating pointers to images.\nBut I will say, the new book mentioned last week does put things in perspective, beyond ‚Äúreproducing‚Äù the code and math, and that is quite exactly what I wanted in the first place."
  },
  {
    "objectID": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#new-intro",
    "href": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#new-intro",
    "title": "Nonlinear Dynamics: on Bifurcations",
    "section": "",
    "text": "It turns out, back in February 2022, I published on the ‚Äúold‚Äù Blog an entry on the Logistic Map.\nAs I was reading through Chapter 2 last week, it was mentioned. This week, I browsed through Chapter 3 (that one will take time to fully follow), which discusses Bifurcations.\nAs the math was getting complicated, with ‚Äúsupercritical pitchfork‚Äù bifurcations, or ‚Äúcusp catastrophe‚Äù including an imperfection parameter and hence play with 2 independent variables (forcing us to look at things as folded surfaces in 3D).\nLong story short, it was a bit overwhelming, and so at one point I disconnected and thought I‚Äôd browse a bit through all the chapters to get a sense of what was ahead, which I did this morning.\nAnd sure enough, chapter 10 is about one-dimensional maps and it comes after the introduction of chaos with the Lorenz equations.\nWell, I‚Äôm not re-writing what I wrote some time ago, so instead I hereby reproduce the old entry, only updating pointers to images.\nBut I will say, the new book mentioned last week does put things in perspective, beyond ‚Äúreproducing‚Äù the code and math, and that is quite exactly what I wanted in the first place."
  },
  {
    "objectID": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#the-original-post-reproduced",
    "href": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#the-original-post-reproduced",
    "title": "Nonlinear Dynamics: on Bifurcations",
    "section": "The original Post, reproduced",
    "text": "The original Post, reproduced\n\nSome Context\nThis was written while I was taking a course within the scope of my last MSc, which explains the reference to the course, next."
  },
  {
    "objectID": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#old-intro",
    "href": "posts/2025-07-20_NonLinearDynamics_Chapter3/index.html#old-intro",
    "title": "Nonlinear Dynamics: on Bifurcations",
    "section": "OLD Intro",
    "text": "OLD Intro\nSo I took a course in ‚ÄúNumerical Methods‚Äù, and (somehow) passed (I loved every bit of it, although it was HARD!).\nBut then of course, taking a course doesn‚Äôt make me ‚Äúproficient‚Äù at the subject matter. At best, it has exposed me to it and given me some confidence that I in fact can understand its concepts and solve problems ‚Äì even if I‚Äôm not too fast‚Ä¶ I simply feel there is SO MUCH MORE to it, and indeed I have several books on the subject to confirm it: I still have plenty to learn. Which is why I want to keep digging into it on my own.\nIf anything, I did get a good dose of Engineering-level Maths exposure, and I needed that (after a few years working in Cyber ‚Äì and I guess in most jobs ‚Äì one might tend to forget about matrices or how/why to differentiate equations, and many white-collar workers will simply spend their days using Outlook, PowerPoint and maybe Excel‚Ä¶).\nAnyhow, I was thrilled I took that course. And I am looking forward for more similar courses (the Master continues, for me spread over three years‚Ä¶). But while that comes, I was particularly interested in some ideas of non-linear equations, differential equations, and Chaos Theory. We did do an exercise about Lorenz‚Äôs typical differential equations, and I saw the strange-attractors and the ‚Äúbutterfly-like‚Äù drawing come to life from my own implementation (in Matlab) of these 3 simple equations, and I kind of fell in love with it.\nLet me be clear: I am not a mathematician, and I know I don‚Äôt fully grasp the ideas (far from it, in fact!). But I keep reading about it. While reading ‚ÄúChaos‚Äù by James Gleick (a reference on the subject), I came across the chapter about Ecology and the ‚ÄúLogistic Map‚Äù. And I thought: This is BEAUTIFUL.\n\n\n\n\n\nLast note for the Intro: The below has been done MANY TIMES, I am not inventing the wheel. I will just write my own R code to play around the simple equation and see its magic. I found references, particularly one that I will mention, that HEAVILY inspired this post (although I‚Äôm creating my own code ‚Äì and doing it in R), on top of the book. Please do have a look at both if you have any interest.\n\nThe Logistic Map\nSo I‚Äôm not the right person to explain it in details, but the below is basically a mathematical expression of the evolution of a supposed population (say of fish), that considers a ‚Äúgrowth rate‚Äù r, an initial population x0, and then tries to estimate the population say one year later (x1), and then the year after that (x2), etc. The following short equation ‚Äì the ‚Äúlogistic map‚Äù ‚Äì is all you need to produce the graph from the introduction!\n\\[\nx_{k+1} = rx_k (1-x_k)\n\\]\nIf you consider a limited environment, the typical example being a pond with fish, you need to consider that maybe a predator-prey thing might happen: If a population grows too much, it will deplete its resources (food, space‚Ä¶), and then will have to reduce its population so as to adapt to the available resources. This is the ‚Äú* (1-x)‚Äù part of the equation: If there is too much fish, there won‚Äôt be enough food, space or oxygen. Hence the population would decrease. The decrease would leave more resources available, so that the fish population would be able to increase again (but in cycles, not continuously, as we can suppose the fish doesn‚Äôt reproduce and die instantaneously).\nFor the sake of the example, let‚Äôs assume an initial population x0 of 0.5. (Here x is set between 0 and 1, so that things work as expected).\n\n\nBack to the graph of the introduction\nSo what is the graph¬† in the intro all about?\nIt‚Äôs called a Bifurcation Diagram. It shows the evolution of the theoretical population over several generation (each dot is one value of the population at a given generation), as described above, but with different values for the growth ratio, after say 1000 generations.\nOn the x axis, different values of our growth ratio, and on the y axis, the number of individuals in the population. For a growth ratio below 1, as can be expected, the population tends to grow smaller and smaller and hence tends to decrease to 0. That‚Äôs the left part of the blue line, after 100 generations, the population is 0 in these cases.\n\n\n\n\n\nWhat‚Äôs interesting is that for growth ratios between 1 and 3.0, the population tends to stabilize to one specific value, which is why we see how the line grows somewhat but appears as a line: For each growth ratio in that range, the population stabilizes to one value. (What you can‚Äôt really see is that, in fact, there are many dots on each position of the line, one for each generation: For a given growth ratio, the population is stable at that particular value).\n\n¬†\nFrom 3.0 to roughly 3.4, it turns out that the population oscillates between two values! That is: Either they have enough resources (population grows to a specific value) or not (the population decreases to another specific value), and each generation, it cycles to one of those two values.\nAfter that it gets weirder:\nBefore a growth of¬† ~3.45, more possible values appear, then again at ~3.54. But then the number of individuals in each generation seems to become ‚Äúrandom‚Äù, and takes any value within some ranges, which is why we don‚Äôt see ‚Äúlines‚Äù anymore, but rather clouds of points.\nWith a growth ratio of 3.999, it would seem each generation has a different number of individual, ranging basically from 0 to 1 (all possible values!), seemingly random!\n\n\nInterlude\nRandomness is important in cybersecurity. So having an equation THAT SIMPLE generating seemingly random numbers sounds appealing. It‚Äôs not much more complex than the ‚Äúlinear congruential generator‚Äú, in fact. Maybe we could compare those two?\nSo let‚Äôs implement a simplistic generator of random number:\n# Linear congruential generator\nrandom_numbers_vector &lt;- c()\nX0 &lt;- 12 # seed\na &lt;- 36\nc &lt;- 2\nm &lt;- 3583 # also, this one is prime\nmax_iterations &lt;- 200\nXi_plus_1 &lt;- function(x, current_iter = 0, max_iter = max_iterations) {\n  random_numbers_vector[current_iter+1] &lt;&lt;- x\n  if(current_iter == max_iter) return(x)\n  Xi_plus_1( (a * x + c) %% m, current_iter+1, max_iter)\n}\nrandom_numbers_vector &lt;- rep(0, max_iterations)\nXi_plus_1(X0)\n# scale to have values between 0 and 1\nrandom_numbers_vector &lt;- random_numbers_vector/max(random_numbers_vector)\nThen, for comparison, let‚Äôs generate our population values with a growth rate of 3.999, for the same amount of generations:\n# Recursive version of our Logistic Map function\nlogistic_numbers_vector &lt;- rep(0.5, max_iterations)\nmy_logistic_map3 &lt;- function(my_r, x, current_iter = 0, max_iter = max_iterations) {\n  logistic_numbers_vector[current_iter+1] &lt;&lt;- x\n  if(current_iter == max_iter) return(x)\n  my_logistic_map3(my_r, my_r * x * (1-x), current_iter+1, max_iter)\n}\nmy_logistic_map3(3.999, 0.5)\nThen let‚Äôs compare two consecutive values, from each set of generated numbers:\ncomparator_df &lt;- data.frame(generation = 0:200, \n   logistic_map_num = logistic_numbers_vector, \n   random_num = random_numbers_vector)\ncomparator_df %&gt;% pivot_longer(cols = contains(\"num\"),\n   names_to = \"generator\",\n   values_to = \"vals\") -&gt; for_plot\nggplot(for_plot[for_plot$generation %in% 30:50,], aes(x = generation, y = vals, colour = generator)) +\n  geom_line()\nAnd they seem rather ‚Äúrandom‚Äù at first sight, both of them, wouldn‚Äôt you say?\n\n\n\n\n\nMe at least, at first sight, I wouldn‚Äôt be able to tell which one is random, and which one isn‚Äôt (but is chaotic).\nBut HERE IS THE KEY: The logistic map is NOT at all random, but rather perfectly deterministic (well, to be fair, our pseudo-random number generator is deterministic too, but it behaves more as expected).\nSo how can we tell the difference? Here the ‚Äúhorse-shoe‚Äù figure makes its entrance. In the above graph, we could have thought that both generators gave back random numbers.\nBUT if we graph the values from two consecutive generations against each other (apparently that‚Äôs called a Phase Diagram), the magic appears:\ncomparator_df$logistic_map_num1 &lt;- c(comparator_df$logistic_map_num[2:nrow(comparator_df)],0)\ncomparator_df$random_num1 &lt;- c(comparator_df$random_num[2:nrow(comparator_df)],0)\n# Finally, the beauty!\nggplot(comparator_df) +\n  geom_point(aes(x = logistic_map_num, y = logistic_map_num1, colour = \"logistic_map\")) +\n  geom_point(aes(x = random_num, y = random_num1, colour = \"pseudo_random\")) + \n  scale_color_manual(values = c(\"logistic_map\" = \"blue\", \"pseudo_random\" = \"red\"))+\n  ggtitle(\"Comparing Logistic Map and Pseudo-Random Generator\")+\n  xlab(\"'Generation N'\") +\n  ylab(\"'Generation N+1'\")\n\nAnd, to me, that‚Äôs absolutely & simply wonderful. I can‚Äôt avoid but to feel impressed by the structure appearing there, from something that anyone would otherwise have reasonably assumed is complete ‚Äúchaos‚Äù‚Ä¶ (And it is üòÄ Structure in Chaos, I suppose that‚Äôs where this came from‚Ä¶ Although I haven‚Äôt read enough yet :D)\n\n\nThe code\nOf course, the above is done in R‚Ä¶ I leave the demo code on my GitHub account for reference.\nLet‚Äôs just say, it involves a few loops applying the very simple equation above, but with different growth rates, for a certain number of generations (at one point, we‚Äôre talking of about ~4 million points).\nIn the spirit of ‚ÄúNumerical Methods‚Äù, and taking advantage of our computer, we can repeat the calculations many times. In this case, the ‚Äúapply()‚Äù family of functions were not too helpful, as the equation is recurrent, so we need one result before we can calculate the next (we could probably trick it, but that‚Äôs not the point for today).\n\n\nConclusion\nI just loved this example: One of the simplest of equations (it doesn‚Äôt look that scary, does it), and yet so much can happen from one small change in one parameter!\nTo me, this is a thing of wonder. But then, maybe I am a bit of a geek for math after all (while not at all good at it).\nThere is of course MUCH MORE to it all. But I really wanted to implement this exercise for myself and reproduce it.\n\n\nReferences\nSomeone did all the above (and better/more) in Python\nThe book (I don‚Äôt earn anything from the link, buy it where you like best)\nMy code on GitHub"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html",
    "title": "RLCS: Caring for better performance",
    "section": "",
    "text": "There was still room for improvement. Probably still is, of course, just‚Ä¶ Not with a total redo, I guess.\nThere were two or 3 key ingredients to the improvements.\nDaring with fewer epochs (and I found out eventually, I really didn‚Äôt need hundreds or thousands in some cases, so I‚Äôve been waiting during many tests for overall probably quite a few hours that could have been minutes, had I tried better combinations of hyperparameters!)\nJust so we‚Äôre clear: With the Rcpp trick last week, now working on my Mac (Macbook Air M1), and quite a few basic improvements (unnecessary iterations here and there (shame on me), particularly with subsumption and deletion, faster sorting now without resorting to rbind.fill(lapply()), which is nice, but quite unnecessary, and sorting is key at several moments)‚Ä¶\nAnd (and this is relevant) by using a better set of hyperparameters per use-case‚Ä¶\nOverall, we‚Äôre talking quite literally about one order of magnitude in performance gain, in some cases.\nNot bad!"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#rcpp-did-its-part-but",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#rcpp-did-its-part-but",
    "title": "RLCS: Caring for better performance",
    "section": "",
    "text": "There was still room for improvement. Probably still is, of course, just‚Ä¶ Not with a total redo, I guess.\nThere were two or 3 key ingredients to the improvements.\nDaring with fewer epochs (and I found out eventually, I really didn‚Äôt need hundreds or thousands in some cases, so I‚Äôve been waiting during many tests for overall probably quite a few hours that could have been minutes, had I tried better combinations of hyperparameters!)\nJust so we‚Äôre clear: With the Rcpp trick last week, now working on my Mac (Macbook Air M1), and quite a few basic improvements (unnecessary iterations here and there (shame on me), particularly with subsumption and deletion, faster sorting now without resorting to rbind.fill(lapply()), which is nice, but quite unnecessary, and sorting is key at several moments)‚Ä¶\nAnd (and this is relevant) by using a better set of hyperparameters per use-case‚Ä¶\nOverall, we‚Äôre talking quite literally about one order of magnitude in performance gain, in some cases.\nNot bad!"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#from-7-minutes-to-2-minutes-with-bigger-training-sets",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#from-7-minutes-to-2-minutes-with-bigger-training-sets",
    "title": "RLCS: Caring for better performance",
    "section": "From 7 minutes to <2 minutes (with bigger training sets)",
    "text": "From 7 minutes to &lt;2 minutes (with bigger training sets)\nQuite literally. I had a screenshot of me training with images here.\nThere it said, basically:\n6.9 (~7) minutes. For better results, even 9 minutes. For a training set of 500 samples. That was 2 months ago.\nHere is what it is today:\n\n\n\n\n\nThat‚Äôs well under one fourth of the runtime, and with 1.6x the data."
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#from-4-minutes-to-3-seconds",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#from-4-minutes-to-3-seconds",
    "title": "RLCS: Caring for better performance",
    "section": "From 4 minutes to <3 seconds",
    "text": "From 4 minutes to &lt;3 seconds\nYes. Well, this one is my fault, really.\nI THOUGHT (in my head, with no tangible proof) that the ‚Äúnot_bit_4_10‚Äù was supposed to be hard for the machine. What with 10-bits strings and all‚Ä¶ As it turns out, if you trust the process, it needs not be.\nHere is the original runtime for that particular test:\n\n\n\nnot_bit_4 in a 10bits string\n\n\nThat was bad!\nAs I‚Äôve been working on performance, here a screenshot of runtime with same perfect resulting classifier today:\n\n\n\nhard to believe: 10-20x faster‚Ä¶\n\n\nNow, to be fair: Hyperparameters were ‚Äúoptimized‚Äù for MUX6, and I was still focusing on functionality more than performance, back then, but now‚Ä¶ Well, now it is ‚Äúbearable‚Äù :)"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#what-about-iris",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#what-about-iris",
    "title": "RLCS: Caring for better performance",
    "section": "What about iris?",
    "text": "What about iris?\nWell, not to worry!\nI did myself (and the community) a great disservice by not optimizing this a week ago. During my last presentation (last week), I mentioned it took 3 minutes to train on Iris dataset. What a pity. What poor performance that was, truly‚Ä¶\nHere is the update, and I believe it‚Äôs significant:\n\n\n\nTraining on Iris dataset within seconds\n\n\nFor reference (for myself, to have a sense of where the competition is at), I ran a demo with a Neuralnet. Indeed, that‚Äôs like &lt;2 seconds, maybe &lt;1 sec.¬†But it‚Äôs probably (my guess) all C.\nPlus, we know the LCS algorithm is inherently slow, there are limits to what we can do about it.\nStill.\nWell, now it‚Äôs faster. It takes 3 seconds. 1.7% the time announced a few days back‚Ä¶"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#same-for-rl",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#same-for-rl",
    "title": "RLCS: Caring for better performance",
    "section": "Same for RL!",
    "text": "Same for RL!\nTraining an agent that is reasonably good (remember, it is stochastic, so the thing isn‚Äôt always easily comparable), at least from statistics of its last 1000 moves, used to take quite literally 10 minutes.\nI‚Äôve gotten under 2m now:\n\n\n\nTraining a valid agent under 2 minutes"
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#limits-of-rcpp-for-doparallel-for-now",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#limits-of-rcpp-for-doparallel-for-now",
    "title": "RLCS: Caring for better performance",
    "section": "Limits of Rcpp for DoParallel (for now)",
    "text": "Limits of Rcpp for DoParallel (for now)\nSo I found one thing that will require more work: %dopar% and Rcpp don‚Äôt play nice ‚Äúout of the box‚Äù.\nSeems like they will WHEN I make the whole thing into a package.\nEven then, parallel training for images classification with 1.6x the original training size, parallelized over 7 cores (M1) and split accordingly (input subsets), gets me similar results without the Rcpp gains as the Rcpp serial version. And the serial Rcpp version is already about &gt; 1.5x as fast as the pure-R version, so‚Ä¶\nMaybe we can go even faster (and I don‚Äôt know that this particular example was the harder one for justifying parallel computing‚Ä¶ Oh well).\nSo here, another thing I will have to work on."
  },
  {
    "objectID": "posts/2025-05-25_RLCS_overall_faster/index.html#conclusions",
    "href": "posts/2025-05-25_RLCS_overall_faster/index.html#conclusions",
    "title": "RLCS: Caring for better performance",
    "section": "Conclusions",
    "text": "Conclusions\nI don‚Äôt know that I‚Äôll be capable of making this much faster by now, lest I review the overall approach with lists for something even better, maybe (data.table?). But that would be for a V3 or something, so not for now.\nRight now, it‚Äôs not too bad.\nHeck, dare I‚Ä¶ I‚Äôd say it‚Äôs actually maybe even quite competitive now, given the readability of the output model."
  },
  {
    "objectID": "posts/2022-05-08_OnDiminishing_Parallel/index.html",
    "href": "posts/2022-05-08_OnDiminishing_Parallel/index.html",
    "title": "Diminishing returns of parallelization",
    "section": "",
    "text": "It‚Äôs been a while without new entries here, as usual because I was busy one way or another.\nIn keeping with the Master‚Äôs studies, one of my excuses is the homework for the ‚Äúhigh performance computing‚Äù course.\nRecently we worked on OpenMP, and then with MPI.\nBoth are cool and those that read this blog know how much I care about improving processing speeds‚Ä¶"
  },
  {
    "objectID": "posts/2022-05-08_OnDiminishing_Parallel/index.html#intro",
    "href": "posts/2022-05-08_OnDiminishing_Parallel/index.html#intro",
    "title": "Diminishing returns of parallelization",
    "section": "",
    "text": "It‚Äôs been a while without new entries here, as usual because I was busy one way or another.\nIn keeping with the Master‚Äôs studies, one of my excuses is the homework for the ‚Äúhigh performance computing‚Äù course.\nRecently we worked on OpenMP, and then with MPI.\nBoth are cool and those that read this blog know how much I care about improving processing speeds‚Ä¶"
  },
  {
    "objectID": "posts/2022-05-08_OnDiminishing_Parallel/index.html#not-r",
    "href": "posts/2022-05-08_OnDiminishing_Parallel/index.html#not-r",
    "title": "Diminishing returns of parallelization",
    "section": "Not R",
    "text": "Not R\nSo I make the parallel in my head between OpenMP and ‚Äúfutures‚Äù in R, and on the other hand of MPI and PlumbeR. It‚Äôs all WRONG of course, they‚Äôre not even alike, but it does help me visualize some of the differences, as the course is using C/C++‚Ä¶ (incidentally, I found I am real ‚Äúrusty‚Äù working with C)\nAs a side note, I liked that the last exercises applied the MPI configs to run code, to some of the Numerical Methods concepts learnt a few months back (calculating PI using 1e11 operations is indeed faster across 32 CPUs‚Ä¶)."
  },
  {
    "objectID": "posts/2022-05-08_OnDiminishing_Parallel/index.html#to-the-point",
    "href": "posts/2022-05-08_OnDiminishing_Parallel/index.html#to-the-point",
    "title": "Diminishing returns of parallelization",
    "section": "To the point",
    "text": "To the point\nOne important (in my personal opinion) lesson I take out of that past exercise, is how parallelizing execution has diminishing returns.\nIn an ideal world, one could divide by two the overall runtime (provided we forget about sequential parts and overhead, which we can‚Äôt do) of some code each time one doubles the number of CPUs.\nBut although it‚Äôs quite obvious: dividing 30‚Äô in two saves us 15‚Äô. But after very few such improvements (I.e. doubling CPUs‚Ä¶), you get to go from 5‚Äô to 2 and a half."
  },
  {
    "objectID": "posts/2022-05-08_OnDiminishing_Parallel/index.html#conclusion",
    "href": "posts/2022-05-08_OnDiminishing_Parallel/index.html#conclusion",
    "title": "Diminishing returns of parallelization",
    "section": "Conclusion",
    "text": "Conclusion\nAs always maybe we need to look for a balance. After all, for operations that might take weeks, literally (like training a Deep Neural Net ‚Äì not that I‚Äôm experienced there, I just read a lot ;)), yes, it makes sense. But sometimes it doesn‚Äôt. I‚Äôm not saying not to optimize code of course, but once the code is clean and stable, duplicating CPUs will only get us so far and IN SOME cases, I‚Äôm happy if my laptop gets me a result within hours, and if I‚Äôm being honest and I organize myself a bit around it, I don‚Äôt really need to divide the running time by 2 once more.\nAnd there resides the question with having plenty of CPUs: Is it needed?\nIt‚Äôs not the first time I think about these things‚Ä¶"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "",
    "text": "So as I keep working on an upcoming presentation I shall give in a few weeks, I thought I‚Äôd prepare something a bit more ‚Äúlive‚Äù than just a PPT with Memes (although who doesn‚Äôt like a few Memes in a PPT?).\nMy current idea is to talk about some ‚ÄúMachine Learning Key Concepts‚Äù, and then bring it back to Cybersecurity applications.\nSo part of it could be about two key things:\n\nSupervised vs Unsupervised Learning\nSymbolic vs Sub-Symbolic ‚ÄúAI‚Äù\n\nWhich I feel help frame a bit what we‚Äôre talking about when we talk about Machine Learning.\nToday, we‚Äôll do some review, and then talk about Clustering. Here an output of one such algorithm, in 3D:"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#section",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#section",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "",
    "text": "So as I keep working on an upcoming presentation I shall give in a few weeks, I thought I‚Äôd prepare something a bit more ‚Äúlive‚Äù than just a PPT with Memes (although who doesn‚Äôt like a few Memes in a PPT?).\nMy current idea is to talk about some ‚ÄúMachine Learning Key Concepts‚Äù, and then bring it back to Cybersecurity applications.\nSo part of it could be about two key things:\n\nSupervised vs Unsupervised Learning\nSymbolic vs Sub-Symbolic ‚ÄúAI‚Äù\n\nWhich I feel help frame a bit what we‚Äôre talking about when we talk about Machine Learning.\nToday, we‚Äôll do some review, and then talk about Clustering. Here an output of one such algorithm, in 3D:"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#simplified-definition-of-machine-learning",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#simplified-definition-of-machine-learning",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Simplified definition of Machine Learning",
    "text": "Simplified definition of Machine Learning\nNow I‚Äôm probably NOT the right source for you to learn this, so I really suggest you read about that somewhere else. The wiki puts it a bit like so:\n‚ÄúThe study of statistical algorithms¬†that can learn from¬†data¬†and¬†generalize¬†to unseen data, and thus perform¬†tasks¬†without explicit¬†instructions.‚Äù\nThere are quite a FEW THINGS in that sentence right there. But for today:\n\nIn traditional programming, a person WRITES A PROGRAM, that receives INPUT (say a picture), and generates an OUTPUT (say‚Ä¶ ‚ÄúDog‚Äù or ‚ÄúCat‚Äù)\nIn a Machine Learning approach, a person PROVIDES (LOTS OF) INPUTS AND CORRESPONDING OUTPUTS, and the COMPUTER CREATES THE PROGRAM (usually then called a ‚Äúmodel‚Äù).\n\nThe above is specifically applicable to ‚ÄúSupervised‚Äù learning, but nevermind that, the key here is: The computer CREATES the MODEL that we (humans) can then apply to new data."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#why-unsupervised-learning",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#why-unsupervised-learning",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Why Unsupervised Learning?",
    "text": "Why Unsupervised Learning?\nIn Cybersecurity, a relevant part of the job for ML can be about detecting anomalies.\nOften times, you don‚Äôt get pre-trained neural networks applicable to your scenario. Or more simple: you don‚Äôt have access to relevant ‚Äúbig data‚Äù (which would help with training your models, indeed), i.e.¬†people (companies) rarely share detailed data (network packets, logs, configurations, etc.) of their breaches. Understandable.\nAnd so ‚Äúunsupervised‚Äù learning might make sense in that scenario. Unsupervised Learning is about discovering structure in your data, that you might not have known about upfront."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#warning",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#warning",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Warning",
    "text": "Warning\nAlso there are lots of potential issues with leveraging ML, but two possibly relevant ones would be:\n\nImbalance between classes (hopefully you have little data as examples of real attacks on your network, and a LOT of ‚Äúnormal traffic‚Äù data, for instance),\nBase-rate fallacy (a SOC analyst might, in certain settings, work most of their time on false-positives)\n\nThat said, let‚Äôs keep it simple for today, we will keep it clean, no complications (yet, anyway)."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#symbolic-vs-sub-symbolic",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#symbolic-vs-sub-symbolic",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Symbolic vs Sub-symbolic",
    "text": "Symbolic vs Sub-symbolic\nSimplifying A LOT, let‚Äôs just say for today that ‚ÄúSymbolic‚Äù can be read by a Human, and so it could look like sets of rules of the type:\nIF (A & NOT B) THEN (ACTION X)\nWhere a person could read A (‚Äúnumber of Errors in 1‚Ä≤ log file &gt; 100‚Äù), B (‚Äúless than 10 errors are of type ‚Äòlogin failed‚Äô‚Äù), X (‚ÄúBlock originating IP on Firewall‚Äù). (Note the negation of B in the expression above ;))\nPutting together many of these rules a person COULD setup a reactive security configuration for a firewall based on monitoring logs. I mean, conceptually, why not?! That would be an ‚ÄúExpert System‚Äù, as they called them in the 80‚Äôs.\nOh: And you COULD have ‚ÄúMachine Learning‚Äù on top of Rule-based systems. For example one interesting field (to me) that somehow has received little attention so far is that of the ‚ÄúLearning Classifier Systems‚Äù (LCS)‚Ä¶ But that‚Äôs for another day.\nWhen you enter the realm of Neural Networks, Dimensionality Reduction (say PCA on TF-IDF), BackPropagation, non-linearity, differentiable functions, etc., you quickly leave the realm of ‚Äúhuman readable‚Äù, and you enter the world of vectors, matrices, tensors‚Ä¶¬†In these settings, you use numbers, linear algebra, and the concept of distance.\nFor instance, distances between the ‚Äúcalculated class‚Äù and ‚Äúreal class‚Äù for a set of entries (say, images of cats and dogs, or log files, or‚Ä¶), trying to reduce these distances would mean trying to reduce the prediction error. Said like that, it is probably a bit confusing. But to be perfectly clear: That last sentence is a BIG part of what supervised machine learning with Neural Networks is all about! (More exactly in this case the goal is to minimize the difference between predicted and real class, or predicted and real value)\nLet‚Äôs just make a note at this point, then: Sub-symbolic is the domain of neural networks, a world of algebra and calculus, weights and thresholds, which often are hard to translate into ‚Äúhuman-readable rules‚Äù. And more specifically in the case of the current trend with deep neural networks (which are truly an impressive thing!), it‚Äôs a big issue, because there is a problem with how we can UNDERSTAND what the algorithm does. And that introduces things like lack of trust, issues with responsibility, and not being able to explain why something works (or, usually more to the point, why something suddenly DOES NOT work).\nBut the goal here and today is not to explain the details (‚Äúwhy backpropagation expects differentiable activation functions, for gradient descent, and the Chain Rule‚Äù ‚Äì or ‚Äúwhy ReLU works so good for training a NNet, but it‚Äôs not a differentiable function, and so people use approximations like leaky ReLU‚Äù‚Ä¶ All that might be a bit much ‚Äì Me at least, I still often need to come back to my books each time I want to explain these things correctly‚Ä¶ So some other time :D).\nToday I‚Äôll focus on the concept of distance between points, and leverage that to identify ‚Äúclusters‚Äù of points (and we‚Äôll mention multi-dimensional spaces real quick)."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#clustering",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#clustering",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Clustering",
    "text": "Clustering\nOne type of ‚ÄúUnsupervised Learning‚Äù is what is called clustering. The main idea is to look at data and to try and create ‚Äúgroups of similar data points‚Äù. That‚Äôs it. That‚Äôs what Clustering is all about.\nRight, but‚Ä¶ How?\nSo let‚Äôs see:\nIf a = 20, b = 21, c = 99 and d = 100‚Ä¶ Would you agree you could possibly say ‚Äúa is nearer from b than from d‚Äù. And iterating, you might conclude:\n\nGroup 1: a, b\nGroup 2: c, d\n\nDoes that make sense? Hopefully YES üôÇ\n\n\n\n1d and 3 groups of points\n\n\nLet‚Äôs move on to two dimensions. You get a set of points (imagine, for Cybersecurity, I don‚Äôt know: for each point representing a machine on a network, the x coordinate represents the number of TCP Packets sent by the machine from its TCP Port 80 in the last minute, and the y coordinate represents the number of TCP Packets sent by the same machine from its port TCP 443 in the last minute).\nSo now you might have two sets of points that ‚Äúcluster together‚Äù, some with very little activity on both axis, that is: (x, y) = 0, and others (maybe only a few), that have a range of numbers but overall have maybe lots of activity as per both axis, so say for example (x &gt; 1000, y &gt; 1000).\nLet‚Äôs apply the same logic as above. There will probably be two clusters, one of which might have many points but overlapping, and the other a cloud of points on the top right‚Ä¶ Representing Web Servers.\nThat‚Äôs probably a very dumb example, but it serves a purpose: You COULD identify groups of machines in these two dimensions. Distances here would probably use Euclidean Distance, but if you understand it visually, good enough for today.\n\n\n\n2d and 2 groups of points\n\n\nAnd with more (very similar) dimensions, you might be able to discover groups of machines that are similar to one another, but a bit different from those of another group‚Ä¶\nHere, I just gave you an algorithm to group machines and separate Windows from Linux, or Clients from Servers, or Web from Mail from LDAP from NTP from DNS servers‚Ä¶ Obviously, the above categories are a bit‚Ä¶ not great, well because most of the time you will KNOW what the machines are to begin with. But what if all you have to work from is a tcpdump file?\nLet‚Äôs visualize this, shall we?"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#dbscan",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#dbscan",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "DBScan",
    "text": "DBScan\nOne (of MANY) algorithms out there to do clustering is DBScan. Its very name says most of it: ‚ÄúDensity based Spatial Clustering‚Äù.\nI‚Äôm not going to reinvent the wheel today, and we‚Äôll go right ahead and leverage the dbscan R package and its documentation. The code is here.\nSo first, we‚Äôll generate a set of seemingly almost-random points in a 2-dimensional space.\n\nVisually, a person can already tell there seems to be some structure in there, some groups. How many might be a bit of a judgement call, but still.\nLeveraging a number of neighbours (say, 4 nearest points to identify a group)¬† to identify an ‚Äúelbow‚Äù of the separation of the groups, we can set a ‚Äúnoise threshold‚Äù to the above whereby if a node is too removed from a group, it could be considered as SEPARATE.\nLet‚Äôs see:\n\n\n\nidentifying noise in clustering\n\n\nIn the above, there is a ‚Äúclear‚Äù change in trend in the line that finds said distances, at 0.85 approximately (red line) that identifies regions of LOW DENSITY of points, that the DBScan algorithm would then propose as a limit to separate OUTLIERS from the rest of clustered points.\nIt‚Äôs a bit of a mess to write down, but hopefully the results are self explanatory:\n\nHere we color the groups of points by cluster, or what the algorithm has proposed as such. Again, the only concept in use was the distance to other points. A detailed look in the last picture would show that maybe something is amiss, at least one point had x &lt; 0 before, and it doesn‚Äôt show up here.\nThat‚Äôs an identified outlier.\n\nLet‚Äôs take a minute here: We‚Äôve identified stuff that goes together, so ‚Äúclusters‚Äù.\nBut one key aspect (value) of DBScan over some alternative algorithms for clustering is, it can help with ANOMALY DETECTION. Indeed, that‚Äôs why I have chosen this algorithm today (the typical intro to clustering would have probably focused on KMeans first :D).\nSo now, we have an ‚Äúautomated ML algorithm‚Äù that receives coordinates of points, and is capable of identifying groups of points, AND points that seem to not quite fit anywhere.\nRemember earlier when we mentioned ‚Äúimbalance‚Äù of prevalence of ‚Äúnormal traffic‚Äù vs ‚Äúattack traffic‚Äù on a corporate network? Well, this is why I mentioned it. With a little luck, what a DBScan output tells us are ‚Äúoutliers‚Äù is something that is UNUSUAL, and HOPEFULLY that‚Äôs actually identifying attack-related data for us!\nOK, back to the demos."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#why-bother",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#why-bother",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Why bother?",
    "text": "Why bother?\nOK, so beyond finding things out about your data, the data you have‚Ä¶ What if you could get information from new data (of the same kind, that is)?\nAfter all, you‚Äôve identified groups. And that‚Äôs cool, and maybe you‚Äôve learned that somehow ten computers seem to behave similarly, and quite differently from another set of 50 computers, on the same network. And maybe that leads you to do some digging and conclude that all 10 of the first group were DB servers, and the other were front-end stuff (Idk, Apache). All from network dump files. Not too bad.\nBut now you receive a new dump file, which you‚Äôre told contains network traces from other computers. Wouldn‚Äôt it be cool to then just feed that to your ‚Äútrained‚Äù model (which, remember, was actually unsupervised to begin with), and get it to tell you ‚Äì like a supervised algorithm would: That new machine is a ‚ÄúGroup 1‚Äù machine (and so you can deduce it‚Äôs a DB server).\nI know, I know. Just look at ports, and you would know, fair enough. Plus, it‚Äôs not clear the example above would even work (there are MANY considerations in there). Anyhow, let‚Äôs take your ‚Äúpre-trained‚Äù model from above, and see what would happen with say 12 new points:\n That‚Äôs it: New data, and without you having to look at it, the machine will tell you to which group each entry belongs. That‚Äôs the cool thing about Machine Learning üôÇ"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#going-3d",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#going-3d",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Going 3D",
    "text": "Going 3D\nAn almost identical exercise, but in 3 Dimensions. I just want to show it so that we can all agree on one thing: We human can conceptualize up to three dimensions. But with this next visualization, I hope to show one important idea: There is nothing precluding an algorithm from going and work into ‚Äúhigher dimensions‚Äù. We can easily visualize groups in 1-D, 2-D, now 3-D (maybe, on a screen, with the help of some animation). But 4-D, or 1000-D, is NOT a problem for a computer!\nOK, so in 3D, same algorithm, similarly random-generated data points. What DBScan can do is shown at the top of this Blog post üôÇ\n(I just know people are more impressed by 3-D animations than 2D visuals for some reason, and so I put it at the top to keep you interested :D)"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#its-not-magic",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#its-not-magic",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "It‚Äôs NOT magic",
    "text": "It‚Äôs NOT magic\nLet‚Äôs see a very classical example, and how DBScan kinda‚Äô fails. Not really, but still.\nWhen applied to the ‚ÄúIris‚Äù dataset (if you‚Äôve ever studied a bit of data science, you know what it is), DBScan identifies two clusters, while we all know there are 3 types of flowers represented in the dataset.\nThat does NOT mean that DBScan FAILED. It just means that the information it can tell us about that dataset is that one group of flowers is clearly different from the rest. And that‚Äôs OK, although we know it‚Äôs insufficient. BUT YOU NEED TO KNOW IT‚ÄôS NOT MAGIC. From a few data points / coordinates, it‚Äôs still only working with so much information‚Ä¶\nReal groups: 3\n\n\n\nreal iris groups\n\n\nDBScan (with selected parameters)groups: 2 (and a few outlier points)\n\n\n\ndbscan identified iris groups"
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#warning-2",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#warning-2",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Warning 2",
    "text": "Warning 2\nNOT ALL numbers are ordinals/cardinals. Although 20, 21, 22, 23 might seem nearer from one another than say from 80, 123, or 443‚Ä¶ That doesn‚Äôt mean you can use THAT ‚Äúdistance‚Äù.\nIn Cybersecurity (but in any other field), PLEASE remember DOMAIN KNOWLEDGE can ‚Äúmake or break‚Äù a data scientist. And not knowing why things don‚Äôt work as you expect then is a bad thing. And it‚Äôs not always the algorithm fault.\nWeb is different from NTP, while HTTPS uses cryptography and so does SSH, but‚Ä¶ In context, port TCP 80 is NOT nearer TCP port 22 than it is from TCP Port 443.\nYou‚Äôve been warned."
  },
  {
    "objectID": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#conclusions",
    "href": "posts/2024-10-26_UnsupervisedLearning_DBScan/index.html#conclusions",
    "title": "ML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan",
    "section": "Conclusions",
    "text": "Conclusions\nUnsupervised Machine Learning has potential for applications to Cybersecurity data. Maybe used on network traffic captures or logs, one can identify structure and propose groupings of machines, users (by their activity, accesses, hours, who knows‚Ä¶).\nAlthough we‚Äôve seen one algorithm and how to visualize its decisions with 2- and 3-dimensional data, the ‚Äúsky is the limit‚Äù, and if one can come up with 100 (or 1000) such dimensions (that‚Äôs the concept behind ‚Äúfeature engineering‚Äù), there is nothing precluding our machines to work with that and propose groupings for us (although not all algorithms deal nicely with ‚Äúcurse of dimensionality‚Äù, but that‚Äôs a different topic). In ML, more (quality) data is often a good thing. Also, if one of the 100 dimensions helps us separate perfectly some groups, some ML algorithm will find that and use it for us. Would you visualize manually and study 100 dimensions? 1000?\nAnd that‚Äôs where it‚Äôs powerful: A person might have a hard time grouping hundreds of machines or users while considering several aspects at once, much less when the number of groups or ‚Äúkinds of groups‚Äù to be found are not known upfront‚Ä¶ But that‚Äôd be no issue for a computer üôÇ\nHopefully I can walk some of my colleagues through the above concepts (organised in a PPT) and show them (in R :P) how all the concepts ‚Äúwork‚Äù, and then translate into ‚Äúreal world applications‚Äù.\nMaybe next week I‚Äôll move on to making text into multi-dimensional data points. And then, we‚Äôd be set to apply all the above to text data. Which is quite prevalent in Cybersecurity (CVE descriptions, logs, code‚Ä¶ it‚Äôs all text :D).\n\nResources\nWikipedia as linked above, and dbscan R Package documentation, mostly.\nAlso this about making a video from 3D scatter plot with RGL"
  },
  {
    "objectID": "posts/2023-07-09_SummerFun_Optimization/index.html",
    "href": "posts/2023-07-09_SummerFun_Optimization/index.html",
    "title": "Summer fun: Testing Optimization Algorithms (1/n)",
    "section": "",
    "text": "Intro\nI have some more spare time for the upcoming few weeks, and I haven‚Äôt had the opportunity to take the ‚ÄúMetaheuristics‚Äù course in the Master, and so I feel I‚Äôm missing out a bit‚Ä¶ But then, what precludes me from learning on my own?\nSo I came across a book (I spend a bit too much time in book stores just ‚Äúbrowsing‚Äù‚Ä¶ Or buying books online) about ‚ÄúOptimisation‚Äù in Matlab. As it turns out, this appears to be in fact a great book to understand a few algorithms of the field of ‚ÄúMetaheuristics‚Äù.\n\n\nFirst thing First\nBefore I start with optimization per-se, as the books relies somewhat heavily on two visualizations, Contours and 3D perspectives of bi-variate functions, I have to get acquainted with the necessary R code for just that.\nThe code for that is all in here.\nAside from learning that the base graphics in R are very capable, with ‚Äúcontour()‚Äù and ‚Äúpersp()‚Äù readily available, I‚Äôve had to learn what Azimuth meant‚Ä¶ Thankfully given the context, it wasn‚Äôt hard, and the Wikipedia is always helpful.\nHere the results for today. I generate a 3D cone, and then we visualize through a couple of drawings that will be helpful later on.\nA contour plot will show altitudes in 2D, which can be helpful when visualizing say ‚Äúwhere is the minimum altitude‚Äù:\n\n\n\nA Contour Plot\n\n\nA Contour Plot\nThen the 3D perspective visualization can be as bad as this:\n\n\n\nBad perspective for 3D\n\n\nOr a bit nicer, like so:\n\n\n\nBetter 3D visualization\n\n\n\n\nNext time\nIn the next blog entry, I will be discussing one of the first algorithms the book comments: Gradient Descent.\n\n\nReferences\nAbout persp and the cone"
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html",
    "title": "RLCS as a package?",
    "section": "",
    "text": "I have plenty of work still, with this RLCS Package idea.\nOne of them, indeed, is to make it into‚Ä¶ A package.\nI have been postponing this for quite some time, and well, I can only stall for so long."
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#finally-i-am-moving-forward-with-this",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#finally-i-am-moving-forward-with-this",
    "title": "RLCS as a package?",
    "section": "",
    "text": "I have plenty of work still, with this RLCS Package idea.\nOne of them, indeed, is to make it into‚Ä¶ A package.\nI have been postponing this for quite some time, and well, I can only stall for so long."
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#might-actually-be-feasible",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#might-actually-be-feasible",
    "title": "RLCS as a package?",
    "section": "Might actually be feasible",
    "text": "Might actually be feasible\nThe thing is, I have been worried about how hard it would be. Well‚Ä¶\nI use RStudio (side note: I hope it lives as product for still a long time‚Ä¶).\nSo I ‚Äújust‚Äù created a ‚ÄúPackage Project‚Äù, and then went through some of the chapters of the ‚ÄúR Packages‚Äù book once again this morning with a coffee.\nTime has come, and so‚Ä¶ What I needed to actually get it moving was to copy my current, non-package, functional code from my (usual) RLibs/ folder to the new project‚Äôs R/ folder‚Ä¶\nThen I deleted some temporary code that shouldn‚Äôt have been there‚Ä¶\nThen I know and accept this is far from finished and I have plenty more to do still but‚Ä¶\nLong story short, I then made sure I had a clean environment, ran ‚Äúdevtools::load_all()‚Äù and ran a function I knew was stand-alone and should work (actually I ‚Äúfudged‚Äù even the new project name, but this is just a first test :D):\n\n\n\nfrom scripts to package, one step at a time"
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#basically-it-works-with-kinks",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#basically-it-works-with-kinks",
    "title": "RLCS as a package?",
    "section": "Basically, it works, with ‚Äúkinks‚Äù",
    "text": "Basically, it works, with ‚Äúkinks‚Äù\nSo it looks like it ‚Äúworks‚Äù almost as-is:\n\n\n\nworking basics in package form\n\n\nHowever the above has for now a couple of issues at least:\n\nThat‚Äôs the version WITHOUT RCpp faster version of match function\nAnd for some reason, I have to manually re-load the functions that set the print and plot for rules and population of RLCS, which‚Ä¶ Well I don‚Äôt know yet why :D\n\nBut as-is, I can actually use this ‚Äúas a package‚Äù to do supervised learning and it would in fact work, essentially."
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#conclusions",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#conclusions",
    "title": "RLCS as a package?",
    "section": "Conclusions",
    "text": "Conclusions\nIt‚Äôs very early in that part of the process.\nBut while reviewing the book this morning, I realized I had actually been fairly organized following my own rules, and minimal changes would get me somewhere.\nIndeed, I have a lot more to do. For instance:\n\nwhat if I do not want to expose a function, and make it available only internally? Not sure yet about how to go about that.\nDocumentation, roxygen2? I‚Äôm not too familiar yet. Vignette? Sounds like a nice idea but, not there yet either.\nRCpp? I have just the one function that did make a difference in terms of processing speed, and it makes sense it is kept as part of the package, so I need to make sure I include it, although I‚Äôm unclear on exactly how‚Ä¶\n\nSo yes, plenty yet to do. But it looks quite‚Ä¶ Feasible? That‚Äôs good news."
  },
  {
    "objectID": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#resources",
    "href": "posts/2025-07-05_RLCS_as_a_package_at_last/index.html#resources",
    "title": "RLCS as a package?",
    "section": "Resources",
    "text": "Resources\nhttps://r-pkgs.org/"
  },
  {
    "objectID": "posts/2023-11-07_Interlude/index.html",
    "href": "posts/2023-11-07_Interlude/index.html",
    "title": "Interlude",
    "section": "",
    "text": "But then‚Ä¶ I finished this book, and I liked it, and I thought I would recommend it.\n\nI don‚Äôt know how something not at the level of ‚Äúintroduction‚Äù would look like, but this was just sooo in line with my MSc dissertation‚Ä¶ Funny I hadn‚Äôt read it before!\nAlso, code in there is in Python, I‚Äôm sure many would appreciate that.\nSo there. A book recommendation."
  },
  {
    "objectID": "posts/2023-11-07_Interlude/index.html#i-said-i-wouldnt-code-and-i-didnt.",
    "href": "posts/2023-11-07_Interlude/index.html#i-said-i-wouldnt-code-and-i-didnt.",
    "title": "Interlude",
    "section": "",
    "text": "But then‚Ä¶ I finished this book, and I liked it, and I thought I would recommend it.\n\nI don‚Äôt know how something not at the level of ‚Äúintroduction‚Äù would look like, but this was just sooo in line with my MSc dissertation‚Ä¶ Funny I hadn‚Äôt read it before!\nAlso, code in there is in Python, I‚Äôm sure many would appreciate that.\nSo there. A book recommendation."
  },
  {
    "objectID": "posts/2022-10-15_ThinkingAboutCYSOps/index.html",
    "href": "posts/2022-10-15_ThinkingAboutCYSOps/index.html",
    "title": "Thinking about Cybersecurity Operations",
    "section": "",
    "text": "I‚Äôve seen a few ‚ÄúSOCs‚Äù by now (not many either, just a few), and often times companies use the NIST framework to kind of organize the teams.\nAlright, so I have been thinking quite a bit lately on modeling such organizations.\nHere I‚Äôll mention only a few ideas for now."
  },
  {
    "objectID": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#intro",
    "href": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#intro",
    "title": "Thinking about Cybersecurity Operations",
    "section": "",
    "text": "I‚Äôve seen a few ‚ÄúSOCs‚Äù by now (not many either, just a few), and often times companies use the NIST framework to kind of organize the teams.\nAlright, so I have been thinking quite a bit lately on modeling such organizations.\nHere I‚Äôll mention only a few ideas for now."
  },
  {
    "objectID": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#feedback-and-influence",
    "href": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#feedback-and-influence",
    "title": "Thinking about Cybersecurity Operations",
    "section": "Feedback and Influence",
    "text": "Feedback and Influence\nIt‚Äôs quite straightforward to understand really:\nMore/Better Threat Intelligence should improve detection capabilities. Namely, by better prioritizing things. In fact, one could argue that Threat Intel should not necessarily improve detection by increasing number of things to worry about, but in fact by just prioritizing. Although of course a lacking Threat Intel might miss things, in which case yes, better would mean more. So right there, what impact does a better Threat Intel process mean? There is probably a line to draw with a sufficient basis, and then changing trend for further improvement?\nNext, in ‚ÄúIdentify‚Äù (in terms of the NIST framework) for instance, one of the first things mentioned is ‚ÄúAssets‚Äù. Well, should we focus on better assets inventory, i.e.¬†more assets known; or should we consider better data to be more important than more data (e.g.¬†quality vs coverage)? Both, sure, are needed. But to what degree? Wrong data about a system (say incorrect OS family): is it better or worse than no entry at all for the system?\nWe can keep going, for sure:\nIn the ‚ÄúDetect‚Äù function: Do we want more alerts definitions (e.g.¬†use-cases) or better quality use-cases (less false positives maybe?). Do we want more alerts (and more FP) but being a certain amount ‚Äúmore confident‚Äù (and then how much is enough) we catch bad stuff, although maybe our analysts team can‚Äôt keep up with the noise (and hence we still miss the important stuff), or fewer alerts but highly confident, high true positive rates (however maybe missing important things happening on our network)?\nWhat about training, Protect tools efficacy, connected providers protection measure, surface/exposure on the Internet, awareness against say phishing, outbound connection controls, zero trust, source code review & hardening, red team exercises, company vertical and its inherent interest for bad actors‚Ä¶ (this list could be quite long‚Ä¶)\nAnd how each piece of the puzzle affects the whole, and the other pieces?\nThese ‚Äúpieces‚Äù conform a system of sorts, and some feedback loops in the system exist‚Ä¶ (hence my recent interest in cybernetics, complex systems, operations research, simulations, graph networks and the likes‚Ä¶)\nThese are the questions I‚Äôm asking myself again and again lately. Most of the time, the answer will be ‚Äúit depends‚Äù:\n\nWhat‚Äôs the company risk appetite?\nWhat‚Äôs the SOC budget for analysts and tools?\n‚Ä¶\n\nAt the end it boils down to the question: how to best invest the Cybersecurity budget? (I was recently told maybe I should focus on ‚Äúbest spent next dollar‚Äù, fixing a few starting point parameters, instead of generic overall budget‚Ä¶ it was a great comment!)"
  },
  {
    "objectID": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#conclusions",
    "href": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#conclusions",
    "title": "Thinking about Cybersecurity Operations",
    "section": "Conclusions?",
    "text": "Conclusions?\nNo conclusion at all just yet.\nI frown upon an ‚Äúeconomical-mathematical‚Äù modeling approach, whereby I could put a Variable name to each piece, and sum or rest or multiply or divide each of these variables based on how much they influence say the required number of Analysts necessary to attend a varying volume of alerts.\nThis approach by the way (putting together an equation) I found is actually apparently not completely crazy, people have done that to predict certain economic indicators in the past, for instance I read about P.A. Samuelson and his work on National Income model, which does just that‚Ä¶ (Found in ‚ÄúMathematical Modeling‚Äù, by S. Heinz, Ed. Springer). But that should work for deterministic changes at best, and if only that, attackers are not too ‚Äúdeterministic‚Äù in how they behave against organizations (part of it is opportunistic, another part depends on motivation, more even depends on other context‚Ä¶)\nBut that a Springer book on math (I consider those to be ‚Äúserious stuff‚Äù) would consider this idea, tells me there is still some value to be found in such exercises.\nAnd similar to simulation approaches, maybe the whole goal of such exercises can be to try to learn and better understand something, through varying certain parameters (read: assumptions), even though probably no ‚Äúactual valid specific numerical dollar value‚Äù can come out of it (maybe ordinal values could?).\nLong story short, these ideas still interest me a lot, and I will probably have to break it down into smaller pieces (so parts of the system, not the whole of it‚Ä¶).\nI think these things will be the general orientation of my thesis."
  },
  {
    "objectID": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#references",
    "href": "posts/2022-10-15_ThinkingAboutCYSOps/index.html#references",
    "title": "Thinking about Cybersecurity Operations",
    "section": "References",
    "text": "References\nhttps://www.nist.gov/cyberframework/framework"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html",
    "href": "posts/2023-01-20_Ashby_matrices/index.html",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "",
    "text": "I really do not have that much spare time, but I also really wanted to learn more about ‚ÄúCybernetics‚Äù. So I bought (yet another) book, a classic in this case (I think it was first edited in 1956): ‚ÄúAn Introduction to Cybernetics‚Äù, by W. Ross Ashby (‚ÄúAshby‚Äù from now on for short).\nSo far, let me be clear: If interested in the concept of ‚ÄúCybernetics‚Äù, so far, the book seems like an EXCELLENT reference.\nAs I was combing through it though, I came across chapter 2, section 2/10 ‚ÄúRepresentation as a matrix‚Äù, and there already something bothered me‚Ä¶ And then the text kept bugging me some more, so I thought I‚Äôd give it a more honest study‚Ä¶\nThis entry is in fact about matrices and digraphs, and how the matrix transpose affects the edges directions in the corresponding digraph üôÇ"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#intro",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#intro",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "",
    "text": "I really do not have that much spare time, but I also really wanted to learn more about ‚ÄúCybernetics‚Äù. So I bought (yet another) book, a classic in this case (I think it was first edited in 1956): ‚ÄúAn Introduction to Cybernetics‚Äù, by W. Ross Ashby (‚ÄúAshby‚Äù from now on for short).\nSo far, let me be clear: If interested in the concept of ‚ÄúCybernetics‚Äù, so far, the book seems like an EXCELLENT reference.\nAs I was combing through it though, I came across chapter 2, section 2/10 ‚ÄúRepresentation as a matrix‚Äù, and there already something bothered me‚Ä¶ And then the text kept bugging me some more, so I thought I‚Äôd give it a more honest study‚Ä¶\nThis entry is in fact about matrices and digraphs, and how the matrix transpose affects the edges directions in the corresponding digraph üôÇ"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#important-edit-after-writing-the-blog-post",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#important-edit-after-writing-the-blog-post",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Important EDIT after writing the blog post",
    "text": "Important EDIT after writing the blog post\nTHIS WHOLE POST is rendered somewhat pointless by this sentence of the Wikipedia entry on adjacency matrix:\n\nAs I am a student of Graph Theory, and reading about Cybernetics (an ‚Äúapplied science‚Äù), the whole thing was just a matter of convention!\nREGARDLESS, this exercise here has helped me better grasp the concepts and relationships of digraphs, matrices and their transpose, and so I feel it wasn‚Äôt a total loss of time after all‚Ä¶ (Although it took me a few hours overall until I was happy with my understanding of it all‚Ä¶)\nSo keep reading if you want, although I‚Äôd understand if you didn‚Äôt‚Ä¶ (tip: there is code to work with the ‚Äútwisted‚Äù ways of applied scientists using graph theory approach to adjacency matrices ;))."
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#ashbys-matrix-is-in-the-wrong-direction",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#ashbys-matrix-is-in-the-wrong-direction",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Ashby‚Äôs matrix is in the wrong direction",
    "text": "Ashby‚Äôs matrix is in the wrong direction\nAlright, so maybe it‚Äôs just a choice, more than a convention, but as I am used to it, a digraph (directed graph) can be represented as an adjacency matrix, where for each ROW (representing an origin vertex), one can tell to which other vertex there is an edge if there is a value different from 0 in a certain column (representing the destination vertex).\nSo I read edges ‚Äúfrom left to right‚Äù, basically, to visualize edges. The igraph package follows this convention. An example in R:\nlibrary(igraph)\n\nmy_sort_matrix &lt;- function(t_m) {\n  # For readability...\n  t_m[order(rownames(t_m)), order(colnames(t_m))]\n}\n\nclean_adj_mat_from_g &lt;- function(g) {\n  m_g &lt;- igraph::as_adjacency_matrix(g)\n  m_g &lt;- as.matrix(m_g) # required for transposing.\n  my_sort_matrix(m_g)\n}\n\n# Traditional look of an adjacency matrix, as defined by \"change\" here (edges of a graph, visually):\n# A -&gt; A, B -&gt; C, C -&gt; C\ng &lt;- igraph::graph(c(\"A\", \"A\", \"B\", \"C\", \"C\", \"C\"), directed = TRUE)\nplot(g)\n\n# Now to the directed adjacency matrix, igraph format:\nm_g &lt;- clean_adj_mat_from_g(g)\n¬†\nAshby‚Äôs matrix representation however is to be read VERTICALLY, from top to bottom: First read a column (representing an origin vertex) downwards, and where you see a ‚Äò+‚Äô sign (instead of a 1), there is an edge towards that row‚Äôs vertex (the destination). The ‚Äútransformation‚Äù notation is then really the transpose of the adjacency matrix.\nAnd that‚Äôs interesting‚Ä¶"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#representing-a-transformation-matrix-transpose-and-time",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#representing-a-transformation-matrix-transpose-and-time",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Representing a ‚Äútransformation‚Äù: Matrix Transpose and Time",
    "text": "Representing a ‚Äútransformation‚Äù: Matrix Transpose and Time\nTo put it shortly, an edge from an origin vertex (the ‚Äúoperand‚Äù) to a destination vertex (the ‚Äútransform‚Äù) represents a ‚Äútransition‚Äù.\nA graph generated by an Ashby‚Äôs matrix is a representation of a set of transitions, also called a ‚Äútransformation‚Äù.\ntransformation_from_adjacency &lt;- function(t_m) {\n    # an adjacency matrix, with 1 for directed edges in the reverse direction\n    # 0 otherwise.\n    my_sort_matrix(\n        t(t_m) # Quite straightforward. But expects valid numerical matrix as input\n    )\n}\n\n# Print a \"transformation\" in Ashby's \"matrix\" format:\n# Note: We assume each operand and transform is named with one letter only.\nprint_1char_transformation &lt;- function(transformation_adjacency_matrix) {\n    t_a_m &lt;- transformation_adjacency_matrix # shorter\n      cat(paste(' V', \n        paste0(colnames(t_a_m), collapse= ' '),\n        \"\\n\",\n        paste0(lapply(rownames(t_a_m),\n          function(x) { \n            paste(x, paste0(ifelse(t_a_m[x,] == 1, '+', '0'), collapse=' '), '\\n ') \n          }), collapse='')))\n}\n\n# Take a \"normal\" igraph directed adjacency matrix,\n# make it follow the \"transformation\" format\nt_m_g &lt;- transformation_from_adjacency(m_g)\nprint_1char_transformation(t_m_g)\nThen the adjacency matrix from above that looked like this:\n# A -&gt; A, B -&gt; C, C -&gt; C\n&gt; m_g\n  A B C\nA 1 0 0\nB 0 0 1\nC 0 0 1\nIn Ashby‚Äôs matrix format looks like so:\n&gt; t_m_g &lt;- transformation_from_adjacency(m_g)\n&gt; print_1char_transformation(t_m_g)\nV A B C \nA + 0 0 \nB 0 0 0 \nC 0 + +\nObserve in the above, how the edge B -&gt; C is moved to another position of the matrix.\nHere an important note, for the intuitive understanding. As I was getting my head around it‚Ä¶ I had to look it up to understand what this all meant intuitively:\nNaturally, this can be shown as a graph or a matrix, but as seen earlier, using directly igraph would represent the transformations in the wrong direction (replacing ‚Äòx‚Äô with 1)‚Ä¶ Which in fact just means:\nIf a matrix represents a transformation (from operand to transform), the transpose represents what would happen if we went ‚Äúback in time‚Äù.\nI didn‚Äôt invent that explanation (found it in this reference), but it makes complete sense intuitively (to me) when looking at the Cybernetics concept of transformation, matrices, and corresponding graphs. In any case, this ‚Äúexplains‚Äù why when you show a matrix representing a digraph, and then its transpose, you get the same graph with the edges in the opposite direction."
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#composing-a-transformation",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#composing-a-transformation",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Composing a transformation",
    "text": "Composing a transformation\nNow If you apply to an operand a transition, you get a transform (Call that ‚Äúoperation T‚Äù).\nYou can then use that transform as an operand in another, different (or not) transition, to obtain a new transform (‚Äúoperation U‚Äù).\nIf T is represented as an m*n matrix A, and a vector x of n elements is to be transformed, the ‚Äúnatural‚Äù way to write that mathematically is ‚ÄúAx‚Äù (x being then vertical).\nThat would justify Ashby‚Äôs format.\nLet‚Äôs have a look from a code perspective‚Ä¶\ncomposition should be, ‚Äúapply transformation T, then apply transformation U, i.e.¬†U(T(x))‚Äù:\ncomposition &lt;- function(m_t, m_u) {\n  transformation_from_adjacency(\n    transformation_from_adjacency(m_u) %*% \n      transformation_from_adjacency(m_t)\n  )\n}\nWe can then try to do it ‚Äúfor real‚Äù:\n# Exercise 3 of section 2/16 of the book becomes:\ngt &lt;- igraph::graph(c(\"a\", \"b\", \"b\", \"d\", \"c\", \"a\", \"d\", \"b\"), directed = TRUE)\ngu &lt;- igraph::graph(c(\"a\", \"d\", \"b\", \"c\", \"c\", \"d\", \"d\", \"b\"), directed = TRUE)\ngv &lt;- igraph::graph(c(\"a\", \"c\", \"b\", \"b\", \"c\", \"d\", \"d\", \"c\"), directed = TRUE)\n\nm_t &lt;- clean_adj_mat_from_g(gt)\nm_u &lt;- clean_adj_mat_from_g(gu)\nm_v &lt;- clean_adj_mat_from_g(gv)\n\n# Let's look at some examples here of what things look like:\nm_t # adjacency matrix\nprint_1char_transformation(transformation_from_adjacency(m_t)) # Ashby's transformation in matrix notation\nm_u\nprint_1char_transformation(transformation_from_adjacency(m_u))\nm_v # Expected result of composition\nSo here, if we apply T, then U, the origin vertex (operand) ‚Äúa‚Äù should first transform to ‚Äúb‚Äù, then ‚Äúb‚Äù should transform to ‚Äúc‚Äù . This applies to all proposed transitions, and V represents applying U after applying T indeed.\nTo do it in mathematical traditional notation, it would be: U(T(x)), so in R, we would be doing U %*% T %*% x.\nIn Ashby‚Äôs notation, yes:\nm_t_then_u &lt;- composition(m_t, m_u) # Apply T, then U\n# This should give the same result as for m_v\n&gt; print_1char_transformation(transformation_from_adjacency(m_t_then_u))\nV a b c d\na 0 0 0 0\nb 0 + 0 0\nc + 0 0 +\nd 0 0 + 0\n\n&gt; print_1char_transformation(transformation_from_adjacency(m_v))\nV a b c d\na 0 0 0 0\nb 0 + 0 0\nc + 0 0 +\nd 0 0 + 0\nIndeed, they are the same."
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#but-wait-re-discovering-the-wheel",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#but-wait-re-discovering-the-wheel",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "BUT WAIT! ‚ÄúRe-discovering the wheel‚Äù",
    "text": "BUT WAIT! ‚ÄúRe-discovering the wheel‚Äù\nHow about we applied the adjacency matrices in the other order, where T (in adjacency matrix format) multiplies our (horizontal) x vector, and then we multiply that by U (in adjacency matrix format).\n&gt; simple_compose &lt;- m_t %*% m_u\n&gt; print_1char_transformation(transformation_from_adjacency(simple_compose)) \nV a b c d\na 0 0 0 0\nb 0 + 0 0\nc + 0 0 +\nd 0 0 + 0\nThat works JUST THE SAME! Granted, as these transformations are closures, they are represented by square matrices.\nWe just have multiplied in the opposite order, with x an horizontal vector of n elements, that‚Äôs it (‚ÄúT_a‚Äù here is the adjacency matrix, which is in fact an n*m matrix, from the transpose of T, an m*n matrix representing the corresponding ‚Äútransformation‚Äù‚Ä¶):\nx %*% T_a %*% U_a = y\nCould then be read like so: ‚Äúx is transformed by T, then by U‚Äù. And code-wise, we can use igraph‚Äôs expected format for adjacency matrix for a digraph, plotting it then easily:\nplot(graph_from_adjacency_matrix(simple_compose))\n\nWe now just have re-discovered that from two transformations applied in a given order, to go back in time you need to run the transpose, in opposite direction:\n\\((AB)^T = B^TA^T\\)\nAnd ‚Äúintuitively‚Äù (if any of this is intuitive‚Ä¶), the visualization for this ‚Äúrevert time‚Äù, and changing direction of edges in the corresponding graph, and how it all ties together‚Ä¶ Hopefully this here helps:\n\nWell, it would simply seem that Ashby ‚Äútransformation‚Äù notation is a bit backwards for my taste (and¬† that of the igraph package), but otherwise not wrong at all‚Ä¶ I just need to be careful in the order of the matrices multiplications‚Ä¶"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#validations",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#validations",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Validations",
    "text": "Validations\nFollowing this, we can now do some tests‚Ä¶\n&gt; x &lt;- c(1, 0, 0, 0) # What would the input \"a\" become?\n&gt; names(x) &lt;- c(\"a\", \"b\", \"c\", \"d\")\n&gt; x %*% simple_compose # a should become c\n     a b c d\n[1,] 0 0 1 0\nWhich is what was expected‚Ä¶ And the same as the transformation described by V (as defined earlier :))."
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#notes",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#notes",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Notes",
    "text": "Notes\nThere are two ‚Äúbasins‚Äù (‚Äúwhere the concept of stability appears‚Äù) in the above graph (transformation), one at ‚Äúb‚Äù, and one at ‚Äúc-d‚Äù (a cycle). That is, the transformation here, which could be a system, when it transitions from one state to the next, stabilizes towards either of both basins, depending on the origin state.\nSuch systems and transformations (I have only had time to read so far in the book) look to me like a simplistic Markov chain with probabilities 1‚Ä¶\nOne last detail here, though: In the graph above, if we go from ‚Äúa‚Äù to ‚Äúc‚Äù using the normal transition, what would be of ‚Äúgoing back in time‚Äù, as moving from ‚Äúc‚Äù to ‚Äúa‚Äù would then be one of two options, the other being going to ‚Äúd‚Äù‚Ä¶ We then would face a case of multi-valued transition. Oh well‚Ä¶"
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#conclusion",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#conclusion",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "Conclusion",
    "text": "Conclusion\nAshby‚Äôs matrix notation is wrong to me, EXCEPT FOR the fact that it help writing the math in the ‚Äúright‚Äù order (The way I‚Äôm used to it in math classes, for systems of equations).\nBut for igraph, the adjacency matrix format expects things to come the other way around, and so it‚Äôs easier to write R code to work the other way around‚Ä¶\nAnd I feel this exercise has refreshed my intuition of what a matrix is all about, and how a matrix and a corresponding graph are related to one another. The idea of a ‚Äútransformation‚Äù as an explanation of what a graph represents, the implications on operations with matrices‚Ä¶ This exercise was a nice little dive into the whole concept.\nRegardless, I should be studying for the two term papers I am expected to deliver next week, instead of diving in yet other subjects (albeit very much related here to Graph Theory)‚Ä¶ So I‚Äôll get back to that."
  },
  {
    "objectID": "posts/2023-01-20_Ashby_matrices/index.html#references",
    "href": "posts/2023-01-20_Ashby_matrices/index.html#references",
    "title": "Learning Cybernetics: Working on Ashby‚Äôs Transformation Matrices",
    "section": "References",
    "text": "References\n‚ÄúAn Introduction to Cybernetics‚Äù, by W. Ross Ashby (found in Ed. Martino Publishing, 2015) ‚Äì (This is not a referral link, i.e.¬†I have no personal interest in you clicking it or not‚Ä¶)\nMy code for today\nIntuition of transpose\nWikipedia on Adjacency matrices"
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html",
    "title": "RLCS package: Progressing nicely",
    "section": "",
    "text": "Yesterday was the first day of testing.\nToday, I fixed 2 things I considered key.\n\nOverwriting the defaults for prints and plots\nusing the C++ component for matching (and thereby fixing a bit of parallel processing!)\n\nBoth I describe next."
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html#documentation-aside-things-move-forward",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html#documentation-aside-things-move-forward",
    "title": "RLCS package: Progressing nicely",
    "section": "",
    "text": "Yesterday was the first day of testing.\nToday, I fixed 2 things I considered key.\n\nOverwriting the defaults for prints and plots\nusing the C++ component for matching (and thereby fixing a bit of parallel processing!)\n\nBoth I describe next."
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html#easy-or-not-so-easy-s3methods-overwrites",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html#easy-or-not-so-easy-s3methods-overwrites",
    "title": "RLCS package: Progressing nicely",
    "section": "Easy or not so easy: S3Methods overwrites",
    "text": "Easy or not so easy: S3Methods overwrites\nI will say: It gets confusing to me, whether/how/when Roxyen2 will be key‚Ä¶ And when not?\nI know the thing works now with a mix of roxygen2\n#' @export\nprint.rlcs_rule &lt;- function(x, ...) {\n  print(paste(x$condition_string, x$action), ...)\n}\nBut also required was an EDIT to NAMESPACE (which roxygen somehow then complains about?)\nS3method(print,rlcs_rule)\nS3method(print,rlcs_population)\nS3method(plot,rlcs_population)\nBoth together, at least, do work as expected.\n\n\n\nfixed_printing_and_plotting‚Ä¶"
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html#using-c-was-not-difficult",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html#using-c-was-not-difficult",
    "title": "RLCS package: Progressing nicely",
    "section": "Using C++ was not difficult",
    "text": "Using C++ was not difficult\nJust‚Ä¶ Put your correctly formatted .cpp file in the src/ directory, and RStudio will know how to go about it (supposing you created your RStudio project with C++ support, at least).\nAnd I know it works, because I made sure the function for matching uses it, and more importantly‚Ä¶"
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html#it-fixed-something-else",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html#it-fixed-something-else",
    "title": "RLCS package: Progressing nicely",
    "section": "It fixed something else",
    "text": "It fixed something else\nParallelizing with %dopar% with the C++ version failed before, but with the package loaded, it now works seamlessly!\n\n\n\nparallel processing failed with C++ components until packaged"
  },
  {
    "objectID": "posts/2025-07-06_RLCS_package_test_progress/index.html#conclusion",
    "href": "posts/2025-07-06_RLCS_package_test_progress/index.html#conclusion",
    "title": "RLCS package: Progressing nicely",
    "section": "Conclusion",
    "text": "Conclusion\nMy next focus should be on clean-up and documentation. And maybe a better understanding of the Roxygen2 role and NAMESPACE (for exporting only certain functions, I believe‚Ä¶).\nBut overall, I‚Äôm back on track with the RLCS package :)"
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "",
    "text": "So I‚Äôm currently taking this course about ‚ÄúHigh Performance Computing‚Äù. This entry is not about that exactly: let‚Äôs face it, R is not the best option there üòÄ\nBut some concepts I touched in the past I thought I could summarise today (for example of past entries:¬†here or here, and more links in the post), with some context of efficiency theory. Note: I‚Äôm not inventing the wheel here, just summarising a bit my personal approach to this topic with R."
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#intro",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#intro",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "",
    "text": "So I‚Äôm currently taking this course about ‚ÄúHigh Performance Computing‚Äù. This entry is not about that exactly: let‚Äôs face it, R is not the best option there üòÄ\nBut some concepts I touched in the past I thought I could summarise today (for example of past entries:¬†here or here, and more links in the post), with some context of efficiency theory. Note: I‚Äôm not inventing the wheel here, just summarising a bit my personal approach to this topic with R."
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#amdahls-law",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#amdahls-law",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "Amdahl‚Äôs Law",
    "text": "Amdahl‚Äôs Law\nI don‚Äôt pretend to replicate the Wikipedia entry here.\nLet‚Äôs just say this: Parallelising is one option to reduce execution times of your program, but it‚Äôs not perfect. And as such, one also would have to consider optimising the code ‚Äúas is‚Äù BEFORE parallelizing tasks.\nFrom Amdahl‚Äôs Law, I would then personally take out: Try and first reduce the ‚ÄúSequential‚Äù execution times of your code.\nThe few tricks I normally would use in R to speed things up (before parallelizing stuff) are, more or less in order:\n\nMove away from ‚Äúfor-loops‚Äù, and use a vectorized approach where possible (e.g.¬†lapply() and the likes)\nIf you want to go faster with the same data, maybe consider moving from data FRAMES and instead use DATA TABLES (but the code looks quite different)\nAs much as I like how dplyr code looks (and reads), if speed is a concern, I would definitely look into base-R alternatives (I have tested in more than one occasion the effects of this change of approach, and results always surprise me‚Ä¶)\nWorst case scenario, if you REALLY need it, use RCPP. But warning, here the trick kicks in: In normal script (I‚Äôm told not so much for packages developers, but I‚Äôm not doing that just yet), using RCPP means you will compile your code as C++, which adds a step that might be slow, and depending on the amount of time spent in the function/piece of code you‚Äôre trying to optimize, you might very well end up slowing your script or program overall‚Ä¶ So this option is for things that are REALLY long to run."
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#gustafsons-law",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#gustafsons-law",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "Gustafson‚Äôs Law",
    "text": "Gustafson‚Äôs Law\nSo once again, here is the Wikipedia entry for that.\nHow does that translate for me?\nWell, consider parallelising in large and/or slow enough programs/scripts. Otherwise, it might not make sense.\nTo do so in R, I usually use these two approaches, in this particular order:\n\nUse ‚Äúfutures‚Äù (and I personally focus usually on future_lapply()). This will create new processes that can run on other Cores of your CPU, while native R is single core single thread.\nUse plumbeR, so that you can run your program over different CPUs/Servers/Containers altogether."
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#personal-notes",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#personal-notes",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "Personal notes",
    "text": "Personal notes\nI don‚Äôt write programs THAT complex too often, meaning that most of the time, I only focus on small optimisations where applicable, but rarely will I actually use plumbeR and create a full-fledged distributed piece of Software. I simply don‚Äôt have the need MOST of the time (sometimes though, it‚Äôs a cool thing to have in your toolbox).\nNow think about the value of the speed up, and the **tradeoffs**:\n\nRefactoring code to make it faster, but maybe somewhat less readable (e.g.¬†moving away from dplyr) is not always the best idea.\nMoving away from what you‚Äôre comfortable with for minimal gains (data tables take some getting used to) will depend on, well, the gain and the value of the gain (for bigger datasets, it might be better‚Ä¶)\nThen again, overall, does your code even really need to be faster? This is probably going to be controversial, I know‚Ä¶ Here more often than not, I personally end up saying yes, mind you: I don‚Äôt like to wait for my Laptop‚Ä¶ And I never know when I am going to re-use some of my own old code, so the better it is upfront, the less work I am giving myself in the future‚Ä¶ But I‚Äôll admit in some case I have made the following choice: if the thing is going to run for a long time, maybe it‚Äôs fine to have the PC do its thing overnight, and making it faster (but still multiple hours) adds no real value for me as I wouldn‚Äôt take it back until the next morning anyway‚Ä¶ (It‚Äôs a weird thing to say, even in terms of having my laptop spending energy during the night‚Ä¶). I guess all I‚Äôm saying is, optimising MY spare time is more important (somewhat anyway) than optimising my MACHINE‚Äôs spare time, and in some cases, these are not the same thing.\n\nThen the equation from Amdahl‚Äôs law I personally found to be simplistic (from what I understand, and although I get that it pretends to generalise the concept), as one often shouldn‚Äôt forget about the ‚Äúadded cost of the parallelising‚Äù itself. This is well known, but let me explain nevertheless with R futures: If I decide to use futures to make things parallel, new R processes/sessions will need to be created in the background. That might be minimal, but there is some kind of overhead, in creating the processes, maybe almost constant (maybe not so much), to throw into the equation there. If the constant (let‚Äôs call it c) is large enough IN COMPARISON to the overall time T of the SEQUENTIAL version of the code, then the gain from parallelising might not be worth the effort to begin with, regardless of (or maybe depending on) the number of threads the code using the future package is capable of using. But I am being picky, and for long running programs that detail should indeed be negligible‚Ä¶"
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#conclusions",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#conclusions",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "Conclusions",
    "text": "Conclusions\nI like these equations and ‚Äúlaws‚Äù, and how to bring those into consideration when coding (in my case, in R, of course :)).\nThey help put in perspective in which order to try and speed up some code, if the need arises.\nI‚Äôll admit it: I normally do at least some effort to speed things up after the initial version of my code, but usually not ‚Äúseriously‚Äù enough, meaning I rarely end up using RStudio‚Äôs profvis package (an important step mind you, if you seriously need speed gains on large programs‚Ä¶).\nI hope some tricks and the context in the above will be somewhat helpful to you."
  },
  {
    "objectID": "posts/2022-03-05_Amdahl_Gustafson/index.html#references",
    "href": "posts/2022-03-05_Amdahl_Gustafson/index.html#references",
    "title": "Higher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws",
    "section": "References",
    "text": "References\nAlthough I pointed to other pages here, it wouldn‚Äôt be right for me to write about this topic without citing the resource that most useful was to me to improve my code speeds in the past, namely:\nEfficient R"
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html",
    "href": "posts/2022-07-10_CISA_KEV/index.html",
    "title": "A quick look at CISA KEV",
    "section": "",
    "text": "I keep hearing about it, so it was time I had a look at that famous CISA ‚ÄúKnown Exploited Vulnerability‚Äù dataset. Also, it‚Äôs been a while since I did something more directly related to IT Security, so this is good.\nIt turns out, it‚Äôs quite‚Ä¶ Simple (the dataset), and even clean, which makes things rather easy. So we‚Äôll be quick about it."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#looking-for-a-codebook",
    "href": "posts/2022-07-10_CISA_KEV/index.html#looking-for-a-codebook",
    "title": "A quick look at CISA KEV",
    "section": "Looking for a ‚ÄúCodebook‚Äù",
    "text": "Looking for a ‚ÄúCodebook‚Äù\nSo first, let‚Äôs have a look here to understand what this dataset is. (Looking at data without having any background sometimes needs to happen, but whenever possible, let‚Äôs avoid that)\nThere is not exactly a ‚Äúcodebook‚Äù that I could find, describing the dataset column by column, but as it is quite straightforward, the provided background is probably sufficient."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#getting-the-data",
    "href": "posts/2022-07-10_CISA_KEV/index.html#getting-the-data",
    "title": "A quick look at CISA KEV",
    "section": "Getting the data",
    "text": "Getting the data\nToday the code won‚Äôt be that complicated at all. We‚Äôll first get the data, in JSON, and put it into a dataframe.\nlibrary(jsonlite) #fromJSON -&gt; data.frame\nlibrary(httr) # GET/POST\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(wordcloud2)\n\ncisa_response &lt;- httr::GET(url = \"https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json\",\ncontent_type_json(), accept_json())\nView(rawToChar(cisa_response$content))\nkev_list &lt;- fromJSON(txt = rawToChar(cisa_response$content))\nkev_df &lt;- kev_list[['vulnerabilities']]\nAnd that‚Äôs about it."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#about-prevalence",
    "href": "posts/2022-07-10_CISA_KEV/index.html#about-prevalence",
    "title": "A quick look at CISA KEV",
    "section": "About Prevalence",
    "text": "About Prevalence\nSo if we look (again: real quick) at the dataset, we easily get a feeling Microsoft, Google, Apple, Adobe‚Ä¶ A few familiar names appear more often than others. Let‚Äôs check that assumption (not all results shown there, but you get the idea), and no need to be fancy, a simple table will do:\n\nSo yes, there is something there. But this time around, let‚Äôs use our understanding of the so-called ‚Äúdomain knowledge‚Äù: So the bad guys they really want to have tools that get them into systems (to get data) that are‚Ä¶ used, by their targets.\nThis can be checked against things like (random search results for OS and software prevalence):\n\nhttps://gs.statcounter.com/os-market-share\nhttps://www.muchskills.com/blog/top-software-technical-tools-muchskills\nhttps://statisticsanddata.org/data/most-popular-pc-software/\n‚Ä¶\n\nSo it makes sense that the ‚Äúknown exploited vulnerabilities‚Äù affect often used products, say such as Microsoft (Windows, Office, etc.), Google (Chrome, Android‚Ä¶) or Apple (mostly iOS stuff). That‚Äôs not necessarily to say those products have more vulnerabilities than other products (although, the more complex the software‚Ä¶). No, not necessarily. It does say that more people (and organizations) use Windows, Chrome and iPhones, than say Firefox, though, but Firefox is still definitely in the short list.\nWell, it‚Äôs probably really a mix of a few aspects: Prevalence (hackers interest), complexity (possibility to make mistakes), and due diligence (how much you care about the security of your software in the first place).¬†\nBut let‚Äôs keep going."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#patch-your-systems",
    "href": "posts/2022-07-10_CISA_KEV/index.html#patch-your-systems",
    "title": "A quick look at CISA KEV",
    "section": "Patch your systems",
    "text": "Patch your systems\nWhen looking at the recommended actions, we get few options, and really given the nature of the data provided here, it makes sense.\n\nSo it really boils down to this:\n\nPatch your software\nRemove unsupported software\n\nNote: Patching implicitly supposes you have a license, where applicable. But that‚Äôs a different story.\nHow did I get the above tables, you ask? I‚Äôm surprised you would care, but here goes some sample code:\nkev_actions_freqs &lt;- as.data.frame(table(kev_df$requiredAction))\nnames(kev_actions_freqs)[1] &lt;- \"Rec_Action\"\nView(kev_actions_freqs %&gt;% arrange(desc(Freq)))"
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#making-it-a-coding-exercise",
    "href": "posts/2022-07-10_CISA_KEV/index.html#making-it-a-coding-exercise",
    "title": "A quick look at CISA KEV",
    "section": "Making it a coding exercise",
    "text": "Making it a coding exercise\nSo far, no real coding challenge. But when trying to make sense of the ‚ÄúVulnerability Names‚Äù, it became a bit more interesting.\nWhile looking (manually) at the data first, I found out that most vulnerability names end with 2-3 words that somehow help categorize them. Things like ‚Äúmemory corruption vulnerability‚Äù, ‚Äúadobe flash player‚Äù, ‚Äúdirectory traversal vulnerability‚Äù‚Ä¶\nOK so how can we have a look at the most commonly found 3-words occurrences among the vulnerability names? Using ‚ÄúN-grams‚Äù.\nIn text analysis and ‚ÄúNatural Language Processing‚Äù, N-grams are basically that: things (letters, words‚Ä¶) that occur together in the text. This is very useful for validating texts, propose next words to be typed, things like that.\nAnyway, in our case, we‚Äôll look for most common strings of ‚Äú3 words‚Äù happening in our vulnerability names (just for fun). And for the visualization, although it‚Äôs more ‚Äúfun‚Äù than ‚Äúuseful‚Äù (a table, like those above, would probably do better for serious work‚Ä¶), we‚Äôll use a wordcloud (I mean, for this exercise, why not?)\nlibrary(ngram)\nng_words_seq &lt;- paste(unlist(strsplit(tolower(kev_df$vulnerabilityName), \" \")), collapse = \" \")\nng_list &lt;- ngram(ng_words_seq, n = 3)\nwordcloud2(get.phrasetable(ng_list)[, 1:2] %&gt;% filter(freq &gt; 2))\nThat‚Äôs it (it looks easy, but as it was the first time ever I used that ngram package, I had to read the documentation a bit :)).\nAnd here the results:\n\nYou can tell some things occur more than others (also see Prevalence as explained earlier ;)).\n‚ÄúBuffer Overflow‚Äù, ‚ÄúMemory Corruption‚Äù, ‚ÄúCommand Injection‚Äù, ‚ÄúPrivilege Escalation‚Äù, ‚ÄúImproper input validation‚Äù, ‚ÄúDirectory Traversal‚Äù, ‚ÄúType Confusion‚Äù, ‚ÄúAccess Control‚Äù‚Ä¶\nWell, maybe a 2 words N-gram was a better idea after all (and removing ‚Äúvulnerability‚Äù). Let‚Äôs try that (just for fun):\nng_words_seq &lt;- gsub(\"vulnerability\", \"\", ng_words_seq)\nng_list &lt;- ngram(ng_words_seq, n = 2)\nwordcloud2(get.phrasetable(ng_list)[, 1:2] %&gt;% filter(freq &gt; 2))\n\nIt‚Äôs not much better. So maybe this is not the best approach, but fair enough, a good, quick exercise for today."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#what-kev-does-not-say",
    "href": "posts/2022-07-10_CISA_KEV/index.html#what-kev-does-not-say",
    "title": "A quick look at CISA KEV",
    "section": "What KEV does not say",
    "text": "What KEV does not say\nI‚Äôve seen it, more than once, so I‚Äôm going to say it: It‚Äôs ‚ÄúNOT THAT EASY‚Äù to match two datasets of software names and versions. It turns out that some inventory (like this KEV thing) and security products (say some vulnerability management tool for example) will list the SAME SOFTWARE with DIFFERENT NAMES.\nIt sounds ridiculous, I know, but it goes like this, for instance: One might say ‚ÄúMicrosoft Windows‚Äù, another one might say ‚ÄúMS Win Server 2019‚Äù. This very simple example, times the number of vendors of software, their product names, and versions names, times the number of possible ideas each product vendor comes up with‚Ä¶ It rapidly becomes rather difficult (for an automated approach‚Ä¶).\nOne solution is to use the ‚ÄúCPE‚Äù (Common Platform Enumeration ‚Äì which incidentally was created for just this purpose, see here) where possible.\nFor example, the KEV dataset mentions ‚ÄúCVE-2020-1350‚Äù, applicable to Vendor: Microsoft, Product: Windows. That‚Äôs a bit too generic for my taste, most companies have MANY Windows machines‚Ä¶ Does this vulnerability affect servers, clients‚Ä¶?\nOne would then need to pivot somewhat, so if you search for the CVE, you easily end up on the MITRE page for it:\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1350\nThat still doesn‚Äôt give you the info you need, then you keep clicking links from there, and maybe you end up finding what you need here for example:\nhttps://nvd.nist.gov/vuln/detail/CVE-2020-1350\n\n\n\nCPE for CVE\n\n\n¬†\nFinally: This CVE affects certain (most, recent) versions of Windows Server. Now we‚Äôre able to leverage this information and go looking for servers in our network that match this and make sure these are patched.\nI‚Äôm pretty sure there will be a downloadable CVE database (actually there seems to be an API from the NIST NVD, so there would be a good place to start‚Ä¶ Maybe I‚Äôll have some time to look into it in upcoming weeks.), but in the worst case scenario you can always crawl (one-by-one, no brute-forcing there, please, that would be against ethical use of their service) the pages referencing each CVE as you need them. Anyhow."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#conclusions",
    "href": "posts/2022-07-10_CISA_KEV/index.html#conclusions",
    "title": "A quick look at CISA KEV",
    "section": "Conclusions",
    "text": "Conclusions\nFirst of: No ‚Äúbig surprise‚Äù anywhere with this dataset. As said, it‚Äôs clean, clearcut, and just for that I‚Äôm thankful üòÄ\nSecond of all, we could keep going (there is a column of description, and one of dates‚Ä¶ So we might want to use that maybe to extrapolate how much active the bad guys are by month, for example ‚Äì although there are again too many confounding variables to conclude much there from just this dataset‚Ä¶)\nThe key aspect however of the CISA KEV dataset is its purpose: to help organizations (or anyone with some IT gear) to, as they put it on the website, ‚Äúprioritize remediation‚Äù.\nAnd that‚Äôs already an important aspect, as it‚Äôs easy in a company to have thousands of devices, with quite a few software products on each‚Ä¶ Knowing what to take care of first is a good helping hand.\nSo once you have the KEV dataset, you‚Äôll need to find the machines that are affected by each corresponding CVE, so that you can actually patch those first.\nAnd as you‚Äôll want to patch ALL your systems at some point, you might ask ‚Äúwhy not do that directly‚Äù? Well, sometimes applying patches break stuff. So out of precaution, companies usually patch things in waves, usually by importance/business risk (say ‚ÄúCritical patches first, focus on Dev environment first, then low-business-criticality servers‚Ä¶‚Äù).\nAll this is saying is: you might want to review your patch waves to make sure you patch the systems affected by any of the CVEs in the KEV list sooner rather than later, somehow."
  },
  {
    "objectID": "posts/2022-07-10_CISA_KEV/index.html#references",
    "href": "posts/2022-07-10_CISA_KEV/index.html#references",
    "title": "A quick look at CISA KEV",
    "section": "References",
    "text": "References\nQuite a few today, but the main ones were:\nCISA Known Exploited Vulnerabilities\nMITRE CVE\nNIST NVD API\nR Package ngram Documentation"
  },
  {
    "objectID": "posts/2023-06-02_OnEigenvalue/index.html",
    "href": "posts/2023-06-02_OnEigenvalue/index.html",
    "title": "On Eigenvalues (more)",
    "section": "",
    "text": "A quick post to make a note about how often I come across the concept of Eigenvalues now.\nIn summary, so far I have seen at some point or another that you can use them to (at least):\n\nFind PCA components (using the Covariance matrix derived from a Multivariate dataset, because in there the eigenvectors are orthogonal).\nFind the ‚Äúeigenvector centrality‚Äù of nodes in a network graph\nSolve systems of related differential equations\n\nAnd that‚Äôs it. There‚Äôs more of course. But‚Ä¶ That‚Äôs mostly a note to myself. Matrices and linear algebra can be very useful."
  },
  {
    "objectID": "posts/2023-06-02_OnEigenvalue/index.html#more-eigenvalues-value",
    "href": "posts/2023-06-02_OnEigenvalue/index.html#more-eigenvalues-value",
    "title": "On Eigenvalues (more)",
    "section": "",
    "text": "A quick post to make a note about how often I come across the concept of Eigenvalues now.\nIn summary, so far I have seen at some point or another that you can use them to (at least):\n\nFind PCA components (using the Covariance matrix derived from a Multivariate dataset, because in there the eigenvectors are orthogonal).\nFind the ‚Äúeigenvector centrality‚Äù of nodes in a network graph\nSolve systems of related differential equations\n\nAnd that‚Äôs it. There‚Äôs more of course. But‚Ä¶ That‚Äôs mostly a note to myself. Matrices and linear algebra can be very useful."
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "I was in attending a local R conference the other day, and took the opportunity to discuss a bit with some of the (very few) that have a minimal interest (and an understanding) of what I‚Äôm trying to do these days with the RLCS project.\nIt‚Äôs always great to talk with them, they know so much, there is so much experience in there. And of course, that means, they can criticize my work. Which, from them, or anyone with criteria for that matter, I happily welcome!\n\n\n\nAlright, so far I‚Äôve always taken examples where I could translate the problems into binary strings for the input.\nFor images, I took each pixel and set it to 1 if the pixel was ‚Äúused‚Äù (say, a high shade of black), and 0 if it wasn‚Äôt (say, a light shade of grey). See https://kaizen-r.github.io/posts/2025-03-19_ExplainableAI/ for instance, for a visual intuition.\nOther examples were specifically chosen to be already presenting binary ‚Äústates‚Äù. That was the case with ‚Äúnot_bit_4‚Äù or ‚Äúmux_6‚Äù here.\nBut it is very common to have numerical variables as input, not‚Ä¶ Well, not simply binary ones.\nThat said, pause for a second: What is a binary string if not (often times) a numerical value, duly encoded? It‚Äôs quite straightforward, if you think about it. Say you want to use 4 bits, you can encode 16 values, say the natural numbers (0:15). So 0000 is 0, 0010 is 2, and 1111 is 15.\nBut let‚Äôs make a second pause: What if you have more values? Say 32 of them, from 0 to 31? And say, for the sake of example, that we want to limit the number of bits to be used still to 4 bits. Then we could decide to assume a loss of information, and if so, use 0000 as a state for actual values 0 and 1, and 1111 for actual values 30 and 31.\nWhy limit the number of bits, you ask? Well, because the way it is working currently, each added bit to the states increases the search space of the algorithm by a (multiplication) factor of 2. Which is to say, long binary strings as states are costly to process and depending on the problem, with lots of samples for training, for instance, would require a lot of time (Note: I‚Äôm not discussing here ‚Äúa lot of processing power‚Äù, because as it is, paralelising is complex, although not impossible, and with varying efficacy depending on the scenarios). With few samples, or clear separation, for instance, the limitation of forcing a sequential processing can be overcome with nicely chosen hyperparameters. But it‚Äôs not straightforward. Anyhow, back to the topic.\nPause number 3: What if we had real-valued variables. Each variable then fits within its own range. I hereby suggest we could ‚Äúbreak‚Äù it in buckets, so that each bucket can then in turn represent a subset of the chosen variable values, a range.\nHow to break that though? Choosing means kind of makes an assumption about the distribution (normality) of input variable. So for now, and without thinking much about it I prefer to use the median, and quartiles, thereby breaking the input in 4 buckets of similar (or almost identical) sizes. And then, why not, break each bucket in turn in 4 sub-buckets. Voil√†: 16 subsets of the one variable. To be represented each as a 4 bits binary string.\nAnd no, I haven‚Äôt given it much more thought. This is just a simplified approach, one which I do not believe is perfect (maybe considering the input distribution would be better), or even best for the LCS processing; one which my statistician friends will surely criticize the next time I meet them‚Ä¶ But the important thing is the conceptual approach: If you accept loss of information, there is nothing precluding you from encoding your real numbers input into binary strings!\nThereby, of course, making the algorithm more practical to use.\n\n\n\nFinal detail for today: While reading the book ‚ÄúIntroduction to Learning Classifier Systems‚Äù (mentioned in the first post on the RLCS topic), they make a point about the binary encoding.\n‚ÄúNormal binary‚Äù encoding of numbers is not always ‚Äúsequential‚Äù for consecutive numbers, in that the Hamming distance between 0011 and 0100 (3 and 4) is 2.\nThere are alternatives, and one that is proposed in the book is the Gray code. I won‚Äôt delve into the details, but suffice to say, I am not yet fully convinced it is a great approach, but there is some intuition to it that makes it probably better than traditional encoding.\nAnyhow, I make a very very simplistic implementation of all I have discussed thus far today for the (in-)famous iris dataset. (Infamous in that, it‚Äôs almost too common :D But then again, that‚Äôs what makes it a perfect example!)\n\n\n\nSo the iris dataset presents 4 real-valued variables, and 3 classes. Think of 16 buckets per variable, using quartiles and sub-quartiles. And a Gray code.\nCan we make a Supervised Learning model using LCS? Sure we can!\nThis is what it looks like, with the state simply putting together 4 strings of 4 bits:\n\n\n\nencoding iris, binary buckets and grey\n\n\nAnd what about the result?\nWell, it‚Äôs a bit slow: 4‚Äô for training. There are considerations about this, but overall, consider searching for solutions in a 16bits search space, where on top of everything else, classes are overlapping in different dimensions‚Ä¶ But no excuse, and I haven‚Äôt continued tweaking hyperparameters for this particular example.\nAnyhow. And what of the quality of the resulting LCS as a supervised learning classifier?\nI take 80% of the samples for the training (119) samples, leaving only 30 samples for testing (it‚Äôs not a big dataset :D). And the results are like so:\n\n\n\nnot bad a classifier\n\n\nThat‚Äôs about it. Although‚Ä¶\nThen again, other options are proposed in the book‚Ä¶\n\n\n\nWell, in fact, yes. There are alternatives, whereby instead of 0 or 1, you can take real numbers. The way this works (at least the way others have approached it and documented it in the reference book on the topic already mentioned) is like so:\n\neach variable is ‚Äúcovered‚Äù separately by a wide or narrow numerical range\nCoverage (creating new classifiers) would set a range around the variable value. Said range would replace our current bits in the state (bit strings).\nupon calling the Genetic Algorithm, the mutation step can replace said ranges with either generalization (so, # as implemented otherwise), but also it could try to widen or narrow the range.\n\nThe above would allow to cover more or less ground per classifier, making them more or less specific. I feel this seems correct. But I do also believe the computational effort would potentially be higher (I haven‚Äôt thought it through either).\nAlso, we need to decide what ‚Äúnarrow‚Äù or ‚Äúwide‚Äù signifies for each variable, for instance.\nAnd of course, I would need to change the code to account for such inputs, which‚Ä¶ I‚Äôm sorry, but I won‚Äôt do it for now. If someone some day shows a minimum of interest in the possibilities of the algorithm, I shall make sure I implement that.\nActually, I kinda know how to go about it. But there are many pieces of the algorithm, and functionally testing any change (in the functionality) is a slow process (in spite of having run several tests thus far‚Ä¶). Unit testing wouldn‚Äôt be so much of a problem.\n\n\n\nIt is true that ‚Äúonly‚Äù accepting binary input strings for the states (i.e.¬†the input data, in our context) is a difficulty, for sure.\nBut consider that: Neural Networks accept numerical input. And people use them. This is slightly different, but not really if you look at it a certain way.\nSo yes, I should work on a future version that will accept numerical input, not just binary strings. Sure. Some day. Future version is the key here, there is only so much I can cover for now :)"
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#but-you-only-take-binary-strings-as-input",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#but-you-only-take-binary-strings-as-input",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "I was in attending a local R conference the other day, and took the opportunity to discuss a bit with some of the (very few) that have a minimal interest (and an understanding) of what I‚Äôm trying to do these days with the RLCS project.\nIt‚Äôs always great to talk with them, they know so much, there is so much experience in there. And of course, that means, they can criticize my work. Which, from them, or anyone with criteria for that matter, I happily welcome!"
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#a-short-term-partial-but-functional-solution",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#a-short-term-partial-but-functional-solution",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "Alright, so far I‚Äôve always taken examples where I could translate the problems into binary strings for the input.\nFor images, I took each pixel and set it to 1 if the pixel was ‚Äúused‚Äù (say, a high shade of black), and 0 if it wasn‚Äôt (say, a light shade of grey). See https://kaizen-r.github.io/posts/2025-03-19_ExplainableAI/ for instance, for a visual intuition.\nOther examples were specifically chosen to be already presenting binary ‚Äústates‚Äù. That was the case with ‚Äúnot_bit_4‚Äù or ‚Äúmux_6‚Äù here.\nBut it is very common to have numerical variables as input, not‚Ä¶ Well, not simply binary ones.\nThat said, pause for a second: What is a binary string if not (often times) a numerical value, duly encoded? It‚Äôs quite straightforward, if you think about it. Say you want to use 4 bits, you can encode 16 values, say the natural numbers (0:15). So 0000 is 0, 0010 is 2, and 1111 is 15.\nBut let‚Äôs make a second pause: What if you have more values? Say 32 of them, from 0 to 31? And say, for the sake of example, that we want to limit the number of bits to be used still to 4 bits. Then we could decide to assume a loss of information, and if so, use 0000 as a state for actual values 0 and 1, and 1111 for actual values 30 and 31.\nWhy limit the number of bits, you ask? Well, because the way it is working currently, each added bit to the states increases the search space of the algorithm by a (multiplication) factor of 2. Which is to say, long binary strings as states are costly to process and depending on the problem, with lots of samples for training, for instance, would require a lot of time (Note: I‚Äôm not discussing here ‚Äúa lot of processing power‚Äù, because as it is, paralelising is complex, although not impossible, and with varying efficacy depending on the scenarios). With few samples, or clear separation, for instance, the limitation of forcing a sequential processing can be overcome with nicely chosen hyperparameters. But it‚Äôs not straightforward. Anyhow, back to the topic.\nPause number 3: What if we had real-valued variables. Each variable then fits within its own range. I hereby suggest we could ‚Äúbreak‚Äù it in buckets, so that each bucket can then in turn represent a subset of the chosen variable values, a range.\nHow to break that though? Choosing means kind of makes an assumption about the distribution (normality) of input variable. So for now, and without thinking much about it I prefer to use the median, and quartiles, thereby breaking the input in 4 buckets of similar (or almost identical) sizes. And then, why not, break each bucket in turn in 4 sub-buckets. Voil√†: 16 subsets of the one variable. To be represented each as a 4 bits binary string.\nAnd no, I haven‚Äôt given it much more thought. This is just a simplified approach, one which I do not believe is perfect (maybe considering the input distribution would be better), or even best for the LCS processing; one which my statistician friends will surely criticize the next time I meet them‚Ä¶ But the important thing is the conceptual approach: If you accept loss of information, there is nothing precluding you from encoding your real numbers input into binary strings!\nThereby, of course, making the algorithm more practical to use."
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#the-tweak-gray-encoding",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#the-tweak-gray-encoding",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "Final detail for today: While reading the book ‚ÄúIntroduction to Learning Classifier Systems‚Äù (mentioned in the first post on the RLCS topic), they make a point about the binary encoding.\n‚ÄúNormal binary‚Äù encoding of numbers is not always ‚Äúsequential‚Äù for consecutive numbers, in that the Hamming distance between 0011 and 0100 (3 and 4) is 2.\nThere are alternatives, and one that is proposed in the book is the Gray code. I won‚Äôt delve into the details, but suffice to say, I am not yet fully convinced it is a great approach, but there is some intuition to it that makes it probably better than traditional encoding.\nAnyhow, I make a very very simplistic implementation of all I have discussed thus far today for the (in-)famous iris dataset. (Infamous in that, it‚Äôs almost too common :D But then again, that‚Äôs what makes it a perfect example!)"
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#the-iris-classifier",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#the-iris-classifier",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "So the iris dataset presents 4 real-valued variables, and 3 classes. Think of 16 buckets per variable, using quartiles and sub-quartiles. And a Gray code.\nCan we make a Supervised Learning model using LCS? Sure we can!\nThis is what it looks like, with the state simply putting together 4 strings of 4 bits:\n\n\n\nencoding iris, binary buckets and grey\n\n\nAnd what about the result?\nWell, it‚Äôs a bit slow: 4‚Äô for training. There are considerations about this, but overall, consider searching for solutions in a 16bits search space, where on top of everything else, classes are overlapping in different dimensions‚Ä¶ But no excuse, and I haven‚Äôt continued tweaking hyperparameters for this particular example.\nAnyhow. And what of the quality of the resulting LCS as a supervised learning classifier?\nI take 80% of the samples for the training (119) samples, leaving only 30 samples for testing (it‚Äôs not a big dataset :D). And the results are like so:\n\n\n\nnot bad a classifier\n\n\nThat‚Äôs about it. Although‚Ä¶\nThen again, other options are proposed in the book‚Ä¶"
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#could-we-accept-numerical-inputs",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#could-we-accept-numerical-inputs",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "Well, in fact, yes. There are alternatives, whereby instead of 0 or 1, you can take real numbers. The way this works (at least the way others have approached it and documented it in the reference book on the topic already mentioned) is like so:\n\neach variable is ‚Äúcovered‚Äù separately by a wide or narrow numerical range\nCoverage (creating new classifiers) would set a range around the variable value. Said range would replace our current bits in the state (bit strings).\nupon calling the Genetic Algorithm, the mutation step can replace said ranges with either generalization (so, # as implemented otherwise), but also it could try to widen or narrow the range.\n\nThe above would allow to cover more or less ground per classifier, making them more or less specific. I feel this seems correct. But I do also believe the computational effort would potentially be higher (I haven‚Äôt thought it through either).\nAlso, we need to decide what ‚Äúnarrow‚Äù or ‚Äúwide‚Äù signifies for each variable, for instance.\nAnd of course, I would need to change the code to account for such inputs, which‚Ä¶ I‚Äôm sorry, but I won‚Äôt do it for now. If someone some day shows a minimum of interest in the possibilities of the algorithm, I shall make sure I implement that.\nActually, I kinda know how to go about it. But there are many pieces of the algorithm, and functionally testing any change (in the functionality) is a slow process (in spite of having run several tests thus far‚Ä¶). Unit testing wouldn‚Äôt be so much of a problem."
  },
  {
    "objectID": "posts/2025-03-30_Small_Addition_RLCS/index.html#conclusions",
    "href": "posts/2025-03-30_Small_Addition_RLCS/index.html#conclusions",
    "title": "RLCS: Small addition",
    "section": "",
    "text": "It is true that ‚Äúonly‚Äù accepting binary input strings for the states (i.e.¬†the input data, in our context) is a difficulty, for sure.\nBut consider that: Neural Networks accept numerical input. And people use them. This is slightly different, but not really if you look at it a certain way.\nSo yes, I should work on a future version that will accept numerical input, not just binary strings. Sure. Some day. Future version is the key here, there is only so much I can cover for now :)"
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html",
    "title": "Assume the Cow is a Sphere",
    "section": "",
    "text": "I think I might have a start of an idea, for my MSc project. Although it‚Äôs‚Ä¶ Incipient."
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#intro",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#intro",
    "title": "Assume the Cow is a Sphere",
    "section": "",
    "text": "I think I might have a start of an idea, for my MSc project. Although it‚Äôs‚Ä¶ Incipient."
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#how-do-we-know-what-we-know",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#how-do-we-know-what-we-know",
    "title": "Assume the Cow is a Sphere",
    "section": "How do we know what we know?",
    "text": "How do we know what we know?\nSo from a Cybersecurity (blue team) stand-point, one would (generally) want:to ‚Äúsegment‚Äù an IT Network as much as possibleto ‚Äúpatch‚Äù the overall infrastructure as much/fast as possible (‚ÄúProtect‚Äù)to have the employees very much worrying¬† about (i.e.¬†‚Äúaware of‚Äù) Phishing risksto use ‚Äúsecure‚Äù codeto have a perfect inventory (‚ÄúDiscover‚Äù)to have crazy-fast reaction times (‚ÄúIR‚Äù)to detect all weird things (‚ÄúDetect‚Äù)to have the smallest possible IT footprint/surface to protect‚Ä¶The ‚Äú‚Ä¶‚Äù above can easily become a VERY long list.The reality being, either because of budget constraints or complexity of large enterprise networks (or a mix of these and other factors), that you could easily assume none of the above is perfect anywhere. And so it‚Äôs only natural I first thought of Operational Research and Optimization‚Ä¶After all, sometimes you just can‚Äôt patch a Web Server the same day a vulnerability patch is made available, because while testing it, you find out you break the application you were running (i.e.¬†you break you business application, i.e.¬†your income stream, to some extent).(Note: Many such assumptions could go for the ‚Äúattacker‚Äù (alright, obviously a bit different): You want to know the objective‚Äôs surface, find vulnerable systems, as many as possible, use phishing to get credentials, usually with the goal of getting data or extortion‚Ä¶)Where should you put your ‚Äúnext effort‚Äù¬†(a colleague said ‚Äúnext dollar‚Äù, same-same) as the Cybersecurity team?All of the above make sense‚Ä¶¬†Intuitively.But where is the data or ‚Äúscience‚Äù supporting any one action over another?For instance, if you had to choose: Should you implement micro-segmentation, or rather honeypots across your network?Sure: Zero Trust is in fashion, but what is it YOU (your company) needs next? How would you justify your choice (hint: the answer ‚ÄúGartner/Forrester says so‚Äù, well, I don‚Äôt quite agree with, in general‚Ä¶)"
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#a-cyber-secure-organisation-simulator",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#a-cyber-secure-organisation-simulator",
    "title": "Assume the Cow is a Sphere",
    "section": "A Cyber-secure Organisation Simulator",
    "text": "A Cyber-secure Organisation Simulator\nSo here is the deal. A Simulation is‚Ä¶ Imperfect. (hence the title of this entry) Let‚Äôs start right there: I couldn‚Äôt possibly throw in ALL of the complexity of a real-world network ‚Äì and I certainly don‚Äôt intend to.But I‚Äôve been learning about Simulation, Parallel Computing, Mathematical modelling, and reading (quite a bit) about Chaos, complexity, optimisation, Operations Research‚Ä¶ I‚Äôve implemented an SIS-model on Graph Networks (epidemiology stuff), I‚Äôve studied congestion and queuing systems in complex networks, done lots (well, quite a few, by now) of Monte-Carlo runs to observe effects of different configurations ‚Äúwhile time passes‚Äù, I‚Äôve played around with Genetic Algorithms ‚Äì and you can use these for instance to ‚Äútune‚Äù parameters for optimization of things‚Ä¶So how about I simulated one (or MANY, why not) network(s) of systems/applications/software components/users, with:MORE OR LESS Segmentation (i.e.¬†Network topology, that was the second thing I thought of‚Ä¶),FASTER/SLOWER Patching policy,BETTER/WORSE inventory coverage,HIGH/LOW training of Employees about Phishing‚Ä¶As a network, under ‚Äúattack‚Äù, with (based on the former parameters) more or less risk of ‚Äúinfection spreading‚Äù‚Ä¶ALL of the above parameters could be things to optimize (e.g.¬†using a Genetic Algorithm), within supposed budget constraints (Optimisation, Metaheuristic).Each Network would then ‚Äúlive‚Äù for a while (passing of time), and depending of the parameters, an infection would appear (or not), spread more or less‚Ä¶And so we could come up with simulated data about relation of level of segmentation and spreading risk, and MANY MANY other possible prioritization of ‚Äúwhere to spend my next Cybersecurity Budget‚Äôs Dollar‚Äù."
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#applicability",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#applicability",
    "title": "Assume the Cow is a Sphere",
    "section": "Applicability",
    "text": "Applicability\nAll the above could be fully based on purely invented data (and as a ‚Äúnon-teleological‚Äù simulation, would be interesting in itself).Yes, I said ‚Äúnon-teleological‚Äù‚Ä¶ I had to look it up myself, while reading ‚ÄúAntifragility‚Äù by N. Taleb‚Ä¶ (I find the writing to be messy/disorganized, but the contents/ideas are great). What it means here is, I am willing to run such simulations solely for the sake of learning something, NOT to prove anything (i.e.¬†without a clear objective).But then, after some tests, dry-runs, evaluations of metrics, better definition of sensible variables values/ranges‚Ä¶Why not take a ‚Äúreal‚Äù corporate IT network as the basis for the simulated network, with parameters that somehow reflect a company‚Äôs reality, and then run simulations on THAT.Would we learn anything? I just wonder‚Ä¶"
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#starting-point",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#starting-point",
    "title": "Assume the Cow is a Sphere",
    "section": "Starting point",
    "text": "Starting point\nAs it turns out, I wanted to ‚Äújust get started‚Äù, so that this ‚Äúthing‚Äù would have some momentum. Plus, there is only so much note-taking, thinking-while-walking-in-circles, and reading (a lot), that I can do without putting something together to cristalise a bit my ideas.While I was at it (lots of ‚Äúigraph‚Äù), I found quite unexpectedly the ‚Äúggraph‚Äù package, and gave it a go‚Ä¶ It‚Äôs not half bad üôÇMy thinking process has been a mess, with ideas of complexity and emergence and what-not, but I finally decided I should reverse gears and begin‚Ä¶ At the beginning.And so, thinking about Cybersecurity efforts within a company, I guess this could be a reasonable starting point:The Cybersecurity Department works toward ensuring the Company gets paid (duh! But obvious as it may seem, this is just the thing, it‚Äôs not about defending, it‚Äôs about defending for a reason‚Ä¶ Which usually is about money, in the end). To do so, we in fact focus on ensuring protection of:the stability of our services,our client‚Äôs private information,our own IP (if there is any)‚Ä¶Part of that is trying to protect the above from ‚Äúbad‚Äù third party (and here, ‚Äúthird party‚Äù could involve an employee, I mean, who knows‚Ä¶).For the purpose of my simulations, I shall focus on this, though:And that‚Äôs the beginning. It‚Äôs quite‚Ä¶ Unimpressive, granted. But that‚Äôs not the project‚Ä¶ The next step is to¬†‚Äúexplode‚Äù the Company node into its components. And then implement simulations on top of that. And THAT‚Äôs the general idea."
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#conclusions",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#conclusions",
    "title": "Assume the Cow is a Sphere",
    "section": "Conclusions",
    "text": "Conclusions\nNow I have NO IDEA what the ‚Äúthing‚Äù will show. Maybe it‚Äôs a complete flop. Maybe there is no humanly sensible way of interpreting the ‚Äúresults‚Äù.But maybe, JUST MAYBE, I could learn something about the relative value of each security measure one could take to protect a network from intrusion? And IF I did, well, maybe there would be something more to support say a better network segmentation, further employees training (‚Ä¶) than the ‚Äúlogical intuition‚Äù that ‚Äúit makes sense‚Äù.ALSO to be noted: I started looking for potentially relevant papers about the same ideas.I promise I came up with the idea of my simulator completely on my own (i.e.¬†‚Äúindependently‚Äù), but as it happens‚Ä¶¬†Someone almost beat me to it¬†(in a way, not quite the same, so I can move forward)."
  },
  {
    "objectID": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#references",
    "href": "posts/2023-08-16_AssumeTheCowIsASphere/index.html#references",
    "title": "Assume the Cow is a Sphere",
    "section": "References",
    "text": "References\nOn top of¬†the aforementioned paperThis seems tangential in conceptSomething a bit further removed (but interesting)Also probably interesting"
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html",
    "href": "posts/2022-05-14_OnMSSQL/index.html",
    "title": "Working with MS SQL",
    "section": "",
    "text": "So in the past I‚Äôve looked into Postgres and/or (a bit of) MongoDB. Both nice alternatives to consider! But in some cases, one has to use other flavours of SQL, say in some corporate settings: Think for instance Oracle, or MS SQL Server, or if you‚Äôre Cloud inclined‚Ä¶ Azure SQL üòâ\nOne of the things that I usually care about most is to make sure that the data exchanged with the database is as secured as possible‚Ä¶ And when looking into it, I found I wanted to use specific connections options: I recently looked into the Azure SQL setup specifically."
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html#intro",
    "href": "posts/2022-05-14_OnMSSQL/index.html#intro",
    "title": "Working with MS SQL",
    "section": "",
    "text": "So in the past I‚Äôve looked into Postgres and/or (a bit of) MongoDB. Both nice alternatives to consider! But in some cases, one has to use other flavours of SQL, say in some corporate settings: Think for instance Oracle, or MS SQL Server, or if you‚Äôre Cloud inclined‚Ä¶ Azure SQL üòâ\nOne of the things that I usually care about most is to make sure that the data exchanged with the database is as secured as possible‚Ä¶ And when looking into it, I found I wanted to use specific connections options: I recently looked into the Azure SQL setup specifically."
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html#specific-odbc",
    "href": "posts/2022-05-14_OnMSSQL/index.html#specific-odbc",
    "title": "Working with MS SQL",
    "section": "Specific ODBC",
    "text": "Specific ODBC\nSo on top of other ‚Äúissues‚Äù with switching to MS SQL things (like slightly different SQL users management, weird ‚ÄúPaaS‚Äù concepts that still require a (false) MS SQL Server, or different syntaxes (what was wrong with ‚ÄúSELECT * FROM table LIMIT 10;‚Äù, why did you have to use ‚ÄúSELECT TOP(10) * FROM table;‚Äù?)), one thing that happened is: How can I make sure my connection to the Database is ‚Äúas secure as can be‚Äù?\nFor instance, there are options using ODBC for MS SQL products (Server and Azure SQL) in the connection string that helps you enforce connection encryption (why is it not default always? Using an MS SQL Server Management Studio client, you need to click on the option specifically‚Ä¶ Anyway, maybe it is but I wanted to enforce it, as my testing DB would reside in the Cloud this time, far away from my locally-running container). Another option is about trusting or not the server certificates‚Ä¶\nOne thing that happens with my usual setting, using a Docker Container for RStudio (the rocker image, with some tuning, referenced in the past), is that it‚Äôs a Linux, not a native MS Client of course. It‚Äôs rather easy to install an official driver from MS on Ubuntu, just follow the steps on MS Doc.\nNote: That‚Äôs to be executed from within the container in my case, so you probably would run it from a console accessing the shell of the container, and as you need to be root for some steps, the easiest way is to do:\ndocker exec -it rocker1 /bin/bash\nWhere ‚Äúrocker1‚Äù is the name tag of your running RStudio Rocker container‚Ä¶\nOK. That‚Äôs the most important step I guess, having a ‚Äúgood‚Äù ODBC driver to use. (Note: At the time of my tests, I found the current version is 18.)"
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html#then-in-r",
    "href": "posts/2022-05-14_OnMSSQL/index.html#then-in-r",
    "title": "Working with MS SQL",
    "section": "Then in R",
    "text": "Then in R\nSo now that you have a specific driver for it, compatible with recent MS SQL Server/Azure SQL, and you can hopefully use it from R. Just check for it like so:\nlibrary(odbc)\nodbc::odbcListDrivers()\nIf the output mentions something along the lines of ‚ÄúODBC Driver 18 for SQL Server‚Äù (that‚Äôs 3 rows really), you‚Äôre good.\nThen you can use the connection strings to leverage that newly installed driver. I‚Äôll just show one example here. You‚Äôll need to adapt to your version, and probably use the recommended connection string that Azure SQL actually proposes if you have an Azure SQL DB running on the main screen‚Ä¶\ncon &lt;- dbConnect(odbc(), .connection_string = \"Driver={ODBC Driver 18 for SQL Server};Server=tcp:&lt;DB FQDN/URL&gt;,1433;Database=&lt;DB name&gt;;Uid=&lt;user&gt;;Pwd=&lt;pass&gt;;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\")\nNow you can use the ‚Äúcon‚Äù variable to ‚ÄúdbSendQuery()‚Äù and such, being somewhat confident that the connection from your script to the DB will be ciphered."
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html#conclusion",
    "href": "posts/2022-05-14_OnMSSQL/index.html#conclusion",
    "title": "Working with MS SQL",
    "section": "Conclusion",
    "text": "Conclusion\nThe part I was looking for when deciding how to go about the SQL Connection for Microsoft there was the ‚ÄúEncrypt=yes‚Äù. A few supplementary steps to just add that option in there, but I feel better about it üôÇ\nOf course, there is more to it, and securing your database before you have some sensitive data in it should be a top priority‚Ä¶ But the above is one example of such efforts."
  },
  {
    "objectID": "posts/2022-05-14_OnMSSQL/index.html#references",
    "href": "posts/2022-05-14_OnMSSQL/index.html#references",
    "title": "Working with MS SQL",
    "section": "References",
    "text": "References\nMS Doc about the ODBC driver"
  },
  {
    "objectID": "posts/2023-11-08_WhileOnTheTrain/index.html",
    "href": "posts/2023-11-08_WhileOnTheTrain/index.html",
    "title": "While on the Train: Cellular Automata",
    "section": "",
    "text": "I decidedly LOVE riding on a train: For whatever reason, it‚Äôs one particular moment where I somehow focus a bit more than usual. It‚Äôs usually just a few hours, reasonably quiet environment, a bit more spacious than say airplanes (airplanes are just not the same, even with earplugs), no TV to distract my attention, the excuse of limited/imperfect mobile coverage‚Ä¶ You name it. I just don‚Äôt know, but it works, I feel motivated to code & run experiments while on a train‚Ä¶"
  },
  {
    "objectID": "posts/2023-11-08_WhileOnTheTrain/index.html#intro",
    "href": "posts/2023-11-08_WhileOnTheTrain/index.html#intro",
    "title": "While on the Train: Cellular Automata",
    "section": "",
    "text": "I decidedly LOVE riding on a train: For whatever reason, it‚Äôs one particular moment where I somehow focus a bit more than usual. It‚Äôs usually just a few hours, reasonably quiet environment, a bit more spacious than say airplanes (airplanes are just not the same, even with earplugs), no TV to distract my attention, the excuse of limited/imperfect mobile coverage‚Ä¶ You name it. I just don‚Äôt know, but it works, I feel motivated to code & run experiments while on a train‚Ä¶"
  },
  {
    "objectID": "posts/2023-11-08_WhileOnTheTrain/index.html#introducing-the-cellular-automata",
    "href": "posts/2023-11-08_WhileOnTheTrain/index.html#introducing-the-cellular-automata",
    "title": "While on the Train: Cellular Automata",
    "section": "Introducing the Cellular Automata",
    "text": "Introducing the Cellular Automata\nOne thing that I liked about the book I recommended a couple of days back (see last entry before this one) is that it provides nice and easy examples (but in Python), and then reasonable exercises. I loved to read through most of them (and some of the math sections), but reading is not that fun in this case, I wanted to try it out (of course!).\nThe following is the result of a simple R implementation of ‚ÄúCellular Automata‚Äù for simulation of a ‚Äúfire spread‚Äù in a theoretical forest setting. The identification of the ‚Äúneighbour‚Äù trees in fire follows the Von Neumann definition of ‚Äúneighbours‚Äù in this 2D configuration.\nHopefully the video is quite self-explanatory. You start with ONE burning tree, and then let time pass‚Ä¶ üôÇ"
  },
  {
    "objectID": "posts/2023-11-08_WhileOnTheTrain/index.html#visualization-trick",
    "href": "posts/2023-11-08_WhileOnTheTrain/index.html#visualization-trick",
    "title": "While on the Train: Cellular Automata",
    "section": "Visualization trick",
    "text": "Visualization trick\nOne thing I learnt today is how to quickly draw a matrix into a picture. I hereby recommend you look into the ‚ÄúMBCbook‚Äù R package, for its function ‚Äúimshow()‚Äù. Which incidentally I found while looking for alternatives to the Python function‚Ä¶ imshow! (So yeah, it was a fast search that one‚Ä¶)"
  },
  {
    "objectID": "posts/2023-11-08_WhileOnTheTrain/index.html#conclusions",
    "href": "posts/2023-11-08_WhileOnTheTrain/index.html#conclusions",
    "title": "While on the Train: Cellular Automata",
    "section": "Conclusions",
    "text": "Conclusions\nI hope you enjoyed it (I could definitely make it faster, and more or less dense a forest, and change the neighbours identification, and what not‚Ä¶ I‚Äôve tested this a few times with a few parameters).\nAt least to me, this was for no-good-reason quite‚Ä¶ Satisfying üôÇ\nAnd I‚Äôm not sharing the code (not yet anyway) just because this was a first, horrible pasted-together step by step implementation, full of slow and nested ‚Äúfor loops‚Äù, to-be-improved matrix indexing, not enough functions‚Ä¶ And well, just not quite ‚Äúpresentable‚Äù. Find the code linked below. But it does work just fine though üôÇ\nCode on my GitHub account"
  },
  {
    "objectID": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html",
    "href": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html",
    "title": "Random thoughts on ARCAGI",
    "section": "",
    "text": "Alright let‚Äôs see.\nI‚Äôve been reading up a bit more on the ARC AGI1 problem. It‚Äôs definitely interesting.\nPutting different ideas together, after reading that ‚ÄúDomain Specific Language‚Äù was not a novel idea (well, duh! I rarely come up with stuff nobody else has thought of, of course‚Ä¶), although I called it differently, a sort of ‚Äúdatabase of priors‚Äù to be mixed, in my mind, but‚Ä¶ nevermind.\nSo one thing that this DSL approach reminded me is that of S-Expressions, and I had seen that as part of a variation of LCS alphabets. (see references)\nRight now, RLCS only accepts binary inputs. OK, fair. What if we could encode somehow composition of functions, each one representing one prior.\nAfter all: could it be ‚Äúas simple as‚Äù encoding into binary combinations the compositions of functions?\nI know I know: ‚ÄúIf you have a hammer, everything looks like a nail‚Äù. LCS does not need to be a good approach. But‚Ä¶ What if it was?"
  },
  {
    "objectID": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#this-problem-bugs-me-in-a-good-way",
    "href": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#this-problem-bugs-me-in-a-good-way",
    "title": "Random thoughts on ARCAGI",
    "section": "",
    "text": "Alright let‚Äôs see.\nI‚Äôve been reading up a bit more on the ARC AGI1 problem. It‚Äôs definitely interesting.\nPutting different ideas together, after reading that ‚ÄúDomain Specific Language‚Äù was not a novel idea (well, duh! I rarely come up with stuff nobody else has thought of, of course‚Ä¶), although I called it differently, a sort of ‚Äúdatabase of priors‚Äù to be mixed, in my mind, but‚Ä¶ nevermind.\nSo one thing that this DSL approach reminded me is that of S-Expressions, and I had seen that as part of a variation of LCS alphabets. (see references)\nRight now, RLCS only accepts binary inputs. OK, fair. What if we could encode somehow composition of functions, each one representing one prior.\nAfter all: could it be ‚Äúas simple as‚Äù encoding into binary combinations the compositions of functions?\nI know I know: ‚ÄúIf you have a hammer, everything looks like a nail‚Äù. LCS does not need to be a good approach. But‚Ä¶ What if it was?"
  },
  {
    "objectID": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#the-idea-as-is-right-now",
    "href": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#the-idea-as-is-right-now",
    "title": "Random thoughts on ARCAGI",
    "section": "The idea, as-is right now‚Ä¶",
    "text": "The idea, as-is right now‚Ä¶\nLet‚Äôs see.\nThe DSL approach is really a way of talking about S-Expressions, as I understand them, from LISP.\nThe S-Expression mixed with LCS, I didn‚Äôt invent either, that comes from a video by Dr.¬†Will Browne (see references).\nBefore I put these two things together, I basically had an idea aligned with this approach:\nhttps://www.kaggle.com/code/michaelhodel/program-synthesis-starter-notebook\nBut that‚Äôs only part of it now. See, even if I were to code a huge list of priors like that, how would a program know how to combine these?\nThe basic DSL approach would be a brute-force attack. That wouldn‚Äôt scale and seems too‚Ä¶ Simplistic. Basically because each ‚Äúprior function‚Äù added to the list would mean checking all possible combinations again, but with one more dimension. Actually, it‚Äôs bad, because that‚Äôs exponential‚Ä¶ Heck! What if priors application order is also relevant? And composition depth also definitely is relevant.\nSo I need to be able to filter (cleverly) them, somehow.\nNote: I am currently also thinking about grouping: say bits dedicated for grid format, bits dedicated for color-related stuff, bits dedicated for shapes detection‚Ä¶\nAnd then bits for combinations of the above, thinking here about ‚Äúepistasis‚Äù. That, and what Dr.¬†Browne calls ‚ÄúCode Fragments‚Äù.\nI won‚Äôt go into details here, as I still am not even clear on these anyway. Maybe some other time. But there is to me a clear relation between these ideas and the ARC AGI 1 challenge.\n\n\n\nDr.¬†Browne on Code Fragments and LCS\n\n\nI‚Äôm actually thinking of ‚Äúcomposing LCSs‚Äù, really.\nI‚Äôve tried something like that with Supervised Learning:\nI had long search space binary strings. What I did was (and that‚Äôs not a valid theoretical approach!) split the input strings in 2, or 3, or 4 substrings‚Ä¶ And treat each substring as an input to a simpler LCS.\nIF I was very lucky, a substring would suffice to identify uniquely a solution, and then combinations of results of sub-LCSs would point to that fact.\nThe example was simple: ‚ÄúNot Bit 4‚Äù is a rather simple rule to learn, for 5 bits strings. Brute-force for instance is not out of the question (32 bit combinations).\nBut for 10 bits strings (1024 bits combinations), you have a larger search space to test before you come up with a result. Now, again, not correct, but the idea was:\n\nWhat if I split the input strings? 5-first bits, and 5-last bits.\nThen train two LCSs, one on each substrings sets (with their class of course).\nThen combine the results.\n\nYou would see that 5-first bits was a sufficient sub-problem, and then result in a second layer LCS saying:\n\n‚ÄúIf First Layer LCS says 1, final recommendation is 1‚Äù\n‚ÄúIf First Layer LCS says 0, final recommendation is 0‚Äù\n‚ÄúDisregard completely second Layer LCS‚Äù\n\nTraining each sub-LCS was way faster, of course, as the search space is much reduced.\nThat‚Äôs just an idea, but I think it‚Äôs hinting at what could be a valid approach, if I can reduce ARCAGI1 problems to sub-groups‚Ä¶\nAnd conceptually, I would have implemented right there a sort of compounded LCS, multi-layer LCS of sorts, and that would in fact be similar to breaking large problems in sub-problems and then combining them, and somehow that‚Äôs‚Ä¶ What I currently understand of the S-Expression approach, ‚ÄúCode Fragments‚Äù, or whatever you want to call them.\nThen if I encoded each ‚Äúsub-LCS‚Äù as one unique problem solution‚Ä¶ Could I then test multiple-level such combinations, choosing each encoded unique sub-problem (that can be a binary string, right there‚Ä¶)?\nOh! One more thing! So to choose a combination of priors for any one given example, I should of course consider some error distance. That‚Äôs kind of obvious, sure, but still!\nThat‚Äôs where I‚Äôm at right now."
  },
  {
    "objectID": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#conclusions",
    "href": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#conclusions",
    "title": "Random thoughts on ARCAGI",
    "section": "Conclusions",
    "text": "Conclusions\nWell, for now: A database of ‚Äúpriors‚Äù, and a sort of variation on ‚ÄúCode Fragments‚Äù. And then apply LCS to training examples, to come up with ‚Äúcomposed code-fragments‚Äù that are more useful.\nI feel encoding of input will be key. I don‚Äôt see why I couldn‚Äôt use the ternary alphabet still, if I somehow encode combinations and rules separately. Each ‚Äúcode fragment‚Äù (in the terms of the referenced videos) I would encode with a dedicated number. Then a number is just that, a number, so it can still be easily encoded as binary code. IDK.\nYou could then put fragments in order and try to apply them. First (or last?) bits of the input would be application orders.\nAfter training some combinations would stand out? That would help prioritize testing combinations, effectively somewhat pruning the search space which could be huge‚Ä¶\nBut clearly, I don‚Äôt know. It‚Äôs just very interesting."
  },
  {
    "objectID": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#references",
    "href": "posts/2025-10-19_LookingAtARCAGIsomemore/index.html#references",
    "title": "Random thoughts on ARCAGI",
    "section": "References",
    "text": "References\nI will have to keep digging. Here a few options to review‚Ä¶\nSome of Dr.¬†Will Browne‚Äôs videos are very helpful for me to think about approaches‚Ä¶\nhttps://www.youtube.com/watch?v=fN1Fkbx3TnU &lt;- This video is packed with interesting ideas‚Ä¶\nhttps://www.youtube.com/watch?v=bsbJIslrk84"
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html",
    "href": "posts/2021-12-04_R4Math/index.html",
    "title": "More R for math",
    "section": "",
    "text": "A real quick post about a couple of math (matrix) details, and a trick with rational numbers with R."
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#intro",
    "href": "posts/2021-12-04_R4Math/index.html#intro",
    "title": "More R for math",
    "section": "",
    "text": "A real quick post about a couple of math (matrix) details, and a trick with rational numbers with R."
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#inverse-of-a-matrix",
    "href": "posts/2021-12-04_R4Math/index.html#inverse-of-a-matrix",
    "title": "More R for math",
    "section": "Inverse of a Matrix",
    "text": "Inverse of a Matrix\nMathematically, getting to the inverse of an ‚Äúnxn‚Äù matrix A means finding an nxn matrix B such that A ‚Ä¢ B = I, where I is the nxn Identity matrix.\nEasier said than done, when doing that by hand (look around for example for the Gauss-Jordan method for a 3√ó3 matrix, and you‚Äôll see what I mean), but maybe we don‚Äôt need to make it that complex, right? In R, getting to the inverse of a matrix is not complicated, you just need to use the solve() function.\nOf course, you need a square matrix (otherwise multiplying it by a matrix with the same dimensions will not work).\nA &lt;- matrix(1:6, nrow=3, byrow = T)\nA\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\ndet(A)\nError in determinant.matrix(x, logarithm = TRUE, ...) : \n  'x' must be a square matrix\nThen the matrix must be non-singular. If a matrix is singular, it has a determinant 0, but it also means that some combinations of its rows or columns can be used to get a 0 vector, and that means that such rows or columns do not each bring new information to the system.\nIn the next example, the columns are rather clearly linearly dependent vectors (column 1 + column 3 ‚Äì 2*column 2 = 0), and so the determinant will be zero. Which is equivalent to say that there is no inverse matrix for that case.¬†\nA &lt;- matrix(1:9, nrow=3, byrow=TRUE)\nA\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\ndet(A)\n[1] 6.661338e-16\nround(det(A), 10)\n[1] 0\nsolve(A)\nError in solve.default(A) : \n  system is computationally singular: reciprocal condition number = 2.59052e-18"
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#the-trick-human-readable-fractional-values",
    "href": "posts/2021-12-04_R4Math/index.html#the-trick-human-readable-fractional-values",
    "title": "More R for math",
    "section": "The trick: Human-readable fractional values",
    "text": "The trick: Human-readable fractional values\nNow if the matrix is non-singular and square, one can use the ‚Äúsolve()‚Äù function in R:\nA &lt;- matrix(c(1,2,3,1,1,1,8,3,4), nrow=3, byrow=T)\ndet(A)\n[1] -6\nsolve(A)\n           [,1]       [,2]       [,3]\n[1,] -0.1666667 -0.1666667  0.1666667\n[2,] -0.6666667  3.3333333 -0.3333333\n[3,]  0.8333333 -2.1666667  0.1666667\nThe only issue with it is, it shows it‚Äôs done by a computer. And for a human, well, it isn‚Äôt all as practical/readable as one might wish. Sure, you probably can recognise those 0.66666667 as 2/3, or 0.333333 as 1/3, but it gets trickier for 0.8333 or -2.16667, doesn‚Äôt it?\nAs my needs about what I ask from R are evolving because of one of the University courses I‚Äôm taking, I found the ‚Äúfractions()‚Äù function that came in very handy:\nMASS::fractions(solve(A))\n     [,1]  [,2]  [,3] \n[1,]  -1/6  -1/6   1/6\n[2,]  -2/3  10/3  -1/3\n[3,]   5/6 -13/6   1/6\nAnd that‚Äôs it!\nNote: You might recognise that the determinant (in the case above it was -6) might play a role in the denominator of these fractions there, and then maybe you will grasp a hint about why it‚Äôs sooo important that the determinant of the matrix is non-zero to be able to calculate the inverse of a matrix in the first place üôÇ If you don‚Äôt see it clearly in the above, maybe this next example will make it more visual:\nA &lt;- matrix(c(1,2,2,0,5,6,7,2,9), nrow=3, byrow=T)\ndet(A)\n[1] 47\nMASS::fractions(solve(A))\n     [,1]   [,2]   [,3]  \n[1,]  33/47 -14/47   2/47\n[2,]  42/47  -5/47  -6/47\n[3,] -35/47  12/47   5/47"
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#the-easier-case",
    "href": "posts/2021-12-04_R4Math/index.html#the-easier-case",
    "title": "More R for math",
    "section": "The easier case",
    "text": "The easier case\nFor a diagonal matrix, we know it‚Äôs going to be non-singular upfront (you can‚Äôt obtain one row from combinations of the others, and the same goes with the columns). But what‚Äôs more interesting regarding the inverse is that‚Äôs it‚Äôs rather easy to find:\nA &lt;- matrix(c(1,0,0,0,4,0,0,0,10),nrow=3, byrow=T)\nA\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    4    0\n[3,]    0    0   10\nsolve(A)\n     [,1] [,2] [,3]\n[1,]    1 0.00  0.0\n[2,]    0 0.25  0.0\n[3,]    0 0.00  0.1\n1/diag(A)\n[1] 1.00 0.25 0.10\nThat particular case was important because initially, a few weeks back, I‚Äôm ashamed to admit (and I probably shouldn‚Äôt!) that I didn‚Äôt remember how to calculate the inverse of a Matrix, and I almost made the mistake to extrapolate the rule of ‚Äú1/(matrix element)‚Äù, because the first exercise I was faced with had a diagonal matrix‚Ä¶ Thank goodness I questioned myself there (something was too easy), I ran more checks and studied some more, which saved me moving forward‚Ä¶\nAnd that‚Äôs why to me it‚Äôs important to understand why we do the things we do in math, instead of knowing only the ‚Äúhow‚Äù."
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#what-about-irrational-numbers",
    "href": "posts/2021-12-04_R4Math/index.html#what-about-irrational-numbers",
    "title": "More R for math",
    "section": "What about irrational numbers?",
    "text": "What about irrational numbers?\nGlad you asked. By definition, irrational numbers cannot be expressed with a division of two integers. So what would the fractions() function from the MASS package do with, say, Pi or Euler‚Äôs number?\nWell, it will get you to an approximation, with potentially more precision if you ask for it (but then again, there is no real point to it, I‚Äôd say‚Ä¶ It‚Äôs just fun to see it üôÇ )\npi\n[1] 3.141593\nMASS::fractions(pi)\n[1] 4272943/1360120\nMASS::fractions(pi, cycles=20)\n[1] 42581509225984/13554115355257\nMASS::fractions(pi, cycles=30)\n[1] 96912279446380464/30848136640389084\nexp(1)\n[1] 2.718282\nMASS::fractions(exp(1))\n[1] 2721/1001\nMASS::fractions(exp(1), cycles=40)\n[1] 98066981910962752/36076826502774920"
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#conclusions",
    "href": "posts/2021-12-04_R4Math/index.html#conclusions",
    "title": "More R for math",
    "section": "Conclusions",
    "text": "Conclusions\nWell, I made a long post out of a very simple thing: There is an R package, MASS, with a function called fractions()¬† that will find a nice fraction for rational values for us."
  },
  {
    "objectID": "posts/2021-12-04_R4Math/index.html#references",
    "href": "posts/2021-12-04_R4Math/index.html#references",
    "title": "More R for math",
    "section": "References",
    "text": "References\nInvertible matrix definitions\nMASS::fractions() documentation\nExplanations of why one could want to use the calculation of an Inverse"
  },
  {
    "objectID": "posts/2025-10-12_PreparingForPresentation/index.html",
    "href": "posts/2025-10-12_PreparingForPresentation/index.html",
    "title": "Preparing for November Presentation",
    "section": "",
    "text": "A short post for situation awareness, mostly.\nIn short, I need to keep going with preparing the best possible presentation about the RLCS for November.\nSo really, I‚Äôm currently documenting the code, adding a demo dataset, shortening (a LOT) the RLCS presentation, testing, building, testing, building‚Ä¶\nAlthough not per-se fun, as it turns out, I kinda like taking care of such ‚Äúdetails‚Äù and seeing the package improve in quality, even when the functionality is in almost no-way different."
  },
  {
    "objectID": "posts/2025-10-12_PreparingForPresentation/index.html#documenting-is-important.",
    "href": "posts/2025-10-12_PreparingForPresentation/index.html#documenting-is-important.",
    "title": "Preparing for November Presentation",
    "section": "",
    "text": "A short post for situation awareness, mostly.\nIn short, I need to keep going with preparing the best possible presentation about the RLCS for November.\nSo really, I‚Äôm currently documenting the code, adding a demo dataset, shortening (a LOT) the RLCS presentation, testing, building, testing, building‚Ä¶\nAlthough not per-se fun, as it turns out, I kinda like taking care of such ‚Äúdetails‚Äù and seeing the package improve in quality, even when the functionality is in almost no-way different."
  },
  {
    "objectID": "posts/2025-10-12_PreparingForPresentation/index.html#so-documenting-is-good",
    "href": "posts/2025-10-12_PreparingForPresentation/index.html#so-documenting-is-good",
    "title": "Preparing for November Presentation",
    "section": "So documenting is‚Ä¶ Good?",
    "text": "So documenting is‚Ä¶ Good?\nWell, let‚Äôs see. Not ‚Äúfun‚Äù, for sure.\nShortening a 1h30m presentation to do a 15‚Äô stint is HARD. Like, very hard.\nBut, on the other hand: I have created a library. I‚Äôm proud of it, but only because I believe it can be valuable!\nAnd because of that, I perceive value in getting people to understand enough about it that they also perceive the value.\nAnd that means: Communication. And that, in turn, means, why not, documentation. Generating examples. Adding tests to ensure the user has a good experience.\nThis surprises me as much as anyone. It turns out, I now value documenting.\nWho knew?!"
  },
  {
    "objectID": "posts/2025-10-12_PreparingForPresentation/index.html#conclusion",
    "href": "posts/2025-10-12_PreparingForPresentation/index.html#conclusion",
    "title": "Preparing for November Presentation",
    "section": "Conclusion",
    "text": "Conclusion\nI can‚Äôt say that documenting feels as good as producing.\nBut it is good."
  },
  {
    "objectID": "posts/2021-08-22_LearningEveryDay/index.html",
    "href": "posts/2021-08-22_LearningEveryDay/index.html",
    "title": "Every day I keep learning",
    "section": "",
    "text": "I missed writing an entry last week. Not that I haven‚Äôt learned anything I could discuss, but rather because I have been learning and coding a bit too much lately‚Ä¶"
  },
  {
    "objectID": "posts/2021-08-22_LearningEveryDay/index.html#intro",
    "href": "posts/2021-08-22_LearningEveryDay/index.html#intro",
    "title": "Every day I keep learning",
    "section": "",
    "text": "I missed writing an entry last week. Not that I haven‚Äôt learned anything I could discuss, but rather because I have been learning and coding a bit too much lately‚Ä¶"
  },
  {
    "objectID": "posts/2021-08-22_LearningEveryDay/index.html#learning-more-about-postgres",
    "href": "posts/2021-08-22_LearningEveryDay/index.html#learning-more-about-postgres",
    "title": "Every day I keep learning",
    "section": "Learning more about Postgres",
    "text": "Learning more about Postgres\nAmong many other things (that will make for potentially quite a few other entries in the Blog), I learned one detail about one trick (really going down the rabbit holes sometimes‚Ä¶) in ‚ÄúPostgres‚Äù:\n‚ÄúUpsert‚Äù (‚Äúinsert ‚Ä¶ on conflict‚Ä¶‚Äù) is a very neat trick. It makes my R code (a lot) cleaner & ensures atomic operations at the Database level, so I love it. üëç\nWhat I recently learned about that wasn‚Äôt a worry in the past (it keeps happening!) is the impact on serial IDs üßê (and it makes sense why Postgres works that way, I‚Äôm not complaining, I just wasn‚Äôt aware until very recently):\nSay I use it on ~210.000 (bear with me) rows a day, of which most of the time say ~209.900 are repeating entries (so they really should have been ‚Äúupdates‚Äù), on a table using a Serial ID. Those are very realistic numbers. And it‚Äôs not Big Data (although maybe it‚Äôs starting to be somewhere above ‚ÄúSmall Data‚Äù‚Ä¶)\nIt turns out I‚Äôll ‚Äúburn‚Äù my serial identifiers in about ~10.000 days (a round number to justify why I used 210k as the example ü§™), as each Upsert is increasing the IDs to the next value ‚Äì even when nothing at all needs change. So I‚Äôm ‚Äúusing‚Äù 210k IDs instead of 100 a day! Not too efficient (but then again: effective, as the code around the inserts and updates is shorter and cleaner‚Ä¶).\nMaybe that‚Äôs OK? (I really don‚Äôt know where I‚Äôll be in ~27 years üòÖ)\nWhat if someone launches my script 10 times a day? Then everything will probably break (and I haven‚Äôt even thought how) in 2.7 years? I really don‚Äôt know yet if anyone but me would ever be using the same script on the same database‚Ä¶\nWhat if then 10 people use it 10 times a day (that would mean my script went way beyond any expected success, mind you)‚Ä¶ That‚Äôs 100 runs/day‚Ä¶?ü§ï\nShould I use ‚ÄúBigserial‚Äù ‚Äì in practice avoiding the issue (technically pushing it to a much much later future üòÇ)?\nOr should I take care of trying to avoid ‚ÄúUpserts‚Äù where I can ‚Äì thereby making my code a bit more complex (e.g.¬†making transactions my problem) ‚Äì my choice for now.\nWhat‚Äôs the impact of a very sparse & big index? ü§î I guess I need to keep testing and learning‚Ä¶\n(Note: please remember: I‚Äôm not actually a developer per-se, I just happen to use code sometimes, sorry if this is too obvious ;))"
  },
  {
    "objectID": "posts/2021-08-22_LearningEveryDay/index.html#other-details",
    "href": "posts/2021-08-22_LearningEveryDay/index.html#other-details",
    "title": "Every day I keep learning",
    "section": "Other details",
    "text": "Other details\nAs you might expect, using a database is a bit different from using CSV files. It‚Äôs a bit harder to set up, but supposedly faster afterwards‚Ä¶\nBut not if you‚Äôre not careful‚Ä¶\nAt one point I followed a logic of my code and did one update per entry that made sense.\nTrying to avoid the Upsert thing, I would check for duplicates.\nI don‚Äôt have my laptop handy to reproduce the code here, but let‚Äôs just say (from memory) it required some mix of rbind(), group_by_all(),¬†filter(n()&gt;1) and ungroup()‚Ä¶ And then some more filter(!(id %in% duplicated_id))‚Ä¶\n\nUpsert would really make it easier! üòÖ\nAnyhow, to the point:\nWorking with all of a table in memory (one big Select) on many many rows, might very well be faster than even a few select for a few rows‚Ä¶\nIn one case it turned out my assumption about ‚Äúworking with few rows and few selects‚Äù vs ‚Äúworking with lots of rows but only one select‚Äù¬†was wrong by a factor of a hundred!\nJust saying: Some assumptions are wrong and testing stuff is a good idea."
  },
  {
    "objectID": "posts/2021-08-22_LearningEveryDay/index.html#conclusions",
    "href": "posts/2021-08-22_LearningEveryDay/index.html#conclusions",
    "title": "Every day I keep learning",
    "section": "Conclusions",
    "text": "Conclusions\nHere is to the ‚Äúkeep learning‚Äù attitude. Continuous improvement is not always easy, but hopefully it pays off to challenge one self on a regular basis."
  },
  {
    "objectID": "posts/2025-07-25_RLCS_lessSequential/index.html",
    "href": "posts/2025-07-25_RLCS_lessSequential/index.html",
    "title": "RLCS: Less sequential?",
    "section": "",
    "text": "I‚Äôve let time pass lately as I looked into other topics (ODE and migrating content from the old Blog).\nBut I do not forget about my side-project of the RLCS package.\nRecently I mentioned I had it working ‚Äúas a package‚Äù, which to me was an important step (and a useful experiment too, as I have several small R projects that will become easier in the future if I make them into personal R packages‚Ä¶).\nAnd one key aspect of my package is, little to no dependencies. I insist on that.\nHowever‚Ä¶"
  },
  {
    "objectID": "posts/2025-07-25_RLCS_lessSequential/index.html#i-always-say-its-slow-because-its-inherently-sequential-but-what-if",
    "href": "posts/2025-07-25_RLCS_lessSequential/index.html#i-always-say-its-slow-because-its-inherently-sequential-but-what-if",
    "title": "RLCS: Less sequential?",
    "section": "",
    "text": "I‚Äôve let time pass lately as I looked into other topics (ODE and migrating content from the old Blog).\nBut I do not forget about my side-project of the RLCS package.\nRecently I mentioned I had it working ‚Äúas a package‚Äù, which to me was an important step (and a useful experiment too, as I have several small R projects that will become easier in the future if I make them into personal R packages‚Ä¶).\nAnd one key aspect of my package is, little to no dependencies. I insist on that.\nHowever‚Ä¶"
  },
  {
    "objectID": "posts/2025-07-25_RLCS_lessSequential/index.html#what-if-i-could-de-couple-part-of-it",
    "href": "posts/2025-07-25_RLCS_lessSequential/index.html#what-if-i-could-de-couple-part-of-it",
    "title": "RLCS: Less sequential?",
    "section": "What if I could de-couple part of it?",
    "text": "What if I could de-couple part of it?\nSo I have used already %dopar% to run some training in parallel, with some effort on the part of the user (me, in this case), and the corresponding dependencies.\nOne thing I have tested is separating the training data in subsets, and train separate LCS, then combining them, and then iterating.\nWell, what if instead, I separated the ruleset consolidation?\nThe LCS algorithm assumes you expose it to new environment instances, and every now and then you apply subsumption, compaction, deletion and whatever other ‚Äúconsolidation‚Äù processes to the ruleset.\nImportantly, it assumes you do it sequentially.\nWell, what if you didn‚Äôt?\nWhat if every now and then you copied the complete current ruleset, and in a separate subprocess, you had a go at consolidating it?\nThen, once consolidated, you can replace the ruleset used with the cleaner one and keep going. Said replacement would be next to instantaneous. So effectively you would run the consolidation in a separate process in parallel.\nAlthough matching is more costly, consolidation is expensive too. And even though it happens only ever so often, well."
  },
  {
    "objectID": "posts/2025-07-25_RLCS_lessSequential/index.html#caveats",
    "href": "posts/2025-07-25_RLCS_lessSequential/index.html#caveats",
    "title": "RLCS: Less sequential?",
    "section": "Caveats",
    "text": "Caveats\nSure, it‚Äôs not as easy as that. Parallelizing means, while you‚Äôre consolidating a ruleset, copy of the original, in a separate process, the original gets updated!\nSo you potentially could loose track of changes.\nHowever‚Ä¶ Well, you can replace the new with the old and add only the rules that weren‚Äôt part of the original while consolidating. That is, after consolidation, you would be adding back the new rules that have appeared (typically through mutations and rule-discovery).\nBut these will be taken care of in the next consolidation, so you‚Äôre only delaying the cleaning of the new ruleset (if cleaning is needed).\nSo this is not perfect, indeed. But it feels like it might be helpful."
  },
  {
    "objectID": "posts/2025-07-25_RLCS_lessSequential/index.html#conclusions",
    "href": "posts/2025-07-25_RLCS_lessSequential/index.html#conclusions",
    "title": "RLCS: Less sequential?",
    "section": "Conclusions",
    "text": "Conclusions\nI‚Äôm not 100% convinced here. But it seems, for slower cases, say big datasets or long binary strings in the environment (i.e.¬†bigger search space) this decoupling could help, if consolidation per-se is expensive.\nIt might not always make sense, and I‚Äôm actually adding a dependency on parallelizing libraries‚Ä¶\nStill, it sounds like an interesting idea."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html",
    "title": "Getting into Apache Spark",
    "section": "",
    "text": "Most RDBMS‚Äôs are just fine. Hadoop does work for Big Data (I used it some years back), although HQL proved a bit slow‚Ä¶ And I haven‚Äôt ‚Äúneeded‚Äù anything to make things faster for now‚Ä¶\nBut for whatever reason, one can‚Äôt be ‚Äúinto data science‚Äù (or data analysis, or whatever you name it‚Ä¶), without knowing (a bit) about Apache Spark, nowadays. (Spark is not a DBMS, I know‚Ä¶)\nAnd just in case I end up needing interacting with it, I should get acquainted a bit more (I only understand some rudimentary concepts so far).\nSo I decided to try and set up a Spark Cluster (‚Äústandalone‚Äù for now), in Docker (of course), to then try to connect to it with R (of course).\nHere is the first story about that."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#intro",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#intro",
    "title": "Getting into Apache Spark",
    "section": "",
    "text": "Most RDBMS‚Äôs are just fine. Hadoop does work for Big Data (I used it some years back), although HQL proved a bit slow‚Ä¶ And I haven‚Äôt ‚Äúneeded‚Äù anything to make things faster for now‚Ä¶\nBut for whatever reason, one can‚Äôt be ‚Äúinto data science‚Äù (or data analysis, or whatever you name it‚Ä¶), without knowing (a bit) about Apache Spark, nowadays. (Spark is not a DBMS, I know‚Ä¶)\nAnd just in case I end up needing interacting with it, I should get acquainted a bit more (I only understand some rudimentary concepts so far).\nSo I decided to try and set up a Spark Cluster (‚Äústandalone‚Äù for now), in Docker (of course), to then try to connect to it with R (of course).\nHere is the first story about that."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#choosing-the-right-setup",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#choosing-the-right-setup",
    "title": "Getting into Apache Spark",
    "section": "Choosing the right setup",
    "text": "Choosing the right setup\nSo to get a Spark Cluster ready to work, one needs at least a Master Node and a Worker. That‚Äôs at least 2 containers right there, which means we probably want to go the way of the Docker Compose (instead of manually doing it all separately).\nIn looking for a simple alternative (I am more interested in the interacting with Spark than in the setting it up, for now), I came across the Bitnami installation, here.\nIs it the best one for me right now? As it turns out we will (soon) see that ‚Äúnot really‚Äù, but I hope it will still be good enough though.\nBefore we get it running, one thing that will be needed though is for me to modify the docker-compose.yml file for the new containers to use the same network as my RStudio Server container (otherwise, I won‚Äôt be able to have all the pieces seeing each other‚Ä¶). To achieve that, as I already have a Bridge Network in my Docker setup, I add that ‚Äúexternal‚Äù network to the docker-compose YAML file like so:\n\n...\nnetworks:\n    default:\n        name: r_analysis_br0\n        external: true\nAnd then I‚Äôd hope I can get those up and running. For the fun of it, let‚Äôs try to get the Spark Standalone cluster to run one master and two workers:\n$ docker-compose up --scale spark-worker=2\n\nIt seems like we got it!\nNow about the ‚Äúissue‚Äù. In previous tests this morning, using the official Apache images, I got a container that was fully optimized to run on the Macbook with M1 (i.e.¬†ARM arch).\n\nUnfortunately, the Bitnami copy apparently only has been taken for AMD64, which is not optimal:\n\nWell, so we‚Äôll have a ‚Äúnon-optimal‚Äù setup for now. I shall look into improving that in the future, but if this is working, I‚Äôm still quite happy with it."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#connecting-to-the-cluster-from-r",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#connecting-to-the-cluster-from-r",
    "title": "Getting into Apache Spark",
    "section": "Connecting to the cluster from R",
    "text": "Connecting to the cluster from R\nAlright so one more step: We got our Spark Cluster running, but now we need to get our RStudio to connect to that Spark Master node.\nTo get started, we‚Äôll need to install the ‚Äúsparklyr‚Äù package.\n\nNext, let‚Äôs get our RStudio container to participate of the Spark cluster.\nFor whatever reason, connecting from my R session to download the software tar file is not working, but I can wget my way around it in the container‚Äôs console:\nwget https://dlcdn.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop2.tgz\n\nThen from the R session:\nlibrary(sparklyr)\nspark_install_tar(\"/home/rstudio/spark-3.3.0-bin-hadoop2.tgz\")\nThat seems to work (it only takes a second).\nFinally, we should be ready to connect to the Spark Cluster. Taking the URL from the Master Node page (on port 8080):\nsc &lt;- spark_connect(spark_home=spark_install_find(version=\"3.3.0\")$sparkVersionDir, master = \"spark://spark:7077\")\nAnd yes, apparently, we‚Äôre here! At least, that‚Äôs what RStudio is saying:"
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#first-spark-command-test-from-r",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#first-spark-command-test-from-r",
    "title": "Getting into Apache Spark",
    "section": "First Spark command test from R",
    "text": "First Spark command test from R\nFinally we‚Äôre here. Let‚Äôs try¬† to run something in there.\nNote: Restarted the cluster with only one worker, as the setup with two workers wouldn‚Äôt work as expected, killing my R application after only a few seconds. I‚Äôm sure I‚Äôve done something wrong, but I just don‚Äôt really know what‚Ä¶ No matter, with only one node, that works fine. To get there, I just restarted the cluster:\n$ docker-compose down\n$ docker-compose up\nAs by default, it starts with only one worker üôÇ\nOK, so let‚Äôs get started. After restarting the whole setup (including the RStudio container), things finally work as expected:\n&gt; library(sparklyr)\n&gt; sc &lt;- spark_connect(spark_home=spark_install_find(version=\"3.3.0\")$sparkVersionDir, master = \"spark://spark:7077\")\n&gt; sc$master\n[1] \"spark://spark:7077\"\n&gt; temp_df &lt;- data.frame(a=1:25, b=letters[1:25])\n&gt; test &lt;- copy_to(sc, temp_df, \"tempdfspark\")\nAnd there we are: We are writing to a Spark cluster."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#conclusions",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#conclusions",
    "title": "Getting into Apache Spark",
    "section": "Conclusions",
    "text": "Conclusions\nToday we managed to:\n\nInstall a Spark Standalone cluster in Docker containers, using and modifying a Docker Compose YAML file\nInstall the required components into our RStudio Server Container, so that we could connect to that new cluster\nLoad data into the cluster from an R session.\n\nAs a side note, one should disconnect from the Cluster after using it. Doing that is quite easy using:\nspark_disconnect(sc)\nBut then if I reconnect, I won‚Äôt see the data I uploaded just before. From what I‚Äôm gathering that‚Äôs normal because each connection is treated as an independent application‚Ä¶\nI shall look into using some persistent data thing to put behind the Spark processing middleware, to use data across different sessions, and see what else can be done with this Spark cluster‚Ä¶ At some later point."
  },
  {
    "objectID": "posts/2022-08-20_GettingIntoApacheSpark/index.html#references",
    "href": "posts/2022-08-20_GettingIntoApacheSpark/index.html#references",
    "title": "Getting into Apache Spark",
    "section": "References",
    "text": "References\nFastest alternative I could finde to setup Spark Cluster in Docker\nWorking with sparklyr\nClarified needing to point to the spark local install home to connect"
  },
  {
    "objectID": "posts/2025-05-02_Slight_code_rewrites/index.html",
    "href": "posts/2025-05-02_Slight_code_rewrites/index.html",
    "title": "RLCS: small code rewrites",
    "section": "",
    "text": "As announced, I‚Äôm doing some code rewriting, just because‚Ä¶"
  },
  {
    "objectID": "posts/2025-05-02_Slight_code_rewrites/index.html#small-updates-of-the-code",
    "href": "posts/2025-05-02_Slight_code_rewrites/index.html#small-updates-of-the-code",
    "title": "RLCS: small code rewrites",
    "section": "",
    "text": "As announced, I‚Äôm doing some code rewriting, just because‚Ä¶"
  },
  {
    "objectID": "posts/2025-05-02_Slight_code_rewrites/index.html#function-factory",
    "href": "posts/2025-05-02_Slight_code_rewrites/index.html#function-factory",
    "title": "RLCS: small code rewrites",
    "section": "Function Factory",
    "text": "Function Factory\nSo I had 2 or three of these:\ninc_match_count &lt;- function(M_pop) { ## All versions\n  lapply(M_pop, \\(x) {\n    x$match_count &lt;- x$match_count + 1\n    x\n  })\n}\n\ninc_correct_count &lt;- function(C_pop) { ## SL Specific\n  lapply(C_pop, \\(x) {\n    x$correct_count &lt;- x$correct_count + 1\n    x\n  })\n}\n\ninc_action_count &lt;- function(A_pop) { ## RL Specific\n  lapply(A_pop, \\(x) {\n    x$action_count &lt;- x$action_count + 1\n    x\n  })\n}\nNow it looks like so:\n## Function factory to increase parameter counts\ninc_param_count &lt;- function(param) {\n  param &lt;- as.name(param)\n  function(pop) {\n    lapply(pop, \\(x) {\n      x[[param]] &lt;- x[[param]] + 1\n      x\n    })\n  }\n}\n\ninc_match_count &lt;- inc_param_count(\"match_count\")\ninc_correct_count &lt;- inc_param_count(\"correct_count\")\ninc_action_count &lt;- inc_param_count(\"action_count\")\nAs I do not intend to expose these functions in the future ‚Äúpackaged‚Äù version, well, this is pretty safe."
  },
  {
    "objectID": "posts/2025-05-02_Slight_code_rewrites/index.html#object-for-hyperparameters",
    "href": "posts/2025-05-02_Slight_code_rewrites/index.html#object-for-hyperparameters",
    "title": "RLCS: small code rewrites",
    "section": "Object for Hyperparameters",
    "text": "Object for Hyperparameters\nAnd as also announced, I cleaned up a bit the code to ‚Äúcall training‚Äù. Now using an object for the hyperparameters of the algorithm, which has its own defaults, makes things a bit cleaner.\nsource(\"run_params/datamining_examples_recommended_hyperparameters_v001.R\")\n\nbasic_hyperparameters &lt;- RLCS_hyperparameters(\n  wildcard_prob = wildcard_prob,\n  rd_trigger = rd_trigger,\n  mutation_probability = mutation_probability,\n  parents_selection_mode = parents_selection_mode,\n  tournament_pressure = tournament_pressure,\n  n_epochs = n_epochs,\n  deletion_trigger = deletion_trigger,\n  deletion_threshold = deletion_threshold\n)\n\n## It makes it more readable here:\nexample_lcs &lt;- rlcs_train(train_environment, basic_hyperparameters)\nAnd given the number of parameters, it‚Äôs even more readable of course if you take the defaults:\ndefault_lcs_hyperparameters &lt;- RLCS_hyperparameters()\nexample_lcs &lt;- rlcs_train(train_environment, default_lcs_hyperparameters)\nUsing an object might also help with adding error controls‚Ä¶ Probably, that‚Äôs not implemented yet. Also, it‚Äôs a valid approach to clean code, as these variables are all part of the same concept of hyper-parameters for the algorithm, meaning they do belong together.\nAnd as a note here, ‚Äúdefaults‚Äù are seldom all good for an LCS, so you should probably overwrite some of the parameters depending on each problem you look at‚Ä¶\nFor comparison, I saved a version of an old call, and it‚Äôs just that it received too many parameters:\nlcs_res &lt;- rlcs_meta_train(train_environment,\n                           1, ## Warmup with just one epoch\n                           wildcard_prob,\n                           rd_trigger,\n                           parents_selection_mode,\n                           mutation_probability,\n                           tournament_pressure,\n                           deletion_trigger) ## Deletion won't be triggered"
  },
  {
    "objectID": "posts/2025-05-02_Slight_code_rewrites/index.html#resources",
    "href": "posts/2025-05-02_Slight_code_rewrites/index.html#resources",
    "title": "RLCS: small code rewrites",
    "section": "Resources",
    "text": "Resources\nClean Code, by R. C. Martin (‚ÄúUncle Bob‚Äù)\nAdvanced R, by H. Wickham"
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html",
    "href": "posts/2022-02-13_OnChaosTheory/index.html",
    "title": "Reading about Chaos Theory",
    "section": "",
    "text": "So I took a course in ‚ÄúNumerical Methods‚Äù, and (somehow) passed (I loved every bit of it, although it was HARD!).\nBut then of course, taking a course doesn‚Äôt make me ‚Äúproficient‚Äù at the subject matter. At best, it has exposed me to it and given me some confidence that I in fact can understand its concepts and solve problems ‚Äì even if I‚Äôm not too fast‚Ä¶ I simply feel there is SO MUCH MORE to it, and indeed I have several books on the subject to confirm it: I still have plenty to learn. Which is why I want to keep digging into it on my own.\nIf anything, I did get a good dose of Engineering-level Maths exposure, and I needed that (after a few years working in Cyber ‚Äì and I guess in most jobs ‚Äì one might tend to forget about matrices or how/why to differentiate equations, and many white-collar workers will simply spend their days using Outlook, PowerPoint and maybe Excel‚Ä¶).\nAnyhow, I was thrilled I took that course. And I am looking forward for more similar courses (the Master continues, for me spread over three years‚Ä¶). But while that comes, I was particularly interested in some ideas of non-linear equations, differential equations, and Chaos Theory. We did do an exercise about Lorenz‚Äôs typical differential equations, and I saw the strange-attractors and the ‚Äúbutterfly-like‚Äù drawing come to life from my own implementation (in Matlab) of these 3 simple equations, and I kind of fell in love with it.\nLet me be clear: I am not a mathematician, and I know I don‚Äôt fully grasp the ideas (far from it, in fact!). But I keep reading about it. While reading ‚ÄúChaos‚Äù by James Gleick (a reference on the subject), I came across the chapter about Ecology and the ‚ÄúLogistic Map‚Äù. And I thought: This is BEAUTIFUL.\n\nLast note for the Intro: The below has been done MANY TIMES, I am not inventing the wheel. I will just write my own R code to play around the simple equation and see its magic. I found references, particularly one that I will mention, that HEAVILY inspired this post (although I‚Äôm creating my own code ‚Äì and doing it in R), on top of the book. Please do have a look at both if you have any interest."
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#intro",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#intro",
    "title": "Reading about Chaos Theory",
    "section": "",
    "text": "So I took a course in ‚ÄúNumerical Methods‚Äù, and (somehow) passed (I loved every bit of it, although it was HARD!).\nBut then of course, taking a course doesn‚Äôt make me ‚Äúproficient‚Äù at the subject matter. At best, it has exposed me to it and given me some confidence that I in fact can understand its concepts and solve problems ‚Äì even if I‚Äôm not too fast‚Ä¶ I simply feel there is SO MUCH MORE to it, and indeed I have several books on the subject to confirm it: I still have plenty to learn. Which is why I want to keep digging into it on my own.\nIf anything, I did get a good dose of Engineering-level Maths exposure, and I needed that (after a few years working in Cyber ‚Äì and I guess in most jobs ‚Äì one might tend to forget about matrices or how/why to differentiate equations, and many white-collar workers will simply spend their days using Outlook, PowerPoint and maybe Excel‚Ä¶).\nAnyhow, I was thrilled I took that course. And I am looking forward for more similar courses (the Master continues, for me spread over three years‚Ä¶). But while that comes, I was particularly interested in some ideas of non-linear equations, differential equations, and Chaos Theory. We did do an exercise about Lorenz‚Äôs typical differential equations, and I saw the strange-attractors and the ‚Äúbutterfly-like‚Äù drawing come to life from my own implementation (in Matlab) of these 3 simple equations, and I kind of fell in love with it.\nLet me be clear: I am not a mathematician, and I know I don‚Äôt fully grasp the ideas (far from it, in fact!). But I keep reading about it. While reading ‚ÄúChaos‚Äù by James Gleick (a reference on the subject), I came across the chapter about Ecology and the ‚ÄúLogistic Map‚Äù. And I thought: This is BEAUTIFUL.\n\nLast note for the Intro: The below has been done MANY TIMES, I am not inventing the wheel. I will just write my own R code to play around the simple equation and see its magic. I found references, particularly one that I will mention, that HEAVILY inspired this post (although I‚Äôm creating my own code ‚Äì and doing it in R), on top of the book. Please do have a look at both if you have any interest."
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#the-logistic-map",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#the-logistic-map",
    "title": "Reading about Chaos Theory",
    "section": "The Logistic Map",
    "text": "The Logistic Map\nSo I‚Äôm not the right person to explain it in details, but the below is basically a mathematical expression of the evolution of a supposed population (say of fish), that considers a ‚Äúgrowth rate‚Äù r, an initial population x0, and then tries to estimate the population say one year later (x1), and then the year after that (x2), etc. The following short equation ‚Äì the ‚Äúlogistic map‚Äù ‚Äì is all you need to produce the graph from the introduction!\n\\[\nx_{k+1} = rx_k(1-x_k)\n\\]\nIf you consider a limited environment, the typical example being a pond with fish, you need to consider that maybe a predator-prey thing might happen: If a population grows too much, it will deplete its resources (food, space‚Ä¶), and then will have to reduce its population so as to adapt to the available resources. This is the ‚Äú* (1-x)‚Äù part of the equation: If there is too much fish, there won‚Äôt be enough food, space or oxygen. Hence the population would decrease. The decrease would leave more resources available, so that the fish population would be able to increase again (but in cycles, not continuously, as we can suppose the fish doesn‚Äôt reproduce and die instantaneously).\nFor the sake of the example, let‚Äôs assume an initial population x0 of 0.5. (Here x is set between 0 and 1, so that things work as expected)."
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#back-to-the-graph-of-the-introduction",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#back-to-the-graph-of-the-introduction",
    "title": "Reading about Chaos Theory",
    "section": "Back to the graph of the introduction",
    "text": "Back to the graph of the introduction\nSo what is the graph¬† in the intro all about?\nIt‚Äôs called a Bifurcation Diagram. It shows the evolution of the theoretical population over several generation (each dot is one value of the population at a given generation), as described above, but with different values for the growth ratio, after say 1000 generations.\nOn the x axis, different values of our growth ratio, and on the y axis, the number of individuals in the population. For a growth ratio below 1, as can be expected, the population tends to grow smaller and smaller and hence tends to decrease to 0. That‚Äôs the left part of the blue line, after 100 generations, the population is 0 in these cases.\n\nWhat‚Äôs interesting is that for growth ratios between 1 and 3.0, the population tends to stabilize to one specific value, which is why we see how the line grows somewhat but appears as a line: For each growth ratio in that range, the population stabilizes to one value. (What you can‚Äôt really see is that, in fact, there are many dots on each position of the line, one for each generation: For a given growth ratio, the population is stable at that particular value).\n\n¬†\nFrom 3.0 to roughly 3.4, it turns out that the population oscillates between two values! That is: Either they have enough resources (population grows to a specific value) or not (the population decreases to another specific value), and each generation, it cycles to one of those two values.\nAfter that it gets weirder:\nBefore a growth of¬† ~3.45, more possible values appear, then again at ~3.54. But then the number of individuals in each generation seems to become ‚Äúrandom‚Äù, and takes any value within some ranges, which is why we don‚Äôt see ‚Äúlines‚Äù anymore, but rather clouds of points.\nWith a growth ratio of 3.999, it would seem each generation has a different number of individual, ranging basically from 0 to 1 (all possible values!), seemingly random!"
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#interlude",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#interlude",
    "title": "Reading about Chaos Theory",
    "section": "Interlude",
    "text": "Interlude\nRandomness is important in cybersecurity. So having an equation THAT SIMPLE generating seemingly random numbers sounds appealing. It‚Äôs not much more complex than the ‚Äúlinear congruential generator‚Äú, in fact. Maybe we could compare those two?\nSo let‚Äôs implement a simplistic generator of random number:\n# Linear congruential generator\nrandom_numbers_vector &lt;- c()\nX0 &lt;- 12 # seed\na &lt;- 36\nc &lt;- 2\nm &lt;- 3583 # also, this one is prime\nmax_iterations &lt;- 200\nXi_plus_1 &lt;- function(x, current_iter = 0, max_iter = max_iterations) {\n  random_numbers_vector[current_iter+1] &lt;&lt;- x\n  if(current_iter == max_iter) return(x)\n  Xi_plus_1( (a * x + c) %% m, current_iter+1, max_iter)\n}\nrandom_numbers_vector &lt;- rep(0, max_iterations)\nXi_plus_1(X0)\n# scale to have values between 0 and 1\nrandom_numbers_vector &lt;- random_numbers_vector/max(random_numbers_vector)\nThen, for comparison, let‚Äôs generate our population values with a growth rate of 3.999, for the same amount of generations:\n# Recursive version of our Logistic Map function\nlogistic_numbers_vector &lt;- rep(0.5, max_iterations)\nmy_logistic_map3 &lt;- function(my_r, x, current_iter = 0, max_iter = max_iterations) {\n  logistic_numbers_vector[current_iter+1] &lt;&lt;- x\n  if(current_iter == max_iter) return(x)\n  my_logistic_map3(my_r, my_r * x * (1-x), current_iter+1, max_iter)\n}\nmy_logistic_map3(3.999, 0.5)\nThen let‚Äôs compare two consecutive values, from each set of generated numbers:\ncomparator_df &lt;- data.frame(generation = 0:200, \n   logistic_map_num = logistic_numbers_vector, \n   random_num = random_numbers_vector)\ncomparator_df %&gt;% pivot_longer(cols = contains(\"num\"),\n   names_to = \"generator\",\n   values_to = \"vals\") -&gt; for_plot\nggplot(for_plot[for_plot$generation %in% 30:50,], aes(x = generation, y = vals, colour = generator)) +\n  geom_line()\nAnd they seem rather ‚Äúrandom‚Äù at first sight, both of them, wouldn‚Äôt you say?\n\nMe at least, at first sight, I wouldn‚Äôt be able to tell which one is random, and which one isn‚Äôt (but is chaotic).\nBut HERE IS THE KEY: The logistic map is NOT at all random, but rather perfectly deterministic (well, to be fair, our pseudo-random number generator is deterministic too, but it behaves more as expected).\nSo how can we tell the difference? Here the ‚Äúhorse-shoe‚Äù figure makes its entrance. In the above graph, we could have thought that both generators gave back random numbers.\nBUT if we graph the values from two consecutive generations against each other (apparently that‚Äôs called a Phase Diagram), the magic appears:\ncomparator_df$logistic_map_num1 &lt;- c(comparator_df$logistic_map_num[2:nrow(comparator_df)],0)\ncomparator_df$random_num1 &lt;- c(comparator_df$random_num[2:nrow(comparator_df)],0)\n# Finally, the beauty!\nggplot(comparator_df) +\n  geom_point(aes(x = logistic_map_num, y = logistic_map_num1, colour = \"logistic_map\")) +\n  geom_point(aes(x = random_num, y = random_num1, colour = \"pseudo_random\")) + \n  scale_color_manual(values = c(\"logistic_map\" = \"blue\", \"pseudo_random\" = \"red\"))+\n  ggtitle(\"Comparing Logistic Map and Pseudo-Random Generator\")+\n  xlab(\"'Generation N'\") +\n  ylab(\"'Generation N+1'\")\n\nAnd, to me, that‚Äôs absolutely & simply wonderful. I can‚Äôt avoid but to feel impressed by the structure appearing there, from something that anyone would otherwise have reasonably assumed is complete ‚Äúchaos‚Äù‚Ä¶ (And it is üòÄ Structure in Chaos, I suppose that‚Äôs where this came from‚Ä¶ Although I haven‚Äôt read enough yet :D)"
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#the-code",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#the-code",
    "title": "Reading about Chaos Theory",
    "section": "The code",
    "text": "The code\nOf course, the above is done in R‚Ä¶ I leave the demo code on my GitHub account for reference.\nLet‚Äôs just say, it involves a few loops applying the very simple equation above, but with different growth rates, for a certain number of generations (at one point, we‚Äôre talking of about ~4 million points).\nIn the spirit of ‚ÄúNumerical Methods‚Äù, and taking advantage of our computer, we can repeat the calculations many times. In this case, the ‚Äúapply()‚Äù family of functions were not too helpful, as the equation is recurrent, so we need one result before we can calculate the next (we could probably trick it, but that‚Äôs not the point for today)."
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#conclusion",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#conclusion",
    "title": "Reading about Chaos Theory",
    "section": "Conclusion",
    "text": "Conclusion\nI just loved this example: One of the simplest of equations (it doesn‚Äôt look that scary, does it), and yet so much can happen from one small change in one parameter!\nTo me, this is a thing of wonder. But then, maybe I am a bit of a geek for math after all (while not at all good at it).\nThere is of course MUCH MORE to it all. But I really wanted to implement this exercise for myself and reproduce it."
  },
  {
    "objectID": "posts/2022-02-13_OnChaosTheory/index.html#references",
    "href": "posts/2022-02-13_OnChaosTheory/index.html#references",
    "title": "Reading about Chaos Theory",
    "section": "References",
    "text": "References\nSomeone did all the above (and better/more) in Python\nThe book (I don‚Äôt earn anything from the link, buy it where you like best)\nMy code on GitHub"
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "",
    "text": "I keep reading from a book (which I‚Äôll point to again later on I guess) that I mentioned a couple of times around here, this one.\nAnd I am underlining so many passages, sentences‚Ä¶ It‚Äôs a good sign for the book. And also a good sign for me. Because it means ideas‚Ä¶ Some of which, I can probably put to good use‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#on-ideas",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#on-ideas",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "",
    "text": "I keep reading from a book (which I‚Äôll point to again later on I guess) that I mentioned a couple of times around here, this one.\nAnd I am underlining so many passages, sentences‚Ä¶ It‚Äôs a good sign for the book. And also a good sign for me. Because it means ideas‚Ä¶ Some of which, I can probably put to good use‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#pushing-rlcs-to-new-levels",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#pushing-rlcs-to-new-levels",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "Pushing RLCS to new levels",
    "text": "Pushing RLCS to new levels\nI do NOT know yet if ANY of it will make a difference. Really!\nBut I do feel I understand several of the theories put forth in said book about how intelligence evolved. And I do believe, I can implement some version of most of it in the RLCS package.\nMaybe as additional optional parameters that, if any of it proves consistently better (across several test scenarios and datasets of course), could be set to ‚Äúon‚Äù by default."
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#the-key-ideas-coming-up-next",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#the-key-ideas-coming-up-next",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "The key ideas coming up next",
    "text": "The key ideas coming up next\n\nCoverage\nWhen two rules have perfect accuracy, should I keep both? Or maybe is there just one that covers for all samples it has seen, say in a given epoch?\nWe want to generalize, as always with LCS, so that the final ruleset is compact enough that it is readable (sometimes it‚Äôs not feasible, but that doesn‚Äôt mean we shouldn‚Äôt try).\nTo know that, I‚Äôm going to need to keep track of the coverage per-rule. It‚Äôs a simple calculation, per classifier:\n\nfor each epoch, first reset to 0L all counters of coverage\nthen for each sample that matches with the correct class, add one to the rule‚Äôs coverage (which should of course then be divided by the above number of possible matches for that class)\n\nIn Supervised learning, it‚Äôs ‚Äúeasy‚Äù to check how many samples are of one given class from the input data frame.\n\nWhat you obtain, for each rule, is a correct_count_per_epoch, which you can divide by the class prevalence (number of samples of that class) in your training set.\n\n\nSuprise, Episodic Memory: simulation? dreaming?\nI need to read-up some more on that, but for sure there is something about it that makes sense to me, from the experience of‚Ä¶ Well, being a human.\nSo we sleep and we dream, hopefully every day. One theory out there about why we dream, is that it helps ‚Äúdigest‚Äù the information of the day. And in particular, one similar theory is that we sort of re-assess what was shocking, surprising about the day.\nI know nothing about neuro-sciences, but the idea that one consolidates new information, more so than say things that we have already automated.\nWhat does it mean for RLCS?\n\n\n\nConcept: Adding memory to the RLCS agents\n\n\nWell, you can track what samples trigger a new rule. There are two things about that, separately for SL and RL. Here goes‚Ä¶\n\nIn SL: Surprises per epoch\nSo, for each epoch, it‚Äôs rather easy: If as an agent you‚Äôre exposed to an environment sample that matches no correct rule (!), then you trigger the addition of a new rule. That sample is therefore surprising.\nSo let‚Äôs keep track, per epoch, of the surprising samples! We can then, before moving on to the next epoch, ‚Äúquickly review‚Äù the surprises of the ‚Äúday‚Äù (epoch). That would be akin to dreaming, sort-of. Every day, you ‚Äúre-digest‚Äù the day‚Äôs worth of new information.\n(Again: Take that, neural networks ;))\nTrick: If worried about the size of the needed memory or speed-impact, just sample from the surprises, don‚Äôt necessarily keep‚Äôem all. And make sure to clean said episodic memory every epoch (episode).\n\n\nIn RL: Investigate the never seen before\nAlright so that‚Äôs quite different. In RL, you can‚Äôt re-assess a past decision (because the World could change!). Well, you could somewhat, in a sort of dream-simulation of the World, but that supposes you actually have a concept of the World, which, well‚Ä¶ Is a lot to assume! (For now, anyway.)\nHowever, as some neuroscience/psychology experiments on animals (I can‚Äôt remember which right now, sorry) seems to have demonstrated, there is value in surprise when learning about a World. Fair enough! That makes sense!\nSo in RL, you have rounds of exploitation, and sometimes rounds of exploration.\nIn RLCS right now, the way I implemented that is that, during exploration turns, the agent takes a random direction from any of those it has never taken before.\nBut this is incomplete, as per the ‚Äúsurprise‚Äù effect. See, the agent (in my current demo) has very limited perception. It sees one box around itself in all 8 directions.\nWhen it is time to explore, it chooses to explore any direction it hasn‚Äôt tried before. That‚Äôs already leveraging the past experience for sure.\nif(i %% explore_turn == 0) { ## Exploration Turn\n    match_pop &lt;- agents[[j]]$pop[c(match_set)]\n    all_tested_actions &lt;- sapply(match_pop, \\(x) x$action) |&gt; unique()\n\n    ## Cleverer than random exploration:\n    not_tested_yet &lt;- !(possible_actions %in% all_tested_actions)\n    if(any(not_tested_yet))\n      agents[[j]]$chosen_action &lt;- sample(possible_actions[which(not_tested_yet)], 1)\n    else {\n      recommended_action &lt;- rlcs_predict_rl(match_pop)\n      not_recommended_actions &lt;- !(possible_actions %in% recommended_action)\n      agents[[j]]$chosen_action &lt;- sample(possible_actions[which(not_recommended_actions)], 1)\n    }\n}\nBut what if it could decide to explore not only based on past explorations in the exact same situation, but instead in the directions that ‚Äúlook new‚Äù?\nNow I don‚Äôt know if this is going to be worth the effort (the agent is already really exploring when faced with new situations). So I‚Äôll keep that one in the backlog for now."
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#meanwhile-parallel-support-in-package",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#meanwhile-parallel-support-in-package",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "Meanwhile: Parallel support in-package",
    "text": "Meanwhile: Parallel support in-package\nYes. Instead of having people figuring out how to train several agents in one go, I‚Äôm now including the option inside the package itself now.\nTo do so, I added a ‚Äúsoft dependency‚Äù on {foreach} and {doParallel}. For now, that can (but needs not!) influence the Supervised Learning training.\nif(requireNamespace(\"foreach\", quietly=T) &\n     requireNamespace(\"doParallel\", quietly=T) &\n     n_agents &gt; 1) { ## NEW!\n\n    print(paste(\"Using foreach() %dopar% to train up to\", n_agents, \"parallel agents.\"))\n    `%dopar%` &lt;- foreach::`%dopar%`\n\n    if(use_validation) {\n      validation_set &lt;- sample(1:nrow(train_env_df), max(round(.1*nrow(train_env_df)), 1), replace = F)\n      sub_train_environment &lt;- train_env_df[-validation_set,]\n    } else {\n      sub_train_environment &lt;- train_env_df\n    }\n    ...\n}\nRight this moment, if you use the option to leverage a doParallel cluster, you can ask the SL training to train ‚Äún‚Äù parallel agents and keep the best one of them.\nThat‚Äôs the first version. The second step, also included, is that if you do so, instead of taking the best agent by accuracy, you can ask the training to instead use a validation subset. It will then take out randomly 10% of the training set, set it apart, train on the rest, and choose the best version based on accuracy of the validation dataset. That would force it to choose the better agent, considering how good it is at generalizing. An important point, and in the initial tests I‚Äôve done on Iris, it does seem to be slightly better.\nThere is a third improvement on that. And a fourth.\nYou could, instead of just taking the best agent, merge the ‚Äúbest x out of n agents‚Äù, provided, you know, you have more than 1 cores/threads in your cluster. Merging them would be to ‚Äújust‚Äù put together the rules of both, run one subsumption, and return that.\nAnd the fourth improvement on the above is, to train one (or a few) last epoch(s) on the consolidated ruleset of the best agents‚Ä¶ Maybe take the best of n new such agents, too. So you‚Äôd be taking the best of the best, merging them and selecting the best of that. Kind of a higher-level natural selection, if you will.\nFor improvements 3 and 4, I have tested it already, but although they seem better, the Iris dataset is not good enough for that exercise anymore. And I have yet to include that functionality in the package."
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#for-rl-mc-ts",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#for-rl-mc-ts",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "For RL: MC-TS?",
    "text": "For RL: MC-TS?\nThe Reinforcement Learning side of things is not well packaged yet. That is because you could have many agents, for one, but also because you need to make assumptions about the ‚Äúworld‚Äù interactions.\nWell, heck! What if I did make assumptions?\nThings like: Pass a list of agents (RLCS all of them), and pass a World for them to experiment & learn. Assumptions? Well, things like‚Ä¶ If the ‚ÄúWorld‚Äù object is called ‚Äúworld1‚Äù:\n\nThe World returns for an agent that asks for it its current ‚Äústate‚Äù (in our case, we‚Äôll make it a binary string, whatever that represents in the World), through:\nstate &lt;- world1$get_agent_env(agent_id)\"\nThe World returns a picture of itself as-is, upon calling:\nworld1$get_world_plot()\n(Granted, that‚Äôs a nice-to-have, but I feel not seeing what‚Äôs happening would hinder the experience of the person trying to code‚Ä¶)\nThe World accepts actions, for example ‚Äúmovements‚Äù, and returns a reward for each action, maybe like so:\nreward &lt;- move_agent_and_get_reward(agent_id, direction)\n‚Ä¶\n\nSo that kind of assumptions. That agents are all RLCS is easy (I mean, we‚Äôre not working on somethin‚Äô else here, are we now?), but that the World the agent(s) live(s) in has a somewhat standard interface is a harder requirement. However I believe that is fair game after all."
  },
  {
    "objectID": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#conclusions",
    "href": "posts/2025-11-29_RLCS_NewResearchIdeas/index.html#conclusions",
    "title": "New ‚ÄòResearch‚Äô ideas for RLCS",
    "section": "Conclusions",
    "text": "Conclusions\nOh, there is soooo much out there, so many interesting ideas, based on neuro-science & psychology conclusions, that I want to try to use and improve RLCS.\nThis might take a while‚Ä¶ Plus, I should be more intentional about tracking of the before/after or about presenting the differences. I‚Äôll do some post about that now that there are new options implemented‚Ä¶\nInteresting times for RLCS :)"
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html",
    "href": "posts/2021-09-05_SOC_Sim1/index.html",
    "title": "Simulating a SOC (part I)",
    "section": "",
    "text": "Warning: This is a rather long Blog entry. My apologies. Lots of text. But I‚Äôm using it to present some things that will be useful to understand for future entries on the same topic.\nSo I‚Äôve been rather busy the last few weeks. Among other things, in August I sent out some documentation to get myself as a student into an MSc degree. That‚Äôs not too important (and I still have some paperwork pending before I‚Äôm actually officially accepted for it), but one thing however motivates this particular topic of today: One of the upcoming courses is about computer simulations.\nI went on and bought the books for the first courses I aim for, ahead of time, and started studying those. (Personal side note: My matrices math is rusty to say the least, so I am also brushing up on that too, as it seems I might need it very soon :S)\nOK, back on track:\nHow about simulating a SOC in order to try and estimate ‚Äúhow many SOC Analysts might be needed to attend a given volume of alerts‚Äù?"
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#intro",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#intro",
    "title": "Simulating a SOC (part I)",
    "section": "",
    "text": "Warning: This is a rather long Blog entry. My apologies. Lots of text. But I‚Äôm using it to present some things that will be useful to understand for future entries on the same topic.\nSo I‚Äôve been rather busy the last few weeks. Among other things, in August I sent out some documentation to get myself as a student into an MSc degree. That‚Äôs not too important (and I still have some paperwork pending before I‚Äôm actually officially accepted for it), but one thing however motivates this particular topic of today: One of the upcoming courses is about computer simulations.\nI went on and bought the books for the first courses I aim for, ahead of time, and started studying those. (Personal side note: My matrices math is rusty to say the least, so I am also brushing up on that too, as it seems I might need it very soon :S)\nOK, back on track:\nHow about simulating a SOC in order to try and estimate ‚Äúhow many SOC Analysts might be needed to attend a given volume of alerts‚Äù?"
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#context",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#context",
    "title": "Simulating a SOC (part I)",
    "section": "Context",
    "text": "Context\nIf you have even a basic understanding of what a Security Operations Center looks like, you can probably safely skip this section and jump to ‚ÄúSimplified Assumptions‚Äù below‚Ä¶\nA ‚ÄúSecurity Operations Center‚Äù (or SOC for short) is a rather big endeavour for any sizeable company. Beyond the technical considerations, and the many processes to consider, and even the reasons behind the existence of SOCs in companies, let‚Äôs just say that one of the potentially important derived costs (or, depending on how you look at it, investments ‚Äì but that‚Äôs another complex debate)¬† from a SOC is in ‚Äúhead-count‚Äù. (I will NOT get into whether or not those costs are justified, nor discuss my opinions on that. Let‚Äôs assume I have worked in SOC setups in the past, and that‚Äôs that on the matter.)\nIn a SOC, an analyst reviews a queue of incoming Cybersecurity alerts, and treats each alert. Ideally, all alerts are reviewed.\nIn a simplistic and perfect World, supposing no holidays or weekends, you need at the very least 3 persons to cover a 24/7 operation, considering 8h shifts. This amounts to exactly one person per shift, with no respite whatsoever. I.e. those persons would be like robots, really.\nSeparate the week-ends, and you probably need at least another two persons working 12h shifts each, two shifts per weekend, to cover all the hours of the week. As they work less hours in the year, these two might be used to replace the monday-to-friday workers, so that the later can take a day off now and then.\nSo far, we get to 5 persons, 2 of which with 24h workweeks by default. And those are not a realistic assumptions, but let‚Äôs not focus too much on that. Bear with me, as we are talking about simulations here, which simply put generally simplify the real world. And that will hold true onwards.\nIn this our perfect ideal not-at-all realistic productive World, we would then assume that each person, a SOC Analyst, can keep up and respond to all alerts generated during her shift with no help. Our ‚Äúperfect‚Äù analyst hence manages to somehow review and manage alerts at least as fast as those are generated* (see below in this section), on average.\nIn other words, in this scenario, alerts are generated at a certain rate, and one analyst is able to manage that alert faster than the time that passes before the following alert arrives.\nObviously, all the above is incorrect in more than a few ways.\n\nNo human is able to focus perfectly for 8h straight, so right there.\nThrow in holidays, sick-leave, lunch time, human-realistic attention-spans, personal interactions (meetings, coffees, etc.)‚Ä¶\nThen suppose that the rate of alerts generation surpasses somehow the speed at which each alert can be treated. All of the sudden you need more analysts per shift to attend ‚Äúall alerts generated during the shift‚Äù.\n\nBeing conscious of these and many (MANY) other considerations that we should take into account, let‚Äôs try and create a simplified simulator of such a System that obviates most of them. We‚Äôll call it a ‚Äútoy‚Äù simulator for now.\n* For those unfamiliar with the concept:\nA simplistic view of a SOC is that of a System in which many machines send logs to a central repository. The central repository (usually called a SIEM in this scenario) derives alerts from those logs when it ‚Äúsees‚Äù a set of conditions that warrant review, from a Cybersecurity perspective. The most common example out there is that of a brute force attack, whereby someone tries to log in with different usernames and passwords until they are able to get onto a target system. Detecting the many failed logins attempts in a given time period would trigger an alert. That‚Äôs basically one example of what a SIEM does (among other things that are beyond the scope here)."
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#simplified-assumptions",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#simplified-assumptions",
    "title": "Simulating a SOC (part I)",
    "section": "Simplified assumptions",
    "text": "Simplified assumptions\n¬†OK so let‚Äôs make some suppositions (way too many of them once again, but this is for a toy simulation, for now):\n\nOur simulated System (our SOC) sees events as time passes by, in minute intervals. For the time being, let‚Äôs assume these events are ‚Äúalerts‚Äù. These events are discrete (either there is one (or more) alert(s), or not; but there is no such thing as half an alert).¬†\nOur SOC receives alerts from a SIEM, and only from there. In other words, we have one ‚Äúgenerator agent‚Äù for our events (alerts) in our System.\nAlerts are put in ONE queue by the generating agent (i.e.¬†the SIEM). This is a simplification once again, so that we consider ‚Äúall alerts are born equal‚Äù (which obviously is not true in the real world, but that‚Äôs for later versions of the thing).\nAlerts are consumed in a FIFO manner from that queue (‚Ä¶), one at a time. For now, no prioritization. (Once again: all alerts are considered the same in this toy scenario.)\nOne alert is consumed by a consuming agent (i.e.¬†a SOC analyst). A consuming agent only deals with one alert at any given time. She is hence either occupied, or not, at any given minute of the simulation period.\nA given consuming agent spends a certain fixed amount of minutes dealing with one alert.\n\nTo make this only a little interesting, we will allow for more than one agent to consume from the queue, when available, if there are alert(s) in the queue. Each of those (the analysts) then will spend a certain amount of minutes treating an alert, depending on the efficiency of each analyst. We will make the further assumption for now that each agent spends a fixed amount of time each time she treats an alert.\nOn the other hand, in order to keep this first toy simulation simple for now,¬† we consider our SIEM will generate one alert at a specific rate (e.g.¬†1 alert every X minutes)."
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#how-the-code-for-today-works",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#how-the-code-for-today-works",
    "title": "Simulating a SOC (part I)",
    "section": "How the code for today works",
    "text": "How the code for today works\nSo here is the code for our first toy simulator (I‚Äôm sorry for stressing the ‚Äútoy‚Äù part so much, but it‚Äôs just that I need to make it clear I understand this is not at all practical. This is just a personal exercise that I created for the fun of it).\nWe will initialize our System like so:\nsystem_status &lt;- list(a_rcv_int = alerts_rcv_interval,\n  alerts_queue = c(),\n  cons_agents = c_agents, # Analysts are \"Consumer Agents\"\n  treated_alerts_hist = data.frame(alert_generation_time = NULL, \n  alerts_resolved_time = NULL, \n  agent_code = NULL))\nAlerts are received at an interval (in minutes). They get pushed in a queue (FIFO). We will keep track of which alerts were taken out of the queue, at what time they were completely treated, and by which analyst.\nOur Analysts are characterized by how fast they can treat an alert.\nc_agents &lt;- rbind.fill(lapply(1:length(alerts_cons_speed), function(x) {\n data.frame(agent_code = x, \n  ag_resolution_time = alerts_cons_speed[x], \n  ag_occupied = FALSE,\n  ag_current_alert = -1,\n  ag_next_avail = 0)\n}))\nThey are either occupied or not. If occupied, we will store their ‚Äúnext available time‚Äù, and mark which alert they are consuming.\nTo make things simple, our alerts are all considered equal, and so we only care about when they are put in the queue.\nadd_alerts_stable &lt;- function(alerts_queue, alerts_recv_interval, t_mark) {\n # Add to the end of the FIFO\n if(t_mark %% alerts_recv_interval == 0) alerts_queue &lt;- c(alerts_queue, t_mark)\n alerts_queue\n}\nAt any point in time (current minute ‚Äút_mark‚Äù), if a given analyst was occupied, we review whether or not we can free her:\nif(agent_status$ag_occupied) { # Agent (e.g. SOC Analyst) is currently busy\n # Has the agent finished with its last alert?\n  if(t_mark == agent_status$ag_next_avail) {\n   # Add resolution to history of alerts treatment table\n   system_status$treated_alerts_hist &lt;- rbind(system_status$treated_alerts_hist,\n    data.frame(alert_generation_time = agent_status$ag_current_alert,\n     alerts_resolved_time = t_mark,\n     agent_code = agent_status$agent_code))\n   # Update the Agent Status\n   agent_status$ag_occupied &lt;- FALSE\n   agent_status$ag_current_alert &lt;- -1\n }\n}\nOur analysts consume alerts for the queue (FIFO) when they are available, immediately. (This runs if when reaching the current minute, the analyst was free.)\nchanged_alerts_queue &lt;- consume_1_alert(system_status$alerts_queue, t_mark)\nif(!is.null(changed_alerts_queue)) { \n  t_alert &lt;- changed_alerts_queue[[1]]\n  system_status$alerts_queue &lt;- changed_alerts_queue[[2]]\n  agent_status$ag_occupied &lt;- TRUE\n  agent_status$ag_current_alert &lt;- t_alert\n  agent_status$ag_next_avail &lt;- t_mark + agent_status$ag_resolution_time\n}\nWhere:\nconsume_1_alert &lt;- function(alerts_queue, t_mark) { # Get 1 alert from the FIFO\n if(length(alerts_queue) &gt; 0) { # There are alerts to consume\n   alert_orig_t &lt;- alerts_queue[1]\n   alerts_queue &lt;- alerts_queue[-1]\n   return(list(alert_orig_t, alerts_queue))\n }\n NULL\n}\nAt any point in time (current minute ‚Äút_mark‚Äù), we first add alerts to the alerts queue. Then we consume alerts, looping through our list of analysts.\nAnd this is more or less it.\nAll we need to do then is repeat the above things a given amount of minutes (e.g.¬†one shift of 8 * 60 minutes).\nAt the end of the execution, we will have a queue of alerts that were left untreated, as well as a table of who reviewed which alert (which in this case gives us directly the time at which the alert was generated), along with when that particular alert review was completed."
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#running-it-and-some-results",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#running-it-and-some-results",
    "title": "Simulating a SOC (part I)",
    "section": "Running it and some results",
    "text": "Running it and some results\nIn the following example, we decide our System is like follows:\n\n1 alert gets generate every 6 minutes\nTwo analysts treat alerts, one of them in 15 minutes, the other in 12.\n\n\nFrom the above results, you can tell one analyst treats more alerts than the other, and that some alerts are resolved earlier in spite of being taken by someone later than others (see rows 4, 5 and 6 in the screenshot above).\nYou can also tell that some of the time the analyst 1 (for example) was left unoccupied. At row 3 of the above, the first analyst has resolved 2 alerts by the time ‚Äúminute 37‚Äù, while we know she spends 15 minutes on each alert.\nHowever, by the end of the period, two analysts were not able to treat all the alerts received. As we receive 2 alerts in 12 minutes, but our 2 analysts can manage less than that‚Ä¶\nThis is all expected, of course. But we now have a setup to use and try different combinations, changing:\n\nthe rate of alerts arrival (minutes between any two alerts, fixed intervals),¬†\nthe combination of analysts (how many of them) and their respective productivity (time spent on each alert, fixed per analyst).\n\nThis would be the basis for our basic simulator.\nLet‚Äôs test another setup, and then throw in some very basic ggplots in there (not covered on the GitHub version of the code).\nSo here we run a second scenario: 1 alert is received every 4 minutes, and we have four analysts that can respond more or less fast‚Ä¶\n\nAs we can tell, at the end of the period, in spite of having 4 analysts, well, 5 alerts remain untreated. What does it look like graphically?\n\nAs is rather logical, the fastest agents (in order, the fastest is agent 2, while the slowest is agent 3) treat more alerts in the period. They go back to the queue faster.\n\nBut even then, the four of them can‚Äôt really keep up. The ‚Äúage‚Äù of the alerts, that is, the time at which it is treated, compared to the time it was received in the queue, is growing, clearly.\nWe can probably fix that with a fifth consumer (analyst), even a very slow one (e.g.¬†a junior starting in the position, maybe, that takes 40 minutes treating one alert):\n\nThat worked, the overall team was able to cope.\nWhat about training our original team so that they can react faster? Or simplifying a process step, or adding some automation, so that the original 4 analysts each spend one less minute on each alert?\n\nWhat if instead of help the 4 of them, we focused on improving only the productivity of our slower element, making it as fast as the slowest of her colleagues?\n\n¬†\nWell, now we have a tool to help us take such decisions."
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#potential-derived-work",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#potential-derived-work",
    "title": "Simulating a SOC (part I)",
    "section": "Potential derived work",
    "text": "Potential derived work\nAlerts are not received at a set interval. Nor do you necessarily receive one each time. Alerts are also not all the ‚Äúsame‚Äù. Plus¬†Analysts are not robots, and so they might spend more or less time on each alert. Right there I have plenty of potential work on the simulator.\nThen, supposing we can hire a certain amount of analysts:\n\nwithin a given budget\ngiven that there is more than one analyst profile with a corresponding cost and corresponding response time (per profile)\n(‚Ä¶)\n\nCan we decide for example which mix of analyst-profiles we should hire, to ensure that:\n\nat the end of any given shift of 8 hours, the alerts queue is empty (no alert is left unattended),\nwhile minimizing our operational cost (in terms of payrolls), supposing we know the rate of incoming alerts upfront?\n\nSide Note: Nowadays, there is some hype in the Cyber Security Industry around the concept of ‚ÄúSOAR‚Äù. We will not get into that just yet, but for any future reference, we‚Äôll assume a SOAR platform acts as a ‚Äúperfect robot analyst‚Äù capable of managing through automations a subset of alerts , depending on its configurations. In that sense, the SOAR could in theory replace one (or more) of our analysts. That robot analyst is probably priced differently than a human Analyst‚Ä¶ But let‚Äôs get back to the objectives.\nConsidering the above:\nFor now: we just got our first toy simulator to work, and we focus on the first part of the problem. I think simulations like the above (but obviously more elaborate to be nearer the real-world scenarios) could help answer part of such a question.\nI believe the second part of the objectives would point to an ‚ÄúOperations Research‚Äù problem (as simple as it might be, but still)‚Ä¶ However that‚Äôs for future consideration (and incidentally, that‚Äôs another topic of the Master‚Äôs Degree :)).\nThen with forecasting, based on real-world data or simulated distributions, of log sources integration into our SIEM, our rate of definitions of new alerts, relation of logs/alert, and (quite) a few more parameters, we could estimate (or rather do a more educated ballpark estimation) upfront and prepare to size our SOC accordingly.\nIn theory, that is. But even if/when this is not realistic at all, I like to think this kind of exercises is interesting at least.\nAlso, obviously: the presentation of the results of the simulation could be improved, the simulator could be run from a Shiny Application, and so on and so forth. That‚Äôll probably come, but not today üôÇ"
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#conclusions",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#conclusions",
    "title": "Simulating a SOC (part I)",
    "section": "Conclusions",
    "text": "Conclusions\nI really don‚Äôt know if I‚Äôll manage to put enough effort into these concepts soon or not. But if I do, I‚Äôd hope to get a ‚ÄúSOC simulator‚Äù that could help ‚Äúguesstimate‚Äù (at best) the number of analysts to hire for a SOC based on some data.\nFrom there, one could seek to optimize the mix of analysts to hire in order to maintain costs as low as possible (while treating of course all alerts received with a given quality standard).¬†\nAnd if not: it‚Äôs fun to apply some simulation concepts‚Ä¶"
  },
  {
    "objectID": "posts/2021-09-05_SOC_Sim1/index.html#resources",
    "href": "posts/2021-09-05_SOC_Sim1/index.html#resources",
    "title": "Simulating a SOC (part I)",
    "section": "Resources",
    "text": "Resources\nThe complete code of our simplistic simulator"
  },
  {
    "objectID": "posts/2021-12-11_SmallRealizationOnData/index.html",
    "href": "posts/2021-12-11_SmallRealizationOnData/index.html",
    "title": "A small realisation",
    "section": "",
    "text": "A short entry about one small conclusion I reached AGAIN recently. Maybe for the n-th time, but I am now putting words to it.\nPlease bear in mind though, this obviously does not always apply (I don‚Äôt know if the following bullet points will be misinterpreted somehow, I hope not :). Let just say, it does not apply for more scientifically/technically complex stuff. Or life-or-death projects, I guess‚Ä¶ And even then‚Ä¶). I guess it does apply often to me and my use cases of data analysis ‚Äúinitiatives‚Äù.\nAnyhow, here goes:"
  },
  {
    "objectID": "posts/2021-12-11_SmallRealizationOnData/index.html#to-create-value-from-data",
    "href": "posts/2021-12-11_SmallRealizationOnData/index.html#to-create-value-from-data",
    "title": "A small realisation",
    "section": "To create value from data",
    "text": "To create value from data\n\nThere is no lack of data, generally speaking.\nThere is too much focus recently on ‚Äúmachine learning‚Äù, ‚Äúprediction‚Äù, etc.\nWhen what seems to be most often needed is ‚Äúsimpler‚Äù stuff like:\n\njoining datasets, i.e.¬†merging tables, linking data points (maybe even network graphs)‚Ä¶\nthe capacity for filtering & ‚Äúgrepping‚Äù (i.e.¬†mostly: searching)\nthe capacity to create simple but valuable visualisations\nand a simple format for sharing, like CSV/Excel (Excel has one advantage here: most people know how to use it at a basic but sufficient level to allow for data exchange)\n\n\nI am coming to believe the above is often true. If anything, the more ‚Äúadvanced‚Äù stuff cannot happen if the above is not accessible."
  },
  {
    "objectID": "posts/2021-12-11_SmallRealizationOnData/index.html#whats-impeding-reaching-the-basics-above-then",
    "href": "posts/2021-12-11_SmallRealizationOnData/index.html#whats-impeding-reaching-the-basics-above-then",
    "title": "A small realisation",
    "section": "What‚Äôs impeding reaching the basics above, then?",
    "text": "What‚Äôs impeding reaching the basics above, then?\nGlad you asked. In no particular order, I‚Äôd say, mostly:\n\nNot knowing where to look for the data, i.e.¬†lack of communication (in big, complex companies, for instance)\nLack of automation; we need to use more APIs, and do less manual downloading\nAnd of course, dirty data\n\nData silos are an issue, which comes to the first point in both lists: There is probably no lack of data to use, and often in big companies it‚Äôs hard to tell where to find it: one needs to reach out to many colleagues and establish new contacts to locate information, and maybe use documentation repositories or trainings and search through it all.\nIt‚Äôs also no news, you‚Äôll say, that dirty datasets is a common issue, and it‚Äôs rather accepted/common knowledge that most data analysis starts with cleaning data, and that it takes most of the analysis effort to do just that (and my personal experience definitely confirms that).\nThe automation part I add here, because that‚Äôs what will make things easy enough that there will be time left in the future (beyond maintaining the tool or solution) and actually have the capacity to evolve it, improve on it, and get to the more advanced stuff (where needed).\nOnce you get past the above, merging datasets is usually not that hard, nor is filtering, creating a simple graph or saving as CSV. (Which doesn‚Äôt mean it shouldn‚Äôt be done with care, mind you)."
  },
  {
    "objectID": "posts/2021-12-11_SmallRealizationOnData/index.html#summary",
    "href": "posts/2021-12-11_SmallRealizationOnData/index.html#summary",
    "title": "A small realisation",
    "section": "Summary",
    "text": "Summary\nOften times, we might not need as much ‚Äúdata science‚Äù, ‚Äúmachine learning‚Äù, ‚ÄúAI‚Äù, and complex stuff, and rather we need to focus on laying the ground work of the simpler things to enable the providing of some value to begin with.\nOnce the basic stuff is there, sure, let‚Äôs go for the more advance stuff, IF needed (which often, by the way, it isn‚Äôt)."
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "",
    "text": "Alright, two things for today."
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#just-another-saturday",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#just-another-saturday",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "",
    "text": "Alright, two things for today."
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#minor-rlcs-update",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#minor-rlcs-update",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "Minor RLCS update",
    "text": "Minor RLCS update\nThe RLCS presentation of November is coming up, and to be honest I am worried about the time limit. I‚Äôm trying hard to decide what to remove. While I was on that, I found an error in the Rosetta Stone function for the Iris demo. I then added another simple (not great) function to decode rules.\nNot great, but hinting at what can be done, and maybe the future versions of the Rosetta Stone functions could end up being solid. No matter. Good enough for now."
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#visuals-for-arc-agi-1",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#visuals-for-arc-agi-1",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "Visuals for ARC AGI 1",
    "text": "Visuals for ARC AGI 1\nI downloaded a couple of the ARC AGI 1 exercises (I need to look into crawling all of them, actually).\nBut then, I need to visualize the exercises.\nSo I just put together a couple of functions for that.\n\n\n\nvisualizing exercises examples\n\n\nNothing major, but I will say I was having trouble with the image() function, so I‚Äôm moving to ggplot. Nicer looking anyway.\n\n\n\nMaybe grid resizing need to be made more explicit"
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#miscellaneous",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#miscellaneous",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "Miscellaneous",
    "text": "Miscellaneous\nIn the Cybersecurity Market, there are interesting conceptual things to think about. There are things happening in IT, Cybersecurity, etc. that are not perfectly solved. The whole prompt injection/MCP/AI browsers, etc. It‚Äôs a mess (from my perspective).\nAnd it‚Äôs taking a bit of my thinking time, but as I say: Interesting."
  },
  {
    "objectID": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#conclusions",
    "href": "posts/2025-10-25_RLCS_Modifs_and_ARCAGI1_Visuals/index.html#conclusions",
    "title": "Minor Bugs in RLCS, Visuals for ARCAGI1",
    "section": "Conclusions",
    "text": "Conclusions\nNot much today.\nThe hardest part of a presentation is apparently to make it as short as possible. And while at it, I should look into making it somewhat entertaining, too.\nAs for the ARCAGI1, it is still just a nice and interesting thought exercise. Nothing more for now, really, as I have made zero progress towards an actual implementation of anything. In the GEB, D. Hofstadter discusses the Bongard sets and I reviewed the corresponding section of the book this week. It turns out, ‚Äúmy approach‚Äù to the project (well, the way I‚Äôm thinking I want to approach it) is mostly aligned with that described in the book. But aside from a few notes, yes: Zero progress.\nAnd I need to keep thinking about some stuff."
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "",
    "text": "Continuing the exercise of checking RLCS vs RPART vs RF‚Ä¶ And it‚Äôs not that clear."
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#now-i-keep-checking",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#now-i-keep-checking",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "",
    "text": "Continuing the exercise of checking RLCS vs RPART vs RF‚Ä¶ And it‚Äôs not that clear."
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#yesterdays-improvement",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#yesterdays-improvement",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "Yesterday‚Äôs improvement",
    "text": "Yesterday‚Äôs improvement\nOne thing I did do: Tailor some more the Rosetta Stone functions.\nNow, I can go from 1, 2, 3, 4, 5 or even 6 bits strings. That means, I can account for numerical columns and encode them in up to 64 ‚Äúbuckets‚Äù, separated by medians (just a choice).\nWith that done, looking at Iris dataset, I can account for all unique values, which means the RLCS now encodes with sufficient detail, with depth-per-column (so two columns use 5 bits, the other two use 6!), and it‚Äôs also automatic.\nIn other words: No information loss, and then I can compare it with other algorithms.\n(A future Rosetta Stone version will also accept factors for encoding‚Ä¶ But that‚Äôs for some other time.)"
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#todays-observations",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#todays-observations",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "Today‚Äôs observations",
    "text": "Today‚Äôs observations\nA few things:\n\nRLCS is stochastic, that‚Äôs a pain. I need to run it at least a few times with different seeds to get some sense of the quality of a set of hyperparameters.\nRLCS is (awfully awfully awfully) slow running compared to RF or RPART. It‚Äôs different, and I don‚Äôt actually mind, but when you need to run it a few times‚Ä¶ Another kind of pain :D\nRunnin‚Äô hot! A MacBook Air M1 wasn‚Äôt meant to ‚Äúburn CPU‚Äù in a sustainable fashion. This reminds me of my last MSc project (where I had 37h parallel CPU runs). This time it‚Äôs only a few minutes at a time, until I check a different RLCS config. But still, you can reaaaaally feel the heat."
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#some-results",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#some-results",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "Some results",
    "text": "Some results\nThat said, here some results for today.\nGetting RLCS to be as good as RF is not straightforward, and it might still be a fluke, to be honest. But after some hyperparams tuning (that means, lots of runs, trial & error, until I found some configs that work better‚Ä¶), well‚Ä¶\n\n\n\nTakes a looong time, but results are getting better‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#conclusions",
    "href": "posts/2025-11-10_Comparing_RLCS_to_RF_partII/index.html#conclusions",
    "title": "RLCS might possibly be as good as Random Forest?",
    "section": "Conclusions",
    "text": "Conclusions\nWell‚Ä¶ There is room for hope, still. It still very much feels like a right combination of hyperparameters, which needs tailoring per-problem, can make a difference. At this stage, it‚Äôs not completely crazy to assert that maybe RLCS can in fact compete with RF, in certain settings.\nOnce a right pressure to explore is found, giving more time to find the right combinations of course will help, maybe to even consolidate the populations of rules. But that‚Äôs beyond today‚Äôs objectives, and we‚Äôre anyway talking about hundreds of rules‚Ä¶ A bit overkill, for classifying correctly 30 test samples‚Ä¶\nAnyhow. It‚Äôs been a good weekend of work. I‚Äôm happy I have this new objective of comparing with other algorithms. It‚Äôs a new motivation to keep at it :)"
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html",
    "href": "posts/2023-06-04_OnSnowflake/index.html",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "",
    "text": "A short and somewhat different entry."
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#intro",
    "href": "posts/2023-06-04_OnSnowflake/index.html#intro",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "",
    "text": "A short and somewhat different entry."
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#sql-keeps-on-giving",
    "href": "posts/2023-06-04_OnSnowflake/index.html#sql-keeps-on-giving",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "SQL keeps on giving¬†",
    "text": "SQL keeps on giving¬†\nSo these past few days/weeks, I have had the chance to work with a ‚ÄúData Lake‚Äù platform.\nAs it turns out, in ‚ÄúSnowflake‚Äù, the platform, having some understanding of SQL helps‚Ä¶ a LOT.\nThe little I understand about it by now, it seems like a flexible solution, it allows to do many data manipulations, and I feel it will be a good option to do some ‚ÄúELT‚Äù, which is nice in some of my use-cases.\nI still need to learn more, of course, but this entry is an initial praise‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#pre-processing-data",
    "href": "posts/2023-06-04_OnSnowflake/index.html#pre-processing-data",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "Pre-processing data",
    "text": "Pre-processing data\nIn my case, I think I will mostly try to benefit from pre-processing multiple datasets from multiple data sources into ‚Äúcurated‚Äù views & tables to facilitate downstream usage of the info by myself and others. The cool thing is, I think a good part of the preprocessing will be feasible directly from within Snowflake, thereby simplifying my consuming data from scripts and dashboards, all the while providing info from multiple sources in a consolidated manner. We‚Äôll see."
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#very-nice-flexibility",
    "href": "posts/2023-06-04_OnSnowflake/index.html#very-nice-flexibility",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "Very nice flexibility¬†",
    "text": "Very nice flexibility¬†\nNo question about it, the flexibility of storage and processing has impressed me, indeed.\nEven so, my needs are not ‚ÄúBig Data‚Äù ‚Äì still it‚Äôs cool to know/see that there is magnificent flexibility to adapt capacity for bigger needs.\nIn the AAA area, the roles and schemas and al.¬†are nice, in that the model makes sense to me, anyway."
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#multiple-options-too",
    "href": "posts/2023-06-04_OnSnowflake/index.html#multiple-options-too",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "Multiple Options too",
    "text": "Multiple Options too\nSo as with some traditional DBMS you can save stored procedures, which helps organize things a bit.\nWhat‚Äôs more, I have tested running some Python in there too, and I see other languages are available (JS and more).\nEDIT: You can of course also use an API, which is easier done with Python. Then use {reticulate} to help with the interactions from R, and that‚Äôs that."
  },
  {
    "objectID": "posts/2023-06-04_OnSnowflake/index.html#conclusions",
    "href": "posts/2023-06-04_OnSnowflake/index.html#conclusions",
    "title": "How SQL is still proving so useful: Snowflake",
    "section": "Conclusions",
    "text": "Conclusions\nSo much could be said. I have pointed in the past to the value of having nice cleaned-up data views as input for creating Dashboards (say in PowerBI or Tableau‚Ä¶), and in this case it seems a PaaS (or is it a SaaS?) solution can help, while providing speed, scalability (with little effort on the part of the analyst), while also helping with consolidating and (at least to a point) cleaning up what I guess will be messy input data (it never comes perfect, I suppose).\nPlus, if that approach helps share data with some colleagues ‚Äì without requiring my R scripts on my laptop in the middle to do data wrangling -, well that‚Äôs a nice outcome‚Ä¶\nIn the past couple of years I have had the opportunity to ‚Äúplay with‚Äù things beyond my ‚Äúlaptop-Docker-RStudio‚Äù simple setup (which is most cases is quite sufficient).\nTo share info with third parties, PowerBI dashboards are fair.\nFor point-in-time ‚Äúbig data‚Äù processing, I have tested Azure Synapse and PySpark, and that was great.\nWell, Snowflake is great too, very flexible, not for the same use case, but rather to replace databases.\nIn summary I‚Äôm loving it too, so far.\nAnd on a personal note, I can‚Äôt avoid but feel so lucky for being exposed to all these great platforms and solutions. That, and the master I‚Äôm studying, have pushed me to what I feel as ‚Äúanother level‚Äù as a data analyst over the past two years. It‚Äôs a lot of work, but‚Ä¶\nI am incredibly lucky indeed."
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "",
    "text": "First, let me say, I know, it‚Äôs been a while. And that‚Äôs alright. I have plenty of good excuses üôÇ Now that doesn‚Äôt mean I should completely forget about this my little Blog.\nOK, so, for today: I‚Äôve been studying Operations Research for about 3 months now, and we‚Äôre getting (in the Master course) to simulation as a means to do optimization (I guess, for what some call ‚Äúsimheuristics‚Äù). OK, and what‚Äôs cool, is I get to do some exercises, and as the exercises are never proposed in R, I get to do what I want here to reproduce some of it.\nSo, today, Monte-Carlo."
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#intro",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#intro",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "",
    "text": "First, let me say, I know, it‚Äôs been a while. And that‚Äôs alright. I have plenty of good excuses üôÇ Now that doesn‚Äôt mean I should completely forget about this my little Blog.\nOK, so, for today: I‚Äôve been studying Operations Research for about 3 months now, and we‚Äôre getting (in the Master course) to simulation as a means to do optimization (I guess, for what some call ‚Äúsimheuristics‚Äù). OK, and what‚Äôs cool, is I get to do some exercises, and as the exercises are never proposed in R, I get to do what I want here to reproduce some of it.\nSo, today, Monte-Carlo."
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#the-context",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#the-context",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "The context",
    "text": "The context\nIn the past, I‚Äôve prepared a small simulation that would potentially help ‚Äúframe‚Äù the operations of a SOC, and its analysts, team sizing, etc. I wrote about that here and here. Already back then, I mentioned ‚ÄúAlerts are not received at a set interval‚Äù (well, not a fixed one, anyway). Instead, we might consider the alerts are generated following some other density function/probability distribution.\nThe most common distributions for input calls rates to a datacenter are probably Poisson, Exponential, or Weibull (or even Beta‚Ä¶), and in any case, it doesn‚Äôt hurt to have some level of familiarity with a few distributions (on top of the above, I‚Äôd say‚Ä¶ The Normal, lognormal, triangular, a maybe a few others)."
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#more-context",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#more-context",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "More context",
    "text": "More context\nOK, so ‚Äúsimply‚Äù generating data from a certain density function is not all that hard in R. Just call one of stats package functions for it, say a LogNormal density function:\n\n¬†\nYou can also generate sample data from such a distribution, from say an Exponential distribution:\n\n¬†\nThe tweak though is to decide, from a set of data points (observations), which of such distributions would best fit. Here the goal is to find a valid theoretical distribution that ‚Äúfits‚Äù our observations (today, univariate), so that we can then use that theoretical distribution to generate as many sample input values to our system. Each such distribution has parameters, though, so not only do we need to know whether to use an exponential or a beta, but also, with which parameters should those best ‚Äúfit‚Äù our observations.\nSo supposing our alerts are reaching our SIEM at a rate (say, alerts per hour?) that can be akin‚Äô to a Poisson distribution, what are the parameters of such a Poisson distribution?\nEven better, which is it in the first place, a Poisson distribution or an Exponential? Finding that out (‚Äúfitting‚Äù a distribution) will enable us to simulate various executions of our system (say, our SOC simulator) with representative input (alerts reception rate), which is what Monte Carlo is all about.\nThat would greatly improve the validity of our toy simulator. After all, as many say (I‚Äôve invented NOTHING in this blog post‚Ä¶ Just applying/learning): What‚Äôs worse, exact answers to an incorrect simulation model, or approximate answers to the right simulation?"
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#interlude",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#interlude",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "Interlude",
    "text": "Interlude\nWhile working on the code (coming next), I kept looking at the homework I was given, and there I came across a paper, that, simply put, I think is marvellous:\nINTRODUCTION TO MONTE CARLO SIMULATION\nIf at all interested in the subject, and not yet quite clear what Monte-Carlo is all about, please oh please, give this short paper a chance. You‚Äôll thank me later."
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#back-to-work-basic-fitting-visually",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#back-to-work-basic-fitting-visually",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "Back to work: Basic fitting, visually",
    "text": "Back to work: Basic fitting, visually\nTime to do some actual R programming. Let‚Äôs use classics here for now. The MASS package comes with the VERY handy ‚Äúfitdistr()‚Äù function. I know (because I looked it up!) there are other more advanced packages out there that help with this very task (fitting a density function to some data), but sometimes I need to get a better feeling of what‚Äôs happening doing things, so here we are programming our own function‚Ä¶\nHere the function (as formatting is not great, I‚Äôll just post the sample code on my Github account).\nThis short sample function should generate some Plot output with a¬†histogram of our ‚Äúreal‚Äù data (which we can then generate to test fitting or not, visually), and a density function (blue line) for the fitted (parameterized) function that we have selected.\nWe can then test it with some datasets that we ‚Äúknow‚Äù ahead of the fitting will fit one of the distributions (even when a little noise is added)‚Ä¶\nnoise &lt;- runif(1000,0,1) # to make it a bit harder for the fitting estimations...\nmy_normvec &lt;- rnorm(1000, mean=3, sd=2) + noise # self describing\nmy_expvec &lt;- rexp(1000, rate=2) + noise/10 # Generating 1000 numbers of exponential with lambda 2\nmy_lognormvec &lt;- rlnorm(100, meanlog=1, sdlog=2) + noise*5\n\nvis_compare_hist(my_normvec, \"normal\") # Good apparent fit\nvis_compare_hist(my_normvec, \"exponential\") # must have positive values only! That's why we use tryCatch.\nvis_compare_hist(my_expvec, \"exponential\") # Good apparent fit\nvis_compare_hist(my_expvec, \"normal\") # clearly not matching...\nvis_compare_hist(my_lognormvec, \"lognormal\") # ...\nFor which on of the outputs (that of the Exponential) is:\n\nWhereas we can see, trying to ‚Äúfit‚Äù a normal distribution to an exponential-based dataset, isn‚Äôt as good a fit, visually:\n\nAnd as a final note for today (this is part 1 of maybe 2 or 3 entries‚Ä¶), we can generate data from a fitted function to a given dataset with ‚Äújust‚Äù three lines (provided, for now, we know upfront which distribution we‚Äôre expecting, and are only looking for its parameters‚Ä¶)\n# Future use: One can generate random samples from a fitted distribution, to feed a simulation for instance...:\nt_fit &lt;- fitdistr(my_normvec, \"normal\") # fitting a distribution to some data\nt_fit$estimate # looking at the estimated parameters for the fitted function\nsample_fit &lt;- rnorm(t_fit$n, t_fit$estimate) # generating n values with the \"fitted\" distribution parameters"
  },
  {
    "objectID": "posts/2023-01-18-SimsAndMCForDists/index.html#conclusions",
    "href": "posts/2023-01-18-SimsAndMCForDists/index.html#conclusions",
    "title": "Simulation: Monte-Carlo & Input Distributions",
    "section": "Conclusions",
    "text": "Conclusions\nNow IF you have opened (and then checked more thoroughly) the paper recommended above, you might have found that the graphs proposed above look somewhat similar to doing a Chi Square Test. As they put it in the referenced paper (really, have a look):\n‚ÄúThe Chi-square test can be thought of as a formal comparison of a histogram of the data with the density or mass function of the fitted distribution.‚Äù\nNow if that‚Äôs not what we‚Äôve done visually today‚Ä¶\nThere will be more entries on the topic, but I‚Äôm still quite busy these days with homework on top of real daily work‚Ä¶ So it will come when it will come.\nA thing to be tested is the fitdistrplus package and its possibilities, for instance. We‚Äôll have to wait and see‚Ä¶\n¬†\nResources\nStackOverflow for generating the plot\nMy code on GitHub"
  },
  {
    "objectID": "posts/2023-07-23_Simulated_Annealing/index.html",
    "href": "posts/2023-07-23_Simulated_Annealing/index.html",
    "title": "Optimization: Simulated Annealing",
    "section": "",
    "text": "Continuing with this simple ‚Äúseries‚Äù (see here and here), I implement the next algorithm proposed by the reference book, but in R.\nThis time around, it‚Äôs the turn of ‚ÄúSimulated Annealing‚Äù.\n\n\nI like how the concept of molecules excitement and temperatures is used for this algorithm. All in all, it‚Äôs a bit different from Gradient Descent in that it allows to keep going with WORSE results in some cases, proportional to the progress, so that it explores better the overall range of possible values. This is supposed to ensure that this algorithm will in fact avoid falling in local minimum, and so this is better for situations where there are multiple minima.\nThat said, here the code for this algorithm. I haven‚Äôt made any effort to make this implementation ‚Äúgood‚Äù or fast, mind you, but it‚Äôs valid for a bi-variate function.\nAnd here the results. This was not surprising after the algorithm was understood, but still, one can tell it was off-track in this example iteration, and still got to the right results in the end.\n \n\n\n\nAt this point, we might want to look into optimization that work also for non-differentiable functions (maybe). That‚Äôs a probable future post üôÇ"
  },
  {
    "objectID": "posts/2023-07-23_Simulated_Annealing/index.html#intro",
    "href": "posts/2023-07-23_Simulated_Annealing/index.html#intro",
    "title": "Optimization: Simulated Annealing",
    "section": "",
    "text": "Continuing with this simple ‚Äúseries‚Äù (see here and here), I implement the next algorithm proposed by the reference book, but in R.\nThis time around, it‚Äôs the turn of ‚ÄúSimulated Annealing‚Äù.\n\n\nI like how the concept of molecules excitement and temperatures is used for this algorithm. All in all, it‚Äôs a bit different from Gradient Descent in that it allows to keep going with WORSE results in some cases, proportional to the progress, so that it explores better the overall range of possible values. This is supposed to ensure that this algorithm will in fact avoid falling in local minimum, and so this is better for situations where there are multiple minima.\nThat said, here the code for this algorithm. I haven‚Äôt made any effort to make this implementation ‚Äúgood‚Äù or fast, mind you, but it‚Äôs valid for a bi-variate function.\nAnd here the results. This was not surprising after the algorithm was understood, but still, one can tell it was off-track in this example iteration, and still got to the right results in the end.\n \n\n\n\nAt this point, we might want to look into optimization that work also for non-differentiable functions (maybe). That‚Äôs a probable future post üôÇ"
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html",
    "href": "posts/2024-10-20_Interpolation_Example/index.html",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "",
    "text": "As I want to make sure I keep posting here, I keep looking for things to write about in my own personal ‚Äúlibrary‚Äù (book shelves).\nOne topic I want to make sure I don‚Äôt forget about is ‚ÄúNumerical Methods‚Äù. (Another one is graph theory, another one is anomaly detection‚Ä¶ There are a few topics like that :D).\nAnyhow. Today: Interpolation.\nMore specifically, Lagrange polynomials. Which is just one of many possible approaches (and has its own drawbacks)."
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html#intro",
    "href": "posts/2024-10-20_Interpolation_Example/index.html#intro",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "",
    "text": "As I want to make sure I keep posting here, I keep looking for things to write about in my own personal ‚Äúlibrary‚Äù (book shelves).\nOne topic I want to make sure I don‚Äôt forget about is ‚ÄúNumerical Methods‚Äù. (Another one is graph theory, another one is anomaly detection‚Ä¶ There are a few topics like that :D).\nAnyhow. Today: Interpolation.\nMore specifically, Lagrange polynomials. Which is just one of many possible approaches (and has its own drawbacks)."
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html#concept-of-interpolation",
    "href": "posts/2024-10-20_Interpolation_Example/index.html#concept-of-interpolation",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "Concept of Interpolation",
    "text": "Concept of Interpolation\nSo first, what is ‚ÄúInterpolation‚Äù. Most people interested in Statistics and Machine Learning (mostly wrt time series and predicting the future of stock markets, say‚Ä¶) will have heard about Extrapolation. And that‚Äôs mostly it: Take a distribution or timeline and ‚Äúpredict‚Äù what the future of it should look like. (To keep things simple, that is).\nInterpolation is about finding a distribution in between known points. So not about the ‚Äúfuture‚Äù (in the above comparison) but instead about the ‚Äúpresent‚Äù, if you will. It‚Äôs about ‚Äúfilling the gaps‚Äù. Or trying to üôÇ"
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html#lagrange-polynomials",
    "href": "posts/2024-10-20_Interpolation_Example/index.html#lagrange-polynomials",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "Lagrange Polynomials",
    "text": "Lagrange Polynomials\n‚ÄúFor a given set of N+1 data points, we want to find the coefficients of an Nth-degree polynomial function to match them [‚Ä¶]‚Äù\n\nLagrange polynomials are somewhat intuitive because each term x_m can rather easily be shown to correspond exactly to y_m (by definition of L_{N, m} above).\nAlright, and the math above leads me to the following R code (my own, but not saying ‚Äúperfect‚Äù, of course :D):\n\n(The source code can be found here)\nAnd to validate that, I take the same example points as that of the reference book, and we can plot the results:\n\nSo we see a POSSIBLE approach here, which ‚Äúlooks‚Äù sensible (but MIGHT VERY WELL be wrong)."
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html#conclusions",
    "href": "posts/2024-10-20_Interpolation_Example/index.html#conclusions",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "Conclusions",
    "text": "Conclusions\nToday was about one of many approaches, a short introduction to the topic of Interpolation (as ‚Äúopposed‚Äù, though not really, to extrapolation).\nThere are several alternatives, namely Newton Polynomials, for which improvements can be obtained by better choosing sample points (Chebyshev nodes). Or the well appreciated Cubic Splines.\nNewton Polynomials for instance work with recursion, and so might come in handy if one expects to ADD new reference data points in the future, because with Lagrange Polynomials, all calculations need to be redone from scratch.\nAll of which might make for a nice few future entries of this blog üôÇ"
  },
  {
    "objectID": "posts/2024-10-20_Interpolation_Example/index.html#resources",
    "href": "posts/2024-10-20_Interpolation_Example/index.html#resources",
    "title": "Random Exercises: Interpolation with Lagrange Polynomials",
    "section": "Resources",
    "text": "Resources\n‚ÄúApplied Numerical Methods Using MatLab, 2nd Edition‚Äù, Ed. Wiley, by W. Y. Yang, W. Cao, J. Kim & al."
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html",
    "title": "When to parallelize (and when not to)",
    "section": "",
    "text": "I have finally delivered my last term paper for this year (one last year to go). It was about simulating traffic using graphs, onsets of congestion and the likes.\nOnce again, the smallest graph was of order 4000+, and once again I had to work with MonteCarlo approach on 1000+ time steps for each simulation, implementing on top of it all a queuing system‚Ä¶\nAnd for each simulation, a random process occurred (generating vehicles using a Poisson distribution), ensuring that each step depended on the former one, and hence preventing us from directly using parallel processing there‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#intro",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#intro",
    "title": "When to parallelize (and when not to)",
    "section": "",
    "text": "I have finally delivered my last term paper for this year (one last year to go). It was about simulating traffic using graphs, onsets of congestion and the likes.\nOnce again, the smallest graph was of order 4000+, and once again I had to work with MonteCarlo approach on 1000+ time steps for each simulation, implementing on top of it all a queuing system‚Ä¶\nAnd for each simulation, a random process occurred (generating vehicles using a Poisson distribution), ensuring that each step depended on the former one, and hence preventing us from directly using parallel processing there‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#the-initial-realization",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#the-initial-realization",
    "title": "When to parallelize (and when not to)",
    "section": "The initial realization",
    "text": "The initial realization\nBecause I knew upfront things would be slow, any part of the process I could I used ‚Äúfuture.apply‚Äù upfront, whereby several sessions would be used at once to run some code‚Ä¶\nIt seemed like a good idea to generate new vehicles. In the studied model, that happens once every time step. For each node of the network, one generates a number of vehicles (following a lambda for our Poisson process). With small lambda, you generate few vehicles, to put it simply.\nGenerating one new vehicle for one node or for 10 nodes can be done in parallel, as they do not influence (yet) the other nodes queues.\nAnd each vehicle will ‚Äúgo somewhere‚Äù, following in our example the shortest path (using Dijkstra) to that destination node. So it made sense that I would generate all new vehicles and their routes for each node sequentially (they are added to each node‚Äôs queue) but for all nodes in parallel.\nCalculating the shortest path for one node to another node is fast with igraph."
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#first-mistake",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#first-mistake",
    "title": "When to parallelize (and when not to)",
    "section": "First mistake",
    "text": "First mistake\nUsing futures to run in parallel small and fast steps is‚Ä¶ a bad idea!\nThere is an overhead of using future.apply related to session management, copying context stuff‚Ä¶\nAnd for fast steps, one might be better off using a simple vectorized approach, NOT adding parallel processing. In my example, generating one new vehicle was such a situation, MUCH faster with a ‚Äúsimple‚Äù apply to cover all nodes than a future.apply, for instance.\nMuch faster‚Ä¶ For low load of the network.\nUntil it is not."
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#increasing-traffic",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#increasing-traffic",
    "title": "When to parallelize (and when not to)",
    "section": "Increasing traffic",
    "text": "Increasing traffic\nWhen our lambda grows, we generate more vehicles at each time step. In each time step also, all vehicles move to the next node on their respective route (updating all 4000+ queues accordingly). Then we move to the next step.\nNow consider that each simulation is 1000+ steps (the more the better).\nAnd consider relatively high lambdas (0.05 would mean 0.05*4000 means 200 new vehicles in the network queues each time step).\nAnd finally consider you want to do a Monte Carlo approach because there is a random process in there, so you would like to do say a hundred repetition. And that‚Äôs for one configuration of the network, what you want is to observe the impact of varying lambdas. (Not to mention other variables of the setup).\nYou end up calling the Dijkstra algorithm lambda*4000*1000+ times for each simulation, and you might very well want to run thousands of these simulations‚Ä¶\nFiguring this out too late (I had less time than I would have liked dedicated to this simulation exercise, roughly 30h overall), I failed to implement and run fully a version whereby I decided to calculate ALL shortest paths UPFRONT. Saving precious time by then improving runtime of each simulation."
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#the-trade-off",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#the-trade-off",
    "title": "When to parallelize (and when not to)",
    "section": "The trade-off",
    "text": "The trade-off\nAs it turns out (because I did figure out the above after a while obviously, albeit too late), in studying that possibility of calculating all paths upfront, you‚Äôd end up with a list of lists (one path for each of all origins to all destinations in a digraph) of roughly 3GB in memory.\nNow you still want to run each simulation in parallel to the others (as much as you can), so say you use forEach‚Ä¶ %doPar% (I need to check the package name, but it‚Äôs a nice alternative, futures here don‚Äôt quite apply).\nWhat happens (or seems to happen) is for each simulation you need to copy the context (for each iteration you put in a different CPU), and well, with 3GB of one object needed, even with 8 CPUs handy, you‚Äôre in fact limiting parallel processing because of the RAM‚Ä¶ Which was a fresh new problem."
  },
  {
    "objectID": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#conclusions",
    "href": "posts/2023-06-25_when_to_parallelize_and_when_not_to/index.html#conclusions",
    "title": "When to parallelize (and when not to)",
    "section": "Conclusions",
    "text": "Conclusions\nI didn‚Äôt finish looking into all alternatives (not to mention I failed to translate much of the code to C++ to make things faster), mostly because of too tight a deadline (which is my fault of course, but that‚Äôs a different topic).\nFor one MSc term paper, out of five for this semester for that one course, that was not an easy simulation exercise (but it was a fun challenge!).\nBut what‚Äôs more: Making things fast for the low-load network was a good idea, But had I thought through the issues that would creep up in my system under higher loads, I would probably have forgone trying to parallelize one processing step (that ended up happening too much, slowing everything down) in favor of calculating some values (the whole shortest paths lists) upfront, which in the long run would certainly have proven better for processing simulation iterations of the network under high load.\nIn other words: Parallelizing gave me false confidence in runtimes at the beginning that left things too slow in the end, precluding me from thinking of other potentially better alternatives.\nAlso: parallelizing fast things can be slower (because of session management) than the ‚Äúsimply vectorized‚Äù version of the same thing."
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html",
    "href": "posts/2025-12-06_ScalingLab/index.html",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "",
    "text": "Alright, so I have this miniPC with 16 threads, and for the past weeks I was looking at my MacBook M1 screen while waiting for 7 parallel processes to run instead of using that alternative machine‚Ä¶ And because I was testing different configurations and doing a sort-a Monte-Carlo, whereby I would run 50 times each configuration (to compare accuracy with RF, Rpart and now also a simple NeuralNet), but each complicated config I would use for RLCS would take 40s-1m20s, times 50, well‚Ä¶\n16 threads in the mini-PC that are slower each than my 8 cores on the MacBook, yes, but it‚Äôs also a complete separate environment and so I can let it run basically unsupervised and come back only to check the results‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#just-too-many-hours",
    "href": "posts/2025-12-06_ScalingLab/index.html#just-too-many-hours",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "",
    "text": "Alright, so I have this miniPC with 16 threads, and for the past weeks I was looking at my MacBook M1 screen while waiting for 7 parallel processes to run instead of using that alternative machine‚Ä¶ And because I was testing different configurations and doing a sort-a Monte-Carlo, whereby I would run 50 times each configuration (to compare accuracy with RF, Rpart and now also a simple NeuralNet), but each complicated config I would use for RLCS would take 40s-1m20s, times 50, well‚Ä¶\n16 threads in the mini-PC that are slower each than my 8 cores on the MacBook, yes, but it‚Äôs also a complete separate environment and so I can let it run basically unsupervised and come back only to check the results‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#working-on-compatibility",
    "href": "posts/2025-12-06_ScalingLab/index.html#working-on-compatibility",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "Working on Compatibility",
    "text": "Working on Compatibility\nSo recently, I setup my package with a dependency that was‚Ä¶ A bit too harsh.\nNamely, I added a resource that required R 4.5, and that in turn had an impact on RTools, plus re-installing everything (devtools, etc.).\nIt‚Äôs not awful, because that forced me to update like‚Ä¶ Everything, on my work laptop. My personal Mac was already up-to-speed, so no problem there.\nBut do I really want to push any candidate user to upgrade to the very latest? Maybe not. So I edited the dependency to require R4.4 instead (4.4.2 if I recall correctly).\nAnd so I‚Äôm setting up the lab in THAT version. That way I have 3 running environments to test my package, in fact: 2 Windows, with different versions of R, and my Mac, where I do the coding.\nAnd now, setting things up‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#the-new-lab",
    "href": "posts/2025-12-06_ScalingLab/index.html#the-new-lab",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "The ‚Äúnew‚Äù lab",
    "text": "The ‚Äúnew‚Äù lab\nThe miniPC has been sitting idle mostly since my MSc project, where I used {plumbeR} to distribute workload to simulate epidemic processes on networks, and there again, I was doing Monte-Carlo stuff. It was cool, it was multi-PC AND multi-core/PC; with it and my Mac, I would run 6+14 simulations at the same time. (And what can I say, I love that!). Even then, I would have them run for hours‚Ä¶\nAnyway. But that was all on Docker. This time around, I want instead to make sure I reproduce what most people will have to test the package, so namely, RStudio on Windows, with a recent but not latest R version (4.4.2 in that case).\nAnd well, thankfully, that works:"
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#going-parallel",
    "href": "posts/2025-12-06_ScalingLab/index.html#going-parallel",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "Going parallel",
    "text": "Going parallel\nSo next, of course, I want to see how good it can be to have 16 threads (8 cores, but that‚Äôs less relevant here):"
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#next-up",
    "href": "posts/2025-12-06_ScalingLab/index.html#next-up",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "Next up",
    "text": "Next up\nI was working on more tricks for parallel processing, so I‚Äôll have to share the new version of the code to test those, and then I‚Äôll be able to let the (not-so-new but separate) machine run, while I keep coding and writing with the MacBook.\nWhich will give some relief to the poor MacBook, from running hours in multi-CPU‚Ä¶ without a fan."
  },
  {
    "objectID": "posts/2025-12-06_ScalingLab/index.html#conclusions",
    "href": "posts/2025-12-06_ScalingLab/index.html#conclusions",
    "title": "Setting up a better ‚ÄòLab‚Äô",
    "section": "Conclusions",
    "text": "Conclusions\nMaybe it‚Äôs overkill. Maybe not. This is giving me a new validation environment, for one, and allowing me to separate long-running tests of several configurations (hyper-parameter tuning for an LCS can be a bother) while I actually keep working."
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html",
    "href": "posts/2021-05-08_OnAnsible/index.html",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "",
    "text": "Gather Configuration data from Linux boxes. As the saying goes: ‚ÄúYou can‚Äôt manage what you don‚Äôt know‚Äù. Well, today is about just that (with focus on IT Security)."
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html#goal-for-today",
    "href": "posts/2021-05-08_OnAnsible/index.html#goal-for-today",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "",
    "text": "Gather Configuration data from Linux boxes. As the saying goes: ‚ÄúYou can‚Äôt manage what you don‚Äôt know‚Äù. Well, today is about just that (with focus on IT Security)."
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html#introduction",
    "href": "posts/2021-05-08_OnAnsible/index.html#introduction",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "Introduction",
    "text": "Introduction\nThis is part of a series of posts about gathering security data (see for example: Shodan API tests or More external data sources tests: OWASP Amass). But those where about gathering data from the Internet. Let‚Äôs look ‚Äúinwards‚Äù for once.\nI‚Äôve heard a lot the name ‚ÄúAnsible‚Äù, and I understood the concept‚Ä¶ But (until right now) I had not played with it. Today will, as often, only be about demo/testing, so do not expect much detail (or the best possible quality).\nAnd no, it won‚Äôt be about R at all (once again), but rather about gathering (hopefully relevant) data for security purposes."
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html#getting-things-working",
    "href": "posts/2021-05-08_OnAnsible/index.html#getting-things-working",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "Getting things working",
    "text": "Getting things working\nFirst let‚Äôs create a new container; we‚Äôll use the Alpine distro as it is lightweight and supports Ansible (https://wiki.alpinelinux.org/wiki/Ansible)\ndocker pull alpine\nOnce installed, let‚Äôs run that in interactive mode. (We‚Äôll probably want to go the Dockerfile way in the future, but that will be good enough for today).\ndocker run --name ansible1 -it alpine\nThen we‚Äôll install Ansible, like so (we‚Äôll also need SSH, mainly):\n/ # apk add ansible\n/ # apk add openssh\nThat was rather easy, wasn‚Äôt it? Now we can first test access to our ‚ÄúHome Lab‚Äù server:\n/ # ssh -p 22225 10.0.1.10\nWorking, but of course, SSH keys and all are not there. So I‚Äôll fix that (quick fix with bad ciphers and all, but sufficient). Not much security as I will clean this up afterwards. And we‚Äôre ‚Äúready‚Äù, inside the Home Lab Server. Let‚Äôs get back to our Ansible container (which is, by the way, a so-called ‚Äúcontrol node‚Äù).\nnico@home1:~$ exit\nlogout\nConnection to 10.X.X.X closed.\nNow we have an ansible-installed container, and the Home Lab Server to be ‚Äúmanaged‚Äù. The Home Lab already sports a Python3 so nothing else should be needed. That‚Äôs good.\nNote for self: When working with interactive mode in Docker, you might want to pause and come back to your container later on. Then you‚Äôll need to do something along the following lines to re-connect to your container after exiting it:\n# sudo docker ps -a\n# sudo docker start 1b72b31851fd\n# sudo docker attach 1b72b31851fd\nOK so, the APK worked, but some relevant files seem to be missing. For instance, I need to create the /etc/ansible directory, to then be able to add the hosts file in there.\nAs I use a port different from the default on my machines, I need to write the port number with the machine IP in the hosts inventory, so I put it like this (format, not what it actually looks like):\n[linux]\nIP:PORT\nThe Linux tag above will allow to run the Ansible playbooks by groups, in this case on all Linux boxes (only one for our example). Then to the actual test:\n# ansible all -m ping -u nico\n10.0.1.10 | SUCCESS =&gt; {\n   \"ansible_facts\": {\n     \"discovered_interpreter_python\": \"/usr/bin/python3\"\n   },\n   \"changed\": false,\n   \"ping\": \"pong\"\n}\nThat works! Let‚Äôs test some more data-gathering with Ansible:\nansible -m setup --tree out/ all -u nico\nThe output is too long here, but we‚Äôre getting somewhere indeed.¬† That‚Äôs essentially about hardware information. (And: No, I don‚Äôt really know what I‚Äôm doing. So going to the man pages (remember, RTFM): Apparently the -m is to point to a given module, in this case ‚Äúsetup‚Äù.¬† ‚Äìtree would be to indicate the output directory. ‚Äúall‚Äù apparently is indicating to run for all hosts in the inventory, in our case just the one. The last option is to indicate the username to use for the SSH connection, in this case the one for which we have configured the SSH Keys exchange a bit earlier).\nNow suppose we need to get to the software installed on a machine. Let‚Äôs see how that would go:\nThankfully, we‚Äôre not starting from scratch (I couldn‚Äôt learn that much Ansible with my available spare time right now). So for testing purposes, I‚Äôll use the example from here:\nhttps://www.jmrnet.tech/?p=26\nYou‚Äôll notice the reference to ‚Äúhosts: linux‚Äù in there, that‚Äôs why we put a name to our group in the hosts file earlier üòâ\n- name: Capture installed package information for Linux hosts\n  hosts: linux\n  tasks:\n  - name: Get the package facts from hosts\n   package_facts:\n    manager: auto\n  - name: Display output\n   debug:\n    var: ansible_facts.packages\nThen we save that as a YAML file, and we run it like so:\n# ansible-playbook -u nico installed_sw_base_playbook.yml\nAn extract of the results for instance (the list is looooong too):\n[...],\n\"vim\": [\n       {\n         \"arch\": \"amd64\",\n         \"category\": \"editors\",\n         \"name\": \"vim\",\n         \"origin\": \"Ubuntu\",\n         \"source\": \"apt\",\n         \"version\": \"2:8.1.2269-1ubuntu5\"\n       }\n     ],\n[...]\nAnd that‚Äôs about it. We now have a list of software components installed on the Home Lab Server, along with lots of Hardware data.\nDisclaimer: Right now I‚Äôll admit, I don‚Äôt exactly know HOW the commands and YAML files work just yet. It seems pretty straightfoward, but I haven‚Äôt investigated any further just yet. Even then, the thing is working, for a total of maybe 1h work üôÇ"
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html#conclusions",
    "href": "posts/2021-05-08_OnAnsible/index.html#conclusions",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "Conclusions",
    "text": "Conclusions\nKnowing what you have (be it for IT operations or for security posture understanding, cybersecurity operations and so on) is, I believe, quite important. The ‚ÄúAnsible way‚Äù is only one potential way to go about gathering information about Linux (and apparently Windows, and probably more) servers/machines.\nPlus I‚Äôve been meaning to get started with Ansible for a long time, so I thought I would give it a data-collection/security focus for the Blog.\nAnsible seems to be pretty cool indeed: Only Python is required on the managed nodes (as they seem to be called in Ansible Lingo ;)), which helps (as deploying agents on production machines is generally not a beloved approach‚Ä¶)"
  },
  {
    "objectID": "posts/2021-05-08_OnAnsible/index.html#resources",
    "href": "posts/2021-05-08_OnAnsible/index.html#resources",
    "title": "Gathering Security Data: Tests with Ansible",
    "section": "Resources",
    "text": "Resources\nAnsible Official Documentation\nThe blog post I used to find a workable playbook for software inventory\nGetting Ansible to work on Alpine Linux (for container)"
  },
  {
    "objectID": "posts/2025-11-23_MorePastPosts/index.html#it-turnt-out-its-a-lot",
    "href": "posts/2025-11-23_MorePastPosts/index.html#it-turnt-out-its-a-lot",
    "title": "Weekend of old blog posts migrations‚Ä¶",
    "section": "It turnt out, it‚Äôs a lot",
    "text": "It turnt out, it‚Äôs a lot\nSo I want to finalize at some point the migration of the Blog to github.io, just because I am so much fonder of that approach than the old Wordpress blog‚Ä¶\nBut, heck, I have written a lot in the past, haven‚Äôt I?"
  },
  {
    "objectID": "posts/2025-11-23_MorePastPosts/index.html#a-few-realizations",
    "href": "posts/2025-11-23_MorePastPosts/index.html#a-few-realizations",
    "title": "Weekend of old blog posts migrations‚Ä¶",
    "section": "A few realizations",
    "text": "A few realizations\nMy past posts were more varied, and I focused more on Cybersecurity. I should probably go back to these good habits.\nBut already in the past, I had periods of more focus for instance, similar to RLCS in the past‚Ä¶:\n\nMSc (which I‚Äôm simply not reproducing, that‚Äôs 10s of entries for something that is now closed, and fully described in the MSc thesis). Lots of writing will be lost and reflexions and showing the thought process, bumps in the road‚Ä¶\nThe ‚ÄúHome Lab‚Äù entries, which were quite varied and cool, much more SysAdmin-oriented, but‚Ä¶ I just probably would re-do from scratch next time around, and so‚Ä¶ I might very well not reproduce those.\n\nI mean, I might still restore these onto the new site, but‚Ä¶ Only if I truly have spare time. Which right now‚Ä¶ Is scarce."
  },
  {
    "objectID": "posts/2025-11-23_MorePastPosts/index.html#conclusions",
    "href": "posts/2025-11-23_MorePastPosts/index.html#conclusions",
    "title": "Weekend of old blog posts migrations‚Ä¶",
    "section": "Conclusions",
    "text": "Conclusions\nHaving written a lot I feel good about, and revisiting old entries to reproduce them on the new blog site (with better look & feel, thankfully :D), I re-discovered a few things. I have ‚Äúbeen cooking‚Äù these past few years, since starting the Blog, no questions there!\nBut I will probably have to make my peace with parting with some of it. It‚Äôs only natural. Not everything has aged equal. Although I can now see that deciding to start a Blog was truly a good choice for me, that doesn‚Äôt mean everything in there was great, either.\nI don‚Äôt know. I‚Äôll keep migrating old stuff in my spare time, just to make sure I don‚Äôt loose important stuff (for instance, I liked re-discovering this, this and this, or this, and that‚Ä¶)."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html",
    "title": "RLCS: Better code?",
    "section": "",
    "text": "Most of the code thus far was about getting it to work, and for it to not be too slow at runtime (with several approaches considered).\nAnd although I do try to not write pure garbage code, well, sometimes I‚Äôm not happy with the results.\nI rescued the (mostly yet unread) books I have from ‚ÄúUncle Bob‚Äù (see References) to get renewed inspiration on that topic."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#im-worried-about-my-code-being-too-ugly",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#im-worried-about-my-code-being-too-ugly",
    "title": "RLCS: Better code?",
    "section": "",
    "text": "Most of the code thus far was about getting it to work, and for it to not be too slow at runtime (with several approaches considered).\nAnd although I do try to not write pure garbage code, well, sometimes I‚Äôm not happy with the results.\nI rescued the (mostly yet unread) books I have from ‚ÄúUncle Bob‚Äù (see References) to get renewed inspiration on that topic."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#monadic-dyadic-functions",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#monadic-dyadic-functions",
    "title": "RLCS: Better code?",
    "section": "Monadic & Dyadic functions",
    "text": "Monadic & Dyadic functions\nWell, I understand the concept, but‚Ä¶ How do you pass one variable when you need to pass several hyperparameters for the algorithm to work?\nI‚Äôm sure this is not a correct solution, but I just decided to simply move the hyperparameters into an object (which, you know, can be a simple list underneath). That will make the calls cleaner for sure."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#very-similar-functions",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#very-similar-functions",
    "title": "RLCS: Better code?",
    "section": "Very similar functions",
    "text": "Very similar functions\nI have several functions that do almost exactly the same thing, just‚Ä¶ They act on a different parameter.\nThings like ‚Äúincrease_match_count()‚Äù, ‚Äúincrease_correct_count()‚Äù and ‚Äúincrease_action_count()‚Äù, as you can probably intuit, are basically the very same function.\nSo I‚Äôm thinking about not re-writing the complete functions (although, all of them are very very simple, in that they just lapply() and +1 a given parameter for a given population), and overload them, using a function factory (as described in ‚ÄúAdvanced R‚Äù). It‚Äôs probably best to do it that way, but I‚Äôll think about it, because if I need to expose said functions, then they‚Äôd have to have their own .R file each, and then it‚Äôs less self-explanatory‚Ä¶"
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#rl-is-im-still-not-doing-a-package-really",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#rl-is-im-still-not-doing-a-package-really",
    "title": "RLCS: Better code?",
    "section": "RL is‚Ä¶ I‚Äôm still not doing a package, really‚Ä¶",
    "text": "RL is‚Ä¶ I‚Äôm still not doing a package, really‚Ä¶\nI‚Äôm facing an issue in concept: How do you package a Reinforcement Learning Algorithm?\nI don‚Äôt see two ways around it, you must make assumptions about the environment for your agent(s).\nSo say the environment will be passed as a parameter.\nYou have no choice but to interact with it, and so it simply can‚Äôt expose just any interfaces. Things like ‚Äúagent_calls_action(agent, action)‚Äù, or ‚Äúget_action_score(agent, action)‚Äù (that will always return a valid (say, numeric) value) must be somehow standardized.\nMaybe you can require the environment object to answer correctly to ‚Äúlist_available_actions()‚Äù, but then, you need to probably ensure that these actions are all well controlled in different states, so that they are all legal actions whenever the agent calls them‚Ä¶ Or instead you might want to be able to call ‚Äúlist_legal_actions(agent)‚Äù out of your environment object at each stage‚Ä¶\nAnd so in ‚Äúwrapping‚Äù the RLCS code to make it into a package, I have to make assumptions about valid worlds/environment being provided, for RL.\nFor supervised learning, it not that much of an issue, although in the current state of affairs, you will need a specific environment. BUT the key difference is, you can test the complete environment for valid states and actions upon first call, and before you proceed with the algorithm run(s), so ideally you won‚Äôt run into invalid stuff upon working with the package in the future."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#parallel-processing-or-not",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#parallel-processing-or-not",
    "title": "RLCS: Better code?",
    "section": "Parallel processing or not?",
    "text": "Parallel processing or not?\nOne other key thing is processing time. We‚Äôve seen I have tried different calls to parallelize the thing and see what made sense, when. More or less.\nOne rather big issue is that the LCS algorithm is very sequential in nature. And so for large environments (i.e.¬†many states) or long (strings) states (i.e.¬†big search space), it can be slow, and there are not too many ways around it. But I have shown there are possibilities to consider. And I could make that part of the package itself, really.\nOne drawback however is that I have made some effort to limit as much as possible dependencies.\nI use plyr::rbind.fill(), and for the package code itself, I think that‚Äôs basically all of it. No other required library/function I haven‚Äôt coded myself.\n(For World Plotting or Classifier System Visuals, yes, maybe, but I‚Äôm considering leaving that as supplementary code, not part of the package, although I will say, visuals are important to make the thing more attractive‚Ä¶)\nRegardless, even with uncommon plotting functions, maybe I require (directly) 3 packages overall? And nothing such as ‚Äútidyverse‚Äù or other big metapackages.\nThat‚Äôs very much intentional (again, efficiency was a consideration, and I prefer smaller packages with shorter lists of dependencies‚Ä¶). Also, it makes maintainability better, surely (renv() or not).\nBut that‚Äôs a balancing exercise, isn‚Äôt it? And adding support for parallel processing is one set of potentially rather big dependencies. Plus, making sure that works cross-platforms‚Ä¶"
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#conclusions",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#conclusions",
    "title": "RLCS: Better code?",
    "section": "Conclusions",
    "text": "Conclusions\nThese and other similar considerations are in my head these days. Although I will also say, I‚Äôm taking it slow. The whole thing works, and it‚Äôs not awfully slow (considering what it could be).\nBut should the code be ‚Äúbetter looking‚Äù‚Ä¶\n\nI have next to no comments, for instance. Mainly because I try to use functions with self-explanatory names.\nI have done plenty of testing, for each function, but‚Ä¶ I haven‚Äôt done quite exactly TDD, namely I haven‚Äôt written down tests for each function in a neat file or set of test files‚Ä¶\nOther ideas, like functional approaches: There are still plenty of looping things happening. Should I use recursion, with TCO? I haven‚Äôt looked much into TCO in R, for instance, but if it worked nicely (i.e.¬†fast enough), maybe it would make sense for at least some of my funcions? Or does it? My experience with recursion in R is very bad, but I wasn‚Äôt aware of the TCO option. Memoizing could be another option, but there is quite a bit of stochastic stuff happening with this algorithm, and so that might not be a good idea at all.\nNot to mention, I haven‚Äôt even looked into RCpp for this package just yet. It kinda feels unnecessary at this stage but‚Ä¶ I also don‚Äôt have a comparison point, so maybe I‚Äôm loosing an opportunity to have things improving greatly right there? After all, I use vectorized operations (lapply() and al.) a lot, but maybe an RCpp loop of loops would run even faster? I haven‚Äôt tried it here.\n\nSo much to do still‚Ä¶\nAlso, I want to make a page dedicated to documenting this code/package, so that the algorithm can be understood, and presented. I‚Äôve pointed to great resources in the past to understand the algorithm. I just want to make something to explain the algorithm, with my own implementation. But that‚Äôs a different topic, I guess."
  },
  {
    "objectID": "posts/2025-04-24_RLCS_Code_Rework/index.html#resources",
    "href": "posts/2025-04-24_RLCS_Code_Rework/index.html#resources",
    "title": "RLCS: Better code?",
    "section": "Resources",
    "text": "Resources\nClean Code, by R. C. Martin (‚ÄúUncle Bob‚Äù)\nFunctional Design, by R. C. Martin (‚ÄúUncle Bob‚Äù)\nAdvanced R, by H. Wickham"
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "I‚Äôve already tried to parallelize a bit the training of a supervised-learning LCS. It kinda‚Äô works‚Ä¶ But the more I think about it, the more I‚Äôm convinced it‚Äôs not as easy as I thought.\nI initially thought of one way of parallel processing: Break the training samples in N (as many as CPU cores you wanna use) subsets, train N LCS.\nThen ‚Äúmerge‚Äù, subsume, remove duplicates, and‚Ä¶ Repeat.\nIdeally you would bootstrap the thing with an initial epoch on all the training set, just to have relevant coverage to start with.\nBut there is an issue: What if your dataset is ‚Äúnot perfect‚Äù? Let‚Äôs suppose there isn‚Äôt a clear-cut separation between classes to be found, but rather a fuzzy separation. So there aren‚Äôt perfect rules to be discovered. Instead, in each subset, some rules work, but THEN when these are exposed to the complete dataset, the discovered classes in one subset is correct in that subset, but NOT in the overall training data?\nYou end up with classifiers that‚Ä¶ Don‚Äôt work over test sets.\nAt least that‚Äôs my current conclusion after trying it with some messier-than-perfect datasets.\n\n\n\nSo if breaking the dataset in sub-sets does not work‚Ä¶ What about breaking the data POINTS in different parts?\nIn my earlier example, I have tested (quite successfully, in my view) my RLCS on a simplified MNIST exercise.\nThere, I was training to classify images. The original images where too big, in their equivalent bit-strings representation, for my laptop to work on in acceptable runtimes (for my taste). I ended up compressing said images into 49 bits strings per image. It was then manageable, and it worked quite good, in little over 20 seconds of training (with the correct hyper-parameters).\nBut could I instead break each images in say 7x7 lines, and train on each line separately (and in parallel), and then train one more LCS on the result of that (so 7 outputs would become the input states for a new classifier system, another 7-bits train set, so to speak)?\nI would then in effect, in terms of overall processing time, train approximately twice on 7 bits strings, instead of once on 49 bits strings.\nWould that even work? More on that later.\nBut first‚Ä¶\n\n\n\nEpistasis!\nWell, at least that‚Äôs how I understand it right now: Two (or more) different locations of the ‚Äúgenome‚Äù are required to define the phenotype. In my simple RLCS, in that case two or more bits in a state interact in a more or less complex manner so that the class is decided by said interaction. THEN, the second approach would break the assumptions!\nThink of the ‚ÄúMux6‚Äù example explained in this Blog a few entries ago. Two bits pointed to a position, which value was the class to be predicted. In that example, the first two bits pointed to a position in the last 4 bits.\nIF I were to break the 6 bits states in say two sub-strings of 3 bits each, thinking I can learn from each sub-string and then recompose (see ‚Äúidea version 2‚Äù above)‚Ä¶ I would fail miserably: you need the complete 6-bit strings in that example for the LCS to come up with the relevant rules!\nThat said‚Ä¶\n\n\n\nI‚Äôve shown ad-nauseam by now the ‚Äúnot-bit-4‚Äù example. In the example so far, I have used 5 bits strings. So the ‚Äúsearch space‚Äù was that of 5 bits. And the solution was simple in that one bit would suffice to predict the whole class.\nBut that was arbitrary, and meant to be simple.\nWhat if we were to be faced with the exact same rule to be found in 10-bits strings? The solution would be just as simple (two rules would suffice), but the search space would be comparatively‚Ä¶ Well, way bigger.\nIn 5-bits, the not-bit-4 is fully expressed with 32 states.\nIn 10-bits, the SAME not-bit-4 classifier works with‚Ä¶ 1024 states (total). For a perfect data mining exercise, you need to find a ruleset that perfectly matches all 1024 states, and you need to try combinations of 3 possible values per-bit (our ternary alphabet: {‚Äò#‚Äô, ‚Äò0‚Äô, ‚Äò1‚Äô}). If I‚Äôm correct, that could be up to about 3^10*2 (including class) 59049-1 possible unique classifiers to potentially check (coverage ensures here that not-bit-4 is respected, so that‚Äôs only half the overall 10 bits strings + class, as half are illegal, making it a 3^10 matter‚Ä¶ And the ‚Äò##########‚Äô option is not valid for us‚Ä¶). Well, approximately anyway.\nAnd let‚Äôs remember, an LCS is expected to output a combination subset of these ~59K classifiers as an output System, which could be a very large search space indeed‚Ä¶ (In a real world setup, that is.)\nHowever! Well, let‚Äôs try to apply the logic of my ‚Äúapproach number 2‚Äù above to break down the exercise and then see what would happen in such a simple case‚Ä¶\nImagine I break down the exercise into 3 ‚Äútrainings‚Äù:\n\nThe first 5 bits (which in fact are more than enough) per state, creating \\(RLCS_1\\)\nThe last 5 bits per state (completely irrelevant, but we don‚Äôt know that upfront), creating \\(RLCS_2\\)\nThen the outputs of the above to train a third LCS, \\(RLCS_{combined}\\)\n\nThe hope is that we can train the first two in parallel, and use the predictions of these two in combination to then train a third classifier (which incidentally here would be exposed to 2-bits states). So I‚Äôd expect to reduce the search space quite a bit. And hence the training times.\nWell, with no further ado, here come the initial results, and heck!\nParallel runtime using the approach described here to break the problem in just two 5-bit string sub-problems, less than 5 seconds:\n\n\n\nbreaking original problem in two makes it fast!\n\n\nCompared to original sequential time on the 10-bit string, more than 4 minutes:\n\n\n\nThat worked, just‚Ä¶ Very slow, comparatively\n\n\nThe result however is slightly more difficult to interpret (that is, in the current version of this exercise, which I just wanted to see working, but it is not clean‚Ä¶). In particular, each subset I have to keep (for now) better than chance results (anything &gt; 0.5), but that‚Äôs just because it‚Äôs a dirty example, it can be made cleaner for sure:\n\n\n\nFast results, but requires a bit more work to interpret\n\n\nStill, from ‚Äú&gt; 4 minutes‚Äù to ‚Äú&lt; 5 seconds‚Äù! But then again, this will only works for such a problem where the solution did exist in a subset of original bit-strings.\n\n\n\nWell, for one, I am NOT in fact browsing in parallel through 1024 states!\nSee, each sub-string of 5 bits and its class, as a subset can be de-duplicated! There are a lot of repeated instances, say in the first subset, whereby all entries that say ‚Äú00000 -&gt; class 1‚Äù appear 32 times (one for each of the continuing 5-bit strings for the rest of the original state).\nThat kind of deduplication can reduce processing efforts indeed :)\n\n\n\nI haven‚Äôt tested it yet, but I would wager this approach should work just fine on images too, as described above, breaking images in lines and then combining classifiers‚Ä¶\nParallelizing training is an obvious idea (to me) in concept: For some examples, training is slow, and so running it in N parallel processes must be faster (for, you know, complicated examples).\nBut as explained in some detail today, it‚Äôs not that simple! It might work in some cases, as explained, but in the ‚Äúreal world‚Äù, we wouldn‚Äôt know upfront whether it would in fact work, would we? And so we might have to do some trial-and-error‚Ä¶\nBut even just running tests on new datasets, as explained above, might allow us to:\n\nEither see how we can run fast in parallel on a given dataset and still work out a solution\nOr find out that the dataset cannot be broken the way we have initially chosen, indicating possible ‚Äúepistasis‚Äù, which in itself would be interesting and would have just supposed a few seconds lost here.\nOr ‚Äì and that could happen ‚Äì that the chosen dataset cannot be broken down as we would like it to, for an LCS to come up with a proposed classification solution as there is not a very clear-cut solution (think Yahoo finance historical data‚Ä¶ Yes, I‚Äôve had a quick look. Suffice to say, I won‚Äôt beat the markets just yet :D:D:D But that‚Äôs not relevant‚Ä¶ )\n\nI‚Äôll work on that parallelizing stuff some more‚Ä¶ Even if that‚Äôs not part of the package itself, it‚Äôs more about data preparation and how to use the package, I am aware. But demonstrating how the future RLCS package can hopefully be used and competitive compared to a Neural Network (for instance) is part of my overall objective, I guess.\nFun stuff (to me) all of it :)"
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-idea",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-idea",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "I‚Äôve already tried to parallelize a bit the training of a supervised-learning LCS. It kinda‚Äô works‚Ä¶ But the more I think about it, the more I‚Äôm convinced it‚Äôs not as easy as I thought.\nI initially thought of one way of parallel processing: Break the training samples in N (as many as CPU cores you wanna use) subsets, train N LCS.\nThen ‚Äúmerge‚Äù, subsume, remove duplicates, and‚Ä¶ Repeat.\nIdeally you would bootstrap the thing with an initial epoch on all the training set, just to have relevant coverage to start with.\nBut there is an issue: What if your dataset is ‚Äúnot perfect‚Äù? Let‚Äôs suppose there isn‚Äôt a clear-cut separation between classes to be found, but rather a fuzzy separation. So there aren‚Äôt perfect rules to be discovered. Instead, in each subset, some rules work, but THEN when these are exposed to the complete dataset, the discovered classes in one subset is correct in that subset, but NOT in the overall training data?\nYou end up with classifiers that‚Ä¶ Don‚Äôt work over test sets.\nAt least that‚Äôs my current conclusion after trying it with some messier-than-perfect datasets."
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-idea-version-2",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-idea-version-2",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "So if breaking the dataset in sub-sets does not work‚Ä¶ What about breaking the data POINTS in different parts?\nIn my earlier example, I have tested (quite successfully, in my view) my RLCS on a simplified MNIST exercise.\nThere, I was training to classify images. The original images where too big, in their equivalent bit-strings representation, for my laptop to work on in acceptable runtimes (for my taste). I ended up compressing said images into 49 bits strings per image. It was then manageable, and it worked quite good, in little over 20 seconds of training (with the correct hyper-parameters).\nBut could I instead break each images in say 7x7 lines, and train on each line separately (and in parallel), and then train one more LCS on the result of that (so 7 outputs would become the input states for a new classifier system, another 7-bits train set, so to speak)?\nI would then in effect, in terms of overall processing time, train approximately twice on 7 bits strings, instead of once on 49 bits strings.\nWould that even work? More on that later.\nBut first‚Ä¶"
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-caveat",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#the-caveat",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "Epistasis!\nWell, at least that‚Äôs how I understand it right now: Two (or more) different locations of the ‚Äúgenome‚Äù are required to define the phenotype. In my simple RLCS, in that case two or more bits in a state interact in a more or less complex manner so that the class is decided by said interaction. THEN, the second approach would break the assumptions!\nThink of the ‚ÄúMux6‚Äù example explained in this Blog a few entries ago. Two bits pointed to a position, which value was the class to be predicted. In that example, the first two bits pointed to a position in the last 4 bits.\nIF I were to break the 6 bits states in say two sub-strings of 3 bits each, thinking I can learn from each sub-string and then recompose (see ‚Äúidea version 2‚Äù above)‚Ä¶ I would fail miserably: you need the complete 6-bit strings in that example for the LCS to come up with the relevant rules!\nThat said‚Ä¶"
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#counter-caveat-not-bit-4-in-10-bits-states",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#counter-caveat-not-bit-4-in-10-bits-states",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "I‚Äôve shown ad-nauseam by now the ‚Äúnot-bit-4‚Äù example. In the example so far, I have used 5 bits strings. So the ‚Äúsearch space‚Äù was that of 5 bits. And the solution was simple in that one bit would suffice to predict the whole class.\nBut that was arbitrary, and meant to be simple.\nWhat if we were to be faced with the exact same rule to be found in 10-bits strings? The solution would be just as simple (two rules would suffice), but the search space would be comparatively‚Ä¶ Well, way bigger.\nIn 5-bits, the not-bit-4 is fully expressed with 32 states.\nIn 10-bits, the SAME not-bit-4 classifier works with‚Ä¶ 1024 states (total). For a perfect data mining exercise, you need to find a ruleset that perfectly matches all 1024 states, and you need to try combinations of 3 possible values per-bit (our ternary alphabet: {‚Äò#‚Äô, ‚Äò0‚Äô, ‚Äò1‚Äô}). If I‚Äôm correct, that could be up to about 3^10*2 (including class) 59049-1 possible unique classifiers to potentially check (coverage ensures here that not-bit-4 is respected, so that‚Äôs only half the overall 10 bits strings + class, as half are illegal, making it a 3^10 matter‚Ä¶ And the ‚Äò##########‚Äô option is not valid for us‚Ä¶). Well, approximately anyway.\nAnd let‚Äôs remember, an LCS is expected to output a combination subset of these ~59K classifiers as an output System, which could be a very large search space indeed‚Ä¶ (In a real world setup, that is.)\nHowever! Well, let‚Äôs try to apply the logic of my ‚Äúapproach number 2‚Äù above to break down the exercise and then see what would happen in such a simple case‚Ä¶\nImagine I break down the exercise into 3 ‚Äútrainings‚Äù:\n\nThe first 5 bits (which in fact are more than enough) per state, creating \\(RLCS_1\\)\nThe last 5 bits per state (completely irrelevant, but we don‚Äôt know that upfront), creating \\(RLCS_2\\)\nThen the outputs of the above to train a third LCS, \\(RLCS_{combined}\\)\n\nThe hope is that we can train the first two in parallel, and use the predictions of these two in combination to then train a third classifier (which incidentally here would be exposed to 2-bits states). So I‚Äôd expect to reduce the search space quite a bit. And hence the training times.\nWell, with no further ado, here come the initial results, and heck!\nParallel runtime using the approach described here to break the problem in just two 5-bit string sub-problems, less than 5 seconds:\n\n\n\nbreaking original problem in two makes it fast!\n\n\nCompared to original sequential time on the 10-bit string, more than 4 minutes:\n\n\n\nThat worked, just‚Ä¶ Very slow, comparatively\n\n\nThe result however is slightly more difficult to interpret (that is, in the current version of this exercise, which I just wanted to see working, but it is not clean‚Ä¶). In particular, each subset I have to keep (for now) better than chance results (anything &gt; 0.5), but that‚Äôs just because it‚Äôs a dirty example, it can be made cleaner for sure:\n\n\n\nFast results, but requires a bit more work to interpret\n\n\nStill, from ‚Äú&gt; 4 minutes‚Äù to ‚Äú&lt; 5 seconds‚Äù! But then again, this will only works for such a problem where the solution did exist in a subset of original bit-strings."
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#trick-why-so-fast",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#trick-why-so-fast",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "Well, for one, I am NOT in fact browsing in parallel through 1024 states!\nSee, each sub-string of 5 bits and its class, as a subset can be de-duplicated! There are a lot of repeated instances, say in the first subset, whereby all entries that say ‚Äú00000 -&gt; class 1‚Äù appear 32 times (one for each of the continuing 5-bit strings for the rest of the original state).\nThat kind of deduplication can reduce processing efforts indeed :)"
  },
  {
    "objectID": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#conclusion",
    "href": "posts/2025-01-26_About_Parallelizing_RLCS_Training/index.html#conclusion",
    "title": "RLCS: training in parallel?",
    "section": "",
    "text": "I haven‚Äôt tested it yet, but I would wager this approach should work just fine on images too, as described above, breaking images in lines and then combining classifiers‚Ä¶\nParallelizing training is an obvious idea (to me) in concept: For some examples, training is slow, and so running it in N parallel processes must be faster (for, you know, complicated examples).\nBut as explained in some detail today, it‚Äôs not that simple! It might work in some cases, as explained, but in the ‚Äúreal world‚Äù, we wouldn‚Äôt know upfront whether it would in fact work, would we? And so we might have to do some trial-and-error‚Ä¶\nBut even just running tests on new datasets, as explained above, might allow us to:\n\nEither see how we can run fast in parallel on a given dataset and still work out a solution\nOr find out that the dataset cannot be broken the way we have initially chosen, indicating possible ‚Äúepistasis‚Äù, which in itself would be interesting and would have just supposed a few seconds lost here.\nOr ‚Äì and that could happen ‚Äì that the chosen dataset cannot be broken down as we would like it to, for an LCS to come up with a proposed classification solution as there is not a very clear-cut solution (think Yahoo finance historical data‚Ä¶ Yes, I‚Äôve had a quick look. Suffice to say, I won‚Äôt beat the markets just yet :D:D:D But that‚Äôs not relevant‚Ä¶ )\n\nI‚Äôll work on that parallelizing stuff some more‚Ä¶ Even if that‚Äôs not part of the package itself, it‚Äôs more about data preparation and how to use the package, I am aware. But demonstrating how the future RLCS package can hopefully be used and competitive compared to a Neural Network (for instance) is part of my overall objective, I guess.\nFun stuff (to me) all of it :)"
  },
  {
    "objectID": "posts/2025-01-25_RLCS_4_DataMining/index.html",
    "href": "posts/2025-01-25_RLCS_4_DataMining/index.html",
    "title": "RLCS: for Data Mining",
    "section": "",
    "text": "The exact same code to do supervised learning can be used for data mining. In fact, I‚Äôve already shown that, with the ‚Äúnot-bit-4‚Äù example.\nThe approach is simple: Instead of training (and then testing with new data), suppose what you want to understand something about your data. Then you can show it all to the LCS for it to come up with rules. If you‚Äôre lucky, your data has hidden rules that you didn‚Äôt know about.\n\n\n\nSo we‚Äôve seen it already, the ‚Äúnot-bit-4‚Äù example. Well, the LCS can try to find out for you:\n\n\n\nit looks easier like this, doesn‚Äôt it?\n\n\nBut what if what you have is this? Not so easy to find the rule manually, right?\n\n\n\nWhat if your data looks like so?\n\n\nMaybe too easy? But it‚Äôs the concept that matters! Let‚Äôs try a different example. See if you can spot it:\n\n\n\nThis one is just slightly trickier‚Ä¶\n\n\nThe LCS only takes a few second‚Ä¶\n\n\n\nprocessing for simple cases is rather fast\n\n\nAnd finds the rules (4 in this case):\n\n\n\nBit 4 XOR bit 5\n\n\nThat‚Äôs how the LCS here expresses ‚Äúbit 4 XOR bit 5‚Äù. And yes, that was it.\nEnough with the examples. But conceptually, the ‚ÄúMux6‚Äù example for the last entry? Same-same.\nAnd more to the point, I had 6 bits inputs here, but what if there are 10 bits? 20 bits? Would you be able to manually find similar rules? It would take me some time :D\nSure, the algorithm is slower with 20 bits instead of 6 (can you blame it?). But it‚Äôs machine time. :)\n\n\n\nI actually have a use-case at work I want to test this on. As soon as I upload a first version of my project to GitHub, I‚Äôll be able to test it there. I have inventories and some things about them I want to know whether I can explain with short, readable rules. I think the LCS might help. Although‚Ä¶ Maybe there is no simple rule to be found, but that‚Äôs worth trying.\nThe trick there will be: How to encode the data into binary strings, as this is what my code accepts‚Ä¶? But I actually know how to go about that.\n\n\n\nWell, I just like the idea that the same Supervised Learning algorithm can be used to do Data mining. And provide interpretable information about some datasets (if there is something to be found, that is).\nTake that, Neural Networks! :D\nAlright, I guess next week I‚Äôll return to working on the package itself."
  },
  {
    "objectID": "posts/2025-01-25_RLCS_4_DataMining/index.html#lcs-for-data-mining",
    "href": "posts/2025-01-25_RLCS_4_DataMining/index.html#lcs-for-data-mining",
    "title": "RLCS: for Data Mining",
    "section": "",
    "text": "The exact same code to do supervised learning can be used for data mining. In fact, I‚Äôve already shown that, with the ‚Äúnot-bit-4‚Äù example.\nThe approach is simple: Instead of training (and then testing with new data), suppose what you want to understand something about your data. Then you can show it all to the LCS for it to come up with rules. If you‚Äôre lucky, your data has hidden rules that you didn‚Äôt know about."
  },
  {
    "objectID": "posts/2025-01-25_RLCS_4_DataMining/index.html#demonstration",
    "href": "posts/2025-01-25_RLCS_4_DataMining/index.html#demonstration",
    "title": "RLCS: for Data Mining",
    "section": "",
    "text": "So we‚Äôve seen it already, the ‚Äúnot-bit-4‚Äù example. Well, the LCS can try to find out for you:\n\n\n\nit looks easier like this, doesn‚Äôt it?\n\n\nBut what if what you have is this? Not so easy to find the rule manually, right?\n\n\n\nWhat if your data looks like so?\n\n\nMaybe too easy? But it‚Äôs the concept that matters! Let‚Äôs try a different example. See if you can spot it:\n\n\n\nThis one is just slightly trickier‚Ä¶\n\n\nThe LCS only takes a few second‚Ä¶\n\n\n\nprocessing for simple cases is rather fast\n\n\nAnd finds the rules (4 in this case):\n\n\n\nBit 4 XOR bit 5\n\n\nThat‚Äôs how the LCS here expresses ‚Äúbit 4 XOR bit 5‚Äù. And yes, that was it.\nEnough with the examples. But conceptually, the ‚ÄúMux6‚Äù example for the last entry? Same-same.\nAnd more to the point, I had 6 bits inputs here, but what if there are 10 bits? 20 bits? Would you be able to manually find similar rules? It would take me some time :D\nSure, the algorithm is slower with 20 bits instead of 6 (can you blame it?). But it‚Äôs machine time. :)"
  },
  {
    "objectID": "posts/2025-01-25_RLCS_4_DataMining/index.html#so-what",
    "href": "posts/2025-01-25_RLCS_4_DataMining/index.html#so-what",
    "title": "RLCS: for Data Mining",
    "section": "",
    "text": "I actually have a use-case at work I want to test this on. As soon as I upload a first version of my project to GitHub, I‚Äôll be able to test it there. I have inventories and some things about them I want to know whether I can explain with short, readable rules. I think the LCS might help. Although‚Ä¶ Maybe there is no simple rule to be found, but that‚Äôs worth trying.\nThe trick there will be: How to encode the data into binary strings, as this is what my code accepts‚Ä¶? But I actually know how to go about that."
  },
  {
    "objectID": "posts/2025-01-25_RLCS_4_DataMining/index.html#conclusion",
    "href": "posts/2025-01-25_RLCS_4_DataMining/index.html#conclusion",
    "title": "RLCS: for Data Mining",
    "section": "",
    "text": "Well, I just like the idea that the same Supervised Learning algorithm can be used to do Data mining. And provide interpretable information about some datasets (if there is something to be found, that is).\nTake that, Neural Networks! :D\nAlright, I guess next week I‚Äôll return to working on the package itself."
  },
  {
    "objectID": "posts/2025-06-08_Schelling_Segregation_Model/index.html",
    "href": "posts/2025-06-08_Schelling_Segregation_Model/index.html",
    "title": "Classic Computational Social Model: Schelling‚Äôs Segregation",
    "section": "",
    "text": "And I thought some of these ideas were quite interesting. I don‚Äôt know yet what to make of it all (I haven‚Äôt read it all, either). It feels some of it is related to cybernetics, feedback loops, agents-based modelling (that last one, for sure). I am not the biggest fan of sociology, but these agents ideas have me curious though.\nAnyhow, so I was reading on that topic, of modelling things from a bottoms-up perspective, with independent agents making their own decisions, and of course whether there is an emergent behaviour then is interesting.\nOne such social model is the ‚Äúclassic‚Äù computational model of Schelling (1978). I‚Äôm not a fan of the concept it illustrates (supposedly related to some concept of segregation, whichever the kind or inspiratioin‚Ä¶). But the thing is, the emergent behavior of some level of self-organization is interesting, in-as-much there is no central push here for organization, just agents preferences ‚Äúplaying out‚Äù."
  },
  {
    "objectID": "posts/2025-06-08_Schelling_Segregation_Model/index.html#i-was-reading-about-complex-adaptive-systems",
    "href": "posts/2025-06-08_Schelling_Segregation_Model/index.html#i-was-reading-about-complex-adaptive-systems",
    "title": "Classic Computational Social Model: Schelling‚Äôs Segregation",
    "section": "",
    "text": "And I thought some of these ideas were quite interesting. I don‚Äôt know yet what to make of it all (I haven‚Äôt read it all, either). It feels some of it is related to cybernetics, feedback loops, agents-based modelling (that last one, for sure). I am not the biggest fan of sociology, but these agents ideas have me curious though.\nAnyhow, so I was reading on that topic, of modelling things from a bottoms-up perspective, with independent agents making their own decisions, and of course whether there is an emergent behaviour then is interesting.\nOne such social model is the ‚Äúclassic‚Äù computational model of Schelling (1978). I‚Äôm not a fan of the concept it illustrates (supposedly related to some concept of segregation, whichever the kind or inspiratioin‚Ä¶). But the thing is, the emergent behavior of some level of self-organization is interesting, in-as-much there is no central push here for organization, just agents preferences ‚Äúplaying out‚Äù."
  },
  {
    "objectID": "posts/2025-06-08_Schelling_Segregation_Model/index.html#the-algorithm-and-the-results",
    "href": "posts/2025-06-08_Schelling_Segregation_Model/index.html#the-algorithm-and-the-results",
    "title": "Classic Computational Social Model: Schelling‚Äôs Segregation",
    "section": "The algorithm and the results",
    "text": "The algorithm and the results\nSo the concept is pretty simple. You have ‚Äúagents‚Äù (say, people), that prefer to ‚Äúlive next to one another‚Äù if they are of the same type. What that means is up to the reader, I don‚Äôt mind.\nHere, it just means, ‚Äúgreen agents‚Äù will prefer to move if less than 30% of their neighbours are also green. ‚ÄúRed agents‚Äù are less tolerant and want at least 50% of their neighbours to be red as well.\nIf those wishes are not fulfilled, the agents will move to a random (empty) location. We then iterate a few steps of time. At each step, each agent is asked in turn whether they want to move.\nThat‚Äôs two loops, and a very simple logic. We start out with a ‚Äúrandom‚Äù world, with roughly (in this example) 33% of cells filled with green agents, 33% of red agents, 33% of empty cells.\nThat‚Äôs it.\nAnd with just the agents‚Äô preferences, you can probably already guess what will happen. But the fun part is, there will be organization, without a central policy or ruling system, and even though none of the agents prefers to have a majority of the same type of agents. And yet‚Ä¶\nHere the resulting animation of 1 run of said algorithm:"
  },
  {
    "objectID": "posts/2025-06-08_Schelling_Segregation_Model/index.html#conclusions",
    "href": "posts/2025-06-08_Schelling_Segregation_Model/index.html#conclusions",
    "title": "Classic Computational Social Model: Schelling‚Äôs Segregation",
    "section": "Conclusions",
    "text": "Conclusions\nThis was more of an interlude than anything else. I am far from done with the RLCS work. But I can‚Äôt avoid looking into more stuff.\nThe agents-based ideas, complex systems, systems theory, cybernetics, etc. is always quite fascinating to me.\nAnd so I wanted to do one exercise while I had it in mind. The book didn‚Äôt say how to implement it, but gave out enough of the concepts to easily make it into a working demo program."
  },
  {
    "objectID": "posts/2025-06-08_Schelling_Segregation_Model/index.html#references",
    "href": "posts/2025-06-08_Schelling_Segregation_Model/index.html#references",
    "title": "Classic Computational Social Model: Schelling‚Äôs Segregation",
    "section": "References",
    "text": "References\nThe book inspiring this post."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I have yet another day off (that‚Äôs the thing with Holiday season), and I really wanted to keep working on this.\nSo I added the Genetic Algorithm part to my Supervised Learning basic Michigan-style LCS.\nThat means, after covering (done last Sunday) I am done with the (basic) implementation of the Rule Discovery features of the LCS algorithm.\nAnd, heck, it works.\n\n\n\nSo we had covering, whereby new rules were created when none in the classifiers matched the a new-coming environment instance.\nBut this is only part of the discovery of new rules. The second part in the Michigan-style LCS is that of a Genetic Algorithm.\nI implemented now a simple version, with tournament parents selection. That is, from the Correct set (see past entries) ‚Äì but taking numerosity of classifiers into account ‚Äì I choose N (a parameter) parents randomly. Then I take the best 2 parents by fitness. Which is ellitist.\nThen I run a one-point cross-over, to generate 2 children.\nI apply mutation to the children genes in turn, with a mutation pressure set as yet another parameter (default is 5% in my implementation).\nAnd finally I add the children to the population.\nNote that children mutations ensure only valid rules are created (i.e.¬†condition is compatible with the training instance). Mutations either generalize (add a wildcard) or specify (replaces a wildcard by a 0 or 1, depending on training instance).\nFully general (‚Äúall wildcard‚Äù) individuals are of course discarded. If a child actually matches by condition an individual in the correct set, it is discarded and the repeated classifier instead get a numerosity increase.\nAnd that‚Äôs IT!\n\n\n\nIn my current dummy example, whereby the goal is for the LCS to discover the rule ‚ÄúClass is NOT(bit 4 of input state)‚Äù, well‚Ä¶ In manual runs (several of them), I often (not always, mind you) find the two best rules are perfect rules:\n\n\n\nPerfect Rules are often discovered!\n\n\n\n\n\nThe first two rules (ordered by accuracy and numerosity, both decreasing) are the exact rules that perfectly will always predict the correct class/action, and are perfectly balanced in this case between general and specific.\nThese are the kind of things that an LCS provides that a Neural Network won‚Äôt:\nIt tells you WHY it makes a decision.\nHere, it is saying:\n\nRule 1: If bit 4 is 0, then class is 1. I am 100% accurate, whenever that happens.\nRule 2: If bit 4 is 1, then class is 0. I am 100% accurate, whenever that happens.\n\nWhich is exactly what this dummy training data set was trying to say in the first place, with 70% of the training possibilities shown to train the algorithm.\nObviously this is‚Ä¶ A somewhat silly example. But the thing is, I did NOT tell it how to get there, and it got the IF THEN ELSE correctly on its own.\n\n\n\nEvery now and then (after a certain number of Epochs) I run a Deletion process, whereby rules that have Numerosity 1 are discarded, thereby containing the size of the set of classifiers.\nThis is important for interpretability and performance.\n\n\n\nI am quite happy that after only a couple of days of coding, I have a basic, perfectly functional LCS!\nI do miss two components: Subsumption and Compaction.\nPlus of course the Prediction, that comes after training, on a test subset.\nIt‚Äôs all on my to-do, but this thing is already promising!\nGranted, it‚Äôs not real fast. And the code is far from perfect, or duly organized. But it works!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#intro",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#intro",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I have yet another day off (that‚Äôs the thing with Holiday season), and I really wanted to keep working on this.\nSo I added the Genetic Algorithm part to my Supervised Learning basic Michigan-style LCS.\nThat means, after covering (done last Sunday) I am done with the (basic) implementation of the Rule Discovery features of the LCS algorithm.\nAnd, heck, it works."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#what-the-ga-does",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#what-the-ga-does",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "So we had covering, whereby new rules were created when none in the classifiers matched the a new-coming environment instance.\nBut this is only part of the discovery of new rules. The second part in the Michigan-style LCS is that of a Genetic Algorithm.\nI implemented now a simple version, with tournament parents selection. That is, from the Correct set (see past entries) ‚Äì but taking numerosity of classifiers into account ‚Äì I choose N (a parameter) parents randomly. Then I take the best 2 parents by fitness. Which is ellitist.\nThen I run a one-point cross-over, to generate 2 children.\nI apply mutation to the children genes in turn, with a mutation pressure set as yet another parameter (default is 5% in my implementation).\nAnd finally I add the children to the population.\nNote that children mutations ensure only valid rules are created (i.e.¬†condition is compatible with the training instance). Mutations either generalize (add a wildcard) or specify (replaces a wildcard by a 0 or 1, depending on training instance).\nFully general (‚Äúall wildcard‚Äù) individuals are of course discarded. If a child actually matches by condition an individual in the correct set, it is discarded and the repeated classifier instead get a numerosity increase.\nAnd that‚Äôs IT!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#results-with-fully-functional-rule-discovery",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#results-with-fully-functional-rule-discovery",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "In my current dummy example, whereby the goal is for the LCS to discover the rule ‚ÄúClass is NOT(bit 4 of input state)‚Äù, well‚Ä¶ In manual runs (several of them), I often (not always, mind you) find the two best rules are perfect rules:\n\n\n\nPerfect Rules are often discovered!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#important-what-the-rules-set-tells-us",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#important-what-the-rules-set-tells-us",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "The first two rules (ordered by accuracy and numerosity, both decreasing) are the exact rules that perfectly will always predict the correct class/action, and are perfectly balanced in this case between general and specific.\nThese are the kind of things that an LCS provides that a Neural Network won‚Äôt:\nIt tells you WHY it makes a decision.\nHere, it is saying:\n\nRule 1: If bit 4 is 0, then class is 1. I am 100% accurate, whenever that happens.\nRule 2: If bit 4 is 1, then class is 0. I am 100% accurate, whenever that happens.\n\nWhich is exactly what this dummy training data set was trying to say in the first place, with 70% of the training possibilities shown to train the algorithm.\nObviously this is‚Ä¶ A somewhat silly example. But the thing is, I did NOT tell it how to get there, and it got the IF THEN ELSE correctly on its own."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#deletion-is-also-implemented",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#deletion-is-also-implemented",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "Every now and then (after a certain number of Epochs) I run a Deletion process, whereby rules that have Numerosity 1 are discarded, thereby containing the size of the set of classifiers.\nThis is important for interpretability and performance."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#conclusion",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#conclusion",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I am quite happy that after only a couple of days of coding, I have a basic, perfectly functional LCS!\nI do miss two components: Subsumption and Compaction.\nPlus of course the Prediction, that comes after training, on a test subset.\nIt‚Äôs all on my to-do, but this thing is already promising!\nGranted, it‚Äôs not real fast. And the code is far from perfect, or duly organized. But it works!"
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html",
    "href": "posts/2021-08-08_NLP_partIII/index.html",
    "title": "Parts of Speech Tagging",
    "section": "",
    "text": "So I‚Äôve been working on other things lately, but I wanted to keep improving/practicing a bit with the NLP concepts.\nAs I mentioned already, I spent a bit of my (little) spare time to review concepts. One book I am finding I rely heavily upon is ‚ÄúMastering Text Mining with R‚Äù, from the Packt Editorial.\nToday I choose to test some ‚ÄúParts of Speech‚Äù tagging, using my own Blog as reference text."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#intro",
    "href": "posts/2021-08-08_NLP_partIII/index.html#intro",
    "title": "Parts of Speech Tagging",
    "section": "",
    "text": "So I‚Äôve been working on other things lately, but I wanted to keep improving/practicing a bit with the NLP concepts.\nAs I mentioned already, I spent a bit of my (little) spare time to review concepts. One book I am finding I rely heavily upon is ‚ÄúMastering Text Mining with R‚Äù, from the Packt Editorial.\nToday I choose to test some ‚ÄúParts of Speech‚Äù tagging, using my own Blog as reference text."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#getting-the-text",
    "href": "posts/2021-08-08_NLP_partIII/index.html#getting-the-text",
    "title": "Parts of Speech Tagging",
    "section": "Getting the text",
    "text": "Getting the text\nSo we already did that in past entries, which means I‚Äôll skip it here and assume you get your text in a variable.\nIn our case, we ran the function ‚Äúget_all_articles_kaizen_blog_vfuture()‚Äù from this code and ended up with all the blog entries in a dataframe called ‚Äúall_articles_df_vfuture‚Äù.\nall_articles_df_vfuture &lt;- get_all_articles_kaizen_blog_vfuture()\nThe first article (the last one published) is now in the first row of that data frame, and its text, on which we focus today, is in the column ‚Äúarticle_content‚Äù:\nt_strings &lt;- as.String(all_articles_df_vfuture$article_content[1])\n¬†So from now on, we‚Äôll assume you have one text in a variable called t_strings, of type ‚ÄúString‚Äù."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#first-extract-sentences",
    "href": "posts/2021-08-08_NLP_partIII/index.html#first-extract-sentences",
    "title": "Parts of Speech Tagging",
    "section": "First: Extract Sentences",
    "text": "First: Extract Sentences\nYou could think this is quite easy: Separate using the punctuation, and you can get sentences. Just look for the periods, right? Well apparently it‚Äôs not quite that easy.\nSo instead of trying our luck, we‚Äôll use the openNLP package and some of its functions.\nLet‚Äôs prepare a ‚Äúsentence annotator‚Äù:\nsent_annotator &lt;- Maxent_Sent_Token_Annotator(language = \"en\", probs = TRUE, model = NULL)\nAnd then let‚Äôs try and annotate our first article, using the NLP package‚Äôs function ‚Äúannotate‚Äù:\n# Now let's annotate the sentences in our latest article:\nannotated_sentences &lt;- annotate(t_strings, sent_annotator)\n# And let's have a look:\nt_strings[annotated_sentences]\nGood stuff. Indeed the choices these couple of lines of code have made differ a bit from what my personal approach would have done:\n\nMe I‚Äôd have separated ‚ÄúIntro‚Äù, the first title, into a separate sentence. But then that ‚Äúsentence‚Äù would have no verb, for instance‚Ä¶\nAnyhow. So we have our article delimited in sentences.\nNote: The ‚Äúannotated_sentences‚Äù is an object of class ‚ÄúAnnotation‚Äù that plays nice with objects of type String, as it turns out. Good to know. But let‚Äôs move on."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#getting-words-from-sentences",
    "href": "posts/2021-08-08_NLP_partIII/index.html#getting-words-from-sentences",
    "title": "Parts of Speech Tagging",
    "section": "Getting words from sentences",
    "text": "Getting words from sentences\nVery similar to the above, we can get words out of our annotated sentences. (This is needed, though: you need annotated sentences to begin separating words).\n(I‚Äôve separated the first three sentences from the article for clarity):\n# Let's first extract words, from annotated sentences.\nword_annotator &lt;- Maxent_Word_Token_Annotator(language = \"en\", probs = TRUE, model = NULL)\nannotated_words &lt;- annotate(t_strings, word_annotator, annotated_sentences)\nt_strings[annotated_words]\nAnd we get indeed: First the sentences, then the separated ‚Äúwords‚Äù:\n\nGood. Shall we continue?"
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#last-step-tagging-words",
    "href": "posts/2021-08-08_NLP_partIII/index.html#last-step-tagging-words",
    "title": "Parts of Speech Tagging",
    "section": "Last step: Tagging Words",
    "text": "Last step: Tagging Words\nSo far, these functions of separating sentences and words, we could probably have approximated using some regular expressions and ‚Äúeducated‚Äù if-then-else rules on strings.\nBut this last bit, to me, was a bit more of a challenge, theoretically speaking, and is an interesting thing: can we recognize ‚Äúparts of speech‚Äù as in: verbs, nouns, articles‚Ä¶\nNot straightforward, at least to me. Thankfully, the Apache-based openNLP package helps, once again:\npos_tag_annotator &lt;- Maxent_POS_Tag_Annotator(language = \"en\", \nprobs = TRUE, model = NULL)\n#pos_tag_annotator\npos_tagged_sentences &lt;- annotate(t_strings, pos_tag_annotator, annotated_words)\nhead(pos_tagged_sentences, n = 30)\n\nThis is not quite as readable as one might want. We still see the sentences first, then the words, and now a ‚ÄúPOS‚Äù tag appears but it‚Äôs encoded.\nLet‚Äôs see if we can make it better. We will merge a simple data.frame that describes the tags better, with a data frame in which we map each word to their associated POS tag.\n# Let's focus on the words only and for the first sentence only:\npos_tagged_words_sent1 &lt;- pos_tagged_sentences %&gt;%\n   subset(type == \"word\") %&gt;%\n   subset(end &lt;= 108) # 108 was the end of the first sentence, so it makes sense.\n\n# Now we have all words limits for the first string:\nsentence1[pos_tagged_words_sent1]\n\n# Let's make it more readable now\n# For reference: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\npos_simple_explainer &lt;- data.frame(\n   tag = c(\"CC\", \"CD\", \"JJ\", \"NN\", \"NNS\", \"NNP\", \"VB\", \"VBD\", \"IN\", \"DT\", \"RB\"),\n   desc = c(\"Coordinating Conjunction\",\n      \"Cardinal Number\",\n      \"Adjective\",\n      \"Noun, singular or mass\",\n      \"Noun, plural\",\n      \"Noun, proper\",\n      \"Verb, base form\",\n      \"Verb, past tense\",\n      \"Preposition or subordinating conjunction\",\n      \"Determiner\", \"Adverb\")\n   )\n\nword_types_vector &lt;- sapply(pos_tagged_words_sent1$features, function(x) {\n   x$POS[[1]]\n})\n\n# Finally, let's have a look at the tagged POS:\nmerge(data.frame(word = sentence1[pos_tagged_words_sent1],\n         type = word_types_vector),\n   pos_simple_explainer,\n   by.x = \"type\",\n   by.y = \"tag\",\n   all.x = TRUE)\nThe results are shown in the first screenshot of this entry."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#conclusions",
    "href": "posts/2021-08-08_NLP_partIII/index.html#conclusions",
    "title": "Parts of Speech Tagging",
    "section": "Conclusions",
    "text": "Conclusions\nWe have used Apache‚Äôs openNLP libraries to work our way through:\n\nextracting sentences from a text\nextracting words from sentences\ntagging words to their corresponding type (or a reasonably good approximation, anyway), i.e.¬†distinguishing verbs and articles and nouns‚Ä¶\n\nNot bad!\nI do recommend the book ‚ÄúMastering Text Mining with R‚Äù if at all interested. This series of posts about NLP are in part inspired by that book, albeit adapted and applied in my own way and on my own text."
  },
  {
    "objectID": "posts/2021-08-08_NLP_partIII/index.html#resources",
    "href": "posts/2021-08-08_NLP_partIII/index.html#resources",
    "title": "Parts of Speech Tagging",
    "section": "Resources",
    "text": "Resources\nThe code for today\nThe reference book I like"
  },
  {
    "objectID": "posts/2023-08-06_GA_2_3/index.html",
    "href": "posts/2023-08-06_GA_2_3/index.html",
    "title": "Optimization: Genetic Algorithm(s) (2/2)",
    "section": "",
    "text": "This week, I‚Äôll make it short, and instead of boring with code and explanations, I thought I‚Äôd just show an example output‚Ä¶\n\n\nThis is a genetic algorithm in action: A population ‚Äúevolves‚Äù (reproduces, ‚Äúselection of the fittest‚Äù, iterate) towards an objective. Complexity of many local minima don‚Äôt seem to be an issue for this algorithm. The below shows population over 5 frames extracted from 50 generations at regular intervals.\n\n\n\n\nThis example is quite simple, really. I have yet to implement ‚Äúmutations‚Äù, and I chose one of many possible mixes of parents selection, as well as the most simple crossing of parents to create children.\nBut it still works üôÇ"
  },
  {
    "objectID": "posts/2023-08-06_GA_2_3/index.html#intro",
    "href": "posts/2023-08-06_GA_2_3/index.html#intro",
    "title": "Optimization: Genetic Algorithm(s) (2/2)",
    "section": "",
    "text": "This week, I‚Äôll make it short, and instead of boring with code and explanations, I thought I‚Äôd just show an example output‚Ä¶\n\n\nThis is a genetic algorithm in action: A population ‚Äúevolves‚Äù (reproduces, ‚Äúselection of the fittest‚Äù, iterate) towards an objective. Complexity of many local minima don‚Äôt seem to be an issue for this algorithm. The below shows population over 5 frames extracted from 50 generations at regular intervals.\n\n\n\n\nThis example is quite simple, really. I have yet to implement ‚Äúmutations‚Äù, and I chose one of many possible mixes of parents selection, as well as the most simple crossing of parents to create children.\nBut it still works üôÇ"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "So I had a bit of time. And I chose to use it to keep going a bit. I moved a couple of things, created a few more supporting functions, modified them somewhat, and added the covering part.\nCovering needs to happen when for a given training instance (state, class), there is no match in the correct set.\nCorrect set is the subset of the Matching set for which, on top of the condition matching, the predicted class/action is also correct.\nAnd well, it‚Äôs working:\n\n\n\ntesting basic covering functionality\n\n\n\n\n\nNext up is ‚ÄúRule Discovery‚Äù, whereby, in Michigan-style LCS, a GA-like process will take place to create offspring from two parents taken in the Correct set.\nThat will include cross-over (in one way or another) and mutation (with a preset pressure/probability). With these, on top of coverage, the LCS will hence create new valid rules, that will become part of the population, to be evaluated on further training instances.\nOther parts of the algorithm ‚Äì meant to contain the population size ‚Äì will come later. :)"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#its-sunday",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#its-sunday",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "So I had a bit of time. And I chose to use it to keep going a bit. I moved a couple of things, created a few more supporting functions, modified them somewhat, and added the covering part.\nCovering needs to happen when for a given training instance (state, class), there is no match in the correct set.\nCorrect set is the subset of the Matching set for which, on top of the condition matching, the predicted class/action is also correct.\nAnd well, it‚Äôs working:\n\n\n\ntesting basic covering functionality"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#conclusion",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#conclusion",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "Next up is ‚ÄúRule Discovery‚Äù, whereby, in Michigan-style LCS, a GA-like process will take place to create offspring from two parents taken in the Correct set.\nThat will include cross-over (in one way or another) and mutation (with a preset pressure/probability). With these, on top of coverage, the LCS will hence create new valid rules, that will become part of the population, to be evaluated on further training instances.\nOther parts of the algorithm ‚Äì meant to contain the population size ‚Äì will come later. :)"
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html",
    "href": "posts/2021-06-27_NLP_part0/index.html",
    "title": "Diving into NLP",
    "section": "",
    "text": "So I have been thinking a bit about chatbots and other NLP-related things lately. I‚Äôm probably NOT ready to implement an NLP-based Chatbot, that‚Äôs clear, but I can start doing some other things to get practice on the subject.\nSo this is going to be a multi-part thing, or rather a recurring subject in the upcoming weeks/months. I‚Äôll try to take advantage of the summer to present and dive a bit into topics such as: Corpus, Stop-words, Tokenization, Stemming, algorithms such as TF-IDF (already introduced here for instance), and who knows what else.\nThe goal being to be able to understand things (and how they are implemented in R) a bit better maybe (nothing new under the Sun though). And I‚Äôll try to do that through practical examples, some of which maybe will have to deal with logs, URLs classification (good or bad), and the likes. But let‚Äôs not get ahead of ourselves."
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html#intro",
    "href": "posts/2021-06-27_NLP_part0/index.html#intro",
    "title": "Diving into NLP",
    "section": "",
    "text": "So I have been thinking a bit about chatbots and other NLP-related things lately. I‚Äôm probably NOT ready to implement an NLP-based Chatbot, that‚Äôs clear, but I can start doing some other things to get practice on the subject.\nSo this is going to be a multi-part thing, or rather a recurring subject in the upcoming weeks/months. I‚Äôll try to take advantage of the summer to present and dive a bit into topics such as: Corpus, Stop-words, Tokenization, Stemming, algorithms such as TF-IDF (already introduced here for instance), and who knows what else.\nThe goal being to be able to understand things (and how they are implemented in R) a bit better maybe (nothing new under the Sun though). And I‚Äôll try to do that through practical examples, some of which maybe will have to deal with logs, URLs classification (good or bad), and the likes. But let‚Äôs not get ahead of ourselves."
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html#start-simple-webpage-indexing",
    "href": "posts/2021-06-27_NLP_part0/index.html#start-simple-webpage-indexing",
    "title": "Diving into NLP",
    "section": "Start Simple: Webpage indexing",
    "text": "Start Simple: Webpage indexing\nSo I know this might seem like a stupid idea upfront: after all many websites have a so-called ‚Äúsitemap‚Äù, whereby the contents are already somewhat indexed.\nBut I have had an issue recently, a very basic one: How to choose the tags and categories for my posts? Should I keep it to a minimum? Which ones are categories and which ‚Äútags‚Äù? Do my tags convey the actual contents of the different Blog entries?\nTruth is, I only recently started thinking about this particular issue, while writing the last entry, and finding myself at a loss with the already existing (chosen by myself, mind you) categories and tags. And my site has around 40 entries in total by now (43 before the present one, to be exact).\nAnother reason for this idea of tags and categories is, I am now able to recommend my Blog (yes!) to some colleagues (not so much my friends, most don‚Äôt care about programming, R or IT Security). But although I know I have some contents on a specific topic, it takes me a bit of time to locate the entry I‚Äôm thinking of.\nBoth problems clearly are pointing at a particular need I have: I need help with the indexing of my contents so that it is easier for me to find it (and I don‚Äôt have Google JS code on the website, so I‚Äôm not really helping them here). This will probably fall in the category of ‚ÄúTopic Modelling‚Äù, actually.\nI can think of two ways to go: ¬†to gather the data to analyze it: Basic crawling (once I know what I am looking for), or actually using the sitemap. As the first approach covers the concepts of the second, but in a harder way, I‚Äôll do just the first one for now, encompassing in concept both."
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html#note-no-entry-next-week-probably",
    "href": "posts/2021-06-27_NLP_part0/index.html#note-no-entry-next-week-probably",
    "title": "Diving into NLP",
    "section": "Note: No entry next week (probably)",
    "text": "Note: No entry next week (probably)\nAs it turns out, I will be away and will only be able to carry my job‚Äôs materials with me (I travel light, first time in a loooong time), so no server, no personal laptop, and it won‚Äôt be a vacation anyway‚Ä¶\nHence I think I‚Äôll just skip the writing of code for a week, and instead spend some time brushing up on the concepts to be used when I actually start coding.\nNevertheless, let‚Äôs have a quick look at the first step‚Ä¶"
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html#getting-the-data-ill-need-quick-glance-at-whats-ahead",
    "href": "posts/2021-06-27_NLP_part0/index.html#getting-the-data-ill-need-quick-glance-at-whats-ahead",
    "title": "Diving into NLP",
    "section": "Getting the data I‚Äôll need: Quick glance at what‚Äôs ahead",
    "text": "Getting the data I‚Äôll need: Quick glance at what‚Äôs ahead\nSo I really don‚Äôt have much time right now, but I wanted to open a new script and get started.\nAnd so, for today I‚Äôll just get the initial page, and locate the link for the next one. Of course later on I‚Äôll need to repeat that, but for now that‚Äôs about OK.\n# Crawl our website --An Appetizer:\nlibrary(dplyr)\nlibrary(curl)\nlibrary(xml2)\nlibrary(rvest) # for html_attr\n\n# Select base page. Could have been the Home too on this Blog:\npage_0_con &lt;- curl(\"https://www.kaizen-r.com/category/blog/\")\npage_0 &lt;- xml2::read_html(page_0_con)\nI don‚Äôt know you, but I need some help to locate the right tags among all the mess. In Chrome & Firefox (and¬† Edge, last time I checked) you can use the Developper tools (usually key: F12) of the browser and you‚Äôll be able to click on your page, the browser will point you to the correct section of the HTML code:¬†\n\n# Locate next page to crawl: F12 in your browser is your friend...\nnav_next_div &lt;- xml_find_all(page_0, \".//div[@class='nav-next']\")\n# Get the next URL out of the tags...\nnext_url &lt;- nav_next_div %&gt;% html_nodes(\"a\") %&gt;% html_attr(\"href\")\nBut what would happen with a page that does not exist?\n# spoiler - demo: we get a 404 after a few pages (as of today, that is)...\npage_0_con &lt;- curl(\"https://www.kaizen-r.com/category/blog/page/16/\")\npage_0 &lt;- xml2::read_html(page_0_con)\nIndeed, easy to check:\n\nAnd we can get the contents from those pages we gather quite directly:\n# While we're at it, let's get the contents of our first shown article:\npage_articles &lt;- xml_find_all(page_0, \".//article\")\narticle_1_title &lt;- xml_text(xml_find_all(page_articles[1], \".//h1[@class='entry-title']\"))\narticle_1_content &lt;- xml_text(xml_find_all(page_articles[1], \".//div[@class='entry-content']\"))"
  },
  {
    "objectID": "posts/2021-06-27_NLP_part0/index.html#conclusions",
    "href": "posts/2021-06-27_NLP_part0/index.html#conclusions",
    "title": "Diving into NLP",
    "section": "Conclusions",
    "text": "Conclusions\nWe‚Äôll look at the text we‚Äôll be gathering and we‚Äôll see what we can do with it. Maybe I can program a helper that‚Äôll be able to crawl my website‚Äôs articles, and recommend me automatically some tags and categories (and then, maybe not, it‚Äôs too early to say). We‚Äôll see from there.\nBut first, I‚Äôll be out reading. See you in a couple of weeks."
  },
  {
    "objectID": "posts/2021-04-25_OWASP_AMASS/index.html",
    "href": "posts/2021-04-25_OWASP_AMASS/index.html",
    "title": "More external data sources tests: OWASP Amass",
    "section": "",
    "text": "So I already wrote a quick post on Shodan recently. I‚Äôve come across plenty of data sources over time (IPVoid, DomainTools, NetworksDB, the usual Virustotal (‚Ä¶), on top of the classics tools for discovery like whois & nslookup/dig and well, a long list).\nBut I‚Äôve been pointed to a new tool that I didn‚Äôt know about (once again showing that the more I learn, the more I find out how little I know) and it definitely seems‚Ä¶ Promising. So let‚Äôs have a look at that. Thanks guys for the pointer (you know who you are)."
  },
  {
    "objectID": "posts/2021-04-25_OWASP_AMASS/index.html#a-wrapper-around-many-data-sources",
    "href": "posts/2021-04-25_OWASP_AMASS/index.html#a-wrapper-around-many-data-sources",
    "title": "More external data sources tests: OWASP Amass",
    "section": "A wrapper around many data sources",
    "text": "A wrapper around many data sources\nIt seems this will be a great tool to add to the list because it‚Äôs well, several tools in one really. The people at OWASP have put together ‚ÄúAMASS‚Äù (which in context is a cool name).\nAnd I‚Äôm very happy to find out that they‚Äôve made the effort to put together a Docker container, which allows us to do the following in (literally) 2 minutes:\ndocker pull caffix/amass\ndocker run -v `pwd`:/.config/amass caffix/amass enum -d kaizen-r.com\nWith the following output:\n\nBut that doesn‚Äôt tell us much for programatic use (in R in future scripts ;)), so let‚Äôs see what output gets into our mapped ‚Äúvolume‚Äù, and the JSON file seems to be a good future candidate for input to one of our R scripts:\n$ ls\namass.json amass.log amass.txt indexes.bolt\n$ cat amass.txt \nwww.kaizen-r.com\nkaizen-r.com\n$ cat amass.json \n{\"name\":\"www.kaizen-r.com\",\"domain\":\"kaizen-r.com\",\"addresses\":(&lt;EDITED&gt;)}\n{\"name\":\"kaizen-r.com\",\"domain\":\"kaizen-r.com\",\"addresses\":(&lt;EDITED&gt;)}\nBut for the time being, I loved what I found in the amass.log file. Among other things it tells me I need to configure something, but even so:\n$ cat amass.log\n06:22:10.064379 CIRCL: check callback failed for the configuration\n06:22:10.064655 URLScan: API key data was not provided\n06:22:10.064664 DNSDB: API key data was not provided\n(&lt;EDITED&gt; ...)\n06:22:16.193194 Querying VirusTotal for kaizen-r.com subdomains\n06:22:16.193219 Querying Wayback for kaizen-r.com subdomains\n06:22:16.193244 Querying GoogleCT for kaizen-r.com subdomains\n06:22:16.193269 Querying Yahoo for kaizen-r.com subdomains\n06:22:16.193294 Querying HackerOne for kaizen-r.com subdomains\n06:22:16.193321 Querying HackerTarget for kaizen-r.com subdomains\n06:22:16.193339 Querying IPv4Info for kaizen-r.com subdomains\n06:22:16.193355 Querying Mnemonic for kaizen-r.com subdomains\n06:22:16.193372 Querying RapidDNS for kaizen-r.com subdomains\n06:22:16.193400 Querying Riddler for kaizen-r.com subdomains\n06:22:16.193426 Querying Robtex for kaizen-r.com subdomains\n06:22:16.193452 Querying SiteDossier for kaizen-r.com subdomains\n06:22:16.193470 Querying SonarSearch for kaizen-r.com subdomains\n06:22:16.193487 Querying Sublist3rAPI for kaizen-r.com subdomains\n06:22:16.193503 Querying ThreatCrowd for kaizen-r.com subdomains\n06:22:16.193532 Querying Pastebin for kaizen-r.com subdomains\nThat‚Äôs just great. I like to try and program access to APIs and stuff myself, but this seems to be trying to do it all for me on SEVERAL SOURCES AT ONCE, putting results in a JSON format after it‚Ä¶ Which is why it takes a minute to run even on my small website‚Äôs footprint, I guess.\nLast test for today: At the personal level, I have a Twitter API Key, a Shodan API Key, a URLScan API Key (and maybe a few others that do not impact the concepts here, but that I will indeed throw in for good measure for the tests). Can I get more info if I provide my API keys to the container? So I create a config.ini file, copying contents from the example config file. And then edit accordingly with your own choices.\nAnother cool detail about the config file is that you can point AMASS to specific DNS Servers, which might help (solving potentially proxied-connections and the likes).\nWell the results do not differ much (my blog is not too complex a URL to check). The only difference in the JSON file is that it mentions more sources for the fingerprinting, and complains less about API Keys missing, so that seems to be working. Maybe in other cases the API keys will help more, but that didn‚Äôt impact much the lookup results in this case. (My blog is at any rate uninteresting and very simplistic in that sense, which I am quite happy about btw).\nIt did take me a couple of tries to get the amass container to take in the config file correctly, though, so here goes (for my own future reference):\n$ sudo docker run -v `pwd`:/amass_root/ caffix/amass enum -d kaizen-r.com -config /amass_root/config.ini -dir /amass_root/data/\n¬†\nAnyhow: more tests could be run for sure, but this looks promising. I‚Äôll add it to my arsenal for external visibility fingerprinting.\n\nConclusions\nWell, just that we can get a new tool to gather and prepare result datasets for us. So we now have a new source that puts together data from many sources.\nI‚Äôll have to test it on other domains/IPs, as my blog is not too interesting. However, because doing reconnaissance like this depending on configurations (and using my personal API keys) should be authorized, I can‚Äôt go much further in this particular case just yet.\n\n\nResources\nOWASP AMASS"
  },
  {
    "objectID": "posts/2021-04-04_OnShodan/index.html",
    "href": "posts/2021-04-04_OnShodan/index.html",
    "title": "Shodan API Tests",
    "section": "",
    "text": "First of all, sorry I haven‚Äôt published more in the past few weeks. I simply have been‚Ä¶ Pretty busy.\nBut now it is time to try and get back to the good habits, and a weekly publication here is one of my personal goals (and quite fulfilling, in spite of not always being possible)."
  },
  {
    "objectID": "posts/2021-04-04_OnShodan/index.html#introduction",
    "href": "posts/2021-04-04_OnShodan/index.html#introduction",
    "title": "Shodan API Tests",
    "section": "Introduction",
    "text": "Introduction\nFor once, I didn‚Äôt find a package to go about this in R‚Ä¶ Although I haven‚Äôt spent too much time looking. (Maybe I should consider learning how to create a package myself and get it published out there‚Ä¶ Master Hadley has thorough documentation about how to go about it‚Ä¶ But well, for now that‚Äôs beyond today‚Äôs goals‚Ä¶)\nSo as the title may have already made clear, today we‚Äôll test the Shodan API. Why that particular thing today? Well, this very week, they offered a limited-time discount to have access to a life-long membership. I already had an account, but never spent quite enough time on that platform. Now I subscribed and have ‚Äúmembership‚Äù access-level‚Ä¶ Anyhow, that‚Äôs just an excuse.\nShodan is a great tool for gathering information on certain public facing stuff, and I thought it would fit perfectly for this blog: a security-related data source.\n\nAs with the MITRE example, this won‚Äôt be exhaustive, but rather pointing at possibilities‚Ä¶"
  },
  {
    "objectID": "posts/2021-04-04_OnShodan/index.html#accessing-the-api",
    "href": "posts/2021-04-04_OnShodan/index.html#accessing-the-api",
    "title": "Shodan API Tests",
    "section": "Accessing the API",
    "text": "Accessing the API\nSo first, one needs to register for an account and then get their own API key. ‚ÄúAll Shodan accounts come with a free API plan.‚Äù (dixit the Shodan.io website)\nBecause I didn‚Äôt find a package to access Shodan, we‚Äôll revert to using the API with curl & jsonlite.\nlibrary(curl)\nlibrary(jsonlite)\n\nhostname &lt;- \"www.kaizen-R.com\"\n\n# As usual, do not put confidential data in your code...\ns_apikey &lt;- readLines(\"/mnt/R/.shodanAPI.conf\")\n\n# Now on to ourselves as an example: Working on an IP\nconn &lt;- curl(paste0(\"https://api.shodan.io/shodan/host/\", \n   nslookup(hostname)[1], \"?key=\", s_apikey))\ns_q_result &lt;- readLines(conn, warn = FALSE)\nclose(conn)\ns_q_result &lt;- fromJSON(s_q_result, flatten = TRUE)\nAnd that‚Äôs almost it! In the above, we have queried for an IP address (and used the curl package implementation of nslookup() on the go).\nLooking at the results, unsurprisingly, we were pointed to our¬†hosting‚Ä¶ I have no intention of pointing anyone onto how to ‚Äúattack‚Äù this poor Blog of mine, but anyone with a bit of experience would probably go into Shodan for ‚Äúsurface‚Äù/‚Äùexternal footprint‚Äù discovery anyway. Now as I must have mentioned in the past, I am not particularly interested in ‚Äúattacking‚Äù but rather in ‚Äúdefending‚Äù (e.g.¬†I‚Äôm a ‚ÄúBlue Team‚Äù kinda guy). As a defender, however, one needs to have at least a minimal understanding of how attackers work (as already mentioned in the post about Mitre, btw)."
  },
  {
    "objectID": "posts/2021-04-04_OnShodan/index.html#parsing-the-results-and-r-basics",
    "href": "posts/2021-04-04_OnShodan/index.html#parsing-the-results-and-r-basics",
    "title": "Shodan API Tests",
    "section": "Parsing the results and R basics",
    "text": "Parsing the results and R basics\nOne would think that having a package/library would make things MUCH easier, but hold on a minute‚Ä¶\nFirst, you‚Äôll notice the trick ‚Äúflatten = TRUE‚Äù in the ‚ÄúfromJSON‚Äù call. That‚Äôs a nifty trick (one we could have used in the Mitre entry, indeed, but the goal there was on visualizations‚Ä¶).\nSecond, and going back to basic R concepts, one should ALWAYS look at what one gets. The ‚Äústr()‚Äù command in R is rather an important one, and helps us quite a bit here:\nstr(s_q_result)\nNow this is important, for R concepts: The JSON output gave us a list. A list differs from a vector in that it CAN be of DIFFERING TYPES.\nIn this case, we get a list of strings, numbers and‚Ä¶ A data.frame. A structured object in this case. We‚Äôll get to that one in a jiffy.\nBut first, let‚Äôs have a quick look at the info already provided in the list:\n\nBy the way, you might remember we worked on gathering GeoIP data from MaxMind‚Ä¶ Well, as it turns out, there is a good chance that Shodan might have gathered that info for our IP addresses already‚Ä¶\nNow we can get our dataframe out of the list and work with that if we wish to.\ndf &lt;- s_q_result$data\nHere we get further data on the service(s) discovered on that IP we looked up. And it‚Äôs ‚Äúthat easy‚Äù, really. So here we‚Äôll find info about the Apache server (for that particular case). And once again GeoIP info (we really could have skipped the MaxMind exercise a few weeks ago‚Ä¶ Although I still think it was an important exercise‚Ä¶).\n\nConclusions\nIn spite of not having looked enough for a packaged alternative, looking up data on publicly available APIs nowadays should not be cause for stress. With only a little bit of work and more generic packages, one can use such APIs, parse JSON responses and then work on the resulting dataset rather fast. It‚Äôs not (always) messy data, thankfully.\nSure, one needs to study and understand the datasets, how to use them, but then again one would not connect to an API in the first place if they didn‚Äôt expect to get specific data out of it.\nAs usual this blog entry is quite incomplete: there is much more to the Shodan API, but that would probably make for a Book‚Ä¶ Suffice to say, doing a keyword search can bring back MUCH MORE data than one simple IP lookup.\n\n\nReferences\nhttps://www.shodan.io/\nMy code for today on GitHub"
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html",
    "title": "Thinking about Systems",
    "section": "",
    "text": "I did mention some of it a while back, but also I am re-reading ‚ÄúThinking in Systems‚Äù by D. H. Meadows.\nWell, I still truly do NOT know how I will go about it (if and when I decide to put more efforts into coding these things), but for the time being, I thought I‚Äôd run some extremely simplistic - and absolutely incorrect and personal - approach to it all."
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#i-keep-coming-back-to-these-ideas",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#i-keep-coming-back-to-these-ideas",
    "title": "Thinking about Systems",
    "section": "",
    "text": "I did mention some of it a while back, but also I am re-reading ‚ÄúThinking in Systems‚Äù by D. H. Meadows.\nWell, I still truly do NOT know how I will go about it (if and when I decide to put more efforts into coding these things), but for the time being, I thought I‚Äôd run some extremely simplistic - and absolutely incorrect and personal - approach to it all."
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#about-stocks",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#about-stocks",
    "title": "Thinking about Systems",
    "section": "About ‚Äústocks‚Äù",
    "text": "About ‚Äústocks‚Äù\nOne topic that appears a bit in the referenced book is the idea of stock, as in ‚Äústorage buffers‚Äù of ‚Äúflows‚Äù (that‚Äôs how I understood it anyway). Think bathtub, faucet and drain.\nSo how about this for a simplistic idea. Two companies compete to ‚Äúgrow‚Äù with two different HR policies, one more focused on improving hiring, the other on retention.\nBoth have supposedly ‚Äúgood policies‚Äù towards an objective of growth, in that their respective policies seem ‚Äúpositive‚Äù, more ‚Äúin-flow‚Äù that ‚Äúout-flow‚Äù.\nNow (and again, this is stupid as a model I suppose, it is just me warming up to the concepts), what if there was a limited ‚Äúpool‚Äù of potential employees, a ‚Äúgeneral population‚Äù from which to hire from (or ‚Äúfire into‚Äù).\nI coded a very very simplistic (and absolutely zero-optimized, nor probably even quite correct) thing to represent this, which looks at the ‚Äúcurrent stock‚Äù of each company (and well, the general population).\nWhy not visualize that as a basic network graph (or simply ‚Äúgraph‚Äù, which I prefer):\n\n\n\nsimple scenario - starting setup\n\n\nIn the following, for all results, I always initialize the simulation scenario as follows:\nstocks &lt;- list()\n## Let's work with two stocks\n## First will be the unemployed population, with \"big\" capacity to consume/pour flows:\nstocks &lt;- add_stock(stocks, stock_name = \"population\", initial_stock=100, inflow=1000, outflow=1000) \n    \nstocks &lt;- add_stock(stocks, stock_name = \"company1\", initial_stock=20, inflow=3, outflow=2)\nstocks &lt;- add_stock(stocks, stock_name = \"company2\", initial_stock=20, inflow=7, outflow=3)\nEach ‚Äústock‚Äù in turn can evolve with the (discrete) passing of time (how much time will be important as we‚Äôll see in a moment), and I choose to represent that as ‚Äúin-flows‚Äù and ‚Äúout-flows‚Äù volume, which in turn are supposed here to represent the corresponding ‚Äúpolicy‚Äù of each company.\nAgain, I‚Äôm making stuff up as I go here, so‚Ä¶ For instance, I add some randomness to the process (just for the fun of it) so that at time step X, company 1 with inflow 3 would try to ‚Äúhire‚Äù 3 employees, but I add a probability of 40% whereby the company at that particular time-step X decides to hire someone. The same goes for firing (in the case of company 1, the policy says ‚Äúfire 2‚Äù). And all that applies exactly the same for company 2, with its own policy.\nSo it could look like so:\nconsume_from_population &lt;- function(stocks, consumer_stock_num) {\n    ## Add some level of randomness\n    if(runif(1) &gt; 0.4)\n        if(stocks[[1]]$current_stock &gt; 0) { \n            ## stocks[[1]] is the general population...\n            consumable &lt;- min(stocks[[1]]$current_stock, stocks[[consumer_stock_num]]$inflow)\n            stocks[[1]]$current_stock &lt;- stocks[[1]]$current_stock - consumable\n            stocks[[consumer_stock_num]]$current_stock &lt;- stocks[[consumer_stock_num]]$current_stock + consumable\n        }\n    stocks\n}\n\n...\nThe general population starts off with 100 individuals, and is not limiting in that it could potentially gather ‚Äúpeople‚Äù from - or pour into - the companies at a rate much higher than what the companies would do."
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#simulating-the-passing-of-time",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#simulating-the-passing-of-time",
    "title": "Thinking about Systems",
    "section": "Simulating the passing of time",
    "text": "Simulating the passing of time\nQuite simply, this is the core of the simulation, really:\nfor(current_time in 1:n_time_steps) {\n    ## flows processing: circle through the companies\n    for(node_id in sample(2:3, 2, replace = F)) {\n        ## SIMPLISTIC, probably BAD, I know\n        stocks &lt;- consume_from_population(stocks, node_id)\n        stocks &lt;- loose_to_population(stocks, node_id)\n    }\n    ...\n}\nRight now, I only throw graph-related code to show current size of each in number of employees:\nV(g)$size &lt;- sapply(stocks, \\(x) x$current_stock)\nPretty basic stuff, very ‚Äúalgorithmic‚Äù, and again, not much thinking went into doing this ‚Äúright‚Äù.\nThis is what it looks like for one simulation then:"
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#some-results",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#some-results",
    "title": "Thinking about Systems",
    "section": "Some results",
    "text": "Some results\nWhile all the above is pretty simplistic, it does suggest ‚Äúagent-based modeling‚Äù stuff, simulations, etc.\nAnd even for such a simple approach, not realistic in the least, let‚Äôs have a look at some conclusions‚Ä¶\nBecause I added some stochastic parameters in there (the 40% thing), I would need to run several simulations per scenario to get a sense of what really is happening.\nToday I‚Äôll focus on how long I run the simulation and the impact of limited general population. It‚Äôs not rocket science, really, so let‚Äôs break it down.\nIn all cases, I run one scenario 50 times (and then I‚Äôll use that to average results). In all scenarios I start with the same configuration.\nThen I decide to run each scenario a number of steps:\nn_time_steps_vec &lt;- c(100, 500, 1000, 5000, 10000)\nfor(n_time_steps in n_time_steps_vec) {\n    for(i in 1:50) { ## Let's do this simulation a few times, shall we? MC-like\n        ...\n    }\n}\nI‚Äôll show in the next graphics the following, for each company:\n\nAfter 50 simulations of one scenario, what was the resulting size of the company (in number of employee) in each scenario, when the scenario was run 100 time steps.\nSave the resulting 50 simulations per scenario, but run it 100, 500, 1000, 5000 and 10000 time steps. Average (blue line) the resulting size of the company. (Green line: the companies start with 20 employees each)\n\nShow that for both companies (1 on top, 2 at the bottom).\nSo what does this say?\nWell, there is something I am not showing above: The general population!\nSee, as long as the general population has people to hire, both companies grow, one more than the other, as expected per their respective policies. That is: Company 2 hires even more than it fires people, comparatively, in spite of being less careful with loosing people than Company 1.\nHowever, when the population of candidates is depleted, Company 1, which is less aggressive in hiring but more conservative when it comes to loosing people (i.e.¬†possibly better culture, while maybe less ‚Äúattractive‚Äù to the market ‚Äúupfront‚Äù, say maybe it pays a little less than company 2‚Ä¶ Whatever the reason!)‚Ä¶\nRight, so when the ‚Äúgeneral population‚Äù is depleted, the policy of the first company pays off!\n\n\n\nWhat happens if you prolong the simulations\n\n\nIt makes sense, right? If hiring isn‚Äôt an option, well, you better make efforts towards retaining your talent.\nCompany 1 has a better policy when it directly competes with Company 2 for its resources, instead of consuming from a large pool of candidates.\nIn other words, if a resource is scarce, and you‚Äôre competing directly with others, maybe you should focus on saving that resource, more so than getting more.\nAnd maybe it‚Äôs wrong, but this simplistic simulation scenario hints at such a conclusion."
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#limitations",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#limitations",
    "title": "Thinking about Systems",
    "section": "Limitations",
    "text": "Limitations\nWell, to begin with, I don‚Äôt know whether my code even makes sense, for example I simply loop through a list of companies, and the ‚Äúgraph‚Äù structure really is just used for visualization (maybe I could use some adjacency matrix multiplications instead? Ashby‚Äôs Cybernetics book hinted at that‚Ä¶ But for states‚Ä¶ IDK, right now, no matter).\nThis is also all very static, too. Both companies stick to their policies no matter what. Not realistic in the least.\nAnd yes, the population is limited. Like a bounded resource. It feels wrong, or at least very incomplete (if that ever happened, people would rush to train themselves to compete to get hired in that market, wouldn‚Äôt they?).\nPlus, the ‚Äú40%‚Äù decision for hiring/firing at any given time step makes no sense whatsoever, either.\nAnd a long etc. Then again, ‚Äúall models are wrong‚Äù‚Ä¶ Well, this one is very wrong. Anyhow, this was just for the fun of the exercise!"
  },
  {
    "objectID": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#conclusions",
    "href": "posts/2025-08-15_Thinking_About_Thinking_in_Systems/index.html#conclusions",
    "title": "Thinking about Systems",
    "section": "Conclusions",
    "text": "Conclusions\nI know, too simplistic, not realistic at all. Even poor algorithmic approach, for sure, I don‚Äôt know. The goal here was never to go for perfect, but to try out my hand at simulating flows and stocks and a simple interaction scenario.\nAnd yet, some conclusions can come out of it, somewhat in the spirit of ‚ÄúSystems Thinking‚Äù.\nAnd that is more than enough for me for now.\nIt does tell me, once I shift my focus onto a new project for next year (just an idea I have for myself, because I want to work on something that interests me like that, say like the RLCS project these past few months‚Ä¶)‚Ä¶ In between ODE and ABM and FSMs, yes‚Ä¶\nYes, maybe that‚Äôs where I‚Äôll keep looking for fun stuff to learn."
  },
  {
    "objectID": "posts/2021-09-19_dplyrNotFaster/index.html",
    "href": "posts/2021-09-19_dplyrNotFaster/index.html",
    "title": "dplyr is not faster",
    "section": "",
    "text": "The other day, someone asked in a Telegram group how to go about changing some factor with 4 levels to another set of factors with two levels, in R.\nSo you had originally factors A, B, C, and D, and the new factor would be X for the first 3 cases, and Y for the last case."
  },
  {
    "objectID": "posts/2021-09-19_dplyrNotFaster/index.html#intro",
    "href": "posts/2021-09-19_dplyrNotFaster/index.html#intro",
    "title": "dplyr is not faster",
    "section": "",
    "text": "The other day, someone asked in a Telegram group how to go about changing some factor with 4 levels to another set of factors with two levels, in R.\nSo you had originally factors A, B, C, and D, and the new factor would be X for the first 3 cases, and Y for the last case."
  },
  {
    "objectID": "posts/2021-09-19_dplyrNotFaster/index.html#my-first-reaction",
    "href": "posts/2021-09-19_dplyrNotFaster/index.html#my-first-reaction",
    "title": "dplyr is not faster",
    "section": "My first reaction",
    "text": "My first reaction\nSo because I‚Äôm using dplyr quite a bit, as it makes things cleaner (and in R 4.1, you can use the |&gt; pipe instead of the %&gt;% from magrittr), I immediately thought of a mix of mutate and ifelse for this scenario."
  },
  {
    "objectID": "posts/2021-09-19_dplyrNotFaster/index.html#but-then",
    "href": "posts/2021-09-19_dplyrNotFaster/index.html#but-then",
    "title": "dplyr is not faster",
    "section": "But then‚Ä¶",
    "text": "But then‚Ä¶\nWell, I started thinking afterwards:\n\nFirst, that I didn‚Äôt know whether mutate would be faster than a simpler (albeit maybe less readable) base R version.\nSecond, that we were talking about a factor. Factors have levels, so maybe there was something to be done on the level, instead of on the values?\n\nSo I went ahead and created a basic test for that. I created a dummy example dataframe, and then created different alternatives to calculate the new factor.\nHere is the code for comparing the results, if you want to reproduce it.\nAs I wanted to compare processing speeds easily, I put the different alternatives in separate functions that would have to return a dataframe with the new factor.\ntest1 &lt;- data.frame(num = c(1:99),\n    cat = factor(rep(c(\"A\", \"B\", \"C\"), 33)))\n\nf1 &lt;- function(df) { # base R basic way\n  df$new_cat &lt;- ifelse(test1$cat == \"C\", \"cat2\", \"cat1\")\n  df$new_cat &lt;- as.factor(df$new_cat)\n  df[, c(1,3)]\n}\nf2 &lt;- function(df) { # dplyr way\n  df &lt;- df |&gt; mutate(new_cat = ifelse(cat == \"C\", \"cat2\", \"cat1\"))\n  df$new_cat &lt;- as.factor(df$new_cat)\n  df |&gt; select(num, new_cat)\n}\nf3 &lt;- function(df) { # plyr way\n  df$new_cat &lt;- mapvalues(df$cat, from = c(\"A\", \"B\", \"C\"), to = c(\"cat1\", \"cat1\", \"cat2\"))\n  df[, c(1,3)]\n}\nf4 &lt;- function(df) { # base R working on factor levels\n  levels(df$cat)[df$cat %in% c(\"A\", \"B\")] &lt;- \"cat1\"\n  levels(df$cat)[levels(df$cat) == \"C\"] &lt;- \"cat2\"\n  names(df)[2] &lt;- \"new_cat\"\n  df\n}\nAnd here are the results:\n&gt; test_that(\"Validate equal functionality\", {\n+   expect_equal(f1(test1), f2(test1))\n+   expect_equal(f1(test1), f3(test1))\n+   expect_equal(f1(test1), f4(test1))\n+ })\nTest passed üåà\n&gt; \n&gt; microbenchmark(\n+   f1(test1), f2(test1), f3(test1),\n+   f4(test1),\n+   times = 100L)\nUnit: microseconds\n      expr      min        lq      mean    median       uq       max neval\n f1(test1)  164.984  200.1815  301.1756  254.4185  303.167  3379.964   100\n f2(test1) 2532.623 2723.3530 3430.4129 2860.8335 3263.307 16781.194   100\n f3(test1)   88.998  105.5680  203.0238  130.5015  158.680  5710.515   100\n f4(test1)   86.071   96.6425  225.2438  110.8970  136.925  9588.608   100"
  },
  {
    "objectID": "posts/2021-09-19_dplyrNotFaster/index.html#conclusions",
    "href": "posts/2021-09-19_dplyrNotFaster/index.html#conclusions",
    "title": "dplyr is not faster",
    "section": "Conclusions",
    "text": "Conclusions\nThis was a quick post.\nIndeed, the dplyr way seems to be much slower. In general, I prefer dplyr and the pipes to make the code more readable, but in some cases the less readable code is a tradeoff for (much) faster execution.\nTo be noted that the last two functions work directly on the factor levels, instead of the values for each entry, so I‚Äôm guessing that‚Äôs what make them all-the-more fast."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html",
    "href": "posts/2024-11-10_entropy_of_zip/index.html",
    "title": "Entropy - Identifying compressed files",
    "section": "",
    "text": "About Shannon‚Äôs Information Entropy, applied to potentially detecting ciphered or compressed text compared to plain text.\n(First entry of the new platform, let‚Äôs see how it goes.)"
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#shannons-information-entropy",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#shannons-information-entropy",
    "title": "Entropy - Identifying compressed files",
    "section": "Shannon‚Äôs Information Entropy",
    "text": "Shannon‚Äôs Information Entropy\n\nWhy try to understand that?\nLong story short, Information Entropy is useful in quite a few machine learning algorithms, and to name only a few, the following two use it directly:\n\nPartitioning Trees (for nodes selection)\nLogistic Regression (through log loss)\n\nDoesn‚Äôt seem like much, said like that, but the Logistic Regression in turn can be used for‚Ä¶ Neural Networks :)\n\n\nHow it is defined?\nThe best way I personally managed to try and understand information entropy is through the concept of compression and surprise.\nA few helpful descriptions:\n‚Äú[‚Ä¶] the expected amount of information needed to describe the state of the variable [‚Ä¶]‚Äù\n‚ÄúEntropy is the measure of uncertainty of a variable. The more uncertain it is, the higher the entropy is.‚Äù\nHere is the mathematical expression of it:\n\\[\nH(X) = - \\sum_{x \\in X} p(x) log(p(x))\n\\]\nFrom the Wikipedia (I mean, why not?), this is the part that somehow can make sense for an intuitive understanding of the concept:\n‚ÄúThe information content, also called the surprisal or self-information, of an event \\(E\\) is a function which increases as the probability \\(p(E)\\) of an event decreases. When \\(p(E)\\) is close to 1, the surprisal of the event is low, but if \\(p(E)\\) is close to 0, the surprisal of the event is high. This relationship is described by the function\n\\[\nlog({1 \\over p(E)})\n\\]\nwhere \\(log()\\) is the logarithm, which gives 0 surprise when the probability of the event is 1. In fact, log is the only function that satisfies –∞ specific set of conditions [‚Ä¶]‚Äú"
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#application-detecting-cipherzip-on-data-streams",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#application-detecting-cipherzip-on-data-streams",
    "title": "Entropy - Identifying compressed files",
    "section": "Application: Detecting cipher/zip on data streams",
    "text": "Application: Detecting cipher/zip on data streams\nWe‚Äôre aiming for this today:\n\n\n\nCharacters distribution in Plain vs Zip text for a few Wiki entries\n\n\n\nThe code\nThe code will be on my Github soon enough (if not already).\nBut for now, a few blocks of it:\n\nmake_freq_df &lt;- function(filename) {\n    test1 &lt;- file(filename, open=\"rb\", raw = TRUE)\n    t1_bytes &lt;- t1_chars &lt;- c()\n    while(TRUE) {\n        temp &lt;- readBin(test1, what = \"raw\")\n        if(length(temp) == 0) break;\n        t1_bytes &lt;- c(t1_bytes, temp)\n        t1_chars &lt;- c(t1_chars, rawToChar(temp))\n    }\n    close(test1)\n    t1_df &lt;- data.frame(sort(table(as.character.hexmode(t1_bytes)), decreasing = TRUE))\n    t1_df$char &lt;- names(sort(table(t1_chars), decreasing = TRUE))\n    names(t1_df) &lt;- c(\"x\", \"probs\", \"char\")\n    # Instead of counts (table output), make it probability:\n    t1_df$probs &lt;- t1_df$probs/sum(t1_df$probs)\n    # Alternative could have been:\n    #t1_df$probs &lt;- as.numeric(prop.table(sort(table(t1_chars), decreasing = TRUE)))\n    \n    t1_df\n}\n\nThe above function is a (bad, but functional) way of taking a file, reading it in ‚Äúraw‚Äù format, and output byte-by-byte into a dataframe.\n\nThe first output column will be the ‚Äúraw byte‚Äù (for text, the ASCII code, say ‚Äú20‚Äù for space character).\nThe second column contains the Probability of appearance of a character, compared to the whole text being analysed (so, the frequency of it‚Äôs appearance).\nThe third column is for reference only, to ‚Äúsee‚Äù what the character would look like in plain text. Note that ‚Äù ‚Äù (space) and null would look similar‚Ä¶ And so would other encoded bytes, but that‚Äôs not to worry for today.\n\nWith the above in mind, here is an output of plain and zip‚Äôed text, along with the Shannon‚Äôs Entropy of it, correspondingly:\n&gt; firewall_wiki &lt;- compare_clear_zip(1, wiki_pages_df)\nupdating: posts/2024-11-10_entropy_of_zip/firewall_wiki.txt (deflated 63%)\n   x      probs char\n1 20 0.14766670     \n2 65 0.09267745    e\n3 69 0.07790143    i\n4 74 0.06658562    t\n5 6e 0.06621154    n\n6 61 0.06050687    a\n   x       probs char\n1  0 0.012244898     \n2 39 0.006722689    9\n3 72 0.006722689    r\n4 5f 0.006482593    _\n5 34 0.006242497    4\n6 e4 0.006242497 \\xe4\n[1] \"Entropy Plain text: 4.29839806234458\"\n[1] \"Entropy Zip text: 7.94701914818039\"\n\nIn Plain text, the space character appears quite a bit. So do the letters e, i, t, n, a... (That‚Äôs for English, and remember these are small sample texts extracted from some Wikipedia pages‚Ä¶). Plain text has repetition on some characters (higher probability of appearance), with varying distributions (and uses fewer different bytes).\nIn Zip, the probabilities are each MUCH lower, and more even across all possible bytes. And that‚Äôs our KEY concept for today. Zip is compression, so all its characters have as few repetition as possible (i.e.¬†low probability).\nInterestingly, with the above approach, ciphered data would look like zip data.\n\nOK, so let‚Äôs go back to our definitions of the first part:\n‚Äú[‚Ä¶] When \\(p(E)\\) is close to 1, the surprisal of the event is low, but if \\(p(E)\\) is close to 0, the surprisal of the event is high[‚Ä¶]‚Äú\nHopefully we‚Äôre getting somewhere with understanding the concept. Uncommon characters will have higher ‚Äúsurprisal‚Äù, and lower probability of appearing.\nOh: And we should not be afraid of the math, it wasn‚Äôt that bad. Here is what Shannon‚Äôs Entropy actually looks like for varying values of probability of appearance of a given character:\n\n\n\nShannon Entropy across possible probabilities\n\n\n\n\nWhat does it mean in practice?\nWell, it means that if you sample some bytes sniffed on a network, if you see seemingly random characters and no particular prevalence of any given one over the rest, you know it‚Äôs not clear-text.\nAnd yes, if you have the file extension, maybe this is all useless. So why you would care?\nFirst, this is pretty cool. If you sample data (from a network stream, or bytes on a disk‚Ä¶), you can distinguish ‚Äúautomagically‚Äù what‚Äôs plain text and what‚Äôs ciphered/zip.\nSecond: Maybe you can use that to detect covert channels out of packet capture? Or maybe let your computer on its own decide to use one set of algorithm to analyse things when there is plain text, and use another set of characters when there is ciphered/compressed text (or images, etc.)."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#conclusions",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#conclusions",
    "title": "Entropy - Identifying compressed files",
    "section": "Conclusions",
    "text": "Conclusions\nAll this took me quite a while to really understand it. Or think I do, anyway :D\nToday we‚Äôve tried to explain the concept of information entropy through a simple application. If at this point my readers have gotten somewhat of an intuition about the concept, I‚Äôll be very happy.\nAnd the concept is quite relevant for Machine Learning, as we shall see in future posts."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#references",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#references",
    "title": "Entropy - Identifying compressed files",
    "section": "References",
    "text": "References\nhttps://en.wikipedia.org/wiki/Entropy_(information_theory)\nThe original idea about this post I read a few years back in ‚ÄúNetwork Security Through Data Analysis‚Äù, 2nd Ed, by M. Collins (O`Reilly)"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "This is probably one of the last entries from my preparation to introduce ‚ÄúBackground of ML for Cybersecurity‚Äù. This time, it‚Äôs really about what should probably have been the first entry of the series. Also, it‚Äôs not really put in context of Cybersecurity: I‚Äôm just trying to show one needs not be afraid about the math.\nI‚Äôm having lots of doubts about this one, too: Can I even use the ‚ÄúMachine Learning‚Äù tag? After all, this predates ML by quite a bit. It‚Äôs really of the realm of statistics. Then again, the limit of what qualifies as ML and what doesn‚Äôt is somewhat blurry (at least to me).\nAnd some of it is very very simple, and maybe shouldn‚Äôt warrant writing about it. But I like to write things down, it helps organize my thoughts sometimes, and I believe in the idea that really understanding the basics is helpful to grasp concepts when things get more complicated.\n\n\nIF (and that‚Äôs a reasonably big if) you can find a linear relationship between two numerical vectors, then using a linear regression can help ‚Äúencode‚Äù the whole pair of vectors through ‚Äújust‚Äù two numbers: A slope, and an intercept.\nIn effect, you‚Äôre ‚Äúmodelling‚Äù a relationship - and in doing so, you‚Äôre actually compressing information.\nMore to the point, if you have an intuition that such relationship holds true for other points you were not given, then you can interpolate (if the new points are in the range of original vectors - otherwise it‚Äôs called ‚Äúextrapolation‚Äù) an expected output from a given input.\nIn other words: If you know (or expect) there is a linear (straight line) relationship between a webserver load and number of concurrently opened sessions, you could estimate a load (say % CPU) from knowing only the number of users currently connected (or the other way around, obviously). You‚Äôd expect the load to grow with the number of users.\nThe concept of regression (linear or otherwise) are important in ML. It‚Äôs a core part of most models. You doubt? Let me put it this way: Regression is a core part of how training a neural network works. There. Believe me now? (I guess I just justified myself in tagging this entry as Machine Learning, after all.)\n\n\n\nWe‚Äôll start off very easy today. Imagine to begin with you only have two points. So two pairs\\((x_1, y_1), (x_2, y_2)\\) of coordinates then. IF (again, big IF) you somehow expects a straight line could be used to estimate a third \\(y_3\\) from a third \\(x_3\\) coordinate in the range of the two original points‚Ä¶ How can you estimate said value of \\(y_3\\).\nWell, it‚Äôs basic (elementary? high school? Idk) math, you want to find \\(a, b\\) in the following:\n\\[\ny = ax + b\n\\]\nThere are two numbers to find (a slope, and an intercept), and we have two points. That‚Äôs a system of two equations. But instead of just doing the math, let‚Äôs think about this from a conceptual perspective.\nYou can probably skip this, as it‚Äôs really very basic, but I like to make sure I understand things, not just use the math I can find out there, and so I‚Äôm going to explain it nevertheless.\nWhat is a ‚Äúslope‚Äù?\nThink of a bicycle ride, and you‚Äôre faced with a 8% upwards (so ‚Äúpositive‚Äù) slope; what does that mean? That for every 100 meters you advance horizontally, you should expect to gain 8 meters in elevation. So if you gain 8 units in the y direction, you have moved 100 units in the x direction.\nWith two points: \\(y_2 - y_1 = 8, x_2 - x_1 = 100\\). And you get to the slope by dividing both numbers (which is why we expressed the slope in percentage). So you need then:\n\\[\na = slope = {(y_2 - y_1) \\over (x_2 - x_1)}\n\\]\nNot soooo misterious now, is it? If the slope is downwards, \\(y_2 &lt; y_1\\) and \\(a &lt; 0\\), that‚Äôs all.\nAnd what is the ‚Äúintercept‚Äù?\nIf you show lines on a two dimensional graph, you often will see the \\(y\\) and \\(x\\) axis. The ‚Äúintercept‚Äù is simply the point at which our line crosses (‚Äúintercepts‚Äù) the \\(y\\) axis. Which happens when \\(x = 0\\).\nAnd by now, if we take any of our points, we have the following bits \\(y_1, a, x_1\\) for our equation \\(y = ax + b\\). Can we get to \\(b\\)?\n\\[\nb = y_1 - a x_1\n\\]So that for \\(x = 0\\), we have \\(b\\) as the value of \\(y\\). Which is what we were looking for.\nThis was very very very basic stuff. But hopefully for those that don‚Äôt do math in their day-to-day life, or those that use formulas without thinking (or use Excel to estimate these things, if at all), or simply as a refresher‚Ä¶ I don‚Äôt know. Sorry if that was boring.\n\n## Suppose you have any two points:\nmy_x &lt;- c(1.5, 2.5)\nmy_y &lt;- c(5, 2)\n\n# Line goes through two points\n## By definition of \"slope\":\nmy_line_slope &lt;- (my_y[2] - my_y[1]) / (my_x[2]- my_x[1])\n## Then just replace with one point to get intercept:\nmy_intercept &lt;- my_y[1] - (my_line_slope * my_x[1])\n\ncalculate_resulting_y &lt;- function(x) {\n    my_line_slope * x + my_intercept\n}\n\n## Say then we have any value of x (\"independent variable\"):\nmy_interpolation_x_set &lt;- seq(0, 5, 0.1)\n## In a perfect World, we could then get any dependent value:\nmy_interpolation_y_set &lt;- sapply(my_interpolation_x_set, calculate_resulting_y)\n\nplot(my_interpolation_y_set ~ my_interpolation_x_set, col = \"blue\", type=\"l\")\npoints(my_y ~ my_x, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nIn the above, we took a pretty big leap of faith: We just somehow knew/assumed that two points would represent a linear relationship.\nBut we‚Äôd probably feel more confident if we had more points to confirm our expectations first.\nToday we‚Äôll stay with the ‚ÄúSimple Linear Regression‚Äù, which is nicely explained in the Wikipedia.\nWe want to find \\(\\alpha, \\beta\\) that best describe not two points but instead estimate a line for several of them, so that we solve \\(y = \\alpha + \\beta x\\) that best estimate all \\(x_i, y_i\\) pairs we‚Äôre given (provided they look like a straight line).\nAnd I‚Äôve said ‚Äúestimate‚Äù twice above, as there will be some error, and that‚Äôs key here: We essentially try to minimize the error that our estimated \\(\\alpha, \\beta\\) introduce, for each point. Written ‚Äúfancily‚Äù:\n\\[\n\\widehat{\\epsilon}_i = y_i - (\\alpha + \\beta x_i), \\forall i \\in [1..n], n \\in \\mathbb{N}\n\\]\nWhere n is the number of your available points‚Ä¶\n\nMinimizing the error is an important concept in supervised machine learning.\n\nThen using the ‚ÄúSum of Square‚Äù of the residuals, we‚Äôre going to try to minimize that.\n\n\n\nI will take the time to dive into this a bit, as it is relevant to understand for other cases. Although the math is better explained here, that approach of minimizing sum of squares is useful in other contexts and so here goes.\nSo today we are trying to ‚Äúfit‚Äù a line to a set of points that are not necessarily exactly on said line (see ‚Äúthe result‚Äù below). But where do we start? How do we go about finding one line out of an infinite set of possible lines?\nMore or less, we find the parameters for our line equation that minimizes overall distance from all the points. So we try to minimize the sum of the error of our line from each point. It is a minimization exercise, but sometimes the points will be under the line, and others they‚Äôll be above. To correct for that, we actually minimize the sum of distances, each one squared! That way, all values are positive, and we really try to minimize something.\nThere is another important point hidden right here: The key to understand ‚ÄúGradient Descent‚Äù!\nAs we will see with the ‚Äúresults‚Äù below, the errors, when squared, are shaped in a sort of U. But what‚Äôs important is that the function behind that (parabolic) shape is that it‚Äôs differentiable.\nDifferentiating (that‚Äôs calculus) here will mean that we know in which direction (up, down, horizontal) said curve goes for a given point on the x axis. If we know that, we know that if the curve goes upwards, to minimize the thing, we want to go in the opposite direction.\nAnd that‚Äôs exactly what ‚Äúdescending the gradient‚Äù is all about (although in multivariate settings: A gradient in vector calculus is ‚Äúthe direction and the rate of fastest increase‚Äù, so to ‚Äúdescend a gradient‚Äù, you want to move in the opposite direction).\nFor linear regression, it‚Äôs cool because we can do partial derivatives (as shown on the referenced Wiki page above) to find our \\(\\alpha\\) and \\(\\beta\\) parameters that describe the line that ‚Äúbest fit the data‚Äù.\nIt‚Äôs quite clever, mind you: You minimize the error of your predicted value compared to the actual value. That‚Äôs how your machine can learn! But it‚Äôs also what people have been using to train Neural Networks!\nFor today, let‚Äôs just store the following information: The ‚ÄúLeast Square Minimization‚Äù can help find a minimum error through differentiation.\nAnd for a future conversation: Gradient Descent (hidden in today‚Äôs Sum of Square Minimization) is one of the two mathematical keys for back-propagation. (And back-propagation was the before and after of connectionism in Machine Learning theory).\nAlright, let‚Äôs move on and return to our very simple example.\n\n\n\nRemember how we said at some point that in ML, more data points is often better?\nWe‚Äôre going to find the line that best fits a set of points (I know a simple straight line will work here, because I‚Äôm the one generating said line‚Ä¶ :D)\nWe‚Äôre also going to show the square of errors, how it looks like a U shape, and how it‚Äôs clear there is a minimum to it‚Ä¶\n\n## Some points that can be used:\nmy_regression_x_set &lt;- seq(0, 5, 0.1) + rnorm(51,mean = 0, sd = 0.2)\nmy_regression_y_set &lt;- my_interpolation_y_set + rnorm(51, mean = 0, sd = 0.2)\n\n## SIMPLE linear regression. Using Least Squares distance.\n## Key idea: Minimize differences.\n## Find minimum for error function using differentiation.\n## Final equations here instead of step by step explaining how to get there.\n\n## Just follow the math:\nmean_reg_x &lt;- mean(my_regression_x_set)\nmean_reg_y &lt;- mean(my_regression_y_set)\n\ndev_x &lt;- (my_regression_x_set - mean_reg_x)\ndev_y &lt;- (my_regression_y_set - mean_reg_y)\n\nbeta_est &lt;- sum(dev_x * dev_y) / sum(dev_x^2)\nalpha_est &lt;- mean_reg_y - (beta_est * mean_reg_x)\n\nplot(my_regression_y_set ~ my_regression_x_set)\n## alpha & beta can be confusing, I usually use Beta as multipliers of X...\nabline(a = alpha_est, b = beta_est, col=\"blue\")\n\n\n\n\n\n\n\n## Importantly, squared error is differentiable and has a global minimum\n## \"easily\". Related to \"Gradient Descent\"\nerr_x &lt;- my_regression_y_set - (alpha_est + my_regression_x_set * beta_est)\nerr_y &lt;- sapply(err_x, \\(x) x^2)\n\nplot(err_y ~ err_x)\n\n\n\n\n\n\n\n\nAnd that‚Äôs it! We‚Äôve used the math (skipping some steps), to show one can use it to do a linear regression (although nowadays all that stuff is available with one command, if not directly, then through packages).\nSo here we‚Äôve shown a downward slope: Let‚Äôs put it in context of a potential real-world application: Maybe our x axis represented the number of users connected to our system, and the y axis some number to represent the available resources (spare CPU or something) on a given server. If you know a linear relationship applies, you can estimate at which point you will reach 100% CPU‚Ä¶ (I could have started with that, sorry.)\nSo in the future, if you see a clear straight line between two things, well, you could use the above not-scary-at-all math approach to ‚Äúpredict‚Äù what would happen if you move along the x axis.\nLast note about the math: in this simple case, if you look at the code, we‚Äôve in fact used two statistics concepts to do the calculations: the means of the x and y axis, and the ‚Äúdeviations‚Äù of each point to said means.\nDoes it not make some intuitive sense that the line that best fits the points is related to the means and deviations of the points to said means? :)\n\n\n\nIn the above, we‚Äôve used deviations and means. These are basic concepts from statistics. And in the introduction, we have mentioned something about ‚Äúmodels‚Äù and ‚Äúcompression‚Äù. Which is what it is: Statistics are NOT the real world. And they can be misused. Here the 2 most common examples to illustrate how you can go astray with using statistics without looking at the data.\nLet‚Äôs illustrate just that, with a couple of typical (like, VERY typical) examples:\n\n\n\n\n\n\n\n\n\nAnd if it‚Äôs not clear enough, all these here below have the same mean and standard deviation:\n\n\n\n\n\n\n\n\n\n[1] \"Mean x Dino: 47.8322528169014\"\n\n\n[1] \"Mean x Bullseye: 47.8308231552178\"\n\n\n[1] \"SD x Dino: 16.7651420391168\"\n\n\n[1] \"SD x Bullseye: 16.7692394934267\"\n\n\nSee how they are basically the same numbers?\nStatistics are great, useful and very important today (and have been for quite a while, I‚Äôd argue). They‚Äôre just not always the right solution (neither is ML in a larger sense, mind you).\nAlways look at the data!\n\n\n\nWe‚Äôve gone from really REALLY simple stuff all the way to mentioning differentiation, gradient descent, statistics‚Ä¶\nAnd we‚Äôve skipped steps! (i.e.¬†solving systems of equations, which can be represented as matrices, which is relevant for completely different reasons :D)\nNot too shabby, after all‚Ä¶\n\nI‚Äôd like to go into Logistic Regression and Neural Networks a bit in a future entries. Even discuss a bit the history of ML, maybe. And that would conclude my preparation for my sessions about ‚ÄúML Background for Cybersecurity‚Äù. Surely there is more to it all, but if I manage to convey a few key concepts to my colleagues, I‚Äôll be very very happy. And this here is me trying.\nBut after that, I‚Äôll shift gears and focus on a personal project I have had in mind for some time and that is taking shape: It involves writing an R package, for a set of ML algorithms that for reasons I don‚Äôt quite understand have not received as much attention as I personally think they should. To be continued!\n\n\n\n\nThe Wikipedia for Simple Linear Regression does help.\nHere about the Gradient.\nThe math for the simple linear regression we‚Äôve used today.\nThen the more advanced discussion on Linear Regression hopefully can be followed."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#why-linear-regression-in-the-first-place",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#why-linear-regression-in-the-first-place",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "IF (and that‚Äôs a reasonably big if) you can find a linear relationship between two numerical vectors, then using a linear regression can help ‚Äúencode‚Äù the whole pair of vectors through ‚Äújust‚Äù two numbers: A slope, and an intercept.\nIn effect, you‚Äôre ‚Äúmodelling‚Äù a relationship - and in doing so, you‚Äôre actually compressing information.\nMore to the point, if you have an intuition that such relationship holds true for other points you were not given, then you can interpolate (if the new points are in the range of original vectors - otherwise it‚Äôs called ‚Äúextrapolation‚Äù) an expected output from a given input.\nIn other words: If you know (or expect) there is a linear (straight line) relationship between a webserver load and number of concurrently opened sessions, you could estimate a load (say % CPU) from knowing only the number of users currently connected (or the other way around, obviously). You‚Äôd expect the load to grow with the number of users.\nThe concept of regression (linear or otherwise) are important in ML. It‚Äôs a core part of most models. You doubt? Let me put it this way: Regression is a core part of how training a neural network works. There. Believe me now? (I guess I just justified myself in tagging this entry as Machine Learning, after all.)"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#two-points-interextrapolation",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#two-points-interextrapolation",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "We‚Äôll start off very easy today. Imagine to begin with you only have two points. So two pairs\\((x_1, y_1), (x_2, y_2)\\) of coordinates then. IF (again, big IF) you somehow expects a straight line could be used to estimate a third \\(y_3\\) from a third \\(x_3\\) coordinate in the range of the two original points‚Ä¶ How can you estimate said value of \\(y_3\\).\nWell, it‚Äôs basic (elementary? high school? Idk) math, you want to find \\(a, b\\) in the following:\n\\[\ny = ax + b\n\\]\nThere are two numbers to find (a slope, and an intercept), and we have two points. That‚Äôs a system of two equations. But instead of just doing the math, let‚Äôs think about this from a conceptual perspective.\nYou can probably skip this, as it‚Äôs really very basic, but I like to make sure I understand things, not just use the math I can find out there, and so I‚Äôm going to explain it nevertheless.\nWhat is a ‚Äúslope‚Äù?\nThink of a bicycle ride, and you‚Äôre faced with a 8% upwards (so ‚Äúpositive‚Äù) slope; what does that mean? That for every 100 meters you advance horizontally, you should expect to gain 8 meters in elevation. So if you gain 8 units in the y direction, you have moved 100 units in the x direction.\nWith two points: \\(y_2 - y_1 = 8, x_2 - x_1 = 100\\). And you get to the slope by dividing both numbers (which is why we expressed the slope in percentage). So you need then:\n\\[\na = slope = {(y_2 - y_1) \\over (x_2 - x_1)}\n\\]\nNot soooo misterious now, is it? If the slope is downwards, \\(y_2 &lt; y_1\\) and \\(a &lt; 0\\), that‚Äôs all.\nAnd what is the ‚Äúintercept‚Äù?\nIf you show lines on a two dimensional graph, you often will see the \\(y\\) and \\(x\\) axis. The ‚Äúintercept‚Äù is simply the point at which our line crosses (‚Äúintercepts‚Äù) the \\(y\\) axis. Which happens when \\(x = 0\\).\nAnd by now, if we take any of our points, we have the following bits \\(y_1, a, x_1\\) for our equation \\(y = ax + b\\). Can we get to \\(b\\)?\n\\[\nb = y_1 - a x_1\n\\]So that for \\(x = 0\\), we have \\(b\\) as the value of \\(y\\). Which is what we were looking for.\nThis was very very very basic stuff. But hopefully for those that don‚Äôt do math in their day-to-day life, or those that use formulas without thinking (or use Excel to estimate these things, if at all), or simply as a refresher‚Ä¶ I don‚Äôt know. Sorry if that was boring.\n\n## Suppose you have any two points:\nmy_x &lt;- c(1.5, 2.5)\nmy_y &lt;- c(5, 2)\n\n# Line goes through two points\n## By definition of \"slope\":\nmy_line_slope &lt;- (my_y[2] - my_y[1]) / (my_x[2]- my_x[1])\n## Then just replace with one point to get intercept:\nmy_intercept &lt;- my_y[1] - (my_line_slope * my_x[1])\n\ncalculate_resulting_y &lt;- function(x) {\n    my_line_slope * x + my_intercept\n}\n\n## Say then we have any value of x (\"independent variable\"):\nmy_interpolation_x_set &lt;- seq(0, 5, 0.1)\n## In a perfect World, we could then get any dependent value:\nmy_interpolation_y_set &lt;- sapply(my_interpolation_x_set, calculate_resulting_y)\n\nplot(my_interpolation_y_set ~ my_interpolation_x_set, col = \"blue\", type=\"l\")\npoints(my_y ~ my_x, col = \"red\")"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#multiple-points-with-a-linear-relationship",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#multiple-points-with-a-linear-relationship",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "In the above, we took a pretty big leap of faith: We just somehow knew/assumed that two points would represent a linear relationship.\nBut we‚Äôd probably feel more confident if we had more points to confirm our expectations first.\nToday we‚Äôll stay with the ‚ÄúSimple Linear Regression‚Äù, which is nicely explained in the Wikipedia.\nWe want to find \\(\\alpha, \\beta\\) that best describe not two points but instead estimate a line for several of them, so that we solve \\(y = \\alpha + \\beta x\\) that best estimate all \\(x_i, y_i\\) pairs we‚Äôre given (provided they look like a straight line).\nAnd I‚Äôve said ‚Äúestimate‚Äù twice above, as there will be some error, and that‚Äôs key here: We essentially try to minimize the error that our estimated \\(\\alpha, \\beta\\) introduce, for each point. Written ‚Äúfancily‚Äù:\n\\[\n\\widehat{\\epsilon}_i = y_i - (\\alpha + \\beta x_i), \\forall i \\in [1..n], n \\in \\mathbb{N}\n\\]\nWhere n is the number of your available points‚Ä¶\n\nMinimizing the error is an important concept in supervised machine learning.\n\nThen using the ‚ÄúSum of Square‚Äù of the residuals, we‚Äôre going to try to minimize that."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#sum-of-square-minimization",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#sum-of-square-minimization",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "I will take the time to dive into this a bit, as it is relevant to understand for other cases. Although the math is better explained here, that approach of minimizing sum of squares is useful in other contexts and so here goes.\nSo today we are trying to ‚Äúfit‚Äù a line to a set of points that are not necessarily exactly on said line (see ‚Äúthe result‚Äù below). But where do we start? How do we go about finding one line out of an infinite set of possible lines?\nMore or less, we find the parameters for our line equation that minimizes overall distance from all the points. So we try to minimize the sum of the error of our line from each point. It is a minimization exercise, but sometimes the points will be under the line, and others they‚Äôll be above. To correct for that, we actually minimize the sum of distances, each one squared! That way, all values are positive, and we really try to minimize something.\nThere is another important point hidden right here: The key to understand ‚ÄúGradient Descent‚Äù!\nAs we will see with the ‚Äúresults‚Äù below, the errors, when squared, are shaped in a sort of U. But what‚Äôs important is that the function behind that (parabolic) shape is that it‚Äôs differentiable.\nDifferentiating (that‚Äôs calculus) here will mean that we know in which direction (up, down, horizontal) said curve goes for a given point on the x axis. If we know that, we know that if the curve goes upwards, to minimize the thing, we want to go in the opposite direction.\nAnd that‚Äôs exactly what ‚Äúdescending the gradient‚Äù is all about (although in multivariate settings: A gradient in vector calculus is ‚Äúthe direction and the rate of fastest increase‚Äù, so to ‚Äúdescend a gradient‚Äù, you want to move in the opposite direction).\nFor linear regression, it‚Äôs cool because we can do partial derivatives (as shown on the referenced Wiki page above) to find our \\(\\alpha\\) and \\(\\beta\\) parameters that describe the line that ‚Äúbest fit the data‚Äù.\nIt‚Äôs quite clever, mind you: You minimize the error of your predicted value compared to the actual value. That‚Äôs how your machine can learn! But it‚Äôs also what people have been using to train Neural Networks!\nFor today, let‚Äôs just store the following information: The ‚ÄúLeast Square Minimization‚Äù can help find a minimum error through differentiation.\nAnd for a future conversation: Gradient Descent (hidden in today‚Äôs Sum of Square Minimization) is one of the two mathematical keys for back-propagation. (And back-propagation was the before and after of connectionism in Machine Learning theory).\nAlright, let‚Äôs move on and return to our very simple example."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#the-result",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#the-result",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "Remember how we said at some point that in ML, more data points is often better?\nWe‚Äôre going to find the line that best fits a set of points (I know a simple straight line will work here, because I‚Äôm the one generating said line‚Ä¶ :D)\nWe‚Äôre also going to show the square of errors, how it looks like a U shape, and how it‚Äôs clear there is a minimum to it‚Ä¶\n\n## Some points that can be used:\nmy_regression_x_set &lt;- seq(0, 5, 0.1) + rnorm(51,mean = 0, sd = 0.2)\nmy_regression_y_set &lt;- my_interpolation_y_set + rnorm(51, mean = 0, sd = 0.2)\n\n## SIMPLE linear regression. Using Least Squares distance.\n## Key idea: Minimize differences.\n## Find minimum for error function using differentiation.\n## Final equations here instead of step by step explaining how to get there.\n\n## Just follow the math:\nmean_reg_x &lt;- mean(my_regression_x_set)\nmean_reg_y &lt;- mean(my_regression_y_set)\n\ndev_x &lt;- (my_regression_x_set - mean_reg_x)\ndev_y &lt;- (my_regression_y_set - mean_reg_y)\n\nbeta_est &lt;- sum(dev_x * dev_y) / sum(dev_x^2)\nalpha_est &lt;- mean_reg_y - (beta_est * mean_reg_x)\n\nplot(my_regression_y_set ~ my_regression_x_set)\n## alpha & beta can be confusing, I usually use Beta as multipliers of X...\nabline(a = alpha_est, b = beta_est, col=\"blue\")\n\n\n\n\n\n\n\n## Importantly, squared error is differentiable and has a global minimum\n## \"easily\". Related to \"Gradient Descent\"\nerr_x &lt;- my_regression_y_set - (alpha_est + my_regression_x_set * beta_est)\nerr_y &lt;- sapply(err_x, \\(x) x^2)\n\nplot(err_y ~ err_x)\n\n\n\n\n\n\n\n\nAnd that‚Äôs it! We‚Äôve used the math (skipping some steps), to show one can use it to do a linear regression (although nowadays all that stuff is available with one command, if not directly, then through packages).\nSo here we‚Äôve shown a downward slope: Let‚Äôs put it in context of a potential real-world application: Maybe our x axis represented the number of users connected to our system, and the y axis some number to represent the available resources (spare CPU or something) on a given server. If you know a linear relationship applies, you can estimate at which point you will reach 100% CPU‚Ä¶ (I could have started with that, sorry.)\nSo in the future, if you see a clear straight line between two things, well, you could use the above not-scary-at-all math approach to ‚Äúpredict‚Äù what would happen if you move along the x axis.\nLast note about the math: in this simple case, if you look at the code, we‚Äôve in fact used two statistics concepts to do the calculations: the means of the x and y axis, and the ‚Äúdeviations‚Äù of each point to said means.\nDoes it not make some intuitive sense that the line that best fits the points is related to the means and deviations of the points to said means? :)"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#look-at-the-data",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#look-at-the-data",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "In the above, we‚Äôve used deviations and means. These are basic concepts from statistics. And in the introduction, we have mentioned something about ‚Äúmodels‚Äù and ‚Äúcompression‚Äù. Which is what it is: Statistics are NOT the real world. And they can be misused. Here the 2 most common examples to illustrate how you can go astray with using statistics without looking at the data.\nLet‚Äôs illustrate just that, with a couple of typical (like, VERY typical) examples:\n\n\n\n\n\n\n\n\n\nAnd if it‚Äôs not clear enough, all these here below have the same mean and standard deviation:\n\n\n\n\n\n\n\n\n\n[1] \"Mean x Dino: 47.8322528169014\"\n\n\n[1] \"Mean x Bullseye: 47.8308231552178\"\n\n\n[1] \"SD x Dino: 16.7651420391168\"\n\n\n[1] \"SD x Bullseye: 16.7692394934267\"\n\n\nSee how they are basically the same numbers?\nStatistics are great, useful and very important today (and have been for quite a while, I‚Äôd argue). They‚Äôre just not always the right solution (neither is ML in a larger sense, mind you).\nAlways look at the data!"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#conclusions",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#conclusions",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "We‚Äôve gone from really REALLY simple stuff all the way to mentioning differentiation, gradient descent, statistics‚Ä¶\nAnd we‚Äôve skipped steps! (i.e.¬†solving systems of equations, which can be represented as matrices, which is relevant for completely different reasons :D)\nNot too shabby, after all‚Ä¶\n\nI‚Äôd like to go into Logistic Regression and Neural Networks a bit in a future entries. Even discuss a bit the history of ML, maybe. And that would conclude my preparation for my sessions about ‚ÄúML Background for Cybersecurity‚Äù. Surely there is more to it all, but if I manage to convey a few key concepts to my colleagues, I‚Äôll be very very happy. And this here is me trying.\nBut after that, I‚Äôll shift gears and focus on a personal project I have had in mind for some time and that is taking shape: It involves writing an R package, for a set of ML algorithms that for reasons I don‚Äôt quite understand have not received as much attention as I personally think they should. To be continued!"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#references",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#references",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "The Wikipedia for Simple Linear Regression does help.\nHere about the Gradient.\nThe math for the simple linear regression we‚Äôve used today.\nThen the more advanced discussion on Linear Regression hopefully can be followed."
  },
  {
    "objectID": "posts/2023-07-16_GradientDescent/index.html",
    "href": "posts/2023-07-16_GradientDescent/index.html",
    "title": "Optimization: Gradient Descent",
    "section": "",
    "text": "Intro\nSo I keep going with the reference book for a while. BTW, the book can be found here (NOT a referral or anything, I don‚Äôt make money out of this, it‚Äôs just a pointer to one place you can find it). And yes, the book is in Spanish‚Ä¶\nSo one of the first algorithms (beyond ‚Äúrandom search‚Äù, I guess) is the well known Gradient Descent. Let‚Äôs implement that in R.\n\n\nR-based Gradient Descent for bi-variate function\nThe code for today can be found here.\nThe Gradient Descent method (to look for a minimum value, say) is fine for mono-modal (convex) functions that are twice differentiable (in theory at least), in spite of being reasonably slow in converging.\nA numerical method is easy to implement in this case. Let‚Äôs have a look at what it looks like:\n\n\n\nGradient Descent Contour\n\n\n\n\n\nGradient Descent Perspective\n\n\nWhy is Gradient Method important, you ask? Well, at least for what I learnt some time ago, let‚Äôs just say it‚Äôs used in ML for instance to tune neural network through back-propagation. And of course that‚Äôs just one example (but a very common application these days). One could also use it to minimize (or well, maximize) any compatible functions, of course, and so this has application in Operations Research at large, obviously.\n\n\nOne draw-back\nOne of the limitations of the Gradient Descent method is that it works fine for mono-modal functions (in the search space at least, that is), but it can‚Äôt avoid falling into local minima if the starting point goes in that direction‚Ä¶\n\n\n\nFalling in local minima\n\n\n\n\nNext time\nI‚Äôll try and implement the next proposed algorithm, ‚ÄúSimulated Annealing‚Äù, that helps with looking for global minima."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html",
    "href": "posts/2021-07-11_NLP_partI/index.html",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "",
    "text": "To use Natural Language Processing algorithms, we first need data.\nWe‚Äôve seen last time how to scrape ONE article. And how to get to different pages of the Blog. But for this to be usable in the future, we should be able to download all articles UNTIL there is no more (e.g.¬†we probably don‚Äôt want to know up-front how many pages we actually want to ‚Äúcrawl‚Äù)."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#intro",
    "href": "posts/2021-07-11_NLP_partI/index.html#intro",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "",
    "text": "To use Natural Language Processing algorithms, we first need data.\nWe‚Äôve seen last time how to scrape ONE article. And how to get to different pages of the Blog. But for this to be usable in the future, we should be able to download all articles UNTIL there is no more (e.g.¬†we probably don‚Äôt want to know up-front how many pages we actually want to ‚Äúcrawl‚Äù)."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#extracting-one-article-from-one-specific-page",
    "href": "posts/2021-07-11_NLP_partI/index.html#extracting-one-article-from-one-specific-page",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "Extracting one article from one specific page",
    "text": "Extracting one article from one specific page\nFirst, let‚Äôs suppose we have located a page with articles. Let‚Äôs see how to take out the text of ONE of these articles.\nWe‚Äôll want to get, from the page, the title, date of publication and contents (text) of the article. Let‚Äôs see how to do that:\nget_article_in_page &lt;- function(art_num = 1, page_articles) {\n   if(is.list(page_articles) & length(page_articles) &gt;= art_num) {\n      # Date is tricky here:\n      possible_date_locations &lt;- c(\".//time[@class='entry-date published']\", \".//time[@class='entry-date published updated']\")\n      art_date &lt;- xml_text(xml_find_all(page_articles[art_num], possible_date_locations[1]))\n      if(length(art_date) == 0) {\n         art_date &lt;- xml_text(xml_find_all(page_articles[art_num], possible_date_locations[2]))\n      }\n\n      art_title &lt;- xml_text(xml_find_all(page_articles[art_num], \".//h1[@class='entry-title']\"))\n      art_content &lt;- xml_text(xml_find_all(page_articles[art_num], \".//div[@class='entry-content']\"))\n      print(paste(\"Article:\", art_num, \"Date Found: \", art_date)); flush.console();\n\n      return(data.frame(article_date = art_date,\n         article_title = art_title,\n         article_content = art_content))\n   }\n\n   # Should never be reached.\n   print(\"Function get_article_in_page: Uncontrolled error?\"); flush.console()\n   return(NULL)\n}\nThat‚Äôs building on the results from the last Blog post. It turns out (after some tests) that the date is in different tags depending on whether the entry was updated at some point, so I amended for that.\nNow we have a data.frame with one article, including its title, publication date and text contents."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#getting-all-articles-in-one-specific-page",
    "href": "posts/2021-07-11_NLP_partI/index.html#getting-all-articles-in-one-specific-page",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "Getting all articles in one specific page",
    "text": "Getting all articles in one specific page\nNow we have one selected page, which, in the current configuration of the Blog, contains three articles by default. So let‚Äôs put those articles in one data.frame:\nget_page_kaizen_blog &lt;- function(pagenum = 1) {\n   base_page &lt;- \"https://www.kaizen-r.com/category/blog/page/\"\n\n   tryCatch({ # Excessive caution here.\n      page_con &lt;- curl(paste0(base_page, pagenum, \"/\"))\n      \n      page_text &lt;- tryCatch(xml2::read_html(page_con), \n         error = function(e) { \n            close(page_con)\n            return(NULL)\n         })\n\n      if(!is.null(page_text)) {\n         page_articles &lt;- xml_find_all(page_text, \".//article\")\n\n         t_articles_df &lt;- rbind.fill(lapply(1:length(page_articles), \n            get_article_in_page,\n            page_articles))\n\n         return(cbind(data.frame(pagenum = pagenum), t_articles_df))\n      } else {\n         return(NULL)\n      }\n   }, warning = function(w) {\n      message(w)\n      print(\"Function get_page: Controlled warning\"); flush.console()\n      return(NULL)\n   }, error = function(e) {\n      message(e)\n      print(\"Function get_page: Controlled error\"); flush.console()\n      return(NULL)\n   }, finally = {\n      #cleanup-code\n   })\n\n   # Should never be reached.\n   print(\"Function get_page: Uncontrolled error?\"); flush.console()\n   return(NULL)\n}\nIn the above, the error controls (tryCatch) have proven somewhat superfluous.\nThe only issue was with controlling the ‚Äúxml2::read_html()‚Äù bit, really, for cases where I call this function on a page number that turns out to be inexistent.\nThankfully if we have less than 3 articles on one page, the rbind.fill function from the plyr package is clever enough to manage that gracefully (not adding that to the row-binded data.frame)."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#getting-all-pages-in-the-blog",
    "href": "posts/2021-07-11_NLP_partI/index.html#getting-all-pages-in-the-blog",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "Getting all pages in the blog",
    "text": "Getting all pages in the blog\nNow we need to go through all pages. There are three possible outcomes, looping through this Blog‚Äôs pages:\n\nA page has 3 results (complete page)\nA page has results, but less than 3\nA page has no results (and throws an Error 404)\n\nSo if we gather the articles of our Blog one page at a time, and then go for the ‚Äúnext page‚Äù (technically going back in time further and further), we will end up in one of these three scenarios.\nBut as we don‚Äôt know up-front what case we will fall in for each page we crawl, we need to start an infinite loop, and then stop crawling after we get to less than 3 articles on a page, or no article, which will be indicative of us having finished.\nAs the crawler of ONE page gracefully tells us when we reach a page with no articles (returning NULL), we need only control for that case for now:\nHere goes the code:\nget_all_articles_kaizen_blog_v1 &lt;- function() {\n   articles_df &lt;- NULL\n   pagenum &lt;- 1\n\n   while(TRUE) {\n      t_articles &lt;- get_page_kaizen_blog(pagenum)\n      if(is.null(t_articles)) {\n         break;\n      } else {\n         articles_df &lt;- rbind.fill(t_articles,\n            articles_df)\n      }\n      pagenum &lt;- pagenum + 1\n   }\n   articles_df\n}\nRather basic loop, but it does the job."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#making-things-a-bit-faster-using-futures",
    "href": "posts/2021-07-11_NLP_partI/index.html#making-things-a-bit-faster-using-futures",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "Making things a bit faster (using futures)",
    "text": "Making things a bit faster (using futures)\nOnce we‚Äôre here, we implement a lapply-based version of the crawler of all pages. The idea is to be able to loop across 4-pages-crawls at once. It‚Äôs mostly stupid per-se, as we might have to crawl empty pages (supposing we have numpages %% 4¬† != 0) but that‚Äôs useful for the next version.\nI did it because now I can use ‚Äúfuture_lapply‚Äù to crawl 4 pages ‚Äúin parallel‚Äù (well, depending on available cores for use by the Futures multisession package).\nIn our case, on a laptop, we only get two cores, so we can‚Äôt expect to make things 4 times faster, but indeed, it is almost twice as fast as doing one-by-one crawling.\n\nWhat this means is that crawling two pages in parallel compensates handsomely the overhead of launching new ‚Äúsessions‚Äù. In a setup with more available cores to our Docker install, things should go even faster (I need to test this on the Home Server Lab, for instance :))."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#conclusions",
    "href": "posts/2021-07-11_NLP_partI/index.html#conclusions",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "Conclusions",
    "text": "Conclusions\nAs easy as it might have seemed, getting a reasonably clean code to crawl a simple blog as this one is not all as straightforward.\nControlling for certain errors is important (otherwise, going into parallel processing will eventually make it hard to debug stuff). Parsing HTML is not as obvious as a typical user of browsers would expect, one needs to ‚Äúdive‚Äù into the HTML tree and locate stuff.\nBut after some efforts, one can get there, and it can be ‚Äúrepeatable‚Äù, which will be good for us, as we will crawl ‚Äúanew‚Äù our website every time we will analyse its contents. Now with three functions and one call, we can get a dataframe with the contents of our Blog entries.\nSo first step: Done.\nNext time, we will start looking into the collected data. Expect some cleaning, for sure. And then we‚Äôll see."
  },
  {
    "objectID": "posts/2021-07-11_NLP_partI/index.html#references",
    "href": "posts/2021-07-11_NLP_partI/index.html#references",
    "title": "Scraping all the (old) Blog articles (the hard way)",
    "section": "References",
    "text": "References\nMy code for this exercise on GitHub"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Yesterday I did nothing. Like‚Ä¶ Nothing. I considered it an active choice, and as such I wasn‚Äôt sad at the end of the day for not having ‚Äúproduced‚Äù anything‚Ä¶ And today I was motivated to look for something to do.\nBut what? Well, I have options for sure, but one of them was to choose a topic to read about, and I had that book about Strategy that ‚Äúcalled me‚Äù, half-started (maybe 1/4 read‚Ä¶). Of the different options I had, I chose that book.\nAnd while reading it, these ideas of Tolstoi (see ‚ÄúWar and Peace‚Äù) about some limits of the ‚Äúscience‚Äù (rather art) of Strategy, and how history might filter a few decisions as key, discarding many other things that have happened‚Ä¶\n\n\n\nBook Cover for ‚ÄúStrategy, a History‚Äù (see resources)\n\n\nBut let‚Äôs not get ahead of ourselves, as since this morning I have given it some thought‚Ä¶\n\n\n\nBinary things. Yes or No.¬†True or False. Option A or B. This is the simplest level of information encoding I guess.\nAnd so it goes for Decisions! After all, if you have to choose between 3 (competing) options, you can look at them as 3 different binary choices.\nAnd that ‚Äúsimile‚Äù I think is key. Binary is in the end the minimal level of encoding for information AND for decisions, and maybe then it kinda makes sense that information is hence just a support for decision.\nOr maybe not: some will argue randomness, intuition, etc. I don‚Äôt disagree. Chaos theory sorts of proves that point, that you can‚Äôt predict the future. Not absolutely anyway, not in the long run, in complex systems. And decisions are not only binary in nature: they are also about making a prediction, aren‚Äôt they? Otherwise‚Ä¶ They make no sense.\nAnd because of Chaos theory, maybe no one can make perfect decisions, Bayesian thinking would be limited, and then it‚Äôs all irrelevant‚Ä¶ Well, I don‚Äôt know, I suppose there is some truth to that, but I can‚Äôt do much about that, can I?\nAnd so I prefer to look at information-based decisions as imperfect. But not useless or pointless.\n(Incidentally, binary is the current encoding for the RLCS package input, but that is quite irrelevant to today‚Äôs discussion‚Ä¶)\n\n\n\nComing back to the discussion of Tolstoi‚Äôs perspective (I haven‚Äôt read Tolstoi myself), the book implies that he would consider that the impact of specific decisions by military leaders (say, Bonaparte, etc.) was in fact less important than history would have us think, and that the sum of individual decisions (of say the whole armies) in context are then at the very best influenced.\nThis reminded me of two ‚Äúideas‚Äù somehow. Maybe it‚Äôs a bit far-fetched‚Ä¶ But here goes:\n\nCybernetics. Now this is far from a perfect match here, I know. But in concept, originally, that was inspired by a captain that steers a boat, thereby pushes in one direction, but with the wind, waves and what-not, you can‚Äôt perfectly indicate an exact direction, so in that sense you have a lot of influence, yes, but there is some‚Ä¶ wiggle? uncertainty? And although I understand I am being fuzzy in my juxtaposition of these ideas here, well, it also agrees with the fact that although you can have an impact on the overall direction of things, no decision will here be perfect as you cannot have a perfect impact. Yes, you can build negative-feedback loops, constantly improving‚Ä¶ Anyway. Just crossed my mind, there.\nAnd the second idea, is Asimov‚Äôs ‚ÄúPsycho-History‚Äù. I‚Äôve always loved the original trilogy of the Foundations (not the TV adaptation‚Ä¶). The very concept of psycho-history is resounding when reading these concepts by Tolstoi as introduced above‚Ä¶ Again here, maybe steering is possible, but the ‚Äúmasses‚Äù have a sort of inertia to them‚Ä¶ A topic, an idea I always found interesting.\n\nWhat these things are saying, put together, is I guess this: Say in a large company. One boss can make ‚Äústrategic‚Äù decisions. But how much of that translates into a perfectly aligned (maybe more tactical) action? Does anyone know what such an action could/should be (and that‚Äôs the job of managers and employees, you could argue)? Would context accompany, at all?\nContext is of course taken into account in decision making. As it should be. But context evolves, and some talk about 5-year plans, and I would argue, that might not‚Ä¶ Work, as the context is so uncertain. (And there could be a counter-argument made that part of the context is not as ‚Äúchanging‚Äù, or that strategic plans need constant review, etc. All fair points :))\nWould the whole team of many people ever be perfectly aligned with said action or actions? I guess not, and the ideas of Chaos (in that even if deterministic, one cannot cover perfectly an initial situation in all its detail) and Complex Systems (that pieces influence pieces, and one would need to consider each piece, here an employee, in its own context, as well as the system at large) are supporting my view here. Do they (the whole team) actually need to be ‚Äúperfectly‚Äù aligned, one might wonder‚Ä¶?\nAlso, how much of the decision is important vs how much of the actual good-willingness of the underlying execution team (which is what appears to be what Tolstoi would have argued‚Ä¶)? What then is the relative importance of the understanding and alignment of the team?\nIn that context, how important is the decision itself?\nClearly, a wrong decision will make things worse, and a good decision will make things better, that‚Äôs not my point here :)\nThis is all obviously a bit ‚Äúout-there‚Äù and more of a thought exercise. But as I like the topic of decision making and strategy, well‚Ä¶\nAnd yes, I guess I‚Äôm opening more questions than I am answering‚Ä¶ My bad.\n\n\n\nSomewhat related is the topic of the decision making itself and information, and the topic of simulations. Actually above I kinda of made a point of the limits of any simulation. In that the reality is complex, has several levels of abstraction, and too much detail to ever be included in a simulation. Still‚Ä¶ Whenever I think of simulations these days, I think about Monte-Carlo, Reinforcement Learning, and the likes.\n\n\nThis one point has made my day, really. Reinforcement Learning is cool, no question asked, but here is a common derived conversation about RL: So what?\nThe discussion is about the applications of Reinforcement Learning. Well, I will today argue that beyond playing games, it can be considered in context of simulations for decision making. And that opens a lot of potential value for it‚Ä¶\nBack to the conversation, now‚Ä¶\n\n\n\n\nI‚Äôll admit, I‚Äôm a fan of the Ironman movies (and no, I‚Äôm not ashamed). But I mostly like the ‚ÄúJarvis‚Äù part of it. That helpful AI program that helps Tony Stark. Or other simulations that Tony runs to create something‚Ä¶\n\n\n\nrunning simulations to make decisions, Ironman‚Äôs way\n\n\nIn several scenes of different movies in the series of Ironman or the Avengers, Tony launches a simulation of something (say of different ways of programming something, compiling it, and seeing whether the resulting program would successfully fulfill a given purpose, I guess).\nWith all the considerations above about the limits of decision-making, their actual impact, the importance of chaos theory, impossibility of considering future changing-context, the role of the execution, alignment, etc‚Ä¶ With all that in mind‚Ä¶\nI‚Äôve run in the past simulations of traffic in (medium) cities, which helped identify bottlenecks for different traffic scenarios. I‚Äôve run Monte-Carlo simulations of infectious processes on small networks, to decide better on which nodes to act. I‚Äôve been playing with Reinforcement Learning, whereby an agent takes more or less appropriate decisions with (limited) contextual information.\nAnd although maybe this has all been mostly theoretical, I do believe that, within (today‚Äôs) said limits of decision making, that approach makes a lot of sense.\nSo yes, I think RL has a place, maybe, beyond playing Chess and Go‚Ä¶ And maybe if one can setup a valid ‚Äúsimulation‚Äù of a scenario, then RL could be one approach to test different options and see what a computer could come up with.\nBy the way, this is also what Meta-heuristics is all about (including, obviously, Genetic Algorithms, which my readers will know I like :)). And Operations Research (albeit slightly different in approach, or sure).\nI also believe that the ideas of ‚Äúdigital twins‚Äù for instance in Health Care decision support are interesting, in that sense.\nAll in all, I guess this point is that one can support (ever imperfect) decision making with simulations.\n\n\n\nAnd well, that‚Äôs the gist of my thoughts on the topic today.\nI know, I didn‚Äôt invent fire today. It would seem, I rarely have an actually original thought‚Ä¶ Apologies here. The best I can do, it appears, is agreeing or disagreeing with some view, and then changing my mind with everything I learn along the way‚Ä¶ Oh well.\nThen again, hopefully me connecting different ideas is enough of a ‚Äúvalue-add‚Äù. I read somewhere that this connecting the dots is, in fact, a way of ‚Äúinnovating‚Äù.\nI do hope these thoughts are not completely crazy and that they inspire some more thoughts by others‚Ä¶ That would be great.\nAnd that would justify writing about it in the first place, beyond the fact that writing helps me think‚Ä¶\n\n\n\nStrategy, A History, by L. Freedman"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#random-sunday-thoughts",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#random-sunday-thoughts",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Yesterday I did nothing. Like‚Ä¶ Nothing. I considered it an active choice, and as such I wasn‚Äôt sad at the end of the day for not having ‚Äúproduced‚Äù anything‚Ä¶ And today I was motivated to look for something to do.\nBut what? Well, I have options for sure, but one of them was to choose a topic to read about, and I had that book about Strategy that ‚Äúcalled me‚Äù, half-started (maybe 1/4 read‚Ä¶). Of the different options I had, I chose that book.\nAnd while reading it, these ideas of Tolstoi (see ‚ÄúWar and Peace‚Äù) about some limits of the ‚Äúscience‚Äù (rather art) of Strategy, and how history might filter a few decisions as key, discarding many other things that have happened‚Ä¶\n\n\n\nBook Cover for ‚ÄúStrategy, a History‚Äù (see resources)\n\n\nBut let‚Äôs not get ahead of ourselves, as since this morning I have given it some thought‚Ä¶"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#most-simplistic-decisions-information",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#most-simplistic-decisions-information",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Binary things. Yes or No.¬†True or False. Option A or B. This is the simplest level of information encoding I guess.\nAnd so it goes for Decisions! After all, if you have to choose between 3 (competing) options, you can look at them as 3 different binary choices.\nAnd that ‚Äúsimile‚Äù I think is key. Binary is in the end the minimal level of encoding for information AND for decisions, and maybe then it kinda makes sense that information is hence just a support for decision.\nOr maybe not: some will argue randomness, intuition, etc. I don‚Äôt disagree. Chaos theory sorts of proves that point, that you can‚Äôt predict the future. Not absolutely anyway, not in the long run, in complex systems. And decisions are not only binary in nature: they are also about making a prediction, aren‚Äôt they? Otherwise‚Ä¶ They make no sense.\nAnd because of Chaos theory, maybe no one can make perfect decisions, Bayesian thinking would be limited, and then it‚Äôs all irrelevant‚Ä¶ Well, I don‚Äôt know, I suppose there is some truth to that, but I can‚Äôt do much about that, can I?\nAnd so I prefer to look at information-based decisions as imperfect. But not useless or pointless.\n(Incidentally, binary is the current encoding for the RLCS package input, but that is quite irrelevant to today‚Äôs discussion‚Ä¶)"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#about-limits-of-strategy",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#about-limits-of-strategy",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Coming back to the discussion of Tolstoi‚Äôs perspective (I haven‚Äôt read Tolstoi myself), the book implies that he would consider that the impact of specific decisions by military leaders (say, Bonaparte, etc.) was in fact less important than history would have us think, and that the sum of individual decisions (of say the whole armies) in context are then at the very best influenced.\nThis reminded me of two ‚Äúideas‚Äù somehow. Maybe it‚Äôs a bit far-fetched‚Ä¶ But here goes:\n\nCybernetics. Now this is far from a perfect match here, I know. But in concept, originally, that was inspired by a captain that steers a boat, thereby pushes in one direction, but with the wind, waves and what-not, you can‚Äôt perfectly indicate an exact direction, so in that sense you have a lot of influence, yes, but there is some‚Ä¶ wiggle? uncertainty? And although I understand I am being fuzzy in my juxtaposition of these ideas here, well, it also agrees with the fact that although you can have an impact on the overall direction of things, no decision will here be perfect as you cannot have a perfect impact. Yes, you can build negative-feedback loops, constantly improving‚Ä¶ Anyway. Just crossed my mind, there.\nAnd the second idea, is Asimov‚Äôs ‚ÄúPsycho-History‚Äù. I‚Äôve always loved the original trilogy of the Foundations (not the TV adaptation‚Ä¶). The very concept of psycho-history is resounding when reading these concepts by Tolstoi as introduced above‚Ä¶ Again here, maybe steering is possible, but the ‚Äúmasses‚Äù have a sort of inertia to them‚Ä¶ A topic, an idea I always found interesting.\n\nWhat these things are saying, put together, is I guess this: Say in a large company. One boss can make ‚Äústrategic‚Äù decisions. But how much of that translates into a perfectly aligned (maybe more tactical) action? Does anyone know what such an action could/should be (and that‚Äôs the job of managers and employees, you could argue)? Would context accompany, at all?\nContext is of course taken into account in decision making. As it should be. But context evolves, and some talk about 5-year plans, and I would argue, that might not‚Ä¶ Work, as the context is so uncertain. (And there could be a counter-argument made that part of the context is not as ‚Äúchanging‚Äù, or that strategic plans need constant review, etc. All fair points :))\nWould the whole team of many people ever be perfectly aligned with said action or actions? I guess not, and the ideas of Chaos (in that even if deterministic, one cannot cover perfectly an initial situation in all its detail) and Complex Systems (that pieces influence pieces, and one would need to consider each piece, here an employee, in its own context, as well as the system at large) are supporting my view here. Do they (the whole team) actually need to be ‚Äúperfectly‚Äù aligned, one might wonder‚Ä¶?\nAlso, how much of the decision is important vs how much of the actual good-willingness of the underlying execution team (which is what appears to be what Tolstoi would have argued‚Ä¶)? What then is the relative importance of the understanding and alignment of the team?\nIn that context, how important is the decision itself?\nClearly, a wrong decision will make things worse, and a good decision will make things better, that‚Äôs not my point here :)\nThis is all obviously a bit ‚Äúout-there‚Äù and more of a thought exercise. But as I like the topic of decision making and strategy, well‚Ä¶\nAnd yes, I guess I‚Äôm opening more questions than I am answering‚Ä¶ My bad."
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#ironmans-approach-i-feel-is-not-wrong",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#ironmans-approach-i-feel-is-not-wrong",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Somewhat related is the topic of the decision making itself and information, and the topic of simulations. Actually above I kinda of made a point of the limits of any simulation. In that the reality is complex, has several levels of abstraction, and too much detail to ever be included in a simulation. Still‚Ä¶ Whenever I think of simulations these days, I think about Monte-Carlo, Reinforcement Learning, and the likes.\n\n\nThis one point has made my day, really. Reinforcement Learning is cool, no question asked, but here is a common derived conversation about RL: So what?\nThe discussion is about the applications of Reinforcement Learning. Well, I will today argue that beyond playing games, it can be considered in context of simulations for decision making. And that opens a lot of potential value for it‚Ä¶\nBack to the conversation, now‚Ä¶"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#so-simulations",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#so-simulations",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "I‚Äôll admit, I‚Äôm a fan of the Ironman movies (and no, I‚Äôm not ashamed). But I mostly like the ‚ÄúJarvis‚Äù part of it. That helpful AI program that helps Tony Stark. Or other simulations that Tony runs to create something‚Ä¶\n\n\n\nrunning simulations to make decisions, Ironman‚Äôs way\n\n\nIn several scenes of different movies in the series of Ironman or the Avengers, Tony launches a simulation of something (say of different ways of programming something, compiling it, and seeing whether the resulting program would successfully fulfill a given purpose, I guess).\nWith all the considerations above about the limits of decision-making, their actual impact, the importance of chaos theory, impossibility of considering future changing-context, the role of the execution, alignment, etc‚Ä¶ With all that in mind‚Ä¶\nI‚Äôve run in the past simulations of traffic in (medium) cities, which helped identify bottlenecks for different traffic scenarios. I‚Äôve run Monte-Carlo simulations of infectious processes on small networks, to decide better on which nodes to act. I‚Äôve been playing with Reinforcement Learning, whereby an agent takes more or less appropriate decisions with (limited) contextual information.\nAnd although maybe this has all been mostly theoretical, I do believe that, within (today‚Äôs) said limits of decision making, that approach makes a lot of sense.\nSo yes, I think RL has a place, maybe, beyond playing Chess and Go‚Ä¶ And maybe if one can setup a valid ‚Äúsimulation‚Äù of a scenario, then RL could be one approach to test different options and see what a computer could come up with.\nBy the way, this is also what Meta-heuristics is all about (including, obviously, Genetic Algorithms, which my readers will know I like :)). And Operations Research (albeit slightly different in approach, or sure).\nI also believe that the ideas of ‚Äúdigital twins‚Äù for instance in Health Care decision support are interesting, in that sense.\nAll in all, I guess this point is that one can support (ever imperfect) decision making with simulations."
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#conclusions",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#conclusions",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "And well, that‚Äôs the gist of my thoughts on the topic today.\nI know, I didn‚Äôt invent fire today. It would seem, I rarely have an actually original thought‚Ä¶ Apologies here. The best I can do, it appears, is agreeing or disagreeing with some view, and then changing my mind with everything I learn along the way‚Ä¶ Oh well.\nThen again, hopefully me connecting different ideas is enough of a ‚Äúvalue-add‚Äù. I read somewhere that this connecting the dots is, in fact, a way of ‚Äúinnovating‚Äù.\nI do hope these thoughts are not completely crazy and that they inspire some more thoughts by others‚Ä¶ That would be great.\nAnd that would justify writing about it in the first place, beyond the fact that writing helps me think‚Ä¶"
  },
  {
    "objectID": "posts/2025-04-13_About_Information_Decisions_RL/index.html#resources",
    "href": "posts/2025-04-13_About_Information_Decisions_RL/index.html#resources",
    "title": "Sunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.",
    "section": "",
    "text": "Strategy, A History, by L. Freedman"
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html",
    "title": "From local Spark to Azure Synapse",
    "section": "",
    "text": "In the last entry we laid out an Apache Spark foundation locally to our laptop, using some Docker containers. This time around, let‚Äôs look at what a Cloud-based alternative can look like.\nWe‚Äôre going to have a look at Azure Synapse."
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#intro",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#intro",
    "title": "From local Spark to Azure Synapse",
    "section": "",
    "text": "In the last entry we laid out an Apache Spark foundation locally to our laptop, using some Docker containers. This time around, let‚Äôs look at what a Cloud-based alternative can look like.\nWe‚Äôre going to have a look at Azure Synapse."
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#many-things-in-one-service",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#many-things-in-one-service",
    "title": "From local Spark to Azure Synapse",
    "section": "Many things in one service",
    "text": "Many things in one service\nThat‚Äôs what is advertised. And being cloud based, it might be ‚Äúeasier‚Äù to setup, for simple/basic configurations (I‚Äôm sure making things perfect will require a lot more effort).\nUp front, it seems one gets access to:\n\na ‚ÄúDatalake‚Äù storage,\nServerless SQL Resource Pool to query it (or with Server),\nsome kind of Spark implementation,\nand Notebooks to interact with these things\n(and more, but those are the main aspects I‚Äôm interested in).¬†¬†\n\nNotebooks unfortunately apparently don‚Äôt sport R support üôÅ\nOh well, I‚Äôll have to brush up on my Python for once‚Ä¶"
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#getting-started",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#getting-started",
    "title": "From local Spark to Azure Synapse",
    "section": "Getting started",
    "text": "Getting started\nIt might not be all that hard:\nLet‚Äôs take the 30 days challenge (hopefully a bit faster than that) to have a look. These Microsoft ‚Äúchallenges‚Äù help you actually get into concepts WHILE practicing.\nI often advocate that a good way to learn is to ‚Äúdo‚Äù, not just to read. (And teaching is another way to learn some more!)\nThe challenge itself is not the goal (I don‚Äôt necessarily care about the complete challenge, as much as getting acquainted with Azure Synapse itself for my own learning purposes). If I finalise it in time, all the better, but I feel no pressure to get there.\nI already have an Azure account and a ‚ÄúFree trial‚Äù Subscription (from past exercises getting to know more about Azure), let‚Äôs try to use that to follow the steps in the following tutorial:\nhttps://microsoftlearning.github.io/mslearn-synapse/Instructions/Labs/01-Explore-Azure-Synapse.html\nSome results for that first lab are shown next."
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#deploying-iac",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#deploying-iac",
    "title": "From local Spark to Azure Synapse",
    "section": "Deploying & IaC",
    "text": "Deploying & IaC\nOne of the coolest things about Cloud, if you ask me, is the concept of ‚ÄúInfrastructure as Code‚Äù. Creating a whole infrastructure from just text file(s) is something that I think is just brilliant. (Back in‚Ä¶ 2009 I think, I participated in a project with a similar idea, to deploy standardised Windows Virtual Machines on VMWare clusters using just scripts, for configuring deployed software packages, networking, users, etc. (Long story short, it worked.))\nHere the people at Microsoft have put together a whole Powershell script for us, so we just need to run it from a shell prompt in our subscription:\n\nIt even loads the datasets for the exercises for us. All by running one command line.\nBrilliant.\nAfter maybe 15 minutes, the subscription resources look like so:"
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#connecting-to-other-data-sources",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#connecting-to-other-data-sources",
    "title": "From local Spark to Azure Synapse",
    "section": "Connecting to other data sources",
    "text": "Connecting to other data sources\nOne part of the first exercises is about connecting to a CSV file published somewhere on the Internet and saving it into the ‚ÄúAzure Datalake Storage Gen2‚Äù. The fact that we are loading a CSV into a Data ‚ÄúLake‚Äù, not a table, i.e.¬†not doing much of a transformation yet, will be an interesting fact in itself in a moment."
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#reading-a-csv-as-a-sql-table-without-a-sql-server",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#reading-a-csv-as-a-sql-table-without-a-sql-server",
    "title": "From local Spark to Azure Synapse",
    "section": "Reading a CSV as a SQL table (without a SQL Server)",
    "text": "Reading a CSV as a SQL table (without a SQL Server)\nThings get powerful when to work using SQL code with a CSV, all you need to do is ‚Äúload‚Äù the CSV as an input to a ‚Äúserverless‚Äù SQL resource pool.\nNow I can do SQL queries on files without installing (myself) basically anything. Kind of like importing a CSV into Excel and Excel putting things into columns on its own‚Ä¶ But all from a browser, with a SQL-compatible language. I don‚Äôt know, I just liked that one:\n\nAnd it is my understanding one could do something similar with JSON files, too. Nice."
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#playing-with-spark-from-python",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#playing-with-spark-from-python",
    "title": "From local Spark to Azure Synapse",
    "section": "Playing with Spark from Python",
    "text": "Playing with Spark from Python\nAnd finally (for today) this: You can use PySpark to play from a Python Notebook with your data, treating it as a Dataframe. Spark will load the data from the Datalake, and you will have it available to play with üôÇ"
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#conclusion",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#conclusion",
    "title": "From local Spark to Azure Synapse",
    "section": "Conclusion",
    "text": "Conclusion\nThis is a somewhat short post, with no R code, where I invented ABSOLUTELY NOTHING, but it is laying foundations for a specific exercise I need to test for (potentially) an upcoming work task.\nTesting things ahead of time seems like a good idea, as simply reading about stuff (although also useful) is not as good a learning method as actually doing things. (I call this ‚Äúdeliberate practice‚Äù). And I feel already much more confident I will be able to face similar stuff, now that I have seen how it in fact works. This doesn‚Äôt mean everything will always go as smoothly, this here was all prepared and detailed‚Ä¶ In the real world there are always surprises (like: always!)‚Ä¶ But it‚Äôs better than not knowing any of the above.\nAs per the ‚ÄúAzure Synapse Service‚Äù, it looks VERY NICE indeed! Supposing one has access to some prepared scripts up-front, deploying a whole working data analysis environment mixing SQL, Spark and a Datalake is actually a breeze!\nAnd after the exercise, I just deleted the Resources, and voil√†.\nAs per the Azure Challenge, I might never finish it, but that‚Äôs quite alright, I just want to learn for myself üôÇ"
  },
  {
    "objectID": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#resources",
    "href": "posts/2022-08-27_LocalSparkToAzureSynapse/index.html#resources",
    "title": "From local Spark to Azure Synapse",
    "section": "Resources",
    "text": "Resources\n30 Days MS Challenge for Azure Synapse"
  },
  {
    "objectID": "posts/2025-06-09_Notes_to_Self/index.html",
    "href": "posts/2025-06-09_Notes_to_Self/index.html",
    "title": "Morning Coffee Thoughts",
    "section": "",
    "text": "Just a quick note to myself here on a realization.\n\nGame Theory and FSM\nFinite States Machines (FSM), e.g.¬†Moore Machines\nMoore‚Äôs Machines and Ashby‚Äôs transition matrices\nMoore‚Äôs machines and binary representations\nBinary representations and RLCS\nRLCS and RL\nTransition Matrices and Graphs\nGraphs & infectious processes representation (?)\nSchelling‚Äôs model & Agents evolving and making decisions in a simulated world\nSo RL, but not only!\n\nNow:\nCan I use RLCS to create optimize Agents that in turn are representations of FSMs, thereby representing rather complex decision processes, all using a simple binary representation (maybe?), and hence allowing for rather complex modelling with all the pieces of the puzzle almost already implemented?\nI need to learn how to represent FSMs as binary strings to represent them as agents compatible with the RLCS code.\nBut then‚Ä¶ What could be done?"
  },
  {
    "objectID": "posts/2025-06-09_Notes_to_Self/index.html#sum-of-the-parts",
    "href": "posts/2025-06-09_Notes_to_Self/index.html#sum-of-the-parts",
    "title": "Morning Coffee Thoughts",
    "section": "",
    "text": "Just a quick note to myself here on a realization.\n\nGame Theory and FSM\nFinite States Machines (FSM), e.g.¬†Moore Machines\nMoore‚Äôs Machines and Ashby‚Äôs transition matrices\nMoore‚Äôs machines and binary representations\nBinary representations and RLCS\nRLCS and RL\nTransition Matrices and Graphs\nGraphs & infectious processes representation (?)\nSchelling‚Äôs model & Agents evolving and making decisions in a simulated world\nSo RL, but not only!\n\nNow:\nCan I use RLCS to create optimize Agents that in turn are representations of FSMs, thereby representing rather complex decision processes, all using a simple binary representation (maybe?), and hence allowing for rather complex modelling with all the pieces of the puzzle almost already implemented?\nI need to learn how to represent FSMs as binary strings to represent them as agents compatible with the RLCS code.\nBut then‚Ä¶ What could be done?"
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "",
    "text": "(It‚Äôs been a few weeks, taking some time off to recharge batteries before I get myself into a master‚Ä¶ So I thought it would be a good idea.)\nAnyhow, to the point: Many a time, when working with data, the first thing will be to ‚Äúlook at it‚Äù. Then maybe you‚Äôll need to clean up some stuff (it‚Äôs often the case, in my experience).\nSo I‚Äôve done that quite a few times by now. Some of the past Blog entries were around that very subject (here and here). But it‚Äôs tedious, and I started working on some functions of my own to do these things‚Ä¶ Until I came across an entry on LinkedIn, where someone was praising skimr, which seemed very promising to begin with. Looking further into the topic of helping myself ‚Äúprepare‚Äù a data analysis, I found the package DataExplorer.\nBut as we know, it‚Äôs not enough to read about these things, one needs to test them üôÇ"
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html#intro",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html#intro",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "",
    "text": "(It‚Äôs been a few weeks, taking some time off to recharge batteries before I get myself into a master‚Ä¶ So I thought it would be a good idea.)\nAnyhow, to the point: Many a time, when working with data, the first thing will be to ‚Äúlook at it‚Äù. Then maybe you‚Äôll need to clean up some stuff (it‚Äôs often the case, in my experience).\nSo I‚Äôve done that quite a few times by now. Some of the past Blog entries were around that very subject (here and here). But it‚Äôs tedious, and I started working on some functions of my own to do these things‚Ä¶ Until I came across an entry on LinkedIn, where someone was praising skimr, which seemed very promising to begin with. Looking further into the topic of helping myself ‚Äúprepare‚Äù a data analysis, I found the package DataExplorer.\nBut as we know, it‚Äôs not enough to read about these things, one needs to test them üôÇ"
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html#before-we-start",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html#before-we-start",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "Before we start",
    "text": "Before we start\nDataExplorer somehow requires igraph. igraph is nice, but as it turns out, it requires a package on the box running R that wasn‚Äôt there (I still use my tuned Docker containers, using rocker as the base image).\nSo first of, to work with DataExplorer on rocker/rstudio, you‚Äôll need to install that package:\napt-get install libglpk-dev\nThen only will you be able to do:\nlibrary(DataExplorer)"
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html#lets-keep-going-now",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html#lets-keep-going-now",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "Let‚Äôs keep going now",
    "text": "Let‚Äôs keep going now\nGood. So why all the fuss about that DataExplorer package?\nLet me re-use some old ‚Äúdemo CMDB‚Äù generator to prepare some dummy data with a few common issues. (Over time, I‚Äôve seen MANY more issues, but that will have to do for this test).\nUsing that, it should be easy to get to something like so:\n&gt; head(cmdb)\n            machine_name    ip_address\n1 WINDEMO01.KAIZEN-R.COM  192.168.1.17\n2              WinDemo02 192.168.1.142\n3              LinDemo03 192.168.1.252\n4 WINDEMO04.KAIZEN-R.COM  192.168.1.72\n5 LINDEMO05.KAIZEN-R.COM  192.168.1.33\n6 LINDEMO06.KAIZEN-R.COM 192.168.1.187\n&gt; head(cmdb_apps)\n  machine_name           app           type\n1    WinDemo01 Data Platform     Production\n2    WinDemo02 Data Platform     Production\n3    LinDemo03 Data Platform Pre-Production\n4    WinDemo04                        Devel\n5    LinDemo05                        Devel\n6    LinDemo06 Data Platform     Production\nWhich will have to do.\nThen it all is rather simple: Let‚Äôs use the help (a.k.a. ‚ÄúRTFM‚Äù). So let‚Äôs try a few things:\n&gt; DataExplorer::plot_bar(cmdb_apps)\n1 columns ignored with more than 50 categories.\nmachine_name: 100 categories\nGives the following:\n\n¬†\nNow it might not look like much, but believe me: It‚Äôs easier here (1 simple line of code) than it is doing it manually (and actually, I think it‚Äôs easier than doing the same thing in Excel, so there: Hurra for R!)\nWith the same data, if you have a factor column (which I here just forced, it made sense in this case), you can then see things by groups of such factors in one go:\n&gt; cmdb_apps[] &lt;- lapply(cmdb_apps, as.factor)\n&gt; DataExplorer::plot_bar(cmdb_apps, by = \"type\")\n1 columns ignored with more than 50 categories.\nmachine_name: 100 categories\n\nOnce again, the key of the matter is that those are one-liners!\nNot everything can be automated\nUnfortunately it‚Äôs not ALL going to be that easy. So in order to look a bit further into the powers of DataExplorer, I require some data with more‚Ä¶ Columns, to begin with. Thankfully, we already have more columns, only in two different data frames. Let‚Äôs merge them‚Ä¶ But wait! They should merge on the same column name easily if it weren‚Äôt for the difference in naming the machines!\nSo right there, something to be done‚Ä¶\nIt requires a bit of magic, but it‚Äôs feasible:\nlibrary(stringr)\nlibrary(magrittr)\ncmdb_new &lt;- cmdb\ncmdb_new$machine_name %&lt;&gt;% tolower()\ncmdb_new$hostname &lt;- sapply(cmdb_new$machine_name, function(x) {\n  found_pos &lt;- str_locate(x, \"\\\\.\")[[1]]\n  if(is.na(found_pos)) return(x)\n  str_sub(x, end = found_pos - 1)\n})\ncmdb_new$domain &lt;- sapply(cmdb_new$machine_name, function(x) {\n  found_pos &lt;- str_locate(x, \"\\\\.\")[[1]]\n  if(is.na(found_pos)) return(\"\")\n  str_sub(x, start = found_pos + 1)\n})\ncmdb_new$fqdn &lt;- sapply(1:nrow(cmdb_new), function(x) {\n  if(cmdb_new$domain[x] == \"\") return(\"\")\n  paste0(cmdb_new$hostname[x], \".\", cmdb_new$domain[x])\n})\ncmdb_new$machine_name &lt;- NULL\n\ncmdb_apps$machine_name %&lt;&gt;% tolower()\nWhich gives us something a bit more compatible (see the ‚Äúhostname‚Äù in cmdb_new, and ‚Äúmachine_name‚Äù in cmdb_apps‚Ä¶)\n&gt; head(cmdb_new, n = 2)\n     ip_address  hostname       domain                   fqdn\n1  192.168.1.17 windemo01 kaizen-r.com windemo01.kaizen-r.com\n2 192.168.1.142 windemo02                                    \n&gt; head(cmdb_apps, n = 2)\n  machine_name           app       type\n1    windemo01 Data Platform Production\n2    windemo02 Data Platform Production\n&gt; cmdb_new &lt;- merge(cmdb_new, cmdb_apps, by.x = \"hostname\", by.y = \"machine_name\", all = TRUE)\n&gt; head(cmdb_new)\n     hostname    ip_address       domain                    fqdn           app       type\n1  lindemo010 192.168.1.158                                      Data Platform Production\n2  lindemo010 192.168.1.155                                      Data Platform Production\n3 lindemo0100  192.168.1.47                                      Data Platform      Devel\n4  lindemo011  192.168.1.75 kaizen-r.com lindemo011.kaizen-r.com Data Platform Production\n5  lindemo012  192.168.1.94                                      Data Platform Production\n6  lindemo012 192.168.1.236                                      Data Platform Production\nNow that‚Äôs better, let‚Äôs have a look shall we?\n&gt; DataExplorer::introduce(cmdb_new)\n  rows columns discrete_columns continuous_columns all_missing_columns total_missing_values\n1  130       6                6                  0                   0                    0\n  complete_rows total_observations memory_usage\n1           130                780        27464\nNow we might want to have some numerical value in there somewhere, just for testing. In the context of a CMDB of Systems, maybe the amount of RAM per system could make sense, and CPUs speeds. Let‚Äôs throw that in:\nrams_df &lt;- data.frame(hostname = unique(cmdb_new$hostname), ram_amount = sample(c(2,4,8), size = length(unique(cmdb_new$hostname)), replace = TRUE, prob = c(1,1,3)))\ncmdb_new &lt;- merge(cmdb_new, rams_df, all.x = TRUE)\ncpus_df &lt;- data.frame(hostname = unique(cmdb_new$hostname), cpu_ghz = sample(c(1.6,2.4,0.8,3.2), size = length(unique(cmdb_new$hostname)), replace = TRUE, prob = c(2,3,1,3)))\ncmdb_new &lt;- merge(cmdb_new, cpus_df, all.x = TRUE)\nAnd now, DataExplorer will find on its own the numeric variables and help us have a quick glance at them:\nDataExplorer::plot_histogram(cmdb_new)\nDataExplorer::plot_boxplot(cmdb_new, by = \"app\")\n\n\nEven better than all of the above, DataExplorer provides a function (1 liner) to do all of the above and more and generate one report, from one data frame‚Ä¶ I mean, NICE STUFF!\nBut I‚Äôll let you explore that last trick on your own."
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html#a-simple-but-great-alternative-skimr",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html#a-simple-but-great-alternative-skimr",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "A simple (but great) alternative: skimr",
    "text": "A simple (but great) alternative: skimr\nSo just because I‚Äôve seen it, and it is as simple as it gets, BUT it is very useful to get a sense of a data.frame in seconds:\n\nHell it even decided on its own: Empty strings ‚Äú‚Äù count as empty cells to it! That‚Äôs just the kind of things one needs to speed up data sets reviews üôÇ"
  },
  {
    "objectID": "posts/2021-10-16_DataExplorerPackage/index.html#conclusions",
    "href": "posts/2021-10-16_DataExplorerPackage/index.html#conclusions",
    "title": "Cleaning Data: testing DataExplorer",
    "section": "Conclusions",
    "text": "Conclusions\nSome things will still need to be manual. EDA, data cleaning, data imputation, etc. all require us to LOOK AT THE DATA.\nThat doesn‚Äôt necessarily mean however that one needs to program from scratch all the nifty details about understanding and fixing some dataset each time.\nOne of the great things of R, is its community of developers that create a plethora of great packages for the rest of us to be able to do our job faster, and easier.\nSo Kudos to the R Community, thanks all! (I don‚Äôt say that enough‚Ä¶)"
  },
  {
    "objectID": "posts/2021-10-31_OnComputingErrors/index.html",
    "href": "posts/2021-10-31_OnComputingErrors/index.html",
    "title": "Learning about computing errors",
    "section": "",
    "text": "Intro\nAs part of the courses I am taking, I learned about something I guess I, as a ‚Äúcomputer engineer‚Äù, should have come across earlier; but well, it would seem I didn‚Äôt.\nI‚Äôll just show 3 examples anyone can easily find out there on the Internet, of things that happen with floating point operations. Obviously for the purpose of this blog, I‚Äôll be using R.\n(The rest of my weekend I‚Äôll be trying to personally understand precisely how this all works (but not for the Blog, as the explanations I am studying with the University).)\nSo this entry is just about being aware of it, not about explaining the why‚Äôs and how‚Äôs, as that‚Äôs a rather long topic. Also, it‚Äôs easy to program the examples, not as easy to explain exactly the workings of the computer behind the scenes üôÇ\nAll in all, if this Blog entry serves only to pique someone‚Äôs interest so that they can look into the MSc degree I have just started to attend sometimes in the future, it‚Äôll be a job well done.\n\n\nImprecisions\nIn summary, computers sometimes round numeric values, one way or another, because of how they store numbers (particularly, floating point numbers). And for things that have very similar amounts of significant digits, operating with two numbers that are very similar (or very dissimilar) can sometimes have quite an impact.¬†\n\n\nExamples\nThe easiest one, and my first surprise when discovering the topic:\n&gt; a &lt;- 1.0\n&gt; a - .8 - .2\n[1] -5.551115e-17\n&gt; # not 0!!\n&gt; b &lt;- 1.0\n&gt; while(a+b != a) b &lt;- b/2\n&gt; b\n[1] 1.110223e-16\nSo well, two things apparently equal (to us), like 1 and (0.8+0.2), can be ‚Äúvery similar‚Äù for the computer. And when two things are ‚Äúalmost equal‚Äù, well, things get weird.\nAlso, it would seem you can reproduce those in Python on similar computer architectures‚Ä¶ And that‚Äôs due to the IEEE 754 standard for 64bits double precision floating point representation.\nThe value of b in the calculations above is the threshold at which apparently our computer understands it is so small, it considers it negligible, so that a+b = a becomes true. So it can be seen as the minimum distance between two floating point numbers our computer will take into account.\n\n\nNot only for very small values\nOperating with big values that are very similar, things happen too. Here is an example that I am now translating into R code and demo-ing in R.\nSo moving from one version of the formula (left side) to the next (right side of the equation), step by step (you‚Äôre welcome), would look like so (thanks LaTeX):\n\n¬†\nTwo mathematically equivalent functions will have different errors once run in R, in this case for bigger values of x. And that is because things will get very similar with limited precision. In such cases, maybe avoiding subtractions can help‚Ä¶\nUsing the {mosaicCore} package discovered last week, we can now express these like so:\nlibrary(mosaicCore)\nlibrary(plyr)\n\nf1 &lt;- makeFun(sqrt(x) * (sqrt(x + 1) - sqrt(x)) ~ x)\nf2 &lt;- makeFun(sqrt(x) / (sqrt(x + 1) + sqrt(x)) ~ x) # equivalent to f1\n\nmy_function_compare &lt;- function(in_func1, in_func2, e_range, s_step) {\n  rbind.fill(lapply(10^seq(e_range[1],e_range[2],s_step), function(i) {\n    data.frame(x = i, f1_x = sprintf(\"%.18f\", in_func1(i)), f2_x = sprintf(\"%.18f\", in_func2(i)))\n  } ))\n}\n\nmy_function_compare(f1, f2, e_range = c(0, 15), s_step = 1)\nWhich gives the following results:\n&gt; my_function_compare(f1, f2, e_range = c(0, 15), s_step = 1)\n       x                 f1_x                 f2_x\n1  1e+00 0.414213562373095145 0.414213562373095090\n2  1e+01 0.488088481701514754 0.488088481701515475\n3  1e+02 0.498756211208899458 0.498756211208902733\n4  1e+03 0.499875062461021868 0.499875062460964859\n5  1e+04 0.499987500624854420 0.499987500624960890\n6  1e+05 0.499998750005928860 0.499998750006249937\n7  1e+06 0.499999875046341913 0.499999875000062488\n8  1e+07 0.499999987401150925 0.499999987500000576\n9  1e+08 0.500000005558831617 0.499999998749999952\n10 1e+09 0.500000077997506343 0.499999999874999990\n11 1e+10 0.499999441672116518 0.499999999987500054\n12 1e+11 0.500004449631168080 0.499999999998750000\n13 1e+12 0.500003807246685028 0.499999999999874989\n14 1e+13 0.499194546973835973 0.499999999999987510\n15 1e+14 0.502914190292358398 0.499999999999998723\n16 1e+15 0.589020114423405183 0.499999999999999833\nAnd I just think this is beautiful. The math is sound, but knowing how to choose one way or another to express the equation into code will make a whole lot of a difference!¬†\n\n\nConclusions\nThere are things to be done to reduce the compounding of errors due to computers limitations in certain circumstances, by better understanding of how those errors appear and how they interact.\nThis is not too straightforward, but I‚Äôm excited to dive deeper into these things and really get to understand it all. (That I actually get there, is another question :))"
  },
  {
    "objectID": "posts/2024-06-15_MSC_Thesis_delivered/index.html",
    "href": "posts/2024-06-15_MSC_Thesis_delivered/index.html",
    "title": "MSC Thesis delivered",
    "section": "",
    "text": "In the old blog, I did comment/discuss a lot about the latest Master Thesis I was working on.\nInstead of reproducing every single entry, I thought I‚Äôd just link to the resulting paper, and reproduce the last entry on the topic.\nHere goes:\nThesis Link\n\n\n\n\n\nAnd the last Blog entry said‚Ä¶"
  },
  {
    "objectID": "posts/2024-06-15_MSC_Thesis_delivered/index.html#from-the-old-blog",
    "href": "posts/2024-06-15_MSC_Thesis_delivered/index.html#from-the-old-blog",
    "title": "MSC Thesis delivered",
    "section": "",
    "text": "In the old blog, I did comment/discuss a lot about the latest Master Thesis I was working on.\nInstead of reproducing every single entry, I thought I‚Äôd just link to the resulting paper, and reproduce the last entry on the topic.\nHere goes:\nThesis Link\n\n\n\n\n\nAnd the last Blog entry said‚Ä¶"
  },
  {
    "objectID": "posts/2024-06-15_MSC_Thesis_delivered/index.html#old-entry",
    "href": "posts/2024-06-15_MSC_Thesis_delivered/index.html#old-entry",
    "title": "MSC Thesis delivered",
    "section": "Old entry",
    "text": "Old entry\n‚ÄúIt‚Äôs done.\nThe thesis was successfully defended.\nIt has been a great almost 3 years. I‚Äôve learnt many things, re-discovered others. It has opened up new topics to dive in.\nAnd now comes a period I should use to slow down a bit, as the last few weeks have been a bit intense.\nBut I very much liked this Master and if anything, I would take more courses of it if I could‚Ä¶\nAnyhow. This is the end of a 3 years studies period, and I will start thinking more seriously about what‚Äôs next. In a few weeks.\nIn the meantime, I will read, I have lots of reading in the backlog. (Already started üòå)‚Äù"
  },
  {
    "objectID": "posts/2025-10-15_NovemberAboutReady/index.html",
    "href": "posts/2025-10-15_NovemberAboutReady/index.html",
    "title": "Preparing for November Presentation",
    "section": "",
    "text": "I‚Äôm sure I‚Äôll keep going, reviewing, tuning, whatever. But it‚Äôs ready.\nFor now.\nHere:\nThe short-version of the presentation. It makes much less sense without me babbling about it, but alright.\nhttps://kaizen-r.github.io/others/RLCS_documentation_15.html\nAnd I now included the basic demos alongside the package, here:\nhttps://github.com/kaizen-R/RLCS"
  },
  {
    "objectID": "posts/2025-10-15_NovemberAboutReady/index.html#yep-thats-basically-it.",
    "href": "posts/2025-10-15_NovemberAboutReady/index.html#yep-thats-basically-it.",
    "title": "Preparing for November Presentation",
    "section": "",
    "text": "I‚Äôm sure I‚Äôll keep going, reviewing, tuning, whatever. But it‚Äôs ready.\nFor now.\nHere:\nThe short-version of the presentation. It makes much less sense without me babbling about it, but alright.\nhttps://kaizen-r.github.io/others/RLCS_documentation_15.html\nAnd I now included the basic demos alongside the package, here:\nhttps://github.com/kaizen-R/RLCS"
  },
  {
    "objectID": "posts/2025-10-15_NovemberAboutReady/index.html#conclusion",
    "href": "posts/2025-10-15_NovemberAboutReady/index.html#conclusion",
    "title": "Preparing for November Presentation",
    "section": "Conclusion",
    "text": "Conclusion\nShortest post I wrote, quite possibly. And yet, a milestone, kinda."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html",
    "href": "posts/2022-06-25_FasterGraphs/index.html",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "",
    "text": "Network Graphs are NICE and USEFUL (or at least, that‚Äôs my opinion). I have used them many a time, and they really usually help me get an understanding that I wouldn‚Äôt get by just looking at rows and rows of a table‚Ä¶\nTo visualize such ‚Äúnetworks‚Äù, I usually prefer the package visNetwork. It‚Äôs nice, has some cool interactive options, and as I‚Äôm used to it, it‚Äôs ‚Äúeasier‚Äù for me to use it‚Ä¶ And with some practice and a bit of studying different available layouts, you can get nice looking results‚Ä¶\nBut there is a hitch: For ‚Äúlarge‚Äù graphs (and not that large, mind you), it slows down a bit too much. So this here is me looking into alternatives."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#intro",
    "href": "posts/2022-06-25_FasterGraphs/index.html#intro",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "",
    "text": "Network Graphs are NICE and USEFUL (or at least, that‚Äôs my opinion). I have used them many a time, and they really usually help me get an understanding that I wouldn‚Äôt get by just looking at rows and rows of a table‚Ä¶\nTo visualize such ‚Äúnetworks‚Äù, I usually prefer the package visNetwork. It‚Äôs nice, has some cool interactive options, and as I‚Äôm used to it, it‚Äôs ‚Äúeasier‚Äù for me to use it‚Ä¶ And with some practice and a bit of studying different available layouts, you can get nice looking results‚Ä¶\nBut there is a hitch: For ‚Äúlarge‚Äù graphs (and not that large, mind you), it slows down a bit too much. So this here is me looking into alternatives."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#visnetwork-options",
    "href": "posts/2022-06-25_FasterGraphs/index.html#visnetwork-options",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "visNetwork Options",
    "text": "visNetwork Options\nI‚Äôm not going to go into details, but let‚Äôs just say: If you want a visNetwork to show faster in R and you haven‚Äôt looked into it before, your best go-to option is:\nvisNetwork(nodes, edges) %&gt;%\n  visPhysics(stabilization = FALSE)\nThat last bit will make it MUCH faster. It‚Äôs a cool thing to use in a Shiny dashboard, for instance. I definitely recommend you look into this package if you work with say ‚Äúa few hundred vertices‚Äù.\nBut if you get into too many (say &gt; 3000 or &gt; 5000 or so, depending on your hardware of course‚Ä¶) vertices, you might get frustrated looking at how the ‚Äúphysics‚Äù do their magic and get you to a nicely distributed thing‚Ä¶\nIn a test I just ran with a dummy graph with roughly 5100 ‚Äúnodes‚Äù and 5000 edges, it takes roughly 3 minutes to go from here:\n\nto here:\n\nI.e. the structure appears after waiting a while. On the plus side, with visNetwork, you can click, highlight neighbours, drag a node (and thereby its neighbours and neighbours-neighbours‚Ä¶ to any degree :)), it‚Äôs quite interactive, intuitive, and with sufficiently small networks, it‚Äôs actually a good thing to show interactively. (Then, again, a mix of that with Shiny will do absolute magic).\nYes, you CAN absolutely use visNetwork with NO ‚Äúanimation‚Äù, BUT for some reason, I‚Äôve tried MANY different layouts, and not once I was able to make it nice (even when using igraph layouts‚Ä¶) for my use cases WHILE getting directly to the static results.\n(And admittedly‚Ä¶ Maybe I need to keep trying :S)"
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#obvious-trick",
    "href": "posts/2022-06-25_FasterGraphs/index.html#obvious-trick",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "Obvious trick",
    "text": "Obvious trick\nSo in SOME cases, you can‚Ä¶ Simply NOT load the whole network. For my typical use cases (inventories of stuff with different connected data points, say machines to installed SW, OS or IP Network ranges, could be‚Ä¶), you might simply decide that you can focus on a small part of the network, adding a ‚Äúsearch box‚Äù for your Shiny Dashboard, so that your user can look for all things connected to one specific machine or all machines that use a specific software maybe‚Ä¶\nBut in other cases, you might want to see it all, maybe to get a better sense of the overall structure of things, or getting a sense quickly of what clusters you have (connected subgraphs) and maybe which ones have more vertices, bigger diameter or radius‚Ä¶ You name it.\nThen there is not much of a choice: We need to have something fast enough."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#other-packages",
    "href": "posts/2022-06-25_FasterGraphs/index.html#other-packages",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "Other packages",
    "text": "Other packages\nSo there are a few R packages out there. The package ‚Äúnetwork‚Äù might seem obvious (and it works nicely, by the way, from my few tests‚Ä¶). Defaults are rather OK, and it‚Äôs a lot faster (no animation, no interactivity though) to load the result than with visNetwork:\n\nGiven the tradeoffs‚Ä¶ I personally still prefer (by far) visNetwork here.\nBut as far as rendering the final graph in its final distribution form, so far I think the best/fastest alternative I found was the igraph package, and specifically using the ‚Äúfruchtermanreingold‚Äù layout.\n\nNow I know, I know, it looks a bit messier‚Ä¶\nBut the point here was SPEED of rendering, and comparatively, for the same ‚Äúnetwork‚Äù, iGraph was fastest, by a lot.\n(And no, sorry: I didn‚Äôt actually benchmark these renderings‚Ä¶ But you can trust me on that one, it‚Äôs noticeable)."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#but-visnetwork-was-cooler-why-change",
    "href": "posts/2022-06-25_FasterGraphs/index.html#but-visnetwork-was-cooler-why-change",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "But visNetwork was cooler‚Ä¶ Why change?",
    "text": "But visNetwork was cooler‚Ä¶ Why change?\nSo here is the trick. Whatever I do, although the ‚Äúanimation‚Äù of visNetwork is way cooler than a static output and all, if it‚Äôs too slow to load while showing a dashboard to a colleague/boss/client, it‚Äôs‚Ä¶ Too slow for me :S\nThen speed gains value over ‚Äúcoolness‚Äù.\nBut then again‚Ä¶ Most of the times, I‚Äôm using those Graphs in Shiny Dashboards. So I decided to ‚Äúlook for speed output first‚Äù, and that I will look into options for making things more interactive using Shiny later.\nAnd that‚Äôs what I did."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#the-code-for-today",
    "href": "posts/2022-06-25_FasterGraphs/index.html#the-code-for-today",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "The code for today",
    "text": "The code for today\nlibrary(igraph)\n\nex1 &lt;- data.frame(from = paste0(\"a\", 1:5000), to = paste0(sample(c(\"a\", \"b\"), 5000, replace = TRUE), sample(1:100, 5000, replace = TRUE)))\ng &lt;- graph_from_data_frame(ex1, directed = FALSE)\n\nlo &lt;- layout_with_fr(g, niter = 1000) # faster, \"fruchtermanreingold\", and also so far best distribution...\n\n## Different algorithms give different results of course\n#lo &lt;- layout_with_kk(g) # intermediate, and not nice\n#lo &lt;- layout_with_gem(g) # too slow\n#lo &lt;- layout_with_dh(g) # too slow\n#lo &lt;- layout_with_lgl(g) # acceptably fast, but messy\n#lo &lt;- layout_with_sugiyama(g) # Not working?\n\n# Testing layout based on ATLAS2 algo:\n# Found here nice initial code: https://github.com/analyxcompany/ForceAtlas2/blob/master/R/layout.R\n# Nice, sure, but not fast enough... Skipping.\n# lo &lt;- layout.forceatlas2(g, directed = FALSE,\n#   iterations = 600,\n#   k = 1000,\n#   gravity = 10,\n#   ks = 5,\n#   delta = 1.5,\n#   plotstep=0)\n\nlo &lt;- norm_coords(lo, ymin=-1, ymax=1, xmin=-1, xmax=1)\n\nplot(g, \n  edge.arrow.width = .25,\n  edge.arrow.size = .25,\n  vertex.label = NA,\n  vertex.size = 1,\n  rescale=FALSE, \n  layout=lo*1)\n\n# Now testing the \"network\" package instead...\nlibrary(network)\n\ng2 &lt;- network(ex1)\n# here layout defaults to fruchtermanreingold, too.\n# Good BUT much slower than iGraph with a \"large\" dataset...\nplot.network(g2,\n  vertex.cex = 0.5,\n  usearrows = FALSE,\n  displayisolates = TRUE,\n  displaylabels = FALSE)\n\n# And finally visNetwork\nlibrary(visNetwork)\n\nunique_nodes_vector &lt;- unique(c(ex1$from, ex1$to))\nnodes &lt;- data.frame(id = unique_nodes_vector, labels = unique_nodes_vector)\nedges &lt;- ex1\nvisNetwork(nodes, edges) %&gt;% visPhysics(stabilization = FALSE)"
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#edito-after-the-facts",
    "href": "posts/2022-06-25_FasterGraphs/index.html#edito-after-the-facts",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "EDITO: AFTER THE FACTS",
    "text": "EDITO: AFTER THE FACTS\nAfter testing/learning more about igraph layouts, I went back to visNetwork, and sure enough:\nvisNetwork(nodes, edges) %&gt;%\nvisIgraphLayout(layout = \"layout_with_fr\", niter = 1000)\nThat works! Fast as with igraph, static, yes, but I can now leverage this on MANY past network graphs!\nSo some of the present blog entry was‚Ä¶ Not as useful, actually I could have skipped testing other packages altogether (but then I wouldn‚Äôt have tested more igraph and its layouts‚Ä¶), and the conclusion should be updated (but that would be cheating, so I‚Äôll leave it as is).\nvisNetwork: My preferred option. Because slightly cooler."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#conclusions",
    "href": "posts/2022-06-25_FasterGraphs/index.html#conclusions",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "Conclusions",
    "text": "Conclusions\nHere I was testing different packages for rendering ‚Äúlarge‚Äù (well, not really‚Ä¶) Network Graphs.\nI still like visNetwork the best, and I owe it to this package to keep testing and looking for the right combination of options that will get me the result I want, fast.\nBut for now, the fastest alternative that was fitting my needs was the igraph package."
  },
  {
    "objectID": "posts/2022-06-25_FasterGraphs/index.html#references",
    "href": "posts/2022-06-25_FasterGraphs/index.html#references",
    "title": "Faster graphs in R: iGraph vs visNetwork",
    "section": "References",
    "text": "References\nThe best reference I found out there so far for the visNetwork package\nSomeone implemented a ‚Äúbetter suited (for my use-case)‚Äù algorithm for igraph layout, based on a Gephi option"
  },
  {
    "objectID": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html",
    "href": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html",
    "title": "RLCS: Improving‚Ä¶ And getting worse (at the same time!)",
    "section": "",
    "text": "Well, it‚Äôs been a couple of weeks (I was a bit offline last couple of weekends, I guess). So I‚Äôm back at it and, first, I needed to clean things up. It just was messy code.\nSo I did that, removed some duplicate code with functions, unused variables, found out some of it was in fact quite wrong‚Ä¶\nHeck, I half-wonder how it actually worked so well a couple of weeks back learning, that simple agent in that simple small ‚Äúworld‚Äù moving around looking for ‚Äúfood‚Äù‚Ä¶\nI also studied a bit more on RL (although, I have not read as much as I wanted, I had a couple of other books under way‚Ä¶ Anyhow), and modified things so that the reward distribution would better follow the ideas of temporal difference (TD).\nNow code is a bit cleaner, probably running smoother, less cluttered‚Ä¶\nBUT!\n\n\n\nAs it turns out, in fixing the code, I made the learning worse‚Ä¶ It still kind-of works, but from the last few runs, it‚Ä¶ well, it feels it learns worse.\nAnd I‚Äôm really wondering which of the many parameters I have changed, on top of the fixes, have made it bad.\n\n\n\nThere is still stuff to clean. I‚Äôm not advancing as much as I wanted with setting things up in an actual package yet. And while the Supervised Learning is working fine (maybe even better), the Reinforcement Learning example is worse off after this weekend.\nNo matter, I‚Äôll review again. And I‚Äôll fix it. I‚Äôm just slower than I wanted. Oh well‚Ä¶"
  },
  {
    "objectID": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#better-code",
    "href": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#better-code",
    "title": "RLCS: Improving‚Ä¶ And getting worse (at the same time!)",
    "section": "",
    "text": "Well, it‚Äôs been a couple of weeks (I was a bit offline last couple of weekends, I guess). So I‚Äôm back at it and, first, I needed to clean things up. It just was messy code.\nSo I did that, removed some duplicate code with functions, unused variables, found out some of it was in fact quite wrong‚Ä¶\nHeck, I half-wonder how it actually worked so well a couple of weeks back learning, that simple agent in that simple small ‚Äúworld‚Äù moving around looking for ‚Äúfood‚Äù‚Ä¶\nI also studied a bit more on RL (although, I have not read as much as I wanted, I had a couple of other books under way‚Ä¶ Anyhow), and modified things so that the reward distribution would better follow the ideas of temporal difference (TD).\nNow code is a bit cleaner, probably running smoother, less cluttered‚Ä¶\nBUT!"
  },
  {
    "objectID": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#worse-results",
    "href": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#worse-results",
    "title": "RLCS: Improving‚Ä¶ And getting worse (at the same time!)",
    "section": "",
    "text": "As it turns out, in fixing the code, I made the learning worse‚Ä¶ It still kind-of works, but from the last few runs, it‚Ä¶ well, it feels it learns worse.\nAnd I‚Äôm really wondering which of the many parameters I have changed, on top of the fixes, have made it bad."
  },
  {
    "objectID": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#conclusions",
    "href": "posts/2025-03-09_RLCS_RL_BetterAndWorse/index.html#conclusions",
    "title": "RLCS: Improving‚Ä¶ And getting worse (at the same time!)",
    "section": "",
    "text": "There is still stuff to clean. I‚Äôm not advancing as much as I wanted with setting things up in an actual package yet. And while the Supervised Learning is working fine (maybe even better), the Reinforcement Learning example is worse off after this weekend.\nNo matter, I‚Äôll review again. And I‚Äôll fix it. I‚Äôm just slower than I wanted. Oh well‚Ä¶"
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "",
    "text": "So long story short: I‚Äôm soon to start working on some reports that will include some math stuff.\nI could do that with a Word-like editor, but why would I when we have the marvelous R Markdown? Let‚Äôs test a few things that will surely come in handy‚Ä¶"
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#intro",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#intro",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "",
    "text": "So long story short: I‚Äôm soon to start working on some reports that will include some math stuff.\nI could do that with a Word-like editor, but why would I when we have the marvelous R Markdown? Let‚Äôs test a few things that will surely come in handy‚Ä¶"
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#creating-reports-to-share",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#creating-reports-to-share",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Creating reports to share",
    "text": "Creating reports to share\nSo suppose you want to give a human (person) a report for them to use, being able to send it over email, supposing only that that person will be able to open it with a PDF reader. (For a machine, PDFs are awful of course, but for humans well‚Ä¶).\nSo first, we‚Äôll need to have the capacity to ‚Äúknit‚Äù Rmd files, which comes natively with RStudio (good). However, for PDF, our Docker container by default lacks some stuff, so we‚Äôll have to throw that into our Dockerfile; here is the relevant part of it for this purpose:\nRUN apt-get -y install xml2 curl less \\\ndefault-jre python3-virtualenv python3-pip \\\ntexlive-base texlive-latex-base texlive-bibtex-extra texlive-fonts-recommended texlive-latex-extra\nThe third line is what we‚Äôll need to ‚ÄúKnit to PDF‚Äù in our container, which in the base rocker/rstudio image wasn‚Äôt included.\nFor reference, the version of Dockerfile I‚Äôm using at this point is here.\nWe can test it directly with a default new .Rmd (choosing PDF as default format) file, and it should work now."
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#creating-a-template",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#creating-a-template",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Creating a template",
    "text": "Creating a template\nNext up, let‚Äôs make sure we create consistent reports over time (say we need to create new reports for the same person every now and then in the future‚Ä¶). A few things come to mind, but let‚Äôs keep it simple: We want a title, author, table of contents, and a header logo.\nThe header logo I needed to lookup as I had no idea how to do it, I landed on this StackOverflow page which led to the following in the header:\nheader-includes: \n \\usepackage{graphicx}\n \\usepackage{fancyhdr}\n \\pagestyle{fancy}\n \\setlength\\headheight{28pt}\n \\fancyhead[L]{\\includegraphics[width=5cm]{logo_1.png}}\n \\fancyfoot[LE,RO]{GPIM}\nProvided you have the logo_1.png file in the same folder as the Rmd file, you should be OK.\nThen the table of contents, it‚Äôs pretty standard stuff, more on that can be found here.\nThe result header would then look like so:\n---\ntitle: \"Markdown_template.Rmd\"\nauthor: \"Your name here\"\ndate: \"`r Sys.Date()`\"\nheader-includes: \n \\usepackage{graphicx}\n \\usepackage{fancyhdr}\n \\pagestyle{fancy}\n \\setlength\\headheight{28pt}\n \\fancyhead[L]{\\includegraphics[width=5cm]{logo_1.png}}\n \\fancyfoot[LE,RO]{GPIM}\noutput: \n pdf_document:\n  toc: true\n  toc_depth: 2\n---\nSo now we have a basic template we will be able to re-use in future reports, that should help us be a little bit more efficient."
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#throwing-in-some-real-looking-math",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#throwing-in-some-real-looking-math",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Throwing in some real-looking math",
    "text": "Throwing in some real-looking math\nNow we already have loaded LaTeX to our container, so it should be no problem to use it. In R Markdown, you‚Äôd use the ‚Äú$$‚Äù signs to begin/end a LaTeX-evaluated expression:\nSimple equations:\n$$ f(x) = {{ax^2 + bx + c} \\over 10}$$\n\nUsing some Greek symbols...:\n$$ {\\xi(x) \\over \\epsilon(x)} (nonesense \\space probably...)$$\n\nMultplying Matrices:\n$$ \\begin{bmatrix}\na_1 & b_1\\\\\na_2 & b_2 \n\\end{bmatrix} \\cdot \\begin{bmatrix} x_1\\\\\nx_2\n\\end{bmatrix} + \n\\begin{bmatrix} c_1\\\\\nc_2\n\\end{bmatrix} = \n\\begin{bmatrix}\na_1 & b_1 & c_1\\\\\na_2 & b_2 & c_2\n\\end{bmatrix} \\cdot \\begin{bmatrix} x_1\\\\\nx_2\\\\\n1\n\\end{bmatrix} =\n\\begin{cases}\na_1 \\times x_1 + b_1 \\times x_2 + c_1\\\\\na_2 \\times x_2 + b_2 \\times x_2 + c_2\n\\end{cases}$$\n\nCombinations:\n$$ {n \\choose k} = \\frac{n!}{k!(n-k)!} $$\nThe above code nicely helps us output the following:"
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#then-add-some-functions-plots",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#then-add-some-functions-plots",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Then add some functions plots",
    "text": "Then add some functions plots\nFor good measure, let‚Äôs see how we might go about plotting functions using R (although that might not be needed as I might be pushed into using another language, in which case I‚Äôd include screen captures, I guess‚Ä¶).\nSo here is where I found what I needed for this purpose. I‚Äôll have to read a bit more through it, but it‚Äôs looking good. One issue though, the thing I needed here the most was the function slice_plot(), which doesn‚Äôt seem to work (even after testing this).\nSo instead, I went ahead and implemented a simplistic version of it myself:\nlibrary(mosaicCore)\nlibrary(plyr)\nlibrary(ggplot2)\nlibrary(gridExtra)\n# for better readability:\ng &lt;- makeFun(2*x^2 - 5*x + 2 ~ x) # requires mosaicCore\n\nmy_function_plotter &lt;- function(in_func, c_range, s_step = 0.1) {\n  plot_df &lt;- rbind.fill(lapply(seq(c_range[1], c_range[2], s_step), function(i) {\n    data.frame(x = i, f_x = in_func(i))\n  } ))\n\n  ggplot(plot_df, aes(x = x, y = f_x)) +\n    geom_line()\n}\n\nggp_1 &lt;- my_function_plotter(g, c_range = c(-2, 2), s_step = 1)\nggp_2 &lt;- my_function_plotter(g, c_range = c(-2, 2), s_step = 0.1)\n\ngrid.arrange(ggp_1, ggp_2, ncol=2)\nWith that put into the Rmd, we get to plot a function (in this case with two different ‚Äústeps‚Äù, the smaller the step, the better the resolution:\n\nGood enough."
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#conclusions",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#conclusions",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "Conclusions",
    "text": "Conclusions\nI think I‚Äôm about as ready as it gets to start reporting on scientific/mathematical stuff. Which is a good thing, as I‚Äôll need it soon.\nAnd all from our RStudio container!"
  },
  {
    "objectID": "posts/2021-10-23_ReportsLaTeXMath/index.html#references",
    "href": "posts/2021-10-23_ReportsLaTeXMath/index.html#references",
    "title": "Migrating to M1, Docker & RStudio included",
    "section": "References",
    "text": "References\nFor RMD, https://bookdown.org/yihui/rmarkdown-cookbook\nFor LaTeX, overleaf and StackExchange for TeX\nCalculus with R (mostly to make use of ‚ÄúmakeFun()‚Äù), https://dtkaplan.github.io/RforCalculus/"
  },
  {
    "objectID": "posts/2024-11-08_welcome/index.html",
    "href": "posts/2024-11-08_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in this future Blog. Currently testing all kinds of things, will updated hopefully shortly!\nSeems like it will nicely manage some defaults.\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2024-11-08_welcome/index.html#references-for-future-use",
    "href": "posts/2024-11-08_welcome/index.html#references-for-future-use",
    "title": "Welcome To My Blog",
    "section": "References for future use",
    "text": "References for future use\nFor now, I need to keep references of what allowed me to get here:\n\nManage GitHub access\nhttps://usethis.r-lib.org/articles/git-credentials.html\n\n\nSet things up\nhttps://sites.northwestern.edu/researchcomputing/2022/05/11/git-with-rstudio-order-matters/\nhttps://sites.northwestern.edu/researchcomputing/resources/using-git-and-github-with-r-rstudio/\nhttps://ucsb-meds.github.io/creating-quarto-websites/"
  },
  {
    "objectID": "posts/2024-09-29_Cholesky_Matrix/index.html",
    "href": "posts/2024-09-29_Cholesky_Matrix/index.html",
    "title": "Cholesky‚Äôs matrix decomposition and where not to use it",
    "section": "",
    "text": "Cholesky Decomposition to compress info of some matrices\n\n\n\n\nAs I was asked to talk about AI for Cybersecurity, I have been thinking about it for a few weeks, refreshing concepts, taking some notes, gathering some ideas, sources‚Ä¶\nAnd one thing I keep coming back to is: how central matrices are to AI and Computational Engineering. They just are all over the place, the moment you start considering Artificial Neural Networks (and of course, that applies to DL‚Ä¶). Come to think of it, Word2Vec for words embedding learning is a NeuralNet. (I‚Äôm only mentioning this because Word Embeddings are important for LLM, and it seems everyone only wants to hear about LLMs lately‚Ä¶ Not that I agree.)\nAnd then you would know Matrices calculations are important nowadays if it were only for the recent NVidia stock price evolution. GPUs are great at one thing: Multiplying matrices.\nSo yeah, I‚Äôve been thinking about the importance of matrices‚Ä¶\n\n\n\nAs you know, I‚Äôm an enthusiast of Graph Theory.\nLong story short, one option to represent simple graphs is the ‚ÄúAdjacency Matrix‚Äù, whereby one sets a number (usually 1) in position a_ij of the matrix, representing there is an edge between points i and j. This is a square matrix. For an undirected graph, convention (and related calculations) expect that matrix to be symmetrical.\n\\[\na_{ij} = a_{ji}\n\\]\nWell, this is cool, but then the square matrix has a lot of repeated info, doesn‚Äôt it? And that‚Äôs inefficient for, say, storage purposes. Maybe.\n(Lists of nodes + adjacency lists, say as those used in the Pajek Net file formats, are better suited than adjacency matrices, particularly for sparse ones, if storage is actually an issue‚Ä¶ But that‚Äôs a different topic).\nWouldn‚Äôt it be cool to be able to ‚Äúcompress‚Äù the symmetric matrix?\n\n\n\nI was reading random pages of a book on Numerical Methods, looking for inspiration for a Blog entry. I ended up on an explanation of the Cholesky Matrix Decomposition.\nLong story short, at first I only read the first paragraph, which focused on symmetric matrices (like, as noted, those of a simple undirected graph!). You could see how I got enthused upfront‚Ä¶\nThen I kept reading, through the math, until I found a problem‚Ä¶ The matrix needs to be ‚Äúdefinite positive‚Äù?!\n\n\n\nI unwittingly reviewed a bit of spectral theory üòÄ\nSo OK, for a matrix to be definite positive, it needs to fullfil:\n\\[\nX^T[A]X &gt; 0, \\forall{X}\\neq0,X\\in\\mathbb{R}\n\\]¬†\nWhich is to say, for any vector X of real numbers different from vector {0}, the definite positive square matrix A satisfies the above.\nNow on to why it won‚Äôt work for an Adjacency matrix of a simple connected graph:\nFirst, with no loops, well, diagonal elements of our matrix will be 0. Which means, the trace (tr(A)) will be‚Ä¶ zero. Which is not a good sign.\nIndeed, we know that to be definite positive, an equivalent here is that our eigenvalues need to all be (strictly) positive. The trace being the sum of said eigenvalues‚Ä¶ If it is zero indeed, then that‚Äôs already confirming that we cannot apply the chosen algorithm üôÅ\nAnd if there were loop? Well, then we‚Äôd still need to verify for *strictly* positive eigenvalues, as the matrix could still be rank deficient (and so have one or more eigenvalue = 0).\n\nSide note (completely side-tracking things by now‚Ä¶ Just because I was on the topic of matrix decomposition), this is cool: For symmetric matrices, you can simply use the eigenvectors and eigenvalues to reconstruct the matrix.\n\nMoving on.\n\n\n\nRight, so I can‚Äôt apply this algorithm to simple undirected graphs‚Äô Adjacency Matrices. Pity. That‚Äôs not to say it‚Äôs completely useless, though.\nI‚Äôll go ahead and implement from pseudo-code into R the algorithm (which is, incidentally, already in base R with the function chol(), of course, mind you).\nI also use the example provided.\nA &lt;- matrix(c(6, 15, 55, 15, 55, 225, 55, 225, 979), nrow=3)\nmy_chol &lt;- function(mat_A) {\n  ## I should check for definite positive properties here...\n  mat_L &lt;- matrix(rep(0, length(mat_A)), nrow=nrow(mat_A))\n  for(k in 1:nrow(mat_A)) {\n    t_sum &lt;- 0\n    if(k &gt; 1) {\n      for(i in 1:(k-1)) {\n        t_sum &lt;- 0 \n        if(i &gt; 1) { \n          for(j in 1:(i-1)) {\n            t_sum &lt;- t_sum + mat_L[i,j]*mat_L[k, j] \n          }\n        }\n        mat_L[k, i] &lt;- (mat_A[k, i] - t_sum) / mat_L[i, i]\n      }\n      t_sum &lt;- 0\n      for(j in 1:(k-1)) {\n        t_sum &lt;- t_sum + mat_L[k, j]^2\n      }\n    }\n    mat_L[k , k] &lt;- sqrt(mat_A[k , k] - t_sum)\n  }\n  mat_L\n}\nall.equal(my_chol(A)%*%t(my_chol(A)), A)\nAnd this is it. Not very impressive with a small matrix, but for a large (positive definite symmetric) matrix, this could potentially save some resources.\n\n\n\nThis was a weird entry. I know. I thought it would come out different, but it didn‚Äôt.\nAlso, it‚Äôs mostly useless for the topic of AI, as it is, I am well aware. But that wasn‚Äôt really a goal anyway. For one brief moment, I thought there‚Äôd be a cool way, the Cholesky Decomposition, to compress info of adjacency matrices, which‚Ä¶ Most often, doesn‚Äôt apply.\nWell. I learnt something, I guess.\n\n\n\nMatrix Trace\nMatrix Rank\nDefinite Positive Matrices\nChapter 11 of ‚ÄúNumerical Methods for Engineers‚Äù, S. Chapra, R. Canale (Ed. Mc Graw Hill Education) (No link is affiliated)"
  },
  {
    "objectID": "posts/2024-09-29_Cholesky_Matrix/index.html#its-been-a-while-since-i-last-produced-anything-for-the-blog.-so-ill-start-easy-or-so-i-thought-initially.",
    "href": "posts/2024-09-29_Cholesky_Matrix/index.html#its-been-a-while-since-i-last-produced-anything-for-the-blog.-so-ill-start-easy-or-so-i-thought-initially.",
    "title": "Cholesky‚Äôs matrix decomposition and where not to use it",
    "section": "",
    "text": "Cholesky Decomposition to compress info of some matrices\n\n\n\n\nAs I was asked to talk about AI for Cybersecurity, I have been thinking about it for a few weeks, refreshing concepts, taking some notes, gathering some ideas, sources‚Ä¶\nAnd one thing I keep coming back to is: how central matrices are to AI and Computational Engineering. They just are all over the place, the moment you start considering Artificial Neural Networks (and of course, that applies to DL‚Ä¶). Come to think of it, Word2Vec for words embedding learning is a NeuralNet. (I‚Äôm only mentioning this because Word Embeddings are important for LLM, and it seems everyone only wants to hear about LLMs lately‚Ä¶ Not that I agree.)\nAnd then you would know Matrices calculations are important nowadays if it were only for the recent NVidia stock price evolution. GPUs are great at one thing: Multiplying matrices.\nSo yeah, I‚Äôve been thinking about the importance of matrices‚Ä¶\n\n\n\nAs you know, I‚Äôm an enthusiast of Graph Theory.\nLong story short, one option to represent simple graphs is the ‚ÄúAdjacency Matrix‚Äù, whereby one sets a number (usually 1) in position a_ij of the matrix, representing there is an edge between points i and j. This is a square matrix. For an undirected graph, convention (and related calculations) expect that matrix to be symmetrical.\n\\[\na_{ij} = a_{ji}\n\\]\nWell, this is cool, but then the square matrix has a lot of repeated info, doesn‚Äôt it? And that‚Äôs inefficient for, say, storage purposes. Maybe.\n(Lists of nodes + adjacency lists, say as those used in the Pajek Net file formats, are better suited than adjacency matrices, particularly for sparse ones, if storage is actually an issue‚Ä¶ But that‚Äôs a different topic).\nWouldn‚Äôt it be cool to be able to ‚Äúcompress‚Äù the symmetric matrix?\n\n\n\nI was reading random pages of a book on Numerical Methods, looking for inspiration for a Blog entry. I ended up on an explanation of the Cholesky Matrix Decomposition.\nLong story short, at first I only read the first paragraph, which focused on symmetric matrices (like, as noted, those of a simple undirected graph!). You could see how I got enthused upfront‚Ä¶\nThen I kept reading, through the math, until I found a problem‚Ä¶ The matrix needs to be ‚Äúdefinite positive‚Äù?!\n\n\n\nI unwittingly reviewed a bit of spectral theory üòÄ\nSo OK, for a matrix to be definite positive, it needs to fullfil:\n\\[\nX^T[A]X &gt; 0, \\forall{X}\\neq0,X\\in\\mathbb{R}\n\\]¬†\nWhich is to say, for any vector X of real numbers different from vector {0}, the definite positive square matrix A satisfies the above.\nNow on to why it won‚Äôt work for an Adjacency matrix of a simple connected graph:\nFirst, with no loops, well, diagonal elements of our matrix will be 0. Which means, the trace (tr(A)) will be‚Ä¶ zero. Which is not a good sign.\nIndeed, we know that to be definite positive, an equivalent here is that our eigenvalues need to all be (strictly) positive. The trace being the sum of said eigenvalues‚Ä¶ If it is zero indeed, then that‚Äôs already confirming that we cannot apply the chosen algorithm üôÅ\nAnd if there were loop? Well, then we‚Äôd still need to verify for *strictly* positive eigenvalues, as the matrix could still be rank deficient (and so have one or more eigenvalue = 0).\n\nSide note (completely side-tracking things by now‚Ä¶ Just because I was on the topic of matrix decomposition), this is cool: For symmetric matrices, you can simply use the eigenvectors and eigenvalues to reconstruct the matrix.\n\nMoving on.\n\n\n\nRight, so I can‚Äôt apply this algorithm to simple undirected graphs‚Äô Adjacency Matrices. Pity. That‚Äôs not to say it‚Äôs completely useless, though.\nI‚Äôll go ahead and implement from pseudo-code into R the algorithm (which is, incidentally, already in base R with the function chol(), of course, mind you).\nI also use the example provided.\nA &lt;- matrix(c(6, 15, 55, 15, 55, 225, 55, 225, 979), nrow=3)\nmy_chol &lt;- function(mat_A) {\n  ## I should check for definite positive properties here...\n  mat_L &lt;- matrix(rep(0, length(mat_A)), nrow=nrow(mat_A))\n  for(k in 1:nrow(mat_A)) {\n    t_sum &lt;- 0\n    if(k &gt; 1) {\n      for(i in 1:(k-1)) {\n        t_sum &lt;- 0 \n        if(i &gt; 1) { \n          for(j in 1:(i-1)) {\n            t_sum &lt;- t_sum + mat_L[i,j]*mat_L[k, j] \n          }\n        }\n        mat_L[k, i] &lt;- (mat_A[k, i] - t_sum) / mat_L[i, i]\n      }\n      t_sum &lt;- 0\n      for(j in 1:(k-1)) {\n        t_sum &lt;- t_sum + mat_L[k, j]^2\n      }\n    }\n    mat_L[k , k] &lt;- sqrt(mat_A[k , k] - t_sum)\n  }\n  mat_L\n}\nall.equal(my_chol(A)%*%t(my_chol(A)), A)\nAnd this is it. Not very impressive with a small matrix, but for a large (positive definite symmetric) matrix, this could potentially save some resources.\n\n\n\nThis was a weird entry. I know. I thought it would come out different, but it didn‚Äôt.\nAlso, it‚Äôs mostly useless for the topic of AI, as it is, I am well aware. But that wasn‚Äôt really a goal anyway. For one brief moment, I thought there‚Äôd be a cool way, the Cholesky Decomposition, to compress info of adjacency matrices, which‚Ä¶ Most often, doesn‚Äôt apply.\nWell. I learnt something, I guess.\n\n\n\nMatrix Trace\nMatrix Rank\nDefinite Positive Matrices\nChapter 11 of ‚ÄúNumerical Methods for Engineers‚Äù, S. Chapra, R. Canale (Ed. Mc Graw Hill Education) (No link is affiliated)"
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html",
    "title": "RLCS with the mirai package",
    "section": "",
    "text": "I have actually now have had the time to evaluate (only briefly) the use of the mirai R package and it‚Äôs‚Ä¶ interesting.\n\n\n\ninstalling mirai package\n\n\nApplied to the RLCS (because, why not), I thought I‚Äôd give it a go and use it where I thought it would make a difference‚Ä¶ My use-case for today was to address the population cleaning process of the RLCS package, that is (just a bit) slow and very necessary.\nBut the thing is‚Ä¶ Nuanced."
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#i-hinted-at-the-idea-last-time-and-well",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#i-hinted-at-the-idea-last-time-and-well",
    "title": "RLCS with the mirai package",
    "section": "",
    "text": "I have actually now have had the time to evaluate (only briefly) the use of the mirai R package and it‚Äôs‚Ä¶ interesting.\n\n\n\ninstalling mirai package\n\n\nApplied to the RLCS (because, why not), I thought I‚Äôd give it a go and use it where I thought it would make a difference‚Ä¶ My use-case for today was to address the population cleaning process of the RLCS package, that is (just a bit) slow and very necessary.\nBut the thing is‚Ä¶ Nuanced."
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#the-question-is-how-much-i-gain-with-it",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#the-question-is-how-much-i-gain-with-it",
    "title": "RLCS with the mirai package",
    "section": "The question is how much I gain with it",
    "text": "The question is how much I gain with it\nLaunching a parallel dedicated process like so:\nmirai::daemon(1)\n\nmirai::mirai({ &lt;do something here&gt;; }, dependency1=dependency1...)\nSounds easy enough, but it becomes quickly complicated to decide when to wait for the result, why, how to sync things‚Ä¶ Things of parallel computation that are always fun. But it‚Äôs not all.\n\n\n\ncreating a local daemon to receive processing request, avoiding a bit the overhead\n\n\nAnd yet, supposing I manage (I did, I did), I ran some tests and (duh!) it‚Äôs not as simple as it might seem upfront.\nSo here is the thing:\nFor large populations, a process to reduce population size (be it sumbsumption, deletion, compaction or what-not) is a bit slower. For small populations however, it is rather fast.\nIn proportion then, you would want to use a separate process for population size control only if:\n\nit is slow (e.g.¬†large populations)\nOR it happens often\n(or ideally both)\n\nThe trick with this is then that choosing to separate that process into another core/thread is a balancing exercise that can (very easily) prove counter-productive. I know all this because I have just spent half my Sunday afternoon running some tests (profvis and microbenchmark, both handy).\nPlus, to be clear, the code is quite a bit messier (yes, even more :D). That said, I do feel it was a very interesting exercise."
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#so-why-bother",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#so-why-bother",
    "title": "RLCS with the mirai package",
    "section": "So why bother?",
    "text": "So why bother?\nWell, here is the thing: Having that separated sub-process run in parallel allows me to decide to run subsumption quite a bit more often, without a real impact to the runtimes.\nThis means, in the long run, and depending on other parameters (‚Ä¶), smaller populations for matching, and overall faster runtimes then.\nBut well, it‚Äôs not perfect."
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#some-pictures-to-support-the-claims",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#some-pictures-to-support-the-claims",
    "title": "RLCS with the mirai package",
    "section": "Some pictures to support the claims",
    "text": "Some pictures to support the claims\n\n\n\none CAN get small gains, for say mux6(), but it is highly dependent on parameters/use-case\n\n\nHere is an example with the Iris dataset, whereby I set things to do a population cleanup every 8th generation. I ran both the new version and the old. Here another screenshot:\n\n\n\ndifference in delay\n\n\nSo what happening above is: I launch subsumption and deletion processes at every 8th epoch in both cases.\nBut with a mirai process, I delay consolidation of my population for after the cleanup is finished, and I keep running discovery of new rules in the meatime (roughly, this goes on for 3 or 4 epochs), and then only do I consolidate with the cleaned-up population from 3 (or 4) epochs ago (which is made a bit more complicated, as you might guess, by the rules that might have been discovered in the meantime, which also explains that ‚ÄúFinal Population Cleanup (sequential):‚Äù message in there).\nWhere withouth mirai, I have to wait for the same cleanup process to happen before I can continue.\nIf you stop and review the convoluted explanation above, you might see that: If I ‚Äúsave‚Äù 3-4 epochs of processing time associated to the population cleanup, and I clean the population often (say, like here, every 8th epoch), and suppose I want to run this process for a very high number of epochs (which might in some corner cases be warranted), here I‚Äôd be saving 3-4 steps every 11-12 steps. Which is a big gain!\nIncorrect, though, as I do have an overhead for reconciliation of the two parallel populations (and to be perfectly clear, and honest, right now my implementation also makes some educated simplifications in there).\nBut what matters to me here is the order of magnitude. 30%. Or say ‚Äúonly‚Äù 20%, to account for the overhead of reconciliation (it‚Äôs not that hard). That‚Äôs not a lot unless you have a very long running process. Then you might start to appreciate it.\n(Note: In the case of an iris classifier as above with some chosen hyperparameters, I get 9.96 seconds without mirai, and 7.17 seconds with‚Ä¶ Not too bad.)"
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#conclusion",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#conclusion",
    "title": "RLCS with the mirai package",
    "section": "Conclusion",
    "text": "Conclusion\nPopulation consolidation was never the biggest bottleneck. But it is a slow process in cases of large populations. And the overall matching efforts benefit from a more compact population, so more frequent clean-ups might prove very useful sometimes‚Ä¶\nI have yet to test this with my images classifier or the RLCS RL demo use-case. There, I expect to see some more value out of these efforts.\nAt this time and with the tests I ran this afternoon (rather simple ones with not_bit4, mux6 and the iris dataset), is it worth it? Well‚Ä¶ Not really.\nBut depending on the configurations, I could (I did) get roughly 40% time savings. Not too shabby.\nSo the balance between cleaner code, one-less-dependency (mirai, which is also a complex dependency, for a package, as I would have to decide how I let my user manage that or not‚Ä¶), and not awfully slow run-times, or slightly better run-times with less readable code, but possibly a key improvement in larger cases‚Ä¶\nI‚Äôm not 100% sold. I‚Äôll have to keep running tests."
  },
  {
    "objectID": "posts/2025-08-10_RLCS_MIRAI/index.html#reference",
    "href": "posts/2025-08-10_RLCS_MIRAI/index.html#reference",
    "title": "RLCS with the mirai package",
    "section": "Reference",
    "text": "Reference\nI looked for things for a while, but last week this showed up. You have to love the R community for these things."
  },
  {
    "objectID": "posts/2025-08-24_NewProjectForProgressTracking/index.html",
    "href": "posts/2025-08-24_NewProjectForProgressTracking/index.html",
    "title": "Organizing a bit for future work/exercises",
    "section": "",
    "text": "I have dedicated a bit of my spare time to the RLCS package creation. And it‚Äôs still very much ongoing. But as I give myself until end of 2025 to have a first ‚Äúshared‚Äù version of the package, well, I am looking into future work. Something to keep my head busy for 2026, if you will."
  },
  {
    "objectID": "posts/2025-08-24_NewProjectForProgressTracking/index.html#collecting-thoughts-and-code-for-future-project",
    "href": "posts/2025-08-24_NewProjectForProgressTracking/index.html#collecting-thoughts-and-code-for-future-project",
    "title": "Organizing a bit for future work/exercises",
    "section": "",
    "text": "I have dedicated a bit of my spare time to the RLCS package creation. And it‚Äôs still very much ongoing. But as I give myself until end of 2025 to have a first ‚Äúshared‚Äù version of the package, well, I am looking into future work. Something to keep my head busy for 2026, if you will."
  },
  {
    "objectID": "posts/2025-08-24_NewProjectForProgressTracking/index.html#new-github-repo",
    "href": "posts/2025-08-24_NewProjectForProgressTracking/index.html#new-github-repo",
    "title": "Organizing a bit for future work/exercises",
    "section": "New GitHub Repo",
    "text": "New GitHub Repo\nJust because I am slowly getting used to sharing my code more and more (in spite of the shame it supposes sometimes, my code being‚Ä¶ Well, far from perfect), I thought I‚Äôd help myself by setting up a new project early on to collect some ideas.\nAnd so this repo was born earlier today."
  },
  {
    "objectID": "posts/2025-08-24_NewProjectForProgressTracking/index.html#on-the-issue-of-generating-animations",
    "href": "posts/2025-08-24_NewProjectForProgressTracking/index.html#on-the-issue-of-generating-animations",
    "title": "Organizing a bit for future work/exercises",
    "section": "On the issue of generating animations",
    "text": "On the issue of generating animations\nOne thing I still struggle with is generating animations in 2D that are visually pleasant and particulary, that are not slow. (Yes, this is related to the above, as I want to be able to ‚Äúshow‚Äù agent-based modelling simulations.)\nUsing RStudio Viewer and image() to follow the evolution of the cellular automata in past exercises has often required, for niceness, for me to edit a video screenshot and accelerate it.\nAlso, using image(), this is the fastest way I‚Äôve found during my tests:\n## From past exercise with Schelling Seggregation Model, I had this:\ntf &lt;- function(m) t(m)[, nrow(m):1]\nimageM &lt;- function(m, grid = max(dim(m)) &lt;= 25, asp = (nrow(m)-1)/(ncol(m)-1), ...) {\n  image(tf(m), asp=asp, axes = FALSE, useRaster=TRUE, ...)\n}\n\nt_start &lt;- Sys.time()\nfor(i in 1:10) {\n  imageM(world[[i]])\n  Sys.sleep(.2) ## Renders, but runtime goes to 2.22secs for 100*100px.\n  ## Not awful, but not great.\n}\nSys.time() - t_start\nHowever I try‚Ä¶ I just can‚Äôt seem to get past the 10 FPS mark, (i.e.¬†reduce the Sys.sleep() there) whatever I do, and that‚Äôs only for pre-computed matrices, of reasonable size.\nHowever, if you use the animation package like I did at the end of the code here, for instance:\n## Not in RStudio/so post-processing visualization, but can be made fast:\nlibrary(animation)\n# Create the animation\nsaveHTML({ ## This one also offers speed controls...\n  for (i in 1:100) { ## Careful, it generates one PNG per matrix, and JS/CSS/HTML stuff...\n    image(world[[i]], axes=FALSE, useRaster = TRUE, col = grey.colors(256))\n    ani.options(interval = 0.02) ## Key to actual visual speed here\n  }\n},\nhtmlfile = \"random_points.html\",\nani.width = 500,\nani.height = 500)\nWell, the results are nicer.\nApplying this approach to a past exercise on Fire Spread simulation, you get to this result here:\n\n(It‚Äôs actually a cut-down version with low resolution as the original capture of it was 26MB big‚Ä¶)"
  },
  {
    "objectID": "posts/2025-08-24_NewProjectForProgressTracking/index.html#conclusions",
    "href": "posts/2025-08-24_NewProjectForProgressTracking/index.html#conclusions",
    "title": "Organizing a bit for future work/exercises",
    "section": "Conclusions",
    "text": "Conclusions\nI should really be working on finishing the RLCS project, but I am looking into future work instead, just to keep myself entertained really."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "",
    "text": "You can consider two levels of organization. Call them ‚Äúcells‚Äù and ‚Äúwhole bodies‚Äù‚Ä¶ Also today: Matrices multiplications, and issues with subsumption‚Ä¶\nI was reading this book ‚ÄúA history of intelligence‚Äù by Max S. Bennett. But that‚Äôs just for context. Now‚Ä¶ This is probably not the greatest/most original idea out there but‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#im-using-an-idea-of-hierarchies",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#im-using-an-idea-of-hierarchies",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "",
    "text": "You can consider two levels of organization. Call them ‚Äúcells‚Äù and ‚Äúwhole bodies‚Äù‚Ä¶ Also today: Matrices multiplications, and issues with subsumption‚Ä¶\nI was reading this book ‚ÄúA history of intelligence‚Äù by Max S. Bennett. But that‚Äôs just for context. Now‚Ä¶ This is probably not the greatest/most original idea out there but‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#matching-can-be-done-with-matrices",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#matching-can-be-done-with-matrices",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Matching CAN be done with matrices",
    "text": "Matching CAN be done with matrices\nI just finally have a useful idea (maybe) to speed things up.\nSee it bothers me that I use only CPU in today‚Äôs world. Because well, GPUs are supposed to be faster, right?\nAnd it was ‚Äúsimple‚Äù:\nMatching means: Compare a string (input state) and check whether all the zeros for a given population rule match (position wise), and all the ones for the rule match. I won‚Äôt explain the matching operations here again.\nBut in terms of using matrices (which I only consider because‚Ä¶ Tensorflow), let‚Äôs focus on the ‚Äúones‚Äù:\nA rule of ones can be, say, written as a row of zeros (where the rule says either # or 0) and 1 where we want to match‚Ä¶ ones.\nNow, just multiply this vector with your state (as a vector of zeros and ones), and it will return a number of matched ones.\nInvert the state, and do the same for the zeros (I understand myself). That‚Äôs about the gist of it.\nThe key difference (maybe) is that I‚Äôm multiplying these. And I could put all population rules in a matrix (or two, hence, maybe a tensor), rather sparse (that would be great), and matching would be about multiplying one matrix with one vector.\nThen you‚Äôd need to compare the vector with a vector of rules numbers of fixed bits, that‚Äôs one simple vectorized operation.\nIf I‚Äôm not making much sense, well‚Ä¶ Sorry. The idea is clear in my mind, but I‚Äôll have to code it all first just to see whether it all makes sense, and then I‚Äôd have to see if I could move that to GPU (in R on MacBook, I know it can work, from past experiments). Doing that would make the RLCS package much more complex in a way (the tensor calculation works on either GPU or CPU, but I‚Äôd have to check for availability of that, then I‚Äôd have the dependency on a whole new big library‚Ä¶)\nAnyhow!\nIt‚Äôs just a ‚Äúcool‚Äù idea in the sense that matching is, for all purposes, currently the largest chunk of runtime of the algorithm."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#back-to-the-cells-thing",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#back-to-the-cells-thing",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Back to the cells thing",
    "text": "Back to the cells thing\nNow the simil is a bit ‚Äúout there‚Äù, but bear with me:\nWhat if I trained (in parallel, mind you) a few ‚Äúcells‚Äù (really, RLCS agents tasked with supervised learning each).\nThen, I can take the best of them (evolutionary pressure of selection of the fittest) and ‚Äúput them together‚Äù as a new body. That‚Äôs one thing you can do with two LCS populations that you couldn‚Äôt do with two trained neural networks.\nNow here, the simil fails: I then proceed to iterate assimilating the newly created ‚Äúbody‚Äù to N identical‚Ä¶ Well cells, and I repeat the operation."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#why-do-that",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#why-do-that",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Why do that?",
    "text": "Why do that?\nWell, one of the issues with the LCS is that‚Ä¶ It searches in (sometimes) a huge space, right? But it does it in several key aspects very sequentially. No SIMD possible there. And that‚Äôs limiting.\nAnd when that happens, going back to the comparison of evolution of cells‚Ä¶\nWell, consider things a few million/billion years ago: the most ‚Äústable‚Äù cells survive, so to speak. But they all survive and crucially they all evolve, well in parallel‚Ä¶ And there are many!\nIn that comparison, one LCS agent would be one cell‚Ä¶ But Evolution took billions of years for‚Ä¶ Billions of cells!\nSo training one RLCS agent from that perspective seems a bit limiting (to say the least)."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#right-but-crazy-ideas-aside-why",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#right-but-crazy-ideas-aside-why",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Right but crazy ideas aside, why?",
    "text": "Right but crazy ideas aside, why?\nWell, for one thing: I can‚Äôt seem to get one RLCS agent to be trained any faster. Not noticeably so, at this point. Not without skipping steps, training it ‚Äúworse‚Äù.\nBut what I can do‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#so-parallelizing-agents-trainings-and-selecting-the-best-ones",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#so-parallelizing-agents-trainings-and-selecting-the-best-ones",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "So: ‚ÄúParallelizing‚Äù Agents‚Äô trainings and selecting the best ones",
    "text": "So: ‚ÄúParallelizing‚Äù Agents‚Äô trainings and selecting the best ones\nAnd how do I know which are the ‚Äúbest ones‚Äù? Well, I‚Äôm using a sort of K-Fold approach (so far, I had just train and test sets).\nI do a few iteration and for each iteration, I train N agents on a subset of the training set, while holding a (random) small set of validation data points (always from the training set)."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#the-key-for-speed-vs-accuracy-trade-off",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#the-key-for-speed-vs-accuracy-trade-off",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "The key for speed vs accuracy trade-off",
    "text": "The key for speed vs accuracy trade-off\nWell, here the whole point is to either gain speed, or gain accuracy, or (y‚Äôknow, ideally) both.\nSo each agent is trained (much) less (fewer epochs). That‚Äôs the speed gain.\nAll the while, several agents compete with each their own stochastic"
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#can-i-improve-the-subsumption-on-coverage",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#can-i-improve-the-subsumption-on-coverage",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Can I improve the subsumption? On coverage‚Ä¶",
    "text": "Can I improve the subsumption? On coverage‚Ä¶\nI don‚Äôt know, but something bothers me here in this screenshot.\n\n\n\nTwo rules, but one is better, if you know what you‚Äôre doing‚Ä¶\n\n\nTwo ‚Äúgeneral‚Äù rules of setosa, both often found by the algorithm. But one seems to be simpler as it involves only one ‚Äúvariable‚Äù, which the LCS doesn‚Äôt have context about as it only sees the strings of bits.\nAlso, I know that because I have context, I know that Setosa is easy to separate from the rest with one dimension, and that you could do it with just one rule, but that‚Äôs because I‚Äôve seen all the data at once.\nCan I somehow inform subsumption to choose the rule that uses only one variable? How would the algorithm know in this case that rule is ‚Äúbetter‚Äù? I think if there was a way, I should store ‚Äúcoverage‚Äù: If say two rules have perfect accuracy (they are correct whenever they match) they are not necessarily equal: One could have perfect accuracy but only be found in certain cases, while the other could have perfect accuracy AND perfect coverage. I would ‚Äúdiscard‚Äù any other rule for the whole given class!\nThink of it: If there is one perfect rule for a given class, I could skip all operations and calculations for that particular class! No more worrying about matching. And one rule instead of a host of rules for matching means: reduced comparisons, much (much!) faster execution times.\nBut to do that, I need to know the coverage, which in ‚Äútraining‚Äù requires me to count correct cases per epoch. It should be easy, and it could mean a world of difference in the iris case, as there would need to be just the one rule for the one class.\nAlso, an issue: I want to consider the above for perfect rules but, ideally, I want that for simpler rules, so that they are perfect AND informative. Or do I want the more precise rules? Both could be valuable in a data mining scenario‚Ä¶\nTo be continued‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#unrelated-i-dislike-my-rule-discovery-trigger",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#unrelated-i-dislike-my-rule-discovery-trigger",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Unrelated: I dislike my rule discovery trigger",
    "text": "Unrelated: I dislike my rule discovery trigger\nThe RD number tells me how often I want to run the GA algorithm on the correct set. But somehow, I‚Äôve tried different versions of that (when I meet the RD number of iterations) and none of them quite exactly make sense. I‚Äôll revisit that."
  },
  {
    "objectID": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#conclusions",
    "href": "posts/2025-11-14_Comparing_RLCS_to_RF_PartIII/index.html#conclusions",
    "title": "Still trying to get RLCS to be as good as Random Forest‚Ä¶",
    "section": "Conclusions",
    "text": "Conclusions\nThis is all sooooo cool!\nI have a huge amount of work right here, but all of it might make a difference in the RLCS speed and accuracy.\nAs of now, RLCS on average for the iris dataset is slightly better than Partitioning trees and slightly worse than Random Forest. But it‚Äôs incredibly slow to get to these results, I‚Äôm talking something like 40 seconds runs. So it‚Äôs not absolutely better in results and it‚Äôs absolutely worse in runtimes.\nBut I will keep at it. I‚Äôm seeing possibilities to improve, all of which could make a huge difference. Maybe.\nWe‚Äôll have to wait and see!"
  },
  {
    "objectID": "posts/2025-02-15_A_World_To_Play_RL/index.html",
    "href": "posts/2025-02-15_A_World_To_Play_RL/index.html",
    "title": "RLCS: A World to Play RL",
    "section": "",
    "text": "Today I just started something simple: An Object to represent a simulated World in which an Agent can move.\nAs the ‚ÄúAgent‚Äù will need to interact with the World, and the World should return rewards, and understand positions, etc., I decided in this case to go the way of R Objects, more specifically ‚ÄúsetRefClass‚Äù.\nFor today, I just created a basic object to generate a ‚Äúrandom world‚Äù that can have walls, food, even enemy(ies) and in which we can throw an agent at random in any empty space.\nEDIT: Added Agent movements and visualizations\nA few peculiarities maybe: I think it will be simpler in the future to not have to deal with ‚Äúborders‚Äù from the Agent perspective, and so I set my Worlds to necessarily be walls all around.\n\n\n\nLet‚Äôs start today with a simple video showing the results. The agent is the blue thing. Food is green, enemy is red, black are walls.\nAll is initialized randomly, and so are the moves of the current agent. On the left, I show the agent‚Äôs perspective/perception (allocentric) of the World. On the right, the World as it is at each step:\n\nVideos are always more satisfying than matrices, but to understand what happens, let‚Äôs have a look under the hood‚Ä¶\n\n\n\nSo in my matrix, I choose 0 = empty cell, 1 is a wall, 2 is food, 3 is an enemy (defaults to no enemies). And 4 will be an agent. This is all arbitrary, but when in the future I encode into binary there will be a specific order, as this will be relevant for the GA to work with.\nAnyhow, it looks like so:\n\n\n\nA simple world object\n\n\nIn this ‚Äúworld‚Äù, I needed to add methods to move around (from-to positions, or just ‚Äúto‚Äù), control for ilegal moves (can‚Äôt move into a wall), return rewards: good +10 for food, bad -100 if enemy, and empty and walls, well, to be refined.\nAll very simple, but cool at the same time: I can already render ‚Äúanimations‚Äù of said worlds‚Ä¶ Albeit with a very stupid agent for now‚Ä¶\n\n\n\nWell, I‚Äôm afraid now I have most of the pieces. But still:\n\nI will need to implement a variation of my existing RLCS code to account for four possible actions (for now, actions are binary, that‚Äôs not enough).\nI will need to add a sensible binary encoding for the agent to interpret its visible environment\nI will need to account for rewards, change the design for the RL case where I need to add prediction and an Action Set\n‚Ä¶\n\nQuite a bit of work still. But all fun.\nTO BE CONTINUED‚Ä¶"
  },
  {
    "objectID": "posts/2025-02-15_A_World_To_Play_RL/index.html#the-world-should-be-easy-to-interact-with",
    "href": "posts/2025-02-15_A_World_To_Play_RL/index.html#the-world-should-be-easy-to-interact-with",
    "title": "RLCS: A World to Play RL",
    "section": "",
    "text": "Today I just started something simple: An Object to represent a simulated World in which an Agent can move.\nAs the ‚ÄúAgent‚Äù will need to interact with the World, and the World should return rewards, and understand positions, etc., I decided in this case to go the way of R Objects, more specifically ‚ÄúsetRefClass‚Äù.\nFor today, I just created a basic object to generate a ‚Äúrandom world‚Äù that can have walls, food, even enemy(ies) and in which we can throw an agent at random in any empty space.\nEDIT: Added Agent movements and visualizations\nA few peculiarities maybe: I think it will be simpler in the future to not have to deal with ‚Äúborders‚Äù from the Agent perspective, and so I set my Worlds to necessarily be walls all around."
  },
  {
    "objectID": "posts/2025-02-15_A_World_To_Play_RL/index.html#a-random-policy-agent-in-a-random-world",
    "href": "posts/2025-02-15_A_World_To_Play_RL/index.html#a-random-policy-agent-in-a-random-world",
    "title": "RLCS: A World to Play RL",
    "section": "",
    "text": "Let‚Äôs start today with a simple video showing the results. The agent is the blue thing. Food is green, enemy is red, black are walls.\nAll is initialized randomly, and so are the moves of the current agent. On the left, I show the agent‚Äôs perspective/perception (allocentric) of the World. On the right, the World as it is at each step:\n\nVideos are always more satisfying than matrices, but to understand what happens, let‚Äôs have a look under the hood‚Ä¶"
  },
  {
    "objectID": "posts/2025-02-15_A_World_To_Play_RL/index.html#todays-results-in-matrix-format",
    "href": "posts/2025-02-15_A_World_To_Play_RL/index.html#todays-results-in-matrix-format",
    "title": "RLCS: A World to Play RL",
    "section": "",
    "text": "So in my matrix, I choose 0 = empty cell, 1 is a wall, 2 is food, 3 is an enemy (defaults to no enemies). And 4 will be an agent. This is all arbitrary, but when in the future I encode into binary there will be a specific order, as this will be relevant for the GA to work with.\nAnyhow, it looks like so:\n\n\n\nA simple world object\n\n\nIn this ‚Äúworld‚Äù, I needed to add methods to move around (from-to positions, or just ‚Äúto‚Äù), control for ilegal moves (can‚Äôt move into a wall), return rewards: good +10 for food, bad -100 if enemy, and empty and walls, well, to be refined.\nAll very simple, but cool at the same time: I can already render ‚Äúanimations‚Äù of said worlds‚Ä¶ Albeit with a very stupid agent for now‚Ä¶"
  },
  {
    "objectID": "posts/2025-02-15_A_World_To_Play_RL/index.html#what-next",
    "href": "posts/2025-02-15_A_World_To_Play_RL/index.html#what-next",
    "title": "RLCS: A World to Play RL",
    "section": "",
    "text": "Well, I‚Äôm afraid now I have most of the pieces. But still:\n\nI will need to implement a variation of my existing RLCS code to account for four possible actions (for now, actions are binary, that‚Äôs not enough).\nI will need to add a sensible binary encoding for the agent to interpret its visible environment\nI will need to account for rewards, change the design for the RL case where I need to add prediction and an Action Set\n‚Ä¶\n\nQuite a bit of work still. But all fun.\nTO BE CONTINUED‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-10_WhatILikeAboutMyMSc/index.html",
    "href": "posts/2023-06-10_WhatILikeAboutMyMSc/index.html",
    "title": "What I like about the MSc I‚Äôm studying",
    "section": "",
    "text": "My (very few) readers know it, as I mention it often: I am what you could call a life-long student, and currently working my way towards finishing an MSc in Computational Engineering and Mathematics.\nThe reality of it is I wanted to understand a bit better the math and the theory behind all the ‚Äúcommon‚Äù things of data I use (e.g.¬†I‚Äôve been able to run PCA dimensionality reduction for years already, but how it actually worked, what orthogonal projections meant‚Ä¶ was beyond me). I am NOT good at math, but I am curious about it, and so this master has proven a real challenge, but also very satisfying and rewarding up until now.\nMore recently I am studying ‚Äúcomplex networks‚Äù, and for the last exercise I had to implement on reasonably-big graphs a ‚ÄúSusceptible-Infected-Susceptible‚Äù epidemic model with several parameters, over several time steps, and so use MonteCarlo (because part of it uses random numbers and so is not deterministic) to run several such iterations to average the results‚Ä¶\nLong story short: ‚ÄúSimple R‚Äù just wouldn‚Äôt cut it, once again.\nI‚Äôm coming to conclude that *lots* of math (say in ‚Äúnumerical methods‚Äù, and many other mathematical algorithms) require iterations for which each step result is needed for the next step. In other words, some stuff can‚Äôt be run in parallel.\nSo running things faster becomes useful, when one needs to say do 1000 generations, but also do it 5000 times, over thousands of vertices, for instance.\nAnd then use different parameters, and that‚Äôs where you can go parallel.\nAnd that‚Äôs the conclusion for today ‚Äì and yeah, basically I‚Äôm bragging: it‚Äôs been almost two years, not an easy two years mind you, but by now it feels almost natural to me to take an algorithm or mathematical model, implement it in a mix of R and C++, and use 7 CPUs to have my laptop crunch MonteCarlo simulations over night, while I sleep, all so that I can draw graphs and come to conclusions the next morning, about things based on mathematical concepts.\nAgain, to be clear, the math still doesn‚Äôt come ‚Äúeasy‚Äù, but I find I can decipher anything I‚Äôve come across for these two years, albeit with a little effort‚Ä¶\nAnd this is my personal praise for this ‚ÄúMSc‚Äù."
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html",
    "title": "RLCS is now twice as fast!",
    "section": "",
    "text": "Matrices multiplications instead of char-by-char string comparison for matching: From 30s to &lt;1s. GOSH! I just eliminated the biggest bottleneck!"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#youve-gotta-love-it-when-ideas-work-out",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#youve-gotta-love-it-when-ideas-work-out",
    "title": "RLCS is now twice as fast!",
    "section": "",
    "text": "Matrices multiplications instead of char-by-char string comparison for matching: From 30s to &lt;1s. GOSH! I just eliminated the biggest bottleneck!"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#yesterdays-idea-todays-results",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#yesterdays-idea-todays-results",
    "title": "RLCS is now twice as fast!",
    "section": "Yesterday‚Äôs idea: Today‚Äôs results!",
    "text": "Yesterday‚Äôs idea: Today‚Äôs results!\nI mentioned it in yesterday‚Äôs post. Well‚Ä¶ Now it‚Äôs a reality. I just updated the GitHub accordingly.\n\n\n\nUsing Matrices to do matching is, well, much faster!\n\n\nI‚Äôm not proud of ‚Äúhow‚Äù I coded it, mind you, but it is working, and also, it‚Äôs fast. I‚Äôll make it cleaner in upcoming days.\nAlso, as matching was the key step in ‚Äúprediction‚Äù, well predictions are almost instantaneous too, now!"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#memo-ization-of-sorts",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#memo-ization-of-sorts",
    "title": "RLCS is now twice as fast!",
    "section": "Memo-ization of sorts",
    "text": "Memo-ization of sorts\nSo on top of the matrices multiplications approach, which is naturally faster than strings matching the old way, I now keep track of the whole population ‚Äúmatch matrices‚Äù for where a zero is found per rule, and where a 1.\nKeeping it updated ONLY when I CHANGE the population (addition or deletion of rules), separated from the other steps, also ensures matching is now ‚Äújust‚Äù matrix multiplication, no more.\nAgain: I don‚Äôt know if ‚Äúclever‚Äù, but‚Ä¶ What a difference!"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#edit-getting-even-better",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#edit-getting-even-better",
    "title": "RLCS is now twice as fast!",
    "section": "Edit: Getting even better!",
    "text": "Edit: Getting even better!\nThe above was‚Ä¶ This morning. Instead of a new post, I‚Äôll just edit this for ‚Äútonight‚Äôs edition‚Äù.\nThe next bottleneck was: Subsumption. But I could use the same matrix approach to reduce iterations!\nAnd I did, and here what it looks like (see how it changes from the above?):\n\n\n\nSubsumption runtime also greatly reduced now!"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#so-what-well",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#so-what-well",
    "title": "RLCS is now twice as fast!",
    "section": "So what? Well‚Ä¶",
    "text": "So what? Well‚Ä¶\nIf I use all my tricks, I can train a ‚Äúgood‚Äù (97% accuracy) images classifier in under 4 seconds.\n\n\n\n4 seconds to train an image classifier that works\n\n\nAnd if say you don‚Äôt have multi-core/multi-thread, even then‚Ä¶ Processing time went down from 1m20s to 28s, and accuracy (with less cheating) is even better (99%):\n\n\n\n99% correct classification in under 30s of training\n\n\nAnd all that, with lots of compression (and information loss) on input, and training on 800 samples (for testing on 3500+!).\nI still can‚Äôt seem to beat Random Forest on the Iris dataset for whatever reason, but all this will help for sure, and I have a feeling it somehow can be done‚Ä¶"
  },
  {
    "objectID": "posts/2025-11-15_RLCS_twice_as_fast/index.html#conclusions",
    "href": "posts/2025-11-15_RLCS_twice_as_fast/index.html#conclusions",
    "title": "RLCS is now twice as fast!",
    "section": "Conclusions",
    "text": "Conclusions\nHow many hours have I spent testing long-running stuff‚Ä¶ That could have been much much much faster?\nAnyhow‚Ä¶\nThe code was adapted ‚Äúquick-&-dirty‚Äù, so I‚Äôll need to refactor it all (quite a bit). Right now, I‚Äôm skipping passing variables among fonctions and updating ‚Äúparent envs‚Äù, which, well, I don‚Äôt think is a good practice at all. Unless I control exactly what I do, I guess‚Ä¶\nBut the point stands! I just essentially eliminated the bottleneck. Not ‚Äúreduced‚Äù, no no no. Eliminated. This opens a host of new ideas to consider: Longer matching epochs (i.e.¬†reduced triggering of subsumption), for one!\nThis is a great leap forward for RLCS!"
  },
  {
    "objectID": "others/test_new_subsite.html",
    "href": "others/test_new_subsite.html",
    "title": "Test_new_quarto",
    "section": "",
    "text": "Testing subsite with one embedded Quarto file.\n\n\n\n\n1+1\n\n[1] 2"
  },
  {
    "objectID": "others/test_new_subsite.html#sub-content-1",
    "href": "others/test_new_subsite.html#sub-content-1",
    "title": "Test_new_quarto",
    "section": "",
    "text": "Testing subsite with one embedded Quarto file."
  },
  {
    "objectID": "others/test_new_subsite.html#sub-content-2",
    "href": "others/test_new_subsite.html#sub-content-2",
    "title": "Test_new_quarto",
    "section": "",
    "text": "1+1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kaizen-R.com new home",
    "section": "",
    "text": "Rust with R\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nDec 20, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nNLP with RCLS: A ‚Äònew‚Äô challenge\n\n\n\nML\n\nNLP\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 14, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSimple internal state for RL Agent motivation\n\n\n\nRLCS\n\nML\n\nRL\n\n\n\n\n\n\n\n\n\nDec 8, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a better ‚ÄòLab‚Äô\n\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 6, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nNew ‚ÄòResearch‚Äô ideas for RLCS\n\n\n\nML\n\ncode\n\nRLCS\n\nRL\n\n\n\n\n\n\n\n\n\nNov 29, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWeekend of old blog posts migrations‚Ä¶\n\n\n\nInformation\n\n\n\n\n\n\n\n\n\nNov 23, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS is now twice as fast!\n\n\n\nRLCS\n\nOptimization\n\ncode\n\n\n\n\n\n\n\n\n\nNov 15, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nStill trying to get RLCS to be as good as Random Forest‚Ä¶\n\n\n\nRLCS\n\nML\n\nOptimization\n\ncode\n\n\n\n\n\n\n\n\n\nNov 14, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS might possibly be as good as Random Forest?\n\n\n\nRLCS\n\nML\n\n\n\n\n\n\n\n\n\nNov 10, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS is not better than Random Forest (until further notice)\n\n\n\nRLCS\n\nML\n\n\n\n\n\n\n\n\n\nNov 8, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMinor Bugs in RLCS, Visuals for ARCAGI1\n\n\n\nRLCS\n\nARCAGI1\n\nvisualization\n\n\n\n\n\n\n\n\n\nOct 25, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRandom thoughts on ARCAGI\n\n\n\nRLCS\n\nARCAGI1\n\n\n\n\n\n\n\n\n\nOct 19, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nPreparing for November Presentation\n\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nOct 15, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nPreparing for November Presentation\n\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nOct 12, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMiscelanea week of sorts\n\n\n\nRLCS\n\ncode\n\nARCAGI1\n\n\n\n\n\n\n\n\n\nSep 30, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS is now published!\n\n\n\nRLCS\n\ncode\n\n\n\n\n\n\n\n\n\nSep 21, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS goes to the National R Congress!\n\n\n\nRLCS\n\ncode\n\n\n\n\n\n\n\n\n\nSep 16, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOrganizing a bit for future work/exercises\n\n\n\ncode\n\nmath\n\nsystems\n\nOptimization\n\nDecisions\n\nABM\n\nInformation\n\ncomplexity\n\n\n\n\n\n\n\n\n\nAug 24, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nThinking about Systems\n\n\n\ncomplexity\n\nABM\n\nsystems\n\n\n\n\n\n\n\n\n\nAug 15, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS with the mirai package\n\n\n\nRLCS\n\ncode\n\n\n\n\n\n\n\n\n\nAug 10, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Less sequential?\n\n\n\nRLCS\n\ncode\n\n\n\n\n\n\n\n\n\nJul 25, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nNonlinear Dynamics: on Bifurcations\n\n\n\nmath\n\ncode\n\ncomplexity\n\n\n\n\n\n\n\n\n\nJul 20, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nStudying Nonlinear Dynamics: Day 1\n\n\n\nmath\n\ncode\n\ncomplexity\n\n\n\n\n\n\n\n\n\nJul 13, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS package: Progressing nicely\n\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nJul 6, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS as a package?\n\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nJul 5, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS for text? And a new idea‚Ä¶\n\n\n\nNLP\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nJun 21, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMorning Coffee Thoughts\n\n\n\nDecisions\n\n\n\n\n\n\n\n\n\nJun 9, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nClassic Computational Social Model: Schelling‚Äôs Segregation\n\n\n\nDecisions\n\nOptimization\n\nvisualization\n\ncomplexity\n\n\n\n\n\n\n\n\n\nJun 8, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent RL\n\n\n\nRLCS\n\nML\n\nRL\n\n\n\n\n\n\n\n\n\nJun 5, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Caring for better performance\n\n\n\nRLCS\n\ncode\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 25, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Making things faster where it matters\n\n\n\nRLCS\n\ncode\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 18, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: small code rewrites\n\n\n\nML\n\nRLCS\n\ncode\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 2, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Better code?\n\n\n\nML\n\nRLCS\n\ncode\n\nOptimization\n\n\n\n\n\n\n\n\n\nApr 24, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSunday Thoughts: About Strategy, Information, Decisions, Simulations, Reinforcement Learning & al.\n\n\n\nInformation\n\nML\n\nDecisions\n\nOptimization\n\nRL\n\n\n\n\n\n\n\n\n\nApr 13, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Small addition\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nMar 30, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS for Data Mining: Visuals\n\n\n\nML\n\nRLCS\n\nvisualization\n\n\n\n\n\n\n\n\n\nMar 21, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS & Explainable AI\n\n\n\nML\n\nRLCS\n\nvisualization\n\n\n\n\n\n\n\n\n\nMar 19, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS for RL: It works again (using books helps)\n\n\n\nML\n\nRLCS\n\nRL\n\n\n\n\n\n\n\n\n\nMar 16, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating Contents (slowly)\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Improving‚Ä¶ And getting worse (at the same time!)\n\n\n\nML\n\nRLCS\n\nRL\n\n\n\n\n\n\n\n\n\nMar 9, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Reinforcement Learning: World Explorer v1\n\n\n\nML\n\nRLCS\n\nRL\n\n\n\n\n\n\n\n\n\nFeb 16, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: A World to Play RL\n\n\n\nML\n\nRLCS\n\nRL\n\n\n\n\n\n\n\n\n\nFeb 15, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: Reinforcement Learning?\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nFeb 9, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: training in parallel?\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nJan 26, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS: for Data Mining\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nJan 25, 2025\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 4.5 - Fully Functional v0 and New Tests\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 29, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 2 - Full Rule Discovery\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 24, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 1 - Part II: Basic Covering\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 1: Rules formatting, storage, and matching\n\n\n\nML\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nA new project\n\n\n\nML\n\nnews\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 8, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Linear Regression\n\n\n\nML\n\nmath\n\n\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying URLs\n\n\n\nML\n\ncode\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nEntropy - Identifying compressed files\n\n\n\nmath\n\ncode\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 8, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nML Concepts: Word Embeddings\n\n\n\nML\n\nNLP\n\n\n\n\n\n\n\n\n\nNov 2, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nML Concepts: Unsupervised Learning ‚Äì Clustering ‚Äì DBScan\n\n\n\nML\n\nvisualization\n\n\n\n\n\n\n\n\n\nOct 26, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Exercises: Interpolation with Lagrange Polynomials\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nTesting LLMs locally on basic Apple Silicon\n\n\n\nML\n\n\n\n\n\n\n\n\n\nOct 12, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nCholesky‚Äôs matrix decomposition and where not to use it\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nSep 29, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMSC Thesis delivered\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJun 15, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWhile on the Train: Cellular Automata\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nInterlude\n\n\n\ncomplexity\n\n\n\n\n\n\n\n\n\nNov 7, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nAssume the Cow is a Sphere\n\n\n\ncyber\n\nOptimization\n\n\n\n\n\n\n\n\n\nAug 16, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization: Genetic Algorithm(s) (2/2)\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nAug 6, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization: Genetic Algorithm(s) (1/2)\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nJul 29, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization: Simulated Annealing\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nJul 23, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization: Gradient Descent\n\n\n\nOptimization\n\nmath\n\n\n\n\n\n\n\n\n\nJul 16, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSummer fun: Testing Optimization Algorithms (1/n)\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nJul 9, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWhen to parallelize (and when not to)\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nJun 25, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWhat I like about the MSc I‚Äôm studying\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nHow SQL is still proving so useful: Snowflake\n\n\n\nInformation\n\n\n\n\n\n\n\n\n\nJun 4, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nOn Eigenvalues (more)\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Cybernetics: Working on Ashby‚Äôs Transformation Matrices\n\n\n\nmath\n\nsystems\n\n\n\n\n\n\n\n\n\nJan 20, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation: Monte-Carlo & Input Distributions\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nJan 18, 2023\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nGraph Theory: Havel-Hakimi algorithm (and a twist)\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nNov 12, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with Optimization\n\n\n\nmath\n\nOptimization\n\n\n\n\n\n\n\n\n\nNov 6, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nThinking about Cybersecurity Operations\n\n\n\ncyber\n\n\n\n\n\n\n\n\n\nOct 15, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nFrom local Spark to Azure Synapse\n\n\n\nInformation\n\n\n\n\n\n\n\n\n\nAug 27, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nGetting into Apache Spark\n\n\n\nInformation\n\ncode\n\n\n\n\n\n\n\n\n\nAug 20, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nA quick look at CISA KEV\n\n\n\ncyber\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nFaster graphs in R: iGraph vs visNetwork\n\n\n\ncode\n\nvisualization\n\n\n\n\n\n\n\n\n\nJun 25, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with MS SQL\n\n\n\ncode\n\nInformation\n\n\n\n\n\n\n\n\n\nMay 14, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nDiminishing returns of parallelization\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 8, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nIterative function calls with Reduce\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nMar 20, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nHigher Performance in R ‚Äì Amdahl and Gustafson‚Äôs laws\n\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nMar 5, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nReading about Chaos Theory\n\n\n\ncode\n\nmath\n\n\n\n\n\n\n\n\n\nFeb 13, 2022\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nA small realisation\n\n\n\nInformation\n\n\n\n\n\n\n\n\n\nDec 11, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMore R for math\n\n\n\nmath\n\ncode\n\n\n\n\n\n\n\n\n\nDec 4, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating to M1, Docker & RStudio included\n\n\n\nmath\n\ncode\n\n\n\n\n\n\n\n\n\nNov 27, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nLearning about computing errors\n\n\n\nmath\n\ncode\n\n\n\n\n\n\n\n\n\nOct 31, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating to M1, Docker & RStudio included\n\n\n\nmath\n\ncode\n\n\n\n\n\n\n\n\n\nOct 23, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nCleaning Data: testing DataExplorer\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nOct 16, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr is not faster\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nSep 19, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating a SOC (part II): GUI\n\n\n\nvisualization\n\ncyber\n\n\n\n\n\n\n\n\n\nSep 12, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating a SOC (part I)\n\n\n\nvisualization\n\ncyber\n\n\n\n\n\n\n\n\n\nSep 5, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nEvery day I keep learning\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nAug 22, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nParts of Speech Tagging\n\n\n\nNLP\n\ncode\n\n\n\n\n\n\n\n\n\nAug 22, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nParts of Speech Tagging\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nAug 1, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nSharing Results: Shiny Server (beginnings)\n\n\n\ncode\n\nvisualization\n\n\n\n\n\n\n\n\n\nJul 24, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nTokens of Text\n\n\n\nNLP\n\ncode\n\n\n\n\n\n\n\n\n\nJul 18, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nScraping all the (old) Blog articles (the hard way)\n\n\n\nNLP\n\ncode\n\n\n\n\n\n\n\n\n\nJul 11, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nDiving into NLP\n\n\n\nNLP\n\ncode\n\n\n\n\n\n\n\n\n\nJun 27, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Containers\n\n\n\ncyber\n\n\n\n\n\n\n\n\n\nJun 20, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nGathering Security Data: Tests with Ansible\n\n\n\ncyber\n\n\n\n\n\n\n\n\n\nMay 8, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nA revelation: R Futures\n\n\n\ncode\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 1, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nMore external data sources tests: OWASP Amass\n\n\n\ncode\n\ncyber\n\n\n\n\n\n\n\n\n\nApr 25, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nGoing AutoML ‚Äì Clustering Example\n\n\n\nML\n\ncode\n\n\n\n\n\n\n\n\n\nApr 17, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nShodan API Tests\n\n\n\ncode\n\ncyber\n\n\n\n\n\n\n\n\n\nApr 4, 2021\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Entry: Variables\n\n\n\ncode\n\n\n\n\n\n\n\n\n\nJun 20, 2020\n\n\nNico\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html",
    "title": "Simple internal state for RL Agent motivation",
    "section": "",
    "text": "I have had an RL agent (or several) moving around in a simulated World for quite some time now.\nFor RL, you have to choose somehow when to explore, and when to exploit. Up until now, I simply would train with more exploration first, and every 2000 steps or so, I would reduce the pressure to explore (i.e.¬†augment the exploitation). I would start exploring every 2 moves, then every 3, then every 4‚Ä¶ And so on until 1/10 moves.\nToday I worked on an alternative.\nIn reading about RL in context of intelligence evolution, the ‚Äúmore intelligent‚Äù beings would somehow learn when to explore, and when to exploit, to their advantage.\nIn a static World, once you learn the basics, you would have no reason to learn further, you would exploit. Maybe, though, you‚Äôre missing on better alternatives which is why one would still explore sometimes.\nI choose today to supplement my agents with a sense of hunger.\n\n\n\nAgents with an internal ‚Äústatus‚Äù"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#up-until-now",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#up-until-now",
    "title": "Simple internal state for RL Agent motivation",
    "section": "",
    "text": "I have had an RL agent (or several) moving around in a simulated World for quite some time now.\nFor RL, you have to choose somehow when to explore, and when to exploit. Up until now, I simply would train with more exploration first, and every 2000 steps or so, I would reduce the pressure to explore (i.e.¬†augment the exploitation). I would start exploring every 2 moves, then every 3, then every 4‚Ä¶ And so on until 1/10 moves.\nToday I worked on an alternative.\nIn reading about RL in context of intelligence evolution, the ‚Äúmore intelligent‚Äù beings would somehow learn when to explore, and when to exploit, to their advantage.\nIn a static World, once you learn the basics, you would have no reason to learn further, you would exploit. Maybe, though, you‚Äôre missing on better alternatives which is why one would still explore sometimes.\nI choose today to supplement my agents with a sense of hunger.\n\n\n\nAgents with an internal ‚Äústatus‚Äù"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#steps-towards-hunger-motivation",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#steps-towards-hunger-motivation",
    "title": "Simple internal state for RL Agent motivation",
    "section": "Steps towards ‚Äúhunger motivation‚Äù",
    "text": "Steps towards ‚Äúhunger motivation‚Äù\nFirst, I ‚Äúwarm up‚Äù the agent for 2000 steps. That‚Äôs just so they have a minimum ‚Äúintelligence‚Äù.\nNext up:\n\nWhen hungry (‚Äúinternal status‚Äù is below a threshold), the agent explores say one-in-10 moves.\nThen, if the agent is well fed but inexperienced, I force it to explore more than if hungry. One-in-3 moves. This might return it to the state of hungry and the agent will oscillate accordingly around that.\nIf however the agent somehow learns enough to accumulate enough food to pass another high threshold, where the agent is well fed and experienced, I suddenly reduce the exploring pressure, to 1-in-30. That‚Äôs the status of seniority, if you will."
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#whats-cool-about-this",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#whats-cool-about-this",
    "title": "Simple internal state for RL Agent motivation",
    "section": "What‚Äôs cool about this?",
    "text": "What‚Äôs cool about this?\nWell, first, the mechanism described above (which I call mechanism 2) for some reason appears to help in fact the agent become much better than with the original (mechanism 1). Check out the proportion of food, empty cells and enemies, below, with mechanism 1, and then 2, both trained with the same rules of the game:\n\n\n\nmechanism 1: good\n\n\nHere goes the new results with the new approach:\n\n\n\nmechanism 2: better!"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#whats-even-cooler",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#whats-even-cooler",
    "title": "Simple internal state for RL Agent motivation",
    "section": "What‚Äôs even cooler?",
    "text": "What‚Äôs even cooler?\nThis might never happen, BUT what if I coded a world where the rules suddenly changed?\nNow this is potentially very nice: The original mechanism 1 would not react, no change in behaviour.\nBut mechanism 2, when the exploit strategy starts to fail, would jump back to exploration! And depending on how much it has created a habit, it would resist more or less the switching back to learning‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#also",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#also",
    "title": "Simple internal state for RL Agent motivation",
    "section": "Also",
    "text": "Also\nSome more of the code for Reinforcement Learning is included in the published package for RLCS. However as it is still imperfect, and rather complex, I keep it ‚Äúhidden‚Äù by default."
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#bonus-video",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#bonus-video",
    "title": "Simple internal state for RL Agent motivation",
    "section": "Bonus: Video",
    "text": "Bonus: Video"
  },
  {
    "objectID": "posts/2025-12-08_RL_withInternalMotivation/index.html#conclusions",
    "href": "posts/2025-12-08_RL_withInternalMotivation/index.html#conclusions",
    "title": "Simple internal state for RL Agent motivation",
    "section": "Conclusions",
    "text": "Conclusions\nWell, just an interesting exercise really. RL, in this case with simple reward-shaping, per-se has no ‚Äúmotivation to explore further‚Äù.\nI just implemented this as an idea inspired from animals, that can (here the comparison):\n\nchoose to explore more and take more risks if not hungry\nchoose to exploit more if confident they have enough experience\nrevert to exploring in case the world around them changes\n\nAt least, this is what the parameters I used pretend to express. And the fact is, it appears to be an improvement on the basic RL setup I had."
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "",
    "text": "A ‚Äúnew‚Äù rabbit-hole? I want to look into creating as-simple-as-possible rules to classify texts, based on keywords, for a specific classification problem.\nNote that it resembles, yet differs a bit from a past similar exercise‚Ä¶ Both in the input data, and in the motivation, as back then the ‚Äúcreate rules‚Äù condition wasn‚Äôt as valuable as this time around‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#nlp-is-hard",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#nlp-is-hard",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "",
    "text": "A ‚Äúnew‚Äù rabbit-hole? I want to look into creating as-simple-as-possible rules to classify texts, based on keywords, for a specific classification problem.\nNote that it resembles, yet differs a bit from a past similar exercise‚Ä¶ Both in the input data, and in the motivation, as back then the ‚Äúcreate rules‚Äù condition wasn‚Äôt as valuable as this time around‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#intro",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#intro",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "Intro",
    "text": "Intro\nHaving a way to automatically create rules instead of obscure deep learning neural-networks-based models has a potential application to a specific scenario I came across recently‚Ä¶ And it‚Äôs an interesting (to me) problem to look into."
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#issues",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#issues",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "Issues",
    "text": "Issues\nBut #NLP and classification can be a difficult challenge, for one because of the noise to signal ratio (i.e.¬†in this case, most words will be completely irrelevant). Training set data quality is often another key issue.\nI have played with toy problems thus far with #RLCS, but the dimensionality of free-text format worries me as it is waaay too‚Ä¶ well, high-dimensional. PCA and the likes would hinder the creation of readable rules. So I‚Äôm now thinking about how to best do binary encoding (which in itself is a harsh condition, imposed by my implementation of the RLCS package) of the data in an NLP scenario‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#thinking-about-right-encoding",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#thinking-about-right-encoding",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "Thinking about right encoding",
    "text": "Thinking about right encoding\nFirst: Entropy. Chi-square. Names-Entity-Recognition(#NER) might help?\nIf the former don‚Äôt cut it‚Ä¶ Some unnecessarily involved ideas: But also #graphs (maybe even #KG) is maybe another approach (in this case, if words are vertices, high centrality of certain keywords might indicate they are less useful?). Clustering might help too. #IRL (inverse-reinforcement-learning) also comes to mind, although I‚Äôm a newbie there, plus that‚Äôs definitely overkill üòÖ"
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#conclusions",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#conclusions",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "Conclusions",
    "text": "Conclusions\nMaybe it‚Äôs all a stupid/bad idea. I need to keep working on it for a while and see. It looks somewhat promising thus far though.\nIf I managed to come up with even a few simple rules to help classify correctly a few thousand unclassified samples, that would be huge a win already, so it‚Äôs worth a try. And if i manage that without any of the more complex stuff above, well, all the better. I‚Äôll obviously try to work manually through the data first, get a sense of it. Although if it were easy‚Ä¶ it would be done already, I guess.\nPlus, and for me the fun part: it would be a practical application of my hobby for a real need at work. But it might well end up being more of a (possibly failed) weekends research exercise, rather than an actual project‚Ä¶ Only time will say if I manage to put something together."
  },
  {
    "objectID": "posts/2025-12-14_NLP_RabbitHole/index.html#getting-started-encoding",
    "href": "posts/2025-12-14_NLP_RabbitHole/index.html#getting-started-encoding",
    "title": "NLP with RCLS: A ‚Äònew‚Äô challenge",
    "section": "Getting started: Encoding",
    "text": "Getting started: Encoding\nSo I‚Äôve ‚Äúexchanged ideas‚Äù with‚Ä¶ Perplexity. (Yes, it‚Äôs true, I know how to talk to a chatbot! Who would have said someone like me could‚Ä¶ Ask questions‚Ä¶ ANYHOW)\nBecause my first thought went for Entropy, Gini Index‚Ä¶ What a partitioning tree would do. I have plenty of practice with {tm} in R to do text cleaning, but I still always end up with too many variables, and although many times that wasn‚Äôt the key issue (I could use PCA, MDS‚Ä¶), as mentioned earlier, PCA would ‚Äúobscure‚Äù the choices, the resulting rules would be harder (not impossible, as PCA can be reversed‚Ä¶) to read. No, I needed something to help me prioritize keywords while keeping keywords.\nAnd indeed, I needed a dataset (the one I plan to apply all this on is private, so can‚Äôt use that). From a few years back, I remembered there was a dataset about Barack Obama vs Donal Trump tweets somewhere. I found it again: https://github.com/fivethirtyeight/data/tree/master/twitter-ratio.\nLong story short, I ended up with this:\n## Mix it up a bit\ndf &lt;- df[sample(1:nrow(df), nrow(df), replace = F),]\n\n## Clean up a bit\ndf$text &lt;- sapply(df$text, \\(x) {\n  x &lt;- iconv(x, to=\"UTF-8\")\n  x &lt;- tolower(x)\n  x &lt;- gsub(\"https?\\\\:\\\\/\\\\/[a-z0-9.-/]+\", \"\", x)\n  x &lt;- tm::removePunctuation(x)\n  x &lt;- tm::removeWords(x, stopwords(\"english\"))\n  x &lt;- tm::stripWhitespace(x)\n  x\n})\ndf &lt;- df[!is.na(df$text),]\n\n## Let's have a quick look\nhead(df)\ntable(df$class)\n\n## Document Term Matrix for upcoming ChiSquare\ndtm &lt;- tm::DocumentTermMatrix(df$text)\n## Control size a bit:\ndtm &lt;- dtm[,1:min(ncol(dtm), 10000)]\nm &lt;- as.matrix(dtm)\ndim(m)\ny &lt;- factor(df$class)\n\n## This I did have to lookup first, Perplexity more or less gave it to me, once I gave it my specific preferences...\nchisq_scores &lt;- apply(m, 2, function(term_counts) {\n  tab &lt;- table(term_counts &gt; 0, y)\n  if(all(dim(tab) &gt; 1)) {\n    stats::chisq.test(tab, simulate.p.value = F)$statistic\n  } else\n    NA\n})\n\nchisq_scores &lt;- sort(chisq_scores, decreasing = T, na.last = NA)\n## End of LLM help\n\ntop_terms &lt;- names(chisq_scores)[1:1000]\ndtm_redux &lt;- m[, top_terms]\nNow. I haven‚Äôt even started working on the RLCS part of the exercise, but can we maybe agree this could potentially work to separate the two classes, using some sort of binary encoding, maybe on a few key columns to reduce dimensionality (for RLCS)? See pictures next.\n(And as I‚Äôve done in the past for images classification, I could probably train in parallel different populations on smaller subset of data, to then merge them back into one‚Ä¶ IDK.)\nHere what the results would look like. I won‚Äôt tell you which 5 samples are from President Trump, and which from President Obama.\n\n\n\none president, most relevant keywords per tweet for classification\n\n\n\n\n\nanother president, most relevant keywords per tweet for classification\n\n\nOK so clearly this is not ‚Äúenough‚Äù, and yet‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html",
    "href": "posts/2025-12-20_R_Rust_I/index.html",
    "title": "Rust with R",
    "section": "",
    "text": "This is a bit of an aside. R is‚Ä¶ ‚Äúeasy‚Äù. But it has its disadvantages too. I keep coming across mentions of Rust. I actually bought ‚Äúthe Rust Programming Language, 2nd Ed.‚Äù (even though it‚Äôs available online, I like being able to read from the Kindle, offline). But I never spent time with it.\nLearning a new language supposes an effort, so‚Ä¶ why do it?"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#nlp-is-hard",
    "href": "posts/2025-12-20_R_Rust_I/index.html#nlp-is-hard",
    "title": "Rust with R",
    "section": "",
    "text": "A ‚Äúnew‚Äù rabbit-hole? I want to look into creating as-simple-as-possible rules to classify texts, based on keywords, for a specific classification problem.\nNote that it resembles, yet differs a bit from a past similar exercise‚Ä¶ Both in the input data, and in the motivation, as back then the ‚Äúcreate rules‚Äù condition wasn‚Äôt as valuable as this time around‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#intro",
    "href": "posts/2025-12-20_R_Rust_I/index.html#intro",
    "title": "Rust with R",
    "section": "Intro",
    "text": "Intro\nHaving a way to automatically create rules instead of obscure deep learning neural-networks-based models has a potential application to a specific scenario I came across recently‚Ä¶ And it‚Äôs an interesting (to me) problem to look into."
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#issues",
    "href": "posts/2025-12-20_R_Rust_I/index.html#issues",
    "title": "Rust with R",
    "section": "Issues",
    "text": "Issues\nBut #NLP and classification can be a difficult challenge, for one because of the noise to signal ratio (i.e.¬†in this case, most words will be completely irrelevant). Training set data quality is often another key issue.\nI have played with toy problems thus far with #RLCS, but the dimensionality of free-text format worries me as it is waaay too‚Ä¶ well, high-dimensional. PCA and the likes would hinder the creation of readable rules. So I‚Äôm now thinking about how to best do binary encoding (which in itself is a harsh condition, imposed by my implementation of the RLCS package) of the data in an NLP scenario‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#thinking-about-right-encoding",
    "href": "posts/2025-12-20_R_Rust_I/index.html#thinking-about-right-encoding",
    "title": "Rust with R",
    "section": "Thinking about right encoding",
    "text": "Thinking about right encoding\nFirst: Entropy. Chi-square. Names-Entity-Recognition(#NER) might help?\nIf the former don‚Äôt cut it‚Ä¶ Some unnecessarily involved ideas: But also #graphs (maybe even #KG) is maybe another approach (in this case, if words are vertices, high centrality of certain keywords might indicate they are less useful?). Clustering might help too. #IRL (inverse-reinforcement-learning) also comes to mind, although I‚Äôm a newbie there, plus that‚Äôs definitely overkill üòÖ"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#getting-started-encoding",
    "href": "posts/2025-12-20_R_Rust_I/index.html#getting-started-encoding",
    "title": "Rust with R",
    "section": "Getting started: Encoding",
    "text": "Getting started: Encoding\nSo I‚Äôve ‚Äúexchanged ideas‚Äù with‚Ä¶ Perplexity. (Yes, it‚Äôs true, I know how to talk to a chatbot! Who would have said someone like me could‚Ä¶ Ask questions‚Ä¶ ANYHOW)\nBecause my first thought went for Entropy, Gini Index‚Ä¶ What a partitioning tree would do. I have plenty of practice with {tm} in R to do text cleaning, but I still always end up with too many variables, and although many times that wasn‚Äôt the key issue (I could use PCA, MDS‚Ä¶), as mentioned earlier, PCA would ‚Äúobscure‚Äù the choices, the resulting rules would be harder (not impossible, as PCA can be reversed‚Ä¶) to read. No, I needed something to help me prioritize keywords while keeping keywords.\nAnd indeed, I needed a dataset (the one I plan to apply all this on is private, so can‚Äôt use that). From a few years back, I remembered there was a dataset about Barack Obama vs Donal Trump tweets somewhere. I found it again: https://github.com/fivethirtyeight/data/tree/master/twitter-ratio.\nLong story short, I ended up with this:\n## Mix it up a bit\ndf &lt;- df[sample(1:nrow(df), nrow(df), replace = F),]\n\n## Clean up a bit\ndf$text &lt;- sapply(df$text, \\(x) {\n  x &lt;- iconv(x, to=\"UTF-8\")\n  x &lt;- tolower(x)\n  x &lt;- gsub(\"https?\\\\:\\\\/\\\\/[a-z0-9.-/]+\", \"\", x)\n  x &lt;- tm::removePunctuation(x)\n  x &lt;- tm::removeWords(x, stopwords(\"english\"))\n  x &lt;- tm::stripWhitespace(x)\n  x\n})\ndf &lt;- df[!is.na(df$text),]\n\n## Let's have a quick look\nhead(df)\ntable(df$class)\n\n## Document Term Matrix for upcoming ChiSquare\ndtm &lt;- tm::DocumentTermMatrix(df$text)\n## Control size a bit:\ndtm &lt;- dtm[,1:min(ncol(dtm), 10000)]\nm &lt;- as.matrix(dtm)\ndim(m)\ny &lt;- factor(df$class)\n\n## This I did have to lookup first, Perplexity more or less gave it to me, once I gave it my specific preferences...\nchisq_scores &lt;- apply(m, 2, function(term_counts) {\n  tab &lt;- table(term_counts &gt; 0, y)\n  if(all(dim(tab) &gt; 1)) {\n    stats::chisq.test(tab, simulate.p.value = F)$statistic\n  } else\n    NA\n})\n\nchisq_scores &lt;- sort(chisq_scores, decreasing = T, na.last = NA)\n## End of LLM help\n\ntop_terms &lt;- names(chisq_scores)[1:1000]\ndtm_redux &lt;- m[, top_terms]\nNow. I haven‚Äôt even started working on the RLCS part of the exercise, but can we maybe agree this could potentially work to separate the two classes, using some sort of binary encoding, maybe on a few key columns to reduce dimensionality (for RLCS)? See pictures next.\n(And as I‚Äôve done in the past for images classification, I could probably train in parallel different populations on smaller subset of data, to then merge them back into one‚Ä¶ IDK.)\nHere what the results would look like. I won‚Äôt tell you which 5 samples are from President Trump, and which from President Obama.\n\n\n\none president, most relevant keywords per tweet for classification\n\n\n\n\n\nanother president, most relevant keywords per tweet for classification\n\n\nOK so clearly this is not ‚Äúenough‚Äù, and yet‚Ä¶"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#conclusions",
    "href": "posts/2025-12-20_R_Rust_I/index.html#conclusions",
    "title": "Rust with R",
    "section": "Conclusions",
    "text": "Conclusions\nWell, this was ‚Äúeasy‚Äù as in: I just followed a step-by-step, so definitely not hard. But it opens new possibilities.\nI think I‚Äôm going to like Rust, if I manage to set aside some time to learn it. It‚Äôs apparently stricter (good), safer (very good), faster (well, I guess comparable to Rcpp in my usual setups‚Ä¶ Still: good).\nThe fact you need to put a package setup in the middle, the warnings from CRAN about packaging Rust/cargo stuff‚Ä¶ Not so good.\nBut still. I‚Äôm curious about whether I justify to myself spending more time on this topic in the future.\nWe‚Äôll see :)"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#just-because-or-not.",
    "href": "posts/2025-12-20_R_Rust_I/index.html#just-because-or-not.",
    "title": "Rust with R",
    "section": "",
    "text": "This is a bit of an aside. R is‚Ä¶ ‚Äúeasy‚Äù. But it has its disadvantages too. I keep coming across mentions of Rust. I actually bought ‚Äúthe Rust Programming Language, 2nd Ed.‚Äù (even though it‚Äôs available online, I like being able to read from the Kindle, offline). But I never spent time with it.\nLearning a new language supposes an effort, so‚Ä¶ why do it?"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#the-why",
    "href": "posts/2025-12-20_R_Rust_I/index.html#the-why",
    "title": "Rust with R",
    "section": "The Why",
    "text": "The Why\nAs I was saying, R is ‚Äúeasy‚Äù. And if you know how to use vectorized operations, are organized, use functions, run tests, etc. it also becomes rather powerful. For sure, for data, I really like it.\nBut certain things are maybe a bit too simplified.\nSo R is interpreted, which is a guarantee of not being the fastest, most efficient thing out there. And then it abstracts and lets you do stuff that‚Ä¶ maybe, in some cases, it shouldn‚Äôt.\nI don‚Äôt think anyone is going to be using R to code games or OS components, so there is that. But, being a computer scientist by training (a long time ago), I sometimes miss the more involved stuff.\nPython does little for me. It is better than R for many things, particularly outside of data work. Even then I don‚Äôt consider it better because most of what others can do with Python, I can do with R. The exception, is when libraries by some vendors for their APIs are provided for Python, and not for R. Reasonable choice. Then, you know‚Ä¶ {reticulate}.\nOK so why Rust? After all, if it were for speed, there is also Rcpp (indeed! And I‚Äôve used that a lot already).\nWell, I was reading up on Rust and I like a few things. Like how the compiler won‚Äôt let you assign a char to a variable declared as i32. Or immutability by default of variables. I‚Äôm getting to the part of the documentation on Memory management.\n\nOn the memory management thing\nI wouldn‚Äôt‚Ä¶ care. Or even think about it. But then, in trying to optimize RLCS, I‚Äôve seen the GC thing take a bit (not a lot!) of time‚Ä¶ Garbage Collection.\nWell looks like Rust promises to save me from that, too.\n\n\nAll in all\nIf Rust is more difficult but more‚Ä¶ serious, more restrictive, faster‚Ä¶\nIf it has certain advantages over C++ (as in, it is ‚Äúsafer‚Äù).\nIf Linus Torvalds likes it for the Linux Kernel‚Ä¶\nWell, who am I to discard it as an option?\nSo here we are. I really don‚Äôt know if I will end up using any of it in the future, but I like to have the option."
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#ok-setting-things-up",
    "href": "posts/2025-12-20_R_Rust_I/index.html#ok-setting-things-up",
    "title": "Rust with R",
    "section": "OK, setting things up",
    "text": "OK, setting things up\nSo far, I‚Äôve only found this option to get Rust to play nice with R. A {reticulate} of sorts, but instead of Python, you get to use Rust functions.\nDrawback: It‚Äôs only for packages? Looks like so. Well, thankfully I recently decided any new R project would be a package anyway, so there is that. (‚ÄúDumb luck‚Äù, really.)\nFirst, the reference that got me started: https://extendr.rs/rextendr/articles/package.html\nActually, today I‚Äôll basically just try to reproduce the steps in there.\nFirst install the {rextendr} package (in my case, I‚Äôll get up and running using RStudio, but the steps are there for command-line based approaches).\n\nThen, you can use the Option for creating a new R Project of type package:\n\n\n\nGetting started"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#quick-check",
    "href": "posts/2025-12-20_R_Rust_I/index.html#quick-check",
    "title": "Rust with R",
    "section": "Quick check",
    "text": "Quick check\nOnce you‚Äôre there, you‚Äôre actually two steps away from running your first Rust function call from R. I called my new package ‚ÄútestingRustPackaging‚Äù, and the sitrep is optional (but I‚Äôd recommend to run it first regardless, just in case an error shows up there):\nrextendr::rust_sitrep()\nrextendr::document()\n\nlibrary(testingRustPackaging)\nhello_world()\n\nThe rextendr::document() function actually seems to do all the packaging (which differs a bit from the Cmd-Shift-B I got used to). I‚Äôll need to dig a bit deeper there, I don‚Äôt know right now what one and the other do, respectively.\n\nRegardless, by simply following the steps (on my MacBook Air M1, in case that‚Äôs relevant), I got the thing to work:\n\nThe key part here is, the hello_world() function, it‚Äôs actually a Rust function. Mission accomplished, basically! Then you can add another function (as per the referenced guide):\n\n\n\nCalling another Rust function"
  },
  {
    "objectID": "posts/2025-12-20_R_Rust_I/index.html#so-were-done.-what-next",
    "href": "posts/2025-12-20_R_Rust_I/index.html#so-were-done.-what-next",
    "title": "Rust with R",
    "section": "So we‚Äôre done. What next?",
    "text": "So we‚Äôre done. What next?\nWell, next, we can keep adding functions in Rust. Some will need to be ‚Äúexported‚Äù so as to get R to be able to call them, others won‚Äôt need to be (same as ‚Äúnormal‚Äù R package functions).\nSimilar to {roxygen2}, document() of {rextendr} will take care of generating the DOCUMENTATION file, as well as the NAMESPACE for us.\nThere, again, I worry, what will I need to consider in the future if I throw in a mix of simpler R functions and Rust functions‚Ä¶ Will {roxygen2} compete with {rextendr}? I don‚Äôt know. I‚Äôll have to learn some more, but that‚Äôs for later. I guess rextendr will be a wrapper over roxygen? IDK.\nAnyhow, here is apparently where you would edit your Rust functions:\n&lt;package base&gt;/src/rust/src/lib.rs\nAnd here an example of an non-exported function being called from within an exported one:\n\n\n\nexample basic lib.rs\n\n\n\n\n\ncalling from R"
  }
]