[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2024-11-08_welcome/index.html",
    "href": "posts/2024-11-08_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in this future Blog. Currently testing all kinds of things, will updated hopefully shortly!\nSeems like it will nicely manage some defaults.\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2024-11-08_welcome/index.html#references-for-future-use",
    "href": "posts/2024-11-08_welcome/index.html#references-for-future-use",
    "title": "Welcome To My Blog",
    "section": "References for future use",
    "text": "References for future use\nFor now, I need to keep references of what allowed me to get here:\n\nManage GitHub access\nhttps://usethis.r-lib.org/articles/git-credentials.html\n\n\nSet things up\nhttps://sites.northwestern.edu/researchcomputing/2022/05/11/git-with-rstudio-order-matters/\nhttps://sites.northwestern.edu/researchcomputing/resources/using-git-and-github-with-r-rstudio/\nhttps://ucsb-meds.github.io/creating-quarto-websites/"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "So I wasn‚Äôt kidding. I really like this ‚ÄúLearning Classifier System‚Äù (aka LCS) idea, and I really want to develop the R package for it, which I will call ‚ÄúRLCS‚Äù (clever, hu?).\nNow I have to start somewhere, and so I will keep it simple for now. I will first focus on an LCS that does supervised learning only (that means, no reinforcement learning for now.)\nAlso, I will focus on the simplest binary environments. In LCS lingo, for supervised classification, environment is equivalent to saying dataset. Each entry to classify is presented as binary strings, and the class (aka action) is, for simplicity, also a simple 0 or 1.\nSo binary classification of binary strings.\nThis might sound simplistic (and it is somewhat, yes) but the feature engineering and codificatioin into GA-compatible individuals is often harder than the actual training of a ML algorithm.\nAnyhow. I will forego some details for now, but suffice to say I‚Äôm working right now towards a Michigan-style LCS.\n\n\n\nNow we will receive an environment/dataset as input that has ‚Äústates‚Äù in binary format, and actions/classes as either 0 or 1.\n## Suppose test data is:\ntest_environment &lt;- data.frame(state = c('00011', '10010', '01110', '00001'),\n                               class = c(0, 0, 0, 1))\n(It‚Äôs not enough info to conclude that, but these examples all agree with a classifier that would say, in human readable format: ‚ÄúThe Class is the negated bit 4 of the input‚Äù.)\nOne of the key aspects of an LCS, is that it will produce rules. A rule is a pair of a condition and an action.\nA condition in turn is written (in our current approach) as a string of a ternary alphabet, namely characters from the set {0, 1, #}, where # means wildcard and matches either 0 or 1.\nNow for each input of the environment (each entry of the dataset), for today‚Äôs purposes, we will want to know which rules it matches (regardless of the action). In other words, we want to match an input to condition(s). That will tell us the ‚ÄúMatch set‚Äù.\nMatching is one key aspect of the LCS overall algorithm, one that will be run a lot, and therefore I worry that it could be slow.\nA couple more keywords: A classifier is a rule and its statistics. (We will skip the statistics part for today.) And a population is our set of classifiers.\nShort of going the way of C++, I have coded one first simplistic function that takes a classifier set as a dataframe, and another one that uses a list of lists instead.\nConditions can easily be written as strings:\nconditions &lt;- c('#001#', '10#10', '##110', '###0#')\nactions &lt;- c(0, 0, 0, 1)\nFor the first approach, it was quite straightforward:\nlcs_classifier1 &lt;- data.frame(id = 1:4,\n                      condition_string = conditions,\n                      action = actions, #simplest is binary for supervised\n                      accuracy = 1,\n                      numerosity = 1,\n                      first_seen = c(1, 2, 3, 4) ## I'm inventing a coverage trigger\n                      )\n\n## Find Matching Rules\nget_match_set_v001 &lt;- function(ti_condition, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- unlist(strsplit(ti_condition, \"\"))\n    pop &lt;- pop[, c(\"id\", \"condition_string\")] # Same\n\n    which(sapply(1:nrow(pop), function(i) {\n\n        t_cond &lt;- unlist(strsplit(pop$condition_string[i], \"\"))\n        relevant_positions &lt;- which(t_cond %in% c(\"0\", \"1\"))\n        \n        all(t_cond[relevant_positions] == ti_cond[relevant_positions])\n    }))\n}\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v001(test_environment$state[1], lcs_classifier1), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v001(test_environment$state[2], lcs_classifier1),\n        c(1, 2)\n    )\n})\n\n(OUTPUT:) Test passed ü•≥\nFor the second approach, I needed some more supporting functions:\n######\n## Option 2: Use list instead of Data.frame and pre-calculate match sets\n\n## Function to create a new rule from a condition string and an action\n## THIS IS VALID FOR CLASSIFICATION, NOT FOR Reinforcement Learning!!!\n## In our case, a new rule has: A condition string, an (correct!) action\n## Since action is correct, this is useful for future \"covering\"\n## AND we set accuracy to 1\nnew_supervised_rule &lt;- function(condition_string, action) {\n    list(id = 1,\n         condition_string = condition_string,\n         condition_length = nchar(condition_string),\n         condition_list = list(\"0\" = which(unlist(strsplit(condition_string, \"\")) == \"0\"),\n                               \"1\" = which(unlist(strsplit(condition_string, \"\")) == \"1\")),\n         action = action,\n         accuracy = 1,\n         numerosity = 1,\n         first_seen = 1)\n}\n\n## Function to return max id from a classifier set in list format\nmax_id_in_classifier &lt;- function(pop) {\n    max(sapply(pop, function(x) x$id))\n}\n\n## Function to add rule to a population.\n## date_rule_born will be useful stat for future, setting as parameter for now.\nadd_valid_rule_to_pop &lt;- function(pop, condition_string, action, date_rule_born = 1) {\n    \n    t_rule &lt;- new_supervised_rule(condition_string, action)\n    t_rule$id &lt;- max_id_in_classifier(pop)+1\n    t_rule$first_seen &lt;- date_rule_born\n    \n    pop[[length(pop)+1]] &lt;- t_rule\n    \n    pop\n}\n\n## Support function for human-compatible printing:\nmake_pop_printable &lt;- function(classifier) {\n    data.frame\n    rbind.fill(lapply(1:length(classifier), function(i) {\n        t_c &lt;- classifier[[i]]\n        data.frame(id = t_c$id,\n                   condition = t_c$condition_string,\n                   action = t_c$action,\n                   accuracy = t_c$accuracy,\n                   numerosity = t_c$numerosity,\n                   first_seen = t_c$first_seen)\n    }))\n}\n\n## Matching with list formatted population.\nget_match_set_v002 &lt;- function(input_state, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- as.integer(unlist(strsplit(input_state, \"\")))\n    \n    which(sapply(1:length(pop), function(i) {\n        rule &lt;- pop[[i]]$condition_list\n        all(ti_cond[rule$'0'] == 0, ti_cond[rule$'1'] == 1)\n    }))\n}\n\nlcs_classifier2 &lt;- list(new_supervised_rule(conditions[1], actions[1]))\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[2], actions[2])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[3], actions[3])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[4], actions[4])\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v002(test_environment$state[1], lcs_classifier2), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v002(test_environment$state[2], lcs_classifier2),\n        c(1, 2)\n    )\n})\n\n\n\nAn example population\n\n\n\n\n\nmicrobenchmark(\n    sapply(test_environment$state, function(x) { get_match_set_v001(x, lcs_classifier1)}),\n    sapply(test_environment$state, function(x) { get_match_set_v002(x, lcs_classifier2)}),\n    times = 10000L\n)\n\n\n\nlists and pre-calculated match positions is faster\n\n\nLists are more flexible and data.frames are not the fastest option out there anyway. Here the pre-calculations in the second format also helps doing faster matching.\nHowever I know this choice might have an impact, particularly when time will come to implement deletion, subsumption and compaction (all useful for better LCS performance/value). And another idea I have in mind will require further lists management (but it‚Äôs too early to discuss that).\nBut that‚Äôs a problem for future me (and nothing that hasn‚Äôt been solved already).\n\n\n\nWell well: Day 1, and we have covered concepts of environment, states, actions, conditions, rules, classifiers, population and matching/match set.\nAlong with developping a functional (basic) list for storing classifiers, and a matching function.\nNot too bad (albeit all too simplistic and not going for ‚Äúfull-power‚Äù flexible LCS implementation).\n\n\n\nI‚Äôll keep referring to this video (although the book is better to get acquainted with the vocabulary and concepts): intro explaining the algorithm ."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#intro",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#intro",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "So I wasn‚Äôt kidding. I really like this ‚ÄúLearning Classifier System‚Äù (aka LCS) idea, and I really want to develop the R package for it, which I will call ‚ÄúRLCS‚Äù (clever, hu?).\nNow I have to start somewhere, and so I will keep it simple for now. I will first focus on an LCS that does supervised learning only (that means, no reinforcement learning for now.)\nAlso, I will focus on the simplest binary environments. In LCS lingo, for supervised classification, environment is equivalent to saying dataset. Each entry to classify is presented as binary strings, and the class (aka action) is, for simplicity, also a simple 0 or 1.\nSo binary classification of binary strings.\nThis might sound simplistic (and it is somewhat, yes) but the feature engineering and codificatioin into GA-compatible individuals is often harder than the actual training of a ML algorithm.\nAnyhow. I will forego some details for now, but suffice to say I‚Äôm working right now towards a Michigan-style LCS."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#the-ternary-alphabet-for-conditions",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#the-ternary-alphabet-for-conditions",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "Now we will receive an environment/dataset as input that has ‚Äústates‚Äù in binary format, and actions/classes as either 0 or 1.\n## Suppose test data is:\ntest_environment &lt;- data.frame(state = c('00011', '10010', '01110', '00001'),\n                               class = c(0, 0, 0, 1))\n(It‚Äôs not enough info to conclude that, but these examples all agree with a classifier that would say, in human readable format: ‚ÄúThe Class is the negated bit 4 of the input‚Äù.)\nOne of the key aspects of an LCS, is that it will produce rules. A rule is a pair of a condition and an action.\nA condition in turn is written (in our current approach) as a string of a ternary alphabet, namely characters from the set {0, 1, #}, where # means wildcard and matches either 0 or 1.\nNow for each input of the environment (each entry of the dataset), for today‚Äôs purposes, we will want to know which rules it matches (regardless of the action). In other words, we want to match an input to condition(s). That will tell us the ‚ÄúMatch set‚Äù.\nMatching is one key aspect of the LCS overall algorithm, one that will be run a lot, and therefore I worry that it could be slow.\nA couple more keywords: A classifier is a rule and its statistics. (We will skip the statistics part for today.) And a population is our set of classifiers.\nShort of going the way of C++, I have coded one first simplistic function that takes a classifier set as a dataframe, and another one that uses a list of lists instead.\nConditions can easily be written as strings:\nconditions &lt;- c('#001#', '10#10', '##110', '###0#')\nactions &lt;- c(0, 0, 0, 1)\nFor the first approach, it was quite straightforward:\nlcs_classifier1 &lt;- data.frame(id = 1:4,\n                      condition_string = conditions,\n                      action = actions, #simplest is binary for supervised\n                      accuracy = 1,\n                      numerosity = 1,\n                      first_seen = c(1, 2, 3, 4) ## I'm inventing a coverage trigger\n                      )\n\n## Find Matching Rules\nget_match_set_v001 &lt;- function(ti_condition, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- unlist(strsplit(ti_condition, \"\"))\n    pop &lt;- pop[, c(\"id\", \"condition_string\")] # Same\n\n    which(sapply(1:nrow(pop), function(i) {\n\n        t_cond &lt;- unlist(strsplit(pop$condition_string[i], \"\"))\n        relevant_positions &lt;- which(t_cond %in% c(\"0\", \"1\"))\n        \n        all(t_cond[relevant_positions] == ti_cond[relevant_positions])\n    }))\n}\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v001(test_environment$state[1], lcs_classifier1), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v001(test_environment$state[2], lcs_classifier1),\n        c(1, 2)\n    )\n})\n\n(OUTPUT:) Test passed ü•≥\nFor the second approach, I needed some more supporting functions:\n######\n## Option 2: Use list instead of Data.frame and pre-calculate match sets\n\n## Function to create a new rule from a condition string and an action\n## THIS IS VALID FOR CLASSIFICATION, NOT FOR Reinforcement Learning!!!\n## In our case, a new rule has: A condition string, an (correct!) action\n## Since action is correct, this is useful for future \"covering\"\n## AND we set accuracy to 1\nnew_supervised_rule &lt;- function(condition_string, action) {\n    list(id = 1,\n         condition_string = condition_string,\n         condition_length = nchar(condition_string),\n         condition_list = list(\"0\" = which(unlist(strsplit(condition_string, \"\")) == \"0\"),\n                               \"1\" = which(unlist(strsplit(condition_string, \"\")) == \"1\")),\n         action = action,\n         accuracy = 1,\n         numerosity = 1,\n         first_seen = 1)\n}\n\n## Function to return max id from a classifier set in list format\nmax_id_in_classifier &lt;- function(pop) {\n    max(sapply(pop, function(x) x$id))\n}\n\n## Function to add rule to a population.\n## date_rule_born will be useful stat for future, setting as parameter for now.\nadd_valid_rule_to_pop &lt;- function(pop, condition_string, action, date_rule_born = 1) {\n    \n    t_rule &lt;- new_supervised_rule(condition_string, action)\n    t_rule$id &lt;- max_id_in_classifier(pop)+1\n    t_rule$first_seen &lt;- date_rule_born\n    \n    pop[[length(pop)+1]] &lt;- t_rule\n    \n    pop\n}\n\n## Support function for human-compatible printing:\nmake_pop_printable &lt;- function(classifier) {\n    data.frame\n    rbind.fill(lapply(1:length(classifier), function(i) {\n        t_c &lt;- classifier[[i]]\n        data.frame(id = t_c$id,\n                   condition = t_c$condition_string,\n                   action = t_c$action,\n                   accuracy = t_c$accuracy,\n                   numerosity = t_c$numerosity,\n                   first_seen = t_c$first_seen)\n    }))\n}\n\n## Matching with list formatted population.\nget_match_set_v002 &lt;- function(input_state, pop) {\n    # Only part relevant for matching\n    ti_cond &lt;- as.integer(unlist(strsplit(input_state, \"\")))\n    \n    which(sapply(1:length(pop), function(i) {\n        rule &lt;- pop[[i]]$condition_list\n        all(ti_cond[rule$'0'] == 0, ti_cond[rule$'1'] == 1)\n    }))\n}\n\nlcs_classifier2 &lt;- list(new_supervised_rule(conditions[1], actions[1]))\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[2], actions[2])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[3], actions[3])\nlcs_classifier2 &lt;- add_valid_rule_to_pop(lcs_classifier2, conditions[4], actions[4])\n\ntest_that(\"validate correct match on test set\", {\n    expect_equal(\n        get_match_set_v002(test_environment$state[1], lcs_classifier2), \n        c(1)\n    )\n    expect_equal(\n        get_match_set_v002(test_environment$state[2], lcs_classifier2),\n        c(1, 2)\n    )\n})\n\n\n\nAn example population"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#well-keep-the-list-format-for-now",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#well-keep-the-list-format-for-now",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "microbenchmark(\n    sapply(test_environment$state, function(x) { get_match_set_v001(x, lcs_classifier1)}),\n    sapply(test_environment$state, function(x) { get_match_set_v002(x, lcs_classifier2)}),\n    times = 10000L\n)\n\n\n\nlists and pre-calculated match positions is faster\n\n\nLists are more flexible and data.frames are not the fastest option out there anyway. Here the pre-calculations in the second format also helps doing faster matching.\nHowever I know this choice might have an impact, particularly when time will come to implement deletion, subsumption and compaction (all useful for better LCS performance/value). And another idea I have in mind will require further lists management (but it‚Äôs too early to discuss that).\nBut that‚Äôs a problem for future me (and nothing that hasn‚Äôt been solved already)."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#conclusions",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#conclusions",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "Well well: Day 1, and we have covered concepts of environment, states, actions, conditions, rules, classifiers, population and matching/match set.\nAlong with developping a functional (basic) list for storing classifiers, and a matching function.\nNot too bad (albeit all too simplistic and not going for ‚Äúfull-power‚Äù flexible LCS implementation)."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#references",
    "href": "posts/2024-12-22_RLCS_Day1_Matching_and_Classifier_storage/index.html#references",
    "title": "RLCS Day 1: Rules formatting, storage, and matching",
    "section": "",
    "text": "I‚Äôll keep referring to this video (although the book is better to get acquainted with the vocabulary and concepts): intro explaining the algorithm ."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html",
    "href": "posts/2024-11-10_entropy_of_zip/index.html",
    "title": "Entropy - Identifying compressed files",
    "section": "",
    "text": "About Shannon‚Äôs Information Entropy, applied to potentially detecting ciphered or compressed text compared to plain text.\n(First entry of the new platform, let‚Äôs see how it goes.)"
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#shannons-information-entropy",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#shannons-information-entropy",
    "title": "Entropy - Identifying compressed files",
    "section": "Shannon‚Äôs Information Entropy",
    "text": "Shannon‚Äôs Information Entropy\n\nWhy try to understand that?\nLong story short, Information Entropy is useful in quite a few machine learning algorithms, and to name only a few, the following two use it directly:\n\nPartitioning Trees (for nodes selection)\nLogistic Regression (through log loss)\n\nDoesn‚Äôt seem like much, said like that, but the Logistic Regression in turn can be used for‚Ä¶ Neural Networks :)\n\n\nHow it is defined?\nThe best way I personally managed to try and understand information entropy is through the concept of compression and surprise.\nA few helpful descriptions:\n‚Äú[‚Ä¶] the expected amount of information needed to describe the state of the variable [‚Ä¶]‚Äù\n‚ÄúEntropy is the measure of uncertainty of a variable. The more uncertain it is, the higher the entropy is.‚Äù\nHere is the mathematical expression of it:\n\\[\nH(X) = - \\sum_{x \\in X} p(x) log(p(x))\n\\]\nFrom the Wikipedia (I mean, why not?), this is the part that somehow can make sense for an intuitive understanding of the concept:\n‚ÄúThe information content, also called the surprisal or self-information, of an event \\(E\\) is a function which increases as the probability \\(p(E)\\) of an event decreases. When \\(p(E)\\) is close to 1, the surprisal of the event is low, but if \\(p(E)\\) is close to 0, the surprisal of the event is high. This relationship is described by the function\n\\[\nlog({1 \\over p(E)})\n\\]\nwhere \\(log()\\) is the logarithm, which gives 0 surprise when the probability of the event is 1. In fact, log is the only function that satisfies –∞ specific set of conditions [‚Ä¶]‚Äú"
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#application-detecting-cipherzip-on-data-streams",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#application-detecting-cipherzip-on-data-streams",
    "title": "Entropy - Identifying compressed files",
    "section": "Application: Detecting cipher/zip on data streams",
    "text": "Application: Detecting cipher/zip on data streams\nWe‚Äôre aiming for this today:\n\n\n\nCharacters distribution in Plain vs Zip text for a few Wiki entries\n\n\n\nThe code\nThe code will be on my Github soon enough (if not already).\nBut for now, a few blocks of it:\n\nmake_freq_df &lt;- function(filename) {\n    test1 &lt;- file(filename, open=\"rb\", raw = TRUE)\n    t1_bytes &lt;- t1_chars &lt;- c()\n    while(TRUE) {\n        temp &lt;- readBin(test1, what = \"raw\")\n        if(length(temp) == 0) break;\n        t1_bytes &lt;- c(t1_bytes, temp)\n        t1_chars &lt;- c(t1_chars, rawToChar(temp))\n    }\n    close(test1)\n    t1_df &lt;- data.frame(sort(table(as.character.hexmode(t1_bytes)), decreasing = TRUE))\n    t1_df$char &lt;- names(sort(table(t1_chars), decreasing = TRUE))\n    names(t1_df) &lt;- c(\"x\", \"probs\", \"char\")\n    # Instead of counts (table output), make it probability:\n    t1_df$probs &lt;- t1_df$probs/sum(t1_df$probs)\n    # Alternative could have been:\n    #t1_df$probs &lt;- as.numeric(prop.table(sort(table(t1_chars), decreasing = TRUE)))\n    \n    t1_df\n}\n\nThe above function is a (bad, but functional) way of taking a file, reading it in ‚Äúraw‚Äù format, and output byte-by-byte into a dataframe.\n\nThe first output column will be the ‚Äúraw byte‚Äù (for text, the ASCII code, say ‚Äú20‚Äù for space character).\nThe second column contains the Probability of appearance of a character, compared to the whole text being analysed (so, the frequency of it‚Äôs appearance).\nThe third column is for reference only, to ‚Äúsee‚Äù what the character would look like in plain text. Note that ‚Äù ‚Äù (space) and null would look similar‚Ä¶ And so would other encoded bytes, but that‚Äôs not to worry for today.\n\nWith the above in mind, here is an output of plain and zip‚Äôed text, along with the Shannon‚Äôs Entropy of it, correspondingly:\n&gt; firewall_wiki &lt;- compare_clear_zip(1, wiki_pages_df)\nupdating: posts/2024-11-10_entropy_of_zip/firewall_wiki.txt (deflated 63%)\n   x      probs char\n1 20 0.14766670     \n2 65 0.09267745    e\n3 69 0.07790143    i\n4 74 0.06658562    t\n5 6e 0.06621154    n\n6 61 0.06050687    a\n   x       probs char\n1  0 0.012244898     \n2 39 0.006722689    9\n3 72 0.006722689    r\n4 5f 0.006482593    _\n5 34 0.006242497    4\n6 e4 0.006242497 \\xe4\n[1] \"Entropy Plain text: 4.29839806234458\"\n[1] \"Entropy Zip text: 7.94701914818039\"\n\nIn Plain text, the space character appears quite a bit. So do the letters e, i, t, n, a... (That‚Äôs for English, and remember these are small sample texts extracted from some Wikipedia pages‚Ä¶). Plain text has repetition on some characters (higher probability of appearance), with varying distributions (and uses fewer different bytes).\nIn Zip, the probabilities are each MUCH lower, and more even across all possible bytes. And that‚Äôs our KEY concept for today. Zip is compression, so all its characters have as few repetition as possible (i.e.¬†low probability).\nInterestingly, with the above approach, ciphered data would look like zip data.\n\nOK, so let‚Äôs go back to our definitions of the first part:\n‚Äú[‚Ä¶] When \\(p(E)\\) is close to 1, the surprisal of the event is low, but if \\(p(E)\\) is close to 0, the surprisal of the event is high[‚Ä¶]‚Äú\nHopefully we‚Äôre getting somewhere with understanding the concept. Uncommon characters will have higher ‚Äúsurprisal‚Äù, and lower probability of appearing.\nOh: And we should not be afraid of the math, it wasn‚Äôt that bad. Here is what Shannon‚Äôs Entropy actually looks like for varying values of probability of appearance of a given character:\n\n\n\nShannon Entropy across possible probabilities\n\n\n\n\nWhat does it mean in practice?\nWell, it means that if you sample some bytes sniffed on a network, if you see seemingly random characters and no particular prevalence of any given one over the rest, you know it‚Äôs not clear-text.\nAnd yes, if you have the file extension, maybe this is all useless. So why you would care?\nFirst, this is pretty cool. If you sample data (from a network stream, or bytes on a disk‚Ä¶), you can distinguish ‚Äúautomagically‚Äù what‚Äôs plain text and what‚Äôs ciphered/zip.\nSecond: Maybe you can use that to detect covert channels out of packet capture? Or maybe let your computer on its own decide to use one set of algorithm to analyse things when there is plain text, and use another set of characters when there is ciphered/compressed text (or images, etc.)."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#conclusions",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#conclusions",
    "title": "Entropy - Identifying compressed files",
    "section": "Conclusions",
    "text": "Conclusions\nAll this took me quite a while to really understand it. Or think I do, anyway :D\nToday we‚Äôve tried to explain the concept of information entropy through a simple application. If at this point my readers have gotten somewhat of an intuition about the concept, I‚Äôll be very happy.\nAnd the concept is quite relevant for Machine Learning, as we shall see in future posts."
  },
  {
    "objectID": "posts/2024-11-10_entropy_of_zip/index.html#references",
    "href": "posts/2024-11-10_entropy_of_zip/index.html#references",
    "title": "Entropy - Identifying compressed files",
    "section": "References",
    "text": "References\nhttps://en.wikipedia.org/wiki/Entropy_(information_theory)\nThe original idea about this post I read a few years back in ‚ÄúNetwork Security Through Data Analysis‚Äù, 2nd Ed, by M. Collins (O`Reilly)"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "So I had a bit of time. And I chose to use it to keep going a bit. I moved a couple of things, created a few more supporting functions, modified them somewhat, and added the covering part.\nCovering needs to happen when for a given training instance (state, class), there is no match in the correct set.\nCorrect set is the subset of the Matching set for which, on top of the condition matching, the predicted class/action is also correct.\nAnd well, it‚Äôs working:\n\n\n\ntesting basic covering functionality\n\n\n\n\n\nNext up is ‚ÄúRule Discovery‚Äù, whereby, in Michigan-style LCS, a GA-like process will take place to create offspring from two parents taken in the Correct set.\nThat will include cross-over (in one way or another) and mutation (with a preset pressure/probability). With these, on top of coverage, the LCS will hence create new valid rules, that will become part of the population, to be evaluated on further training instances.\nOther parts of the algorithm ‚Äì meant to contain the population size ‚Äì will come later. :)"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#its-sunday",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#its-sunday",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "So I had a bit of time. And I chose to use it to keep going a bit. I moved a couple of things, created a few more supporting functions, modified them somewhat, and added the covering part.\nCovering needs to happen when for a given training instance (state, class), there is no match in the correct set.\nCorrect set is the subset of the Matching set for which, on top of the condition matching, the predicted class/action is also correct.\nAnd well, it‚Äôs working:\n\n\n\ntesting basic covering functionality"
  },
  {
    "objectID": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#conclusion",
    "href": "posts/2024-12-24_RLCS_Day_2_Almost_Done_v001/index.html#conclusion",
    "title": "RLCS Day 1 - Part II: Basic Covering",
    "section": "",
    "text": "Next up is ‚ÄúRule Discovery‚Äù, whereby, in Michigan-style LCS, a GA-like process will take place to create offspring from two parents taken in the Correct set.\nThat will include cross-over (in one way or another) and mutation (with a preset pressure/probability). With these, on top of coverage, the LCS will hence create new valid rules, that will become part of the population, to be evaluated on further training instances.\nOther parts of the algorithm ‚Äì meant to contain the population size ‚Äì will come later. :)"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I have yet another day off (that‚Äôs the thing with Holiday season), and I really wanted to keep working on this.\nSo I added the Genetic Algorithm part to my Supervised Learning basic Michigan-style LCS.\nThat means, after covering (done last Sunday) I am done with the (basic) implementation of the Rule Discovery features of the LCS algorithm.\nAnd, heck, it works.\n\n\n\nSo we had covering, whereby new rules were created when none in the classifiers matched the a new-coming environment instance.\nBut this is only part of the discovery of new rules. The second part in the Michigan-style LCS is that of a Genetic Algorithm.\nI implemented now a simple version, with tournament parents selection. That is, from the Correct set (see past entries) ‚Äì but taking numerosity of classifiers into account ‚Äì I choose N (a parameter) parents randomly. Then I take the best 2 parents by fitness. Which is ellitist.\nThen I run a one-point cross-over, to generate 2 children.\nI apply mutation to the children genes in turn, with a mutation pressure set as yet another parameter (default is 5% in my implementation).\nAnd finally I add the children to the population.\nNote that children mutations ensure only valid rules are created (i.e.¬†condition is compatible with the training instance). Mutations either generalize (add a wildcard) or specify (replaces a wildcard by a 0 or 1, depending on training instance).\nFully general (‚Äúall wildcard‚Äù) individuals are of course discarded. If a child actually matches by condition an individual in the correct set, it is discarded and the repeated classifier instead get a numerosity increase.\nAnd that‚Äôs IT!\n\n\n\nIn my current dummy example, whereby the goal is for the LCS to discover the rule ‚ÄúClass is NOT(bit 4 of input state)‚Äù, well‚Ä¶ In manual runs (several of them), I often (not always, mind you) find the two best rules are perfect rules:\n\n\n\nPerfect Rules are often discovered!\n\n\n\n\n\nThe first two rules (ordered by accuracy and numerosity, both decreasing) are the exact rules that perfectly will always predict the correct class/action, and are perfectly balanced in this case between general and specific.\nThese are the kind of things that an LCS provides that a Neural Network won‚Äôt:\nIt tells you WHY it makes a decision.\nHere, it is saying:\n\nRule 1: If bit 4 is 0, then class is 1. I am 100% accurate, whenever that happens.\nRule 2: If bit 4 is 1, then class is 0. I am 100% accurate, whenever that happens.\n\nWhich is exactly what this dummy training data set was trying to say in the first place, with 70% of the training possibilities shown to train the algorithm.\nObviously this is‚Ä¶ A somewhat silly example. But the thing is, I did NOT tell it how to get there, and it got the IF THEN ELSE correctly on its own.\n\n\n\nEvery now and then (after a certain number of Epochs) I run a Deletion process, whereby rules that have Numerosity 1 are discarded, thereby containing the size of the set of classifiers.\nThis is important for interpretability and performance.\n\n\n\nI am quite happy that after only a couple of days of coding, I have a basic, perfectly functional LCS!\nI do miss two components: Subsumption and Compaction.\nPlus of course the Prediction, that comes after training, on a test subset.\nIt‚Äôs all on my to-do, but this thing is already promising!\nGranted, it‚Äôs not real fast. And the code is far from perfect, or duly organized. But it works!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#intro",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#intro",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I have yet another day off (that‚Äôs the thing with Holiday season), and I really wanted to keep working on this.\nSo I added the Genetic Algorithm part to my Supervised Learning basic Michigan-style LCS.\nThat means, after covering (done last Sunday) I am done with the (basic) implementation of the Rule Discovery features of the LCS algorithm.\nAnd, heck, it works."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#what-the-ga-does",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#what-the-ga-does",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "So we had covering, whereby new rules were created when none in the classifiers matched the a new-coming environment instance.\nBut this is only part of the discovery of new rules. The second part in the Michigan-style LCS is that of a Genetic Algorithm.\nI implemented now a simple version, with tournament parents selection. That is, from the Correct set (see past entries) ‚Äì but taking numerosity of classifiers into account ‚Äì I choose N (a parameter) parents randomly. Then I take the best 2 parents by fitness. Which is ellitist.\nThen I run a one-point cross-over, to generate 2 children.\nI apply mutation to the children genes in turn, with a mutation pressure set as yet another parameter (default is 5% in my implementation).\nAnd finally I add the children to the population.\nNote that children mutations ensure only valid rules are created (i.e.¬†condition is compatible with the training instance). Mutations either generalize (add a wildcard) or specify (replaces a wildcard by a 0 or 1, depending on training instance).\nFully general (‚Äúall wildcard‚Äù) individuals are of course discarded. If a child actually matches by condition an individual in the correct set, it is discarded and the repeated classifier instead get a numerosity increase.\nAnd that‚Äôs IT!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#results-with-fully-functional-rule-discovery",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#results-with-fully-functional-rule-discovery",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "In my current dummy example, whereby the goal is for the LCS to discover the rule ‚ÄúClass is NOT(bit 4 of input state)‚Äù, well‚Ä¶ In manual runs (several of them), I often (not always, mind you) find the two best rules are perfect rules:\n\n\n\nPerfect Rules are often discovered!"
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#important-what-the-rules-set-tells-us",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#important-what-the-rules-set-tells-us",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "The first two rules (ordered by accuracy and numerosity, both decreasing) are the exact rules that perfectly will always predict the correct class/action, and are perfectly balanced in this case between general and specific.\nThese are the kind of things that an LCS provides that a Neural Network won‚Äôt:\nIt tells you WHY it makes a decision.\nHere, it is saying:\n\nRule 1: If bit 4 is 0, then class is 1. I am 100% accurate, whenever that happens.\nRule 2: If bit 4 is 1, then class is 0. I am 100% accurate, whenever that happens.\n\nWhich is exactly what this dummy training data set was trying to say in the first place, with 70% of the training possibilities shown to train the algorithm.\nObviously this is‚Ä¶ A somewhat silly example. But the thing is, I did NOT tell it how to get there, and it got the IF THEN ELSE correctly on its own."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#deletion-is-also-implemented",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#deletion-is-also-implemented",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "Every now and then (after a certain number of Epochs) I run a Deletion process, whereby rules that have Numerosity 1 are discarded, thereby containing the size of the set of classifiers.\nThis is important for interpretability and performance."
  },
  {
    "objectID": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#conclusion",
    "href": "posts/2024-12-22_RLCS_Day1_PartII_Basic_Coverage/index.html#conclusion",
    "title": "RLCS Day 2 - Full Rule Discovery",
    "section": "",
    "text": "I am quite happy that after only a couple of days of coding, I have a basic, perfectly functional LCS!\nI do miss two components: Subsumption and Compaction.\nPlus of course the Prediction, that comes after training, on a test subset.\nIt‚Äôs all on my to-do, but this thing is already promising!\nGranted, it‚Äôs not real fast. And the code is far from perfect, or duly organized. But it works!"
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html",
    "title": "Classifying URLs",
    "section": "",
    "text": "I‚Äôm still working my way through a ‚Äúpractical demos‚Äù session on ML background for Cybersecurity.\nSee I have a ‚Äúplan‚Äù in my head about how to introduce Machine Learning, including demystifying a bit the math behind it. The ‚Äúplan‚Äù goes a bit like this:\n\nWe‚Äôve seen recently a bit of what unsupervised learning can be about. For Cybersecurity, anomaly detection is a clear use-case. We‚Äôve used the concept of distance between points. But there is more to this category (clustering per-se, but also dimensionality reduction is quite useful, for instance).\nML can be about making a line go through points (nicely). That‚Äôs regression. With sufficient data, you‚Äôre compressing information of relationships between dimensions to predict an outcome. In the simplest form, given x, you can estimate y. And the math is quite simple:\n\\[\ny = \\beta_0 + \\beta_1x\n\\]\nSuch a linear regression is then really of the realm of statistics. As such, there is little of practical application of that thing for us in this simplest form, as in Cybersecurity, many things are expected to be black or white. But maybe it‚Äôs not completely crazy to maybe estimate that the more time a machine is connected to the Internet, the higher the risk of infection (all other things being equal, that is). That could be a growing line. Sometimes things can be approximated with the appropriate transformations on the dimensions (say ‚Äúindependent variables‚Äù) and then used in a linear regression (so the ‚Äúmodel is linear on its parameters‚Äù).\n\n\nI‚Äôll make an entry about linear regression soon(-ish), when I have time.\n\n\nML can also be about making a line separate groups of things nicely, i.e.¬†classifying stuff. In its simplest form, we will have input data, and will want to know in which one of two categories a given input should belong too. That‚Äôs our ‚Äúrun of the mill‚Äù Spam classifier.\n\n\nBoth regression (linear or not) and classification are usually considered to be the two most common supervised learning use-cases.\n\n\nThen you have Reinforcement Learning (aka RL). So far, I have yet to personally come across a real-world cybersecurity application of that, although it is pretty cool a concept! (Actually a friend has demonstrated something with Honeypots and such‚Ä¶) But I‚Äôll admit, I have played little with RL myself for now, and it‚Äôs a pending task of mine. It does sound appealing, and there are some papers out there to use RL for optimizing pentesting processes and such.\nAnd then you have Self-Supervised Learning. The first time I read that I was like ‚ÄúWhaaaat?‚Äù. But that‚Äôs LLMs, as noted at the end of one of my most recent posts. You predict next word in a text, and check what actually comes in the‚Ä¶ Rest of the text. So you only need‚Ä¶ The text. Nifty. But I‚Äôm not too fond of it and have yet to think it through enough to come up with something practical beyond LLMs‚Ä¶\n\nThere is plenty more, but this is one way of putting categories to what ML is about.\n\n\n\nAlright, so I‚Äôll skip some of the above, and today jump right onto this:\nHow does Supervised Machine Learning work, as applied to one cybersecurity-relevant classification use-case?\nSomehow I feel it‚Äôs more fun to frame things a little into practical use-cases, instead of pure math (which I suppose is boring/threatening to quite a few).\nEven then, be warned: This entry is pretty long. But hopefully it contains some important things and my wish is, it‚Äôs also understandable."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#i-have-a-plan",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#i-have-a-plan",
    "title": "Classifying URLs",
    "section": "",
    "text": "I‚Äôm still working my way through a ‚Äúpractical demos‚Äù session on ML background for Cybersecurity.\nSee I have a ‚Äúplan‚Äù in my head about how to introduce Machine Learning, including demystifying a bit the math behind it. The ‚Äúplan‚Äù goes a bit like this:\n\nWe‚Äôve seen recently a bit of what unsupervised learning can be about. For Cybersecurity, anomaly detection is a clear use-case. We‚Äôve used the concept of distance between points. But there is more to this category (clustering per-se, but also dimensionality reduction is quite useful, for instance).\nML can be about making a line go through points (nicely). That‚Äôs regression. With sufficient data, you‚Äôre compressing information of relationships between dimensions to predict an outcome. In the simplest form, given x, you can estimate y. And the math is quite simple:\n\\[\ny = \\beta_0 + \\beta_1x\n\\]\nSuch a linear regression is then really of the realm of statistics. As such, there is little of practical application of that thing for us in this simplest form, as in Cybersecurity, many things are expected to be black or white. But maybe it‚Äôs not completely crazy to maybe estimate that the more time a machine is connected to the Internet, the higher the risk of infection (all other things being equal, that is). That could be a growing line. Sometimes things can be approximated with the appropriate transformations on the dimensions (say ‚Äúindependent variables‚Äù) and then used in a linear regression (so the ‚Äúmodel is linear on its parameters‚Äù).\n\n\nI‚Äôll make an entry about linear regression soon(-ish), when I have time.\n\n\nML can also be about making a line separate groups of things nicely, i.e.¬†classifying stuff. In its simplest form, we will have input data, and will want to know in which one of two categories a given input should belong too. That‚Äôs our ‚Äúrun of the mill‚Äù Spam classifier.\n\n\nBoth regression (linear or not) and classification are usually considered to be the two most common supervised learning use-cases.\n\n\nThen you have Reinforcement Learning (aka RL). So far, I have yet to personally come across a real-world cybersecurity application of that, although it is pretty cool a concept! (Actually a friend has demonstrated something with Honeypots and such‚Ä¶) But I‚Äôll admit, I have played little with RL myself for now, and it‚Äôs a pending task of mine. It does sound appealing, and there are some papers out there to use RL for optimizing pentesting processes and such.\nAnd then you have Self-Supervised Learning. The first time I read that I was like ‚ÄúWhaaaat?‚Äù. But that‚Äôs LLMs, as noted at the end of one of my most recent posts. You predict next word in a text, and check what actually comes in the‚Ä¶ Rest of the text. So you only need‚Ä¶ The text. Nifty. But I‚Äôm not too fond of it and have yet to think it through enough to come up with something practical beyond LLMs‚Ä¶\n\nThere is plenty more, but this is one way of putting categories to what ML is about."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#todays-intro",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#todays-intro",
    "title": "Classifying URLs",
    "section": "",
    "text": "Alright, so I‚Äôll skip some of the above, and today jump right onto this:\nHow does Supervised Machine Learning work, as applied to one cybersecurity-relevant classification use-case?\nSomehow I feel it‚Äôs more fun to frame things a little into practical use-cases, instead of pure math (which I suppose is boring/threatening to quite a few).\nEven then, be warned: This entry is pretty long. But hopefully it contains some important things and my wish is, it‚Äôs also understandable."
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#classifying-urls-into-two-categories",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#classifying-urls-into-two-categories",
    "title": "Classifying URLs",
    "section": "Classifying URLs into TWO categories",
    "text": "Classifying URLs into TWO categories\n\nThe data\nIn Cybersecurity sometimes getting to interesting datasets can be a bit challenging. After all, certain things are usually done behind closed doors. You can probably understand why. Which is why I like for instance this resource, secrepo.com.\nToday, we‚Äôre gathering a seemingly simple dataset: A list of web URLs, very simply tagged as either good or bad. Nothing else. But, mind you, 420 thousand of‚Äôem.\n\nPoint number one: to do ML, it can help to have lots of data. (It‚Äôs not always necessary, but it‚Äôs usually a good idea.)\n\n\n\nThe objective\nToday is about trying to distinguish (really just trying!) to classify URLs (‚Äúwebpages‚Äù, for most) in two categories: Good or Bad. Why? Applications are for your protection, and can be used to recommend you to avoid certain websites, which in turn can be maybe used as a supplementary control for other security measures, such as detecting Phishing emails.\nCan we make our computer tell us if a given URL is good or bad?\nThat‚Äôs it. That‚Äôs our goal for today. Using Machine Learning, of course. So we‚Äôre aiming to implement one (or more) model(s) to classify URLs. Based on data we already have. That‚Äôs supervised learning, more precisely a classifier.\n\nJust to be very clear: This is all part of a preparation to an introduction on ML background for Cybersecurity. ‚ÄúIntroduction‚Äù is the key here: I‚Äôm not aiming for complete, perfect, not even good, as long as I can convey certain concepts that I believe are relevant to grasp an idea at best of how ML works.\nEven the code I put together is‚Ä¶ Well, lacking. It‚Äôs not meant to be production grade.\n\nThere is nothing in the way of test-driven anything\nSome of the regular expressions are simplistic\nSome stuff will be badly filtered\nThe trained models are not good\nThe data is what it is, and I‚Äôm not trying to complement it\n‚Ä¶\n\nPlease don‚Äôt come saying ‚Äúthis is not great‚Äù. I know. I only have so much spare time. This post is only my way to support with contents an interactive session I plan to give soon. There is a lot of good training on ML, Cybersecurity & al.¬†out there. Go find it, if you want formal and/or good, detailed training.\nIf you‚Äôre fine with simply trying to wrap our heads around concepts, do keep reading.\n\n\n\nThe code\nThe code will be on my Github eventually. But for now, as usual, a few blocks of it:\n\nurls_df &lt;- read.csv(\"https://raw.githubusercontent.com/faizann24/Using-machine-learning-to-detect-malicious-URLs/refs/heads/master/data/data.csv\")\n\nurls_df$url &lt;- tolower(urls_df$url)\n## Let's have a quick look, a.k.a. \"EDA\"\ndim(urls_df)\n&gt; [1] 420464      2\ntable(urls_df$label) ## Imbalance, we might want e.g. to under-sample \"good\"\n&gt;  bad   good \n 75643 344821 \n\n\nPoint number two: Imbalance is often bad. Here we have 4.5 times more good entries than bad entries. Now, why could that be bad? Here we‚Äôre going to try to learn from our data. If we keep the imbalance in the dataset, to make things simple, our model could learn that there is more good than bad. And maybe that‚Äôs what we want, but then that imbalance could affect the outcome of our model. Unless we want to use that imbalance for some reason, it‚Äôs probably best to manage it upfront.\n\nHow to remove imbalance? Well, one way (of surely many out there, only I only know a few), is to ‚Äúunder-sample‚Äù some of the over-represented class. Today we‚Äôre going to take proportionally less entries from good to train our model, making then sure that we have roughly half and half, of each class.\nAs per the class, it‚Äôs a binary choice, good or bad. We‚Äôll create a variable to encode that as 0 or 1 (or the other way around, it‚Äôs irrelevant). That‚Äôs just to make things compatible with certain models, as most will expect numerical data.\nurls_df$label_num &lt;- ifelse(urls_df$label == \"good\", 0, 1)\nurls_df$url_length &lt;- nchar(urls_df$url)\n\n## A bit of domain knowledge helps:\nnrow(urls_df[urls_df$url_length &gt; 300,]) / nrow(urls_df)\n[1] 0.001203432\n\nPoint number 3: Domain Knowledge is important. We‚Äôre going to leverage that today quite a bit. To begin with, we have 0.1% of the entries with URL length superior to 300 characters, and to make things cleaner, we‚Äôll assume today these are‚Ä¶ Irrelevant. So we remove them. Our classifier will hence not be trained with such data. And maybe that‚Äôs a bad idea, depending on your goals. For today, everything is fair game, we want to keep things simple.\n\n\n\nFeature Engineering\nHeck. We only have URLs. And a class. How is a machine suppose to go from there?\nLet‚Äôs try to extract something akin‚Äô to a signal out of that. So we‚Äôve got already the length of each URL. And maybe that‚Äôs helpful. Are longer URLs more often bad than good? Well, for real long URLs, maybe a bit. But it‚Äôs not really definitive, is it?\n\n\n\nComparing densities of URL lengths per class\n\n\n\nPoint number 4: Always look at the data. Don‚Äôt just run into the modelling, it‚Äôs not a good idea. Get a feeling of the data you want to work with. I can‚Äôt stress this enough.\n\nLet‚Äôs keep going then. Again, domain knowledge is key. The good news is, most of us have seen thousands of URLs in our lifetime, so maybe we have a little understanding of what we could look for.\nToo many slashes ‚Äú/‚Äù? Too many ‚Äúdots‚Äù? Maybe. So those could be two new ‚Äúdimensions‚Äù. Although maybe these two are already somewhat expressed through the length of the URL? In other words, it might make sense that the longer the URL, the more dots and slashes.\n\nPoint number 5: That‚Äôs a correlation right there, and depending on how much two variables are correlated, maybe you‚Äôre better off with fewer variables. There is a lot of background statistics on this topic. And for ML algorithms, sometimes too many variables is a bad thing, more so if they don‚Äôt add any useful information.\n\nFor today, we‚Äôll keep it. After all, we have for now only what, 3 variables to work with? We need more. I‚Äôm going to save you the pain of going through it all one by one, and propose my own few variables I thought we might consider for training our model, ALL extracted from the URLs themselves.\n\nIP as host: Humans use ‚ÄúDomain Names‚Äù that are readable. You need a DNS entry for that, and you need to register things as the owner for the DNS entry, for legal reasons. So if you skip the DNS step, you can still have an IP address, but it will look like‚Ä¶ An IP. It‚Äôs a bit far-fetched, but I‚Äôd argue if a URL reflects a Public IP, it‚Äôs either known good (ours or provided by some trusted third party), or - more often than not - it‚Äôs a bad indicator.\nURL readability: So it‚Äôs not direct. A URL can of course contain stuff that‚Äôs purely technical. But we usually make an effort to make things readable: variable names, folder names, etc. Bad actors might want to obfuscate stuff or generate random folder or what-not. And so if a URL is mostly unreadable gibberish, I‚Äôd guess it‚Äôs a bad sign. Which we can ‚Äúencode‚Äù as: How many vowels has the URL relative to its length? Does the URL contain things with 4 consecutive consonants (not usual in written english, although not good an indicator in some other languages‚Ä¶)? Again, both things are probably somewhat related, but not necessarily/completely. So I take both.\nIs a port expressly identified in the URL? After the host, a column and number is usually not required for a normal website, it‚Äôs usually a default (443 or 80). So if you see ‚Äúsomehost.somedomain.com:12345‚Äù, something exotic is going on. Exotic for normal web browsing is weird (well, it‚Äôs exotic :D), and so not expected for good stuff.\nWe can keep going: Domain extension, file extension (a URL ending in .exe is a red flag, for sure :D), or more simply how common is either of these, is probably helpful too.\n\nIt‚Äôs not exhaustive (not in the least) but hopefully it makes some sense. From a URL, we‚Äôve put together 14 different variables that way. All chosen from experience, from ‚Äúdomain knowledge‚Äù. (See point number 3 above if it wasn‚Äôt clear before.)\n\n\n\nWe should keep looking at our data‚Ä¶\n\n\nFrom no variables (except considering the URL itself‚Ä¶) to 14. Not too shabby.\n&gt; names(urls_df)\n [1] \"url\"                       \"label\"                     \"url_length\"               \n [4] \"label_num\"                 \"slashes_count\"             \"dots_count\"               \n [7] \"host_is_ip\"                \"vowels_prev\"               \"ends_in_slash\"            \n[10] \"contains_port\"             \"n_params\"                  \"domain_ext\"               \n[13] \"file_ext\"                  \"is_common_domain_ext\"      \"is_uncommon_domain_ext\"   \n[16] \"is_uncommon_file_ext\"      \"has_4_consonants_straight\"\nThere is sooo much more to consider.\nFor instance if you check out the code (if/when I make it available on my GitHub), you‚Äôll see at one point I ‚Äúscale‚Äù the data. That is, I try to put all the variable in comparable orders of magnitude. This is to avoid one variable overshadowing all the others. Something that varies from 0.5 to 0.6 might otherwise be considered less important than something that varies from 3 to 4000. Which is not always true.\nI also make a BAD thing: I transform extensions to ‚Äúfactors‚Äù, and then I encode the levels of the factors as numerical data. This is not great, I know :D\nNamely, factors are not ordered, while two numbers could be, providing ordinal value at least, and distances could be considered, when here there is clearly no such thing. BAD! BAD Nico!\nLook, this is no excuse, but hopefully, if you order things upfront, and then encode to numerical value, say bad entries as factors first, then good, you end up with ordered levels where by lower ones are for bad, and higher for good (or vice-versa). It will turn out wrong for today. This is tricky and let me insist, NOT good practice. As it turns out, I have so many possible extensions (values) in there, that a better approach - such as one-hot-encoding - makes my dataset explode in size and not fit my RAM memory‚Ä¶ And I am just too lazy to work through this for what was meant to be a simple demo. So‚Ä¶ My apologies, I know, it hurts the eyes to see this. Moving on.\n\n\nTraining Models\nOne last concept, and we‚Äôll dive in actual ‚ÄúLearning‚Äù.\n\nPoint number 6: Save some entries for testing you trained model. So say we have 10K entries, of which 5000 are good and 5000 are bad entries. How do you know your trained model ‚Äúgeneralizes‚Äù correctly? If you were to try and evaluate your model on data you used to train it, you couldn‚Äôt know whether it just learnt exactly that case, or if it would work on future data. To verify how it would work on future data, you‚Ä¶ Validate using data not seen during training. There is more to that, too, but that‚Äôll be enough for conceptual understanding today.\n\nOK. At last. As today has been dense (I know, sorry), I‚Äôll train just ONE model on our dataset.\ngood_urls &lt;- urls_df[urls_df$label == \"good\",]\nbad_urls &lt;- urls_df[urls_df$label == \"bad\",]\n## Undersampling \"good\" vs \"bad\"\nsample_urls_df &lt;- rbind(bad_urls[sample(1:nrow(bad_urls), size = 10000,replace = FALSE),],\n                        good_urls[sample(1:nrow(good_urls), size = 10000,replace = FALSE),])\n\n## ...\n\nseparate_sets &lt;- sample(c(TRUE, FALSE), nrow(sample_urls_df), replace=TRUE, prob=c(0.7,0.3))\nt_train &lt;- sample_urls_df[separate_sets, ]\nt_test &lt;- sample_urls_df[!separate_sets, ] # i.e. Not train set...\n\n\nPartitioning Tree, train and test\nHere is how you train a Partitioning Tree in R:\n## A Partitioning tree but WITHOUT the bad trick of extensions encoding\n## And low depth:\ntree_model &lt;- rpart(label ~ url_length + slashes_count + dots_count +\n                        host_is_ip + vowels_prev + ends_in_slash + contains_port +\n                        n_params + is_common_domain_ext + is_uncommon_domain_ext +\n                        is_uncommon_file_ext + has_4_consonants_straight,\n                    data = t_train,\n                    method = \"class\",\n                    control = rpart.control(cp = 0.05))\nAnd here how you visualize, and ‚Äútest‚Äù it:\n&gt; tree_model ; plot(tree_model); text(tree_model)\nn= 13929 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 13929 6933 good (0.4977385 0.5022615)  \n  2) dots_count&gt;=0.3877992 2846  729 bad (0.7438510 0.2561490) *\n  3) dots_count&lt; 0.3877992 11083 4816 good (0.4345394 0.5654606)  \n    6) vowels_prev&lt; -0.6992319 1877  658 bad (0.6494406 0.3505594) *\n    7) vowels_prev&gt;=-0.6992319 9206 3597 good (0.3907234 0.6092766) *\n&gt; t_test$predicted &lt;- predict(tree_model, t_test, type=\"class\")\n&gt; table(t_test[, c(\"label\", \"predicted\")])\n      predicted\nlabel   bad good\n  bad  1431 1636\n  good  611 2393\nNow to the important part: We‚Äôve tested on 30% of the data our model trained on the other 70% of the data. In the above, we‚Äôve also excluded the factor-level-encoded variables because they‚Äôre a bad thing (but as we‚Äôll see in a second, they contain useful information, unfortunately). And we got some results, as such:\nBased on the data, we have trained a partitioning tree that makes mistakes about 37% of the time. As we have balanced our dataset, we know that randomly choosing one class of the other would have led us to 50% error, approximately. Still, not great.\nLet‚Äôs have a look at this ‚Äútree‚Äù:\n\n\n\nA simplistic partitioning tree\n\n\nLow depth, and still, with only two choices, we get a 63% correct classification on unseen data.\n\nOne thing to note, I‚Äôm not sure that this particular implementation of the model in fact uses Shannon‚Äôs information entropy to select nodes (it could use Gini impurity, typically). But suffice to say it could, and that‚Äôs one way a Partitioning Tree could decide which variable to choose first to make a separation in two branches, and then iterate. And I only mention it because that was the topic of last week‚Äôs entry.\n\nIt does look like the number of ‚Äúdots‚Äù in the URL, and our prevalence of vowels (which I explained a bit earlier) are important to help classify our URLs. Take note! Actually, this is a fair point, Trees are nice because they‚Äôre readable by a human. That is, the decisions of this algorithm are explainable, and that‚Äôs a good thing.\nNow without further ado, what better models I have managed to produce, just increasing depth and/or adding the (badly encoded) extension variables:\n\nWith just more decisions (more branches in the tree, i.e.¬†more depth), I got my classification to a 75% correct classification rate.\nAdding the (incorrectly) encoded extension variables, I go up to 80%.\n\n\n\n\nA somewhat better tree, albeit using bad practices"
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#conclusions",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#conclusions",
    "title": "Classifying URLs",
    "section": "Conclusions",
    "text": "Conclusions\nLots of theory covered. And only a bit of practical outcome, as today we just have a (first) model that is ‚Äúbetter than chance‚Äù, although well, far from perfect.\nIn a future post, we‚Äôll probably circle back to this exercise, to see potentially things related to other classification algorithms such as logistic regression, random forests, neural nets, and maybe SVM. Now that most of the theory is covered, it should be shorter, more to the point. (I have them all working already, I just don‚Äôt want to add content for today, it‚Äôs already too much‚Ä¶)\n\nNote: If I have time, I‚Äôll make a Shiny Application, so that you can test whether or not you can beat this simple (bad) model. Fair warning: I don‚Äôt know how the URLs were originally tagged; but I‚Äôm not much better than my very own simple partitioning tree model :D"
  },
  {
    "objectID": "posts/2024-11-17_URLs_Classification_Example/index.html#references",
    "href": "posts/2024-11-17_URLs_Classification_Example/index.html#references",
    "title": "Classifying URLs",
    "section": "References",
    "text": "References\nFor today, only the recommended list of potential datasets for Cybersecurity.\nThe rest is of my own doing. Of course, the Internet, Stack Overflow, Wikipedia, etc. as usual."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html",
    "href": "posts/2024-12-08_A_new_project/index.html",
    "title": "A new project",
    "section": "",
    "text": "Ever since I read about the concept in M. Mitchell‚Äôs book ‚ÄúComplexity The emerging science at the edge of order and chaos‚Äù some time last year (I think around this time of the year‚Ä¶), I have been thinking about this, in the background of my head.\n\n\n\nWhat piqued me curiosity\n\n\nThe weird strings above, the 11##10### thing, might mean nothing to most right now (you have to look a bit further into it all, and I‚Äôll probably try and explain some of it in the future), but it was a revelation to me when I first read it.\nSo yes, I‚Äôve had other fish to fry for some time, but now it feels like I might just have the mental space to shift my focus a bit‚Ä¶\n\n\nSo here is my upcoming project, explained in one picture:\n\n\n\nMy new project in one picture\n\n\n(By the way, a personal note here: buying that left book in physical format from Springer was one ‚Äútough cookie‚Äù, thank goodness I‚Äôm motivated, it‚Äôs quite possibly the priciest book I ever bought from my own pocket, in ‚Ç¨-per-page‚Ä¶ Oh well: It looks it still was the right call for me :D)\n\n\n\nAs I said, I‚Äôve been a bit busy. Full-time job, MSc paper (success!), then summer, learning other stuff, (did I mention full-time job? :D)‚Ä¶ But it is time.\nI also have been thinking for quite some time I should try my hand eventually at creating my own R Package. This was all the more true after the last R conferences I attended recently, where it looks like ‚Äúeveryone is doing it‚Äù in the R (mostly academic) community‚Ä¶ So why not me?\nPlus, I have an idea or two. So what if I‚Äôm not the greatest coder out there? I still do have some tricks in my sleeves ;) I have proved (at least to myself) I can do highly distributed processing using (among other things) R and create my own thing. (My very own algorithm, that was.)\nPlus, I‚Äôm into ML just as much as the next person, but I‚Äôve also played quite a bit with Genetic Algorithms recently. And I believe I have all it takes to put that to good use here. (I‚Äôm just a bit sad this will not involve Network Graphs, the way I have it designed (yet, anyway :D).) I believe I understand how the LCS algorithms might be particularly useful in their own specific way. I can see in my head how they must work, what makes them different, all in spite of not having written one line of code yet.\nNow, it might take a while, indeed. Why, with the Holiday season coming, the day job and all. But I have a sort of a plan in mind, already an architecture (in my head, for now), examples of how I would want to validate the implementation (that last thing, one example with application to cybersecurity and logs classification, in particular, woke me up in the middle of the night a couple of weeks back).\nAnd R packages, from what I have read thus far, are not ‚Äúmagic‚Äù. It‚Äôs going to be work, for sure, but I don‚Äôt see anything I can‚Äôt manage. If anything, it‚Äôs less complicated than I thought. I‚Äôve already played with testthat, microbenchmark, I‚Äôve always separated my code in functions, separated R and C++ code, all that‚Ä¶ So yeah, I think I‚Äôm up to the task.\nAnd finally, a note about the ‚Äúwhy now‚Äù: I can‚Äôt find it done yet!! Which to me is quite incredible. I have found this niche, that nobody (in the R community) has deemed relevant enough thus far, and I am willing to put the work towards filling that niche!\n\n\n\nThis here today is me announcing, basically, my intention to create and (hopefully) get my future new RLCS package onto CRAN. I know, I know, I‚Äôm getting WAAAAY ahead of myself here.\nAnd I realize me publishing this entry might very well mean someone beats me to it. If that happens, well‚Ä¶ I‚Äôm already convinced my implementation will be ‚Äúcompetitive‚Äù, so‚Ä¶ let‚Äôem!\n(Plus, why would anyone decide to go for this now? It would just make no sense whatsoever - if not to bother me. If that‚Äôs you: Just give me a few months, and you‚Äôll save yourself the trouble :D)\n\n\n\nIt turns out, for some reason, I know I will. Obviously, I don‚Äôt ‚Äúknow know‚Äù, it‚Äôs more of a feeling.\nI am enthused, to begin with. I have the knowledge. Time is not an issue, although it will take me probably a few months (my best estimate right now, given my current known agenda, is 3-4 months for a functional package, plus whatever time it takes for submission to CRAN of a ‚Äúv001‚Äù).\nMoreover, I somehow needed a new, rather difficult, interesting long-term personal objective. I feel this will help me get in the ‚Äúflow‚Äù, which is a great feeling (but hard to come by).\nAlso, I have this crazy idea that, once the thing works, I can dive further into it and study it towards a bigger goal, maybe research, ideally even (who knows) a PhD‚Ä¶?\n\n\n\nI‚Äôve done my first (of two) presentation about ‚ÄúBackground of ML for Cybersecurity‚Äù. I actually had trouble with some of the demos during the first session :S But not because of the demos themselves, just, ‚Äúheat of the moment‚Äù, computer resources, demo effect, and so on. Nothing major.\nThankfully, I get a second chance, as there is a second session coming. And I have time to prepare some more examples, so that‚Äôs good too, the second session will be all-the-more interesting.\nBut because I have some time, I‚Äôm making a pause there and re-focusing on this new project of mine as a personal interest thing.\n\n\n\nI realize nobody cares, but heck: I do. I need to ‚Äúmigrate‚Äù, move everything (while reviewing each thing) from the old blog to this new setup, because.. Well, because this platform is more convenient, and ‚Äì let‚Äôs be honest ‚Äì cheaper‚Ä¶ After all, it‚Äôs one thing to write for one own‚Äôs pleasure, and quite another to spend money with no return year after year just to maintain it.\nSo yes, I need to organize myself to minimize future costs a bit (it just is the sensible thing to do, economically).\n\n\n\n**This is important: I still don‚Äôt really know why this family of algorithms have received sooo little attention**, beyond the fact that ‚ÄúConnectionism‚Äù has received a lot of said attention (deservingly, for sure).\nBut I‚Äôm curious about whether LCS can be made (ideally equally) valuable. And I have the personal conviction that I am in the right position to dig further into it.\nAnd so it is time, I‚Äôm in an ideal position, and I‚Äôm motivated.\nNow all I have to do is‚Ä¶ Start!\n(To start hear means also put thoughts to paper, design, code, test, document‚Ä¶ Don‚Äôt expect lots of news too soon, either! I‚Äôm not in a hurry, nobody should be: this thing has been known since the 70‚Äôs and it looks like few - aside from noted exceptions - have cared about it thus far‚Ä¶)\n\n\n\nThis is the best intro explaining the algorithm that I found thus far - and if anything it confirmed I was on the right path. It just makes a lot of sense to me!"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#the-new-project",
    "href": "posts/2024-12-08_A_new_project/index.html#the-new-project",
    "title": "A new project",
    "section": "",
    "text": "So here is my upcoming project, explained in one picture:\n\n\n\nMy new project in one picture\n\n\n(By the way, a personal note here: buying that left book in physical format from Springer was one ‚Äútough cookie‚Äù, thank goodness I‚Äôm motivated, it‚Äôs quite possibly the priciest book I ever bought from my own pocket, in ‚Ç¨-per-page‚Ä¶ Oh well: It looks it still was the right call for me :D)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#why-now-why-me",
    "href": "posts/2024-12-08_A_new_project/index.html#why-now-why-me",
    "title": "A new project",
    "section": "",
    "text": "As I said, I‚Äôve been a bit busy. Full-time job, MSc paper (success!), then summer, learning other stuff, (did I mention full-time job? :D)‚Ä¶ But it is time.\nI also have been thinking for quite some time I should try my hand eventually at creating my own R Package. This was all the more true after the last R conferences I attended recently, where it looks like ‚Äúeveryone is doing it‚Äù in the R (mostly academic) community‚Ä¶ So why not me?\nPlus, I have an idea or two. So what if I‚Äôm not the greatest coder out there? I still do have some tricks in my sleeves ;) I have proved (at least to myself) I can do highly distributed processing using (among other things) R and create my own thing. (My very own algorithm, that was.)\nPlus, I‚Äôm into ML just as much as the next person, but I‚Äôve also played quite a bit with Genetic Algorithms recently. And I believe I have all it takes to put that to good use here. (I‚Äôm just a bit sad this will not involve Network Graphs, the way I have it designed (yet, anyway :D).) I believe I understand how the LCS algorithms might be particularly useful in their own specific way. I can see in my head how they must work, what makes them different, all in spite of not having written one line of code yet.\nNow, it might take a while, indeed. Why, with the Holiday season coming, the day job and all. But I have a sort of a plan in mind, already an architecture (in my head, for now), examples of how I would want to validate the implementation (that last thing, one example with application to cybersecurity and logs classification, in particular, woke me up in the middle of the night a couple of weeks back).\nAnd R packages, from what I have read thus far, are not ‚Äúmagic‚Äù. It‚Äôs going to be work, for sure, but I don‚Äôt see anything I can‚Äôt manage. If anything, it‚Äôs less complicated than I thought. I‚Äôve already played with testthat, microbenchmark, I‚Äôve always separated my code in functions, separated R and C++ code, all that‚Ä¶ So yeah, I think I‚Äôm up to the task.\nAnd finally, a note about the ‚Äúwhy now‚Äù: I can‚Äôt find it done yet!! Which to me is quite incredible. I have found this niche, that nobody (in the R community) has deemed relevant enough thus far, and I am willing to put the work towards filling that niche!"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#the-outcome",
    "href": "posts/2024-12-08_A_new_project/index.html#the-outcome",
    "title": "A new project",
    "section": "",
    "text": "This here today is me announcing, basically, my intention to create and (hopefully) get my future new RLCS package onto CRAN. I know, I know, I‚Äôm getting WAAAAY ahead of myself here.\nAnd I realize me publishing this entry might very well mean someone beats me to it. If that happens, well‚Ä¶ I‚Äôm already convinced my implementation will be ‚Äúcompetitive‚Äù, so‚Ä¶ let‚Äôem!\n(Plus, why would anyone decide to go for this now? It would just make no sense whatsoever - if not to bother me. If that‚Äôs you: Just give me a few months, and you‚Äôll save yourself the trouble :D)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#will-i-manage",
    "href": "posts/2024-12-08_A_new_project/index.html#will-i-manage",
    "title": "A new project",
    "section": "",
    "text": "It turns out, for some reason, I know I will. Obviously, I don‚Äôt ‚Äúknow know‚Äù, it‚Äôs more of a feeling.\nI am enthused, to begin with. I have the knowledge. Time is not an issue, although it will take me probably a few months (my best estimate right now, given my current known agenda, is 3-4 months for a functional package, plus whatever time it takes for submission to CRAN of a ‚Äúv001‚Äù).\nMoreover, I somehow needed a new, rather difficult, interesting long-term personal objective. I feel this will help me get in the ‚Äúflow‚Äù, which is a great feeling (but hard to come by).\nAlso, I have this crazy idea that, once the thing works, I can dive further into it and study it towards a bigger goal, maybe research, ideally even (who knows) a PhD‚Ä¶?"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#what-about-the-sessions-on-ml",
    "href": "posts/2024-12-08_A_new_project/index.html#what-about-the-sessions-on-ml",
    "title": "A new project",
    "section": "",
    "text": "I‚Äôve done my first (of two) presentation about ‚ÄúBackground of ML for Cybersecurity‚Äù. I actually had trouble with some of the demos during the first session :S But not because of the demos themselves, just, ‚Äúheat of the moment‚Äù, computer resources, demo effect, and so on. Nothing major.\nThankfully, I get a second chance, as there is a second session coming. And I have time to prepare some more examples, so that‚Äôs good too, the second session will be all-the-more interesting.\nBut because I have some time, I‚Äôm making a pause there and re-focusing on this new project of mine as a personal interest thing."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#and-what-about-the-migration-of-the-old-blog",
    "href": "posts/2024-12-08_A_new_project/index.html#and-what-about-the-migration-of-the-old-blog",
    "title": "A new project",
    "section": "",
    "text": "I realize nobody cares, but heck: I do. I need to ‚Äúmigrate‚Äù, move everything (while reviewing each thing) from the old blog to this new setup, because.. Well, because this platform is more convenient, and ‚Äì let‚Äôs be honest ‚Äì cheaper‚Ä¶ After all, it‚Äôs one thing to write for one own‚Äôs pleasure, and quite another to spend money with no return year after year just to maintain it.\nSo yes, I need to organize myself to minimize future costs a bit (it just is the sensible thing to do, economically)."
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#conclusions",
    "href": "posts/2024-12-08_A_new_project/index.html#conclusions",
    "title": "A new project",
    "section": "",
    "text": "**This is important: I still don‚Äôt really know why this family of algorithms have received sooo little attention**, beyond the fact that ‚ÄúConnectionism‚Äù has received a lot of said attention (deservingly, for sure).\nBut I‚Äôm curious about whether LCS can be made (ideally equally) valuable. And I have the personal conviction that I am in the right position to dig further into it.\nAnd so it is time, I‚Äôm in an ideal position, and I‚Äôm motivated.\nNow all I have to do is‚Ä¶ Start!\n(To start hear means also put thoughts to paper, design, code, test, document‚Ä¶ Don‚Äôt expect lots of news too soon, either! I‚Äôm not in a hurry, nobody should be: this thing has been known since the 70‚Äôs and it looks like few - aside from noted exceptions - have cared about it thus far‚Ä¶)"
  },
  {
    "objectID": "posts/2024-12-08_A_new_project/index.html#references",
    "href": "posts/2024-12-08_A_new_project/index.html#references",
    "title": "A new project",
    "section": "",
    "text": "This is the best intro explaining the algorithm that I found thus far - and if anything it confirmed I was on the right path. It just makes a lot of sense to me!"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "This is probably one of the last entries from my preparation to introduce ‚ÄúBackground of ML for Cybersecurity‚Äù. This time, it‚Äôs really about what should probably have been the first entry of the series. Also, it‚Äôs not really put in context of Cybersecurity: I‚Äôm just trying to show one needs not be afraid about the math.\nI‚Äôm having lots of doubts about this one, too: Can I even use the ‚ÄúMachine Learning‚Äù tag? After all, this predates ML by quite a bit. It‚Äôs really of the realm of statistics. Then again, the limit of what qualifies as ML and what doesn‚Äôt is somewhat blurry (at least to me).\nAnd some of it is very very simple, and maybe shouldn‚Äôt warrant writing about it. But I like to write things down, it helps organize my thoughts sometimes, and I believe in the idea that really understanding the basics is helpful to grasp concepts when things get more complicated.\n\n\nIF (and that‚Äôs a reasonably big if) you can find a linear relationship between two numerical vectors, then using a linear regression can help ‚Äúencode‚Äù the whole pair of vectors through ‚Äújust‚Äù two numbers: A slope, and an intercept.\nIn effect, you‚Äôre ‚Äúmodelling‚Äù a relationship - and in doing so, you‚Äôre actually compressing information.\nMore to the point, if you have an intuition that such relationship holds true for other points you were not given, then you can interpolate (if the new points are in the range of original vectors - otherwise it‚Äôs called ‚Äúextrapolation‚Äù) an expected output from a given input.\nIn other words: If you know (or expect) there is a linear (straight line) relationship between a webserver load and number of concurrently opened sessions, you could estimate a load (say % CPU) from knowing only the number of users currently connected (or the other way around, obviously). You‚Äôd expect the load to grow with the number of users.\nThe concept of regression (linear or otherwise) are important in ML. It‚Äôs a core part of most models. You doubt? Let me put it this way: Regression is a core part of how training a neural network works. There. Believe me now? (I guess I just justified myself in tagging this entry as Machine Learning, after all.)\n\n\n\nWe‚Äôll start off very easy today. Imagine to begin with you only have two points. So two pairs\\((x_1, y_1), (x_2, y_2)\\) of coordinates then. IF (again, big IF) you somehow expects a straight line could be used to estimate a third \\(y_3\\) from a third \\(x_3\\) coordinate in the range of the two original points‚Ä¶ How can you estimate said value of \\(y_3\\).\nWell, it‚Äôs basic (elementary? high school? Idk) math, you want to find \\(a, b\\) in the following:\n\\[\ny = ax + b\n\\]\nThere are two numbers to find (a slope, and an intercept), and we have two points. That‚Äôs a system of two equations. But instead of just doing the math, let‚Äôs think about this from a conceptual perspective.\nYou can probably skip this, as it‚Äôs really very basic, but I like to make sure I understand things, not just use the math I can find out there, and so I‚Äôm going to explain it nevertheless.\nWhat is a ‚Äúslope‚Äù?\nThink of a bicycle ride, and you‚Äôre faced with a 8% upwards (so ‚Äúpositive‚Äù) slope; what does that mean? That for every 100 meters you advance horizontally, you should expect to gain 8 meters in elevation. So if you gain 8 units in the y direction, you have moved 100 units in the x direction.\nWith two points: \\(y_2 - y_1 = 8, x_2 - x_1 = 100\\). And you get to the slope by dividing both numbers (which is why we expressed the slope in percentage). So you need then:\n\\[\na = slope = {(y_2 - y_1) \\over (x_2 - x_1)}\n\\]\nNot soooo misterious now, is it? If the slope is downwards, \\(y_2 &lt; y_1\\) and \\(a &lt; 0\\), that‚Äôs all.\nAnd what is the ‚Äúintercept‚Äù?\nIf you show lines on a two dimensional graph, you often will see the \\(y\\) and \\(x\\) axis. The ‚Äúintercept‚Äù is simply the point at which our line crosses (‚Äúintercepts‚Äù) the \\(y\\) axis. Which happens when \\(x = 0\\).\nAnd by now, if we take any of our points, we have the following bits \\(y_1, a, x_1\\) for our equation \\(y = ax + b\\). Can we get to \\(b\\)?\n\\[\nb = y_1 - a x_1\n\\]So that for \\(x = 0\\), we have \\(b\\) as the value of \\(y\\). Which is what we were looking for.\nThis was very very very basic stuff. But hopefully for those that don‚Äôt do math in their day-to-day life, or those that use formulas without thinking (or use Excel to estimate these things, if at all), or simply as a refresher‚Ä¶ I don‚Äôt know. Sorry if that was boring.\n\n## Suppose you have any two points:\nmy_x &lt;- c(1.5, 2.5)\nmy_y &lt;- c(5, 2)\n\n# Line goes through two points\n## By definition of \"slope\":\nmy_line_slope &lt;- (my_y[2] - my_y[1]) / (my_x[2]- my_x[1])\n## Then just replace with one point to get intercept:\nmy_intercept &lt;- my_y[1] - (my_line_slope * my_x[1])\n\ncalculate_resulting_y &lt;- function(x) {\n    my_line_slope * x + my_intercept\n}\n\n## Say then we have any value of x (\"independent variable\"):\nmy_interpolation_x_set &lt;- seq(0, 5, 0.1)\n## In a perfect World, we could then get any dependent value:\nmy_interpolation_y_set &lt;- sapply(my_interpolation_x_set, calculate_resulting_y)\n\nplot(my_interpolation_y_set ~ my_interpolation_x_set, col = \"blue\", type=\"l\")\npoints(my_y ~ my_x, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nIn the above, we took a pretty big leap of faith: We just somehow knew/assumed that two points would represent a linear relationship.\nBut we‚Äôd probably feel more confident if we had more points to confirm our expectations first.\nToday we‚Äôll stay with the ‚ÄúSimple Linear Regression‚Äù, which is nicely explained in the Wikipedia.\nWe want to find \\(\\alpha, \\beta\\) that best describe not two points but instead estimate a line for several of them, so that we solve \\(y = \\alpha + \\beta x\\) that best estimate all \\(x_i, y_i\\) pairs we‚Äôre given (provided they look like a straight line).\nAnd I‚Äôve said ‚Äúestimate‚Äù twice above, as there will be some error, and that‚Äôs key here: We essentially try to minimize the error that our estimated \\(\\alpha, \\beta\\) introduce, for each point. Written ‚Äúfancily‚Äù:\n\\[\n\\widehat{\\epsilon}_i = y_i - (\\alpha + \\beta x_i), \\forall i \\in [1..n], n \\in \\mathbb{N}\n\\]\nWhere n is the number of your available points‚Ä¶\n\nMinimizing the error is an important concept in supervised machine learning.\n\nThen using the ‚ÄúSum of Square‚Äù of the residuals, we‚Äôre going to try to minimize that.\n\n\n\nI will take the time to dive into this a bit, as it is relevant to understand for other cases. Although the math is better explained here, that approach of minimizing sum of squares is useful in other contexts and so here goes.\nSo today we are trying to ‚Äúfit‚Äù a line to a set of points that are not necessarily exactly on said line (see ‚Äúthe result‚Äù below). But where do we start? How do we go about finding one line out of an infinite set of possible lines?\nMore or less, we find the parameters for our line equation that minimizes overall distance from all the points. So we try to minimize the sum of the error of our line from each point. It is a minimization exercise, but sometimes the points will be under the line, and others they‚Äôll be above. To correct for that, we actually minimize the sum of distances, each one squared! That way, all values are positive, and we really try to minimize something.\nThere is another important point hidden right here: The key to understand ‚ÄúGradient Descent‚Äù!\nAs we will see with the ‚Äúresults‚Äù below, the errors, when squared, are shaped in a sort of U. But what‚Äôs important is that the function behind that (parabolic) shape is that it‚Äôs differentiable.\nDifferentiating (that‚Äôs calculus) here will mean that we know in which direction (up, down, horizontal) said curve goes for a given point on the x axis. If we know that, we know that if the curve goes upwards, to minimize the thing, we want to go in the opposite direction.\nAnd that‚Äôs exactly what ‚Äúdescending the gradient‚Äù is all about (although in multivariate settings: A gradient in vector calculus is ‚Äúthe direction and the rate of fastest increase‚Äù, so to ‚Äúdescend a gradient‚Äù, you want to move in the opposite direction).\nFor linear regression, it‚Äôs cool because we can do partial derivatives (as shown on the referenced Wiki page above) to find our \\(\\alpha\\) and \\(\\beta\\) parameters that describe the line that ‚Äúbest fit the data‚Äù.\nIt‚Äôs quite clever, mind you: You minimize the error of your predicted value compared to the actual value. That‚Äôs how your machine can learn! But it‚Äôs also what people have been using to train Neural Networks!\nFor today, let‚Äôs just store the following information: The ‚ÄúLeast Square Minimization‚Äù can help find a minimum error through differentiation.\nAnd for a future conversation: Gradient Descent (hidden in today‚Äôs Sum of Square Minimization) is one of the two mathematical keys for back-propagation. (And back-propagation was the before and after of connectionism in Machine Learning theory).\nAlright, let‚Äôs move on and return to our very simple example.\n\n\n\nRemember how we said at some point that in ML, more data points is often better?\nWe‚Äôre going to find the line that best fits a set of points (I know a simple straight line will work here, because I‚Äôm the one generating said line‚Ä¶ :D)\nWe‚Äôre also going to show the square of errors, how it looks like a U shape, and how it‚Äôs clear there is a minimum to it‚Ä¶\n\n## Some points that can be used:\nmy_regression_x_set &lt;- seq(0, 5, 0.1) + rnorm(51,mean = 0, sd = 0.2)\nmy_regression_y_set &lt;- my_interpolation_y_set + rnorm(51, mean = 0, sd = 0.2)\n\n## SIMPLE linear regression. Using Least Squares distance.\n## Key idea: Minimize differences.\n## Find minimum for error function using differentiation.\n## Final equations here instead of step by step explaining how to get there.\n\n## Just follow the math:\nmean_reg_x &lt;- mean(my_regression_x_set)\nmean_reg_y &lt;- mean(my_regression_y_set)\n\ndev_x &lt;- (my_regression_x_set - mean_reg_x)\ndev_y &lt;- (my_regression_y_set - mean_reg_y)\n\nbeta_est &lt;- sum(dev_x * dev_y) / sum(dev_x^2)\nalpha_est &lt;- mean_reg_y - (beta_est * mean_reg_x)\n\nplot(my_regression_y_set ~ my_regression_x_set)\n## alpha & beta can be confusing, I usually use Beta as multipliers of X...\nabline(a = alpha_est, b = beta_est, col=\"blue\")\n\n\n\n\n\n\n\n## Importantly, squared error is differentiable and has a global minimum\n## \"easily\". Related to \"Gradient Descent\"\nerr_x &lt;- my_regression_y_set - (alpha_est + my_regression_x_set * beta_est)\nerr_y &lt;- sapply(err_x, \\(x) x^2)\n\nplot(err_y ~ err_x)\n\n\n\n\n\n\n\n\nAnd that‚Äôs it! We‚Äôve used the math (skipping some steps), to show one can use it to do a linear regression (although nowadays all that stuff is available with one command, if not directly, then through packages).\nSo here we‚Äôve shown a downward slope: Let‚Äôs put it in context of a potential real-world application: Maybe our x axis represented the number of users connected to our system, and the y axis some number to represent the available resources (spare CPU or something) on a given server. If you know a linear relationship applies, you can estimate at which point you will reach 100% CPU‚Ä¶ (I could have started with that, sorry.)\nSo in the future, if you see a clear straight line between two things, well, you could use the above not-scary-at-all math approach to ‚Äúpredict‚Äù what would happen if you move along the x axis.\nLast note about the math: in this simple case, if you look at the code, we‚Äôve in fact used two statistics concepts to do the calculations: the means of the x and y axis, and the ‚Äúdeviations‚Äù of each point to said means.\nDoes it not make some intuitive sense that the line that best fits the points is related to the means and deviations of the points to said means? :)\n\n\n\nIn the above, we‚Äôve used deviations and means. These are basic concepts from statistics. And in the introduction, we have mentioned something about ‚Äúmodels‚Äù and ‚Äúcompression‚Äù. Which is what it is: Statistics are NOT the real world. And they can be misused. Here the 2 most common examples to illustrate how you can go astray with using statistics without looking at the data.\nLet‚Äôs illustrate just that, with a couple of typical (like, VERY typical) examples:\n\n\n\n\n\n\n\n\n\nAnd if it‚Äôs not clear enough, all these here below have the same mean and standard deviation:\n\n\n\n\n\n\n\n\n\n[1] \"Mean x Dino: 47.8322528169014\"\n\n\n[1] \"Mean x Bullseye: 47.8308231552178\"\n\n\n[1] \"SD x Dino: 16.7651420391168\"\n\n\n[1] \"SD x Bullseye: 16.7692394934267\"\n\n\nSee how they are basically the same numbers?\nStatistics are great, useful and very important today (and have been for quite a while, I‚Äôd argue). They‚Äôre just not always the right solution (neither is ML in a larger sense, mind you).\nAlways look at the data!\n\n\n\nWe‚Äôve gone from really REALLY simple stuff all the way to mentioning differentiation, gradient descent, statistics‚Ä¶\nAnd we‚Äôve skipped steps! (i.e.¬†solving systems of equations, which can be represented as matrices, which is relevant for completely different reasons :D)\nNot too shabby, after all‚Ä¶\n\nI‚Äôd like to go into Logistic Regression and Neural Networks a bit in a future entries. Even discuss a bit the history of ML, maybe. And that would conclude my preparation for my sessions about ‚ÄúML Background for Cybersecurity‚Äù. Surely there is more to it all, but if I manage to convey a few key concepts to my colleagues, I‚Äôll be very very happy. And this here is me trying.\nBut after that, I‚Äôll shift gears and focus on a personal project I have had in mind for some time and that is taking shape: It involves writing an R package, for a set of ML algorithms that for reasons I don‚Äôt quite understand have not received as much attention as I personally think they should. To be continued!\n\n\n\n\nThe Wikipedia for Simple Linear Regression does help.\nHere about the Gradient.\nThe math for the simple linear regression we‚Äôve used today.\nThen the more advanced discussion on Linear Regression hopefully can be followed."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#why-linear-regression-in-the-first-place",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#why-linear-regression-in-the-first-place",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "IF (and that‚Äôs a reasonably big if) you can find a linear relationship between two numerical vectors, then using a linear regression can help ‚Äúencode‚Äù the whole pair of vectors through ‚Äújust‚Äù two numbers: A slope, and an intercept.\nIn effect, you‚Äôre ‚Äúmodelling‚Äù a relationship - and in doing so, you‚Äôre actually compressing information.\nMore to the point, if you have an intuition that such relationship holds true for other points you were not given, then you can interpolate (if the new points are in the range of original vectors - otherwise it‚Äôs called ‚Äúextrapolation‚Äù) an expected output from a given input.\nIn other words: If you know (or expect) there is a linear (straight line) relationship between a webserver load and number of concurrently opened sessions, you could estimate a load (say % CPU) from knowing only the number of users currently connected (or the other way around, obviously). You‚Äôd expect the load to grow with the number of users.\nThe concept of regression (linear or otherwise) are important in ML. It‚Äôs a core part of most models. You doubt? Let me put it this way: Regression is a core part of how training a neural network works. There. Believe me now? (I guess I just justified myself in tagging this entry as Machine Learning, after all.)"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#two-points-interextrapolation",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#two-points-interextrapolation",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "We‚Äôll start off very easy today. Imagine to begin with you only have two points. So two pairs\\((x_1, y_1), (x_2, y_2)\\) of coordinates then. IF (again, big IF) you somehow expects a straight line could be used to estimate a third \\(y_3\\) from a third \\(x_3\\) coordinate in the range of the two original points‚Ä¶ How can you estimate said value of \\(y_3\\).\nWell, it‚Äôs basic (elementary? high school? Idk) math, you want to find \\(a, b\\) in the following:\n\\[\ny = ax + b\n\\]\nThere are two numbers to find (a slope, and an intercept), and we have two points. That‚Äôs a system of two equations. But instead of just doing the math, let‚Äôs think about this from a conceptual perspective.\nYou can probably skip this, as it‚Äôs really very basic, but I like to make sure I understand things, not just use the math I can find out there, and so I‚Äôm going to explain it nevertheless.\nWhat is a ‚Äúslope‚Äù?\nThink of a bicycle ride, and you‚Äôre faced with a 8% upwards (so ‚Äúpositive‚Äù) slope; what does that mean? That for every 100 meters you advance horizontally, you should expect to gain 8 meters in elevation. So if you gain 8 units in the y direction, you have moved 100 units in the x direction.\nWith two points: \\(y_2 - y_1 = 8, x_2 - x_1 = 100\\). And you get to the slope by dividing both numbers (which is why we expressed the slope in percentage). So you need then:\n\\[\na = slope = {(y_2 - y_1) \\over (x_2 - x_1)}\n\\]\nNot soooo misterious now, is it? If the slope is downwards, \\(y_2 &lt; y_1\\) and \\(a &lt; 0\\), that‚Äôs all.\nAnd what is the ‚Äúintercept‚Äù?\nIf you show lines on a two dimensional graph, you often will see the \\(y\\) and \\(x\\) axis. The ‚Äúintercept‚Äù is simply the point at which our line crosses (‚Äúintercepts‚Äù) the \\(y\\) axis. Which happens when \\(x = 0\\).\nAnd by now, if we take any of our points, we have the following bits \\(y_1, a, x_1\\) for our equation \\(y = ax + b\\). Can we get to \\(b\\)?\n\\[\nb = y_1 - a x_1\n\\]So that for \\(x = 0\\), we have \\(b\\) as the value of \\(y\\). Which is what we were looking for.\nThis was very very very basic stuff. But hopefully for those that don‚Äôt do math in their day-to-day life, or those that use formulas without thinking (or use Excel to estimate these things, if at all), or simply as a refresher‚Ä¶ I don‚Äôt know. Sorry if that was boring.\n\n## Suppose you have any two points:\nmy_x &lt;- c(1.5, 2.5)\nmy_y &lt;- c(5, 2)\n\n# Line goes through two points\n## By definition of \"slope\":\nmy_line_slope &lt;- (my_y[2] - my_y[1]) / (my_x[2]- my_x[1])\n## Then just replace with one point to get intercept:\nmy_intercept &lt;- my_y[1] - (my_line_slope * my_x[1])\n\ncalculate_resulting_y &lt;- function(x) {\n    my_line_slope * x + my_intercept\n}\n\n## Say then we have any value of x (\"independent variable\"):\nmy_interpolation_x_set &lt;- seq(0, 5, 0.1)\n## In a perfect World, we could then get any dependent value:\nmy_interpolation_y_set &lt;- sapply(my_interpolation_x_set, calculate_resulting_y)\n\nplot(my_interpolation_y_set ~ my_interpolation_x_set, col = \"blue\", type=\"l\")\npoints(my_y ~ my_x, col = \"red\")"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#multiple-points-with-a-linear-relationship",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#multiple-points-with-a-linear-relationship",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "In the above, we took a pretty big leap of faith: We just somehow knew/assumed that two points would represent a linear relationship.\nBut we‚Äôd probably feel more confident if we had more points to confirm our expectations first.\nToday we‚Äôll stay with the ‚ÄúSimple Linear Regression‚Äù, which is nicely explained in the Wikipedia.\nWe want to find \\(\\alpha, \\beta\\) that best describe not two points but instead estimate a line for several of them, so that we solve \\(y = \\alpha + \\beta x\\) that best estimate all \\(x_i, y_i\\) pairs we‚Äôre given (provided they look like a straight line).\nAnd I‚Äôve said ‚Äúestimate‚Äù twice above, as there will be some error, and that‚Äôs key here: We essentially try to minimize the error that our estimated \\(\\alpha, \\beta\\) introduce, for each point. Written ‚Äúfancily‚Äù:\n\\[\n\\widehat{\\epsilon}_i = y_i - (\\alpha + \\beta x_i), \\forall i \\in [1..n], n \\in \\mathbb{N}\n\\]\nWhere n is the number of your available points‚Ä¶\n\nMinimizing the error is an important concept in supervised machine learning.\n\nThen using the ‚ÄúSum of Square‚Äù of the residuals, we‚Äôre going to try to minimize that."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#sum-of-square-minimization",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#sum-of-square-minimization",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "I will take the time to dive into this a bit, as it is relevant to understand for other cases. Although the math is better explained here, that approach of minimizing sum of squares is useful in other contexts and so here goes.\nSo today we are trying to ‚Äúfit‚Äù a line to a set of points that are not necessarily exactly on said line (see ‚Äúthe result‚Äù below). But where do we start? How do we go about finding one line out of an infinite set of possible lines?\nMore or less, we find the parameters for our line equation that minimizes overall distance from all the points. So we try to minimize the sum of the error of our line from each point. It is a minimization exercise, but sometimes the points will be under the line, and others they‚Äôll be above. To correct for that, we actually minimize the sum of distances, each one squared! That way, all values are positive, and we really try to minimize something.\nThere is another important point hidden right here: The key to understand ‚ÄúGradient Descent‚Äù!\nAs we will see with the ‚Äúresults‚Äù below, the errors, when squared, are shaped in a sort of U. But what‚Äôs important is that the function behind that (parabolic) shape is that it‚Äôs differentiable.\nDifferentiating (that‚Äôs calculus) here will mean that we know in which direction (up, down, horizontal) said curve goes for a given point on the x axis. If we know that, we know that if the curve goes upwards, to minimize the thing, we want to go in the opposite direction.\nAnd that‚Äôs exactly what ‚Äúdescending the gradient‚Äù is all about (although in multivariate settings: A gradient in vector calculus is ‚Äúthe direction and the rate of fastest increase‚Äù, so to ‚Äúdescend a gradient‚Äù, you want to move in the opposite direction).\nFor linear regression, it‚Äôs cool because we can do partial derivatives (as shown on the referenced Wiki page above) to find our \\(\\alpha\\) and \\(\\beta\\) parameters that describe the line that ‚Äúbest fit the data‚Äù.\nIt‚Äôs quite clever, mind you: You minimize the error of your predicted value compared to the actual value. That‚Äôs how your machine can learn! But it‚Äôs also what people have been using to train Neural Networks!\nFor today, let‚Äôs just store the following information: The ‚ÄúLeast Square Minimization‚Äù can help find a minimum error through differentiation.\nAnd for a future conversation: Gradient Descent (hidden in today‚Äôs Sum of Square Minimization) is one of the two mathematical keys for back-propagation. (And back-propagation was the before and after of connectionism in Machine Learning theory).\nAlright, let‚Äôs move on and return to our very simple example."
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#the-result",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#the-result",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "Remember how we said at some point that in ML, more data points is often better?\nWe‚Äôre going to find the line that best fits a set of points (I know a simple straight line will work here, because I‚Äôm the one generating said line‚Ä¶ :D)\nWe‚Äôre also going to show the square of errors, how it looks like a U shape, and how it‚Äôs clear there is a minimum to it‚Ä¶\n\n## Some points that can be used:\nmy_regression_x_set &lt;- seq(0, 5, 0.1) + rnorm(51,mean = 0, sd = 0.2)\nmy_regression_y_set &lt;- my_interpolation_y_set + rnorm(51, mean = 0, sd = 0.2)\n\n## SIMPLE linear regression. Using Least Squares distance.\n## Key idea: Minimize differences.\n## Find minimum for error function using differentiation.\n## Final equations here instead of step by step explaining how to get there.\n\n## Just follow the math:\nmean_reg_x &lt;- mean(my_regression_x_set)\nmean_reg_y &lt;- mean(my_regression_y_set)\n\ndev_x &lt;- (my_regression_x_set - mean_reg_x)\ndev_y &lt;- (my_regression_y_set - mean_reg_y)\n\nbeta_est &lt;- sum(dev_x * dev_y) / sum(dev_x^2)\nalpha_est &lt;- mean_reg_y - (beta_est * mean_reg_x)\n\nplot(my_regression_y_set ~ my_regression_x_set)\n## alpha & beta can be confusing, I usually use Beta as multipliers of X...\nabline(a = alpha_est, b = beta_est, col=\"blue\")\n\n\n\n\n\n\n\n## Importantly, squared error is differentiable and has a global minimum\n## \"easily\". Related to \"Gradient Descent\"\nerr_x &lt;- my_regression_y_set - (alpha_est + my_regression_x_set * beta_est)\nerr_y &lt;- sapply(err_x, \\(x) x^2)\n\nplot(err_y ~ err_x)\n\n\n\n\n\n\n\n\nAnd that‚Äôs it! We‚Äôve used the math (skipping some steps), to show one can use it to do a linear regression (although nowadays all that stuff is available with one command, if not directly, then through packages).\nSo here we‚Äôve shown a downward slope: Let‚Äôs put it in context of a potential real-world application: Maybe our x axis represented the number of users connected to our system, and the y axis some number to represent the available resources (spare CPU or something) on a given server. If you know a linear relationship applies, you can estimate at which point you will reach 100% CPU‚Ä¶ (I could have started with that, sorry.)\nSo in the future, if you see a clear straight line between two things, well, you could use the above not-scary-at-all math approach to ‚Äúpredict‚Äù what would happen if you move along the x axis.\nLast note about the math: in this simple case, if you look at the code, we‚Äôve in fact used two statistics concepts to do the calculations: the means of the x and y axis, and the ‚Äúdeviations‚Äù of each point to said means.\nDoes it not make some intuitive sense that the line that best fits the points is related to the means and deviations of the points to said means? :)"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#look-at-the-data",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#look-at-the-data",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "In the above, we‚Äôve used deviations and means. These are basic concepts from statistics. And in the introduction, we have mentioned something about ‚Äúmodels‚Äù and ‚Äúcompression‚Äù. Which is what it is: Statistics are NOT the real world. And they can be misused. Here the 2 most common examples to illustrate how you can go astray with using statistics without looking at the data.\nLet‚Äôs illustrate just that, with a couple of typical (like, VERY typical) examples:\n\n\n\n\n\n\n\n\n\nAnd if it‚Äôs not clear enough, all these here below have the same mean and standard deviation:\n\n\n\n\n\n\n\n\n\n[1] \"Mean x Dino: 47.8322528169014\"\n\n\n[1] \"Mean x Bullseye: 47.8308231552178\"\n\n\n[1] \"SD x Dino: 16.7651420391168\"\n\n\n[1] \"SD x Bullseye: 16.7692394934267\"\n\n\nSee how they are basically the same numbers?\nStatistics are great, useful and very important today (and have been for quite a while, I‚Äôd argue). They‚Äôre just not always the right solution (neither is ML in a larger sense, mind you).\nAlways look at the data!"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#conclusions",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#conclusions",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "We‚Äôve gone from really REALLY simple stuff all the way to mentioning differentiation, gradient descent, statistics‚Ä¶\nAnd we‚Äôve skipped steps! (i.e.¬†solving systems of equations, which can be represented as matrices, which is relevant for completely different reasons :D)\nNot too shabby, after all‚Ä¶\n\nI‚Äôd like to go into Logistic Regression and Neural Networks a bit in a future entries. Even discuss a bit the history of ML, maybe. And that would conclude my preparation for my sessions about ‚ÄúML Background for Cybersecurity‚Äù. Surely there is more to it all, but if I manage to convey a few key concepts to my colleagues, I‚Äôll be very very happy. And this here is me trying.\nBut after that, I‚Äôll shift gears and focus on a personal project I have had in mind for some time and that is taking shape: It involves writing an R package, for a set of ML algorithms that for reasons I don‚Äôt quite understand have not received as much attention as I personally think they should. To be continued!"
  },
  {
    "objectID": "posts/2024-11-25_Understanding_Linear_Regression/index.html#references",
    "href": "posts/2024-11-25_Understanding_Linear_Regression/index.html#references",
    "title": "Understanding Linear Regression",
    "section": "",
    "text": "The Wikipedia for Simple Linear Regression does help.\nHere about the Gradient.\nThe math for the simple linear regression we‚Äôve used today.\nThen the more advanced discussion on Linear Regression hopefully can be followed."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Version ‚Äú0‚Äù is done and working. And I will say this, it is already showing some of its power. Let me show you.\n\n\n\nAlright so this is what I have so far:\n\nA basic, fully functional, Michigan-style LCS for Supervised Learning\nA wrapper makes it easier to call the thing for training\nGA (tournament-based parents selection, one-point cross over reproduction, simple mutation) and Covering for rules discovery\nDeletion was somewhat fixed\nAccuracy and other stats work\nPrinting support functions\nNew: It includes subsumption. But calling subsumption affects performance ‚Äì both ways ‚Äì depending on the when/where/how, a known fact. But when used ‚Äì and that‚Äôs an important running decision, by the way ‚Äì, it condensates the relevant information encoded in the system‚Ä¶ Making it, when applicable, much better!\n\n\n\nsubsumption and deletion are costly, but effective to contain the size of the system\n\n\nNew too: Testing can be called now too, which is very helpful to validate the value of the LCS\nThis LCS for SL accepts an environment that, importantly, currently supports only:\n\nBinary classes/actions (so 0 or 1)\nBinary strings as input/states (no more no less) (and I mean, strings)\nAll states must be of equal length (whatever that is)\n\n\nThat‚Äôs on the plus side. On the not-so-great, well:\n\nLittle-to-no error control in there yet\nNext-to-zero documentation so far\nAnd I‚Äôll make a note on performance later in this post.\nImperfect/still-a-bit-disorganized code is probably an understatement.\n\nBut that‚Äôs just what needs to happen next, I guess. Now on to what you can do with this thing.\n\n\n\nSo I‚Äôve already shown that one, but it wasn‚Äôt ‚Äúperfect‚Äù. Here the new version and a few tricks allow me to show how the LCS can be used for data mining.\nSo I give it 70% of the sample space, and it comes up with the following ‚ÄúClassifiers Set‚Äù:\n\n\n\nUsing LCS to discover the hidden rules in the dataset\n\n\nNotice how this is quite exactly what the LCS was supposed to try and discover. And also how it indeed tells us what that particular ‚Äúenvironment‚Äù (dataset and its classes) is all about.\n(Oh, and in this particular exercise, I really did not need to run so many epochs, it‚Äôs just my default hyperparameter setting, but after a hundred or so epochs, it was already done.)\nLet‚Äôs move to a more interesting example.\n\n\n\nThe ‚ÄúIntroduction to Learning Classifier Systems‚Äù book ‚Äì referenced in my first post on LCS ‚Äì explains the algorithm with (among much more explanations) one particular example, called a ‚Äú6-bit multiplexer‚Äù.\nThe rules of that particular example are like so:\n\nyou get a string of 6 bits as input\nthe first two bits point to an address in the resting 4 bits\nthe ‚Äúclass‚Äù of your classifier should be whatever the bit is at the designated address.\n\nA couple of examples:\n\n‚Äú010000‚Äù says ‚ÄúBit 2 of the last 4 bits is the class, so 0‚Äù\n‚Äú110001‚Äù says ‚ÄúBit 4 of the last 4 bits is the class, so 1‚Äù\n‚Äú101101‚Äù says ‚ÄúBit 3 of the last 4 bits is the class, so 0‚Äù\n‚Ä¶\n\nYou get the idea. One aspect of this is meant to show that the LCS SL can somehow recognize things that are interrelated in the data, here how two different parts interact. They call this ‚Äúepistasis‚Äù. For now, suffice to say, it‚Äôs a bit more interesting use-case and we hope our LCS can discover relevant rules.\nAgain, with 70% of the whole dataset (64 entries total, for 6 bits), we train our LCS and hope to identify important rules (ideally, up to 8 perfect rules in this case ‚Äì but that‚Äôs not guaranteed). Here I show one such trained Classifier Set (aka ‚ÄúLCS‚Äù or ‚ÄúLearning Classifier System‚Äù, where the S stands for ‚ÄúSystem‚Äù, implying more than one classifier working together‚Ä¶ but I digress) that gets it almost perfect:\n\n\n\nAlmost perfect MUX6 LCS\n\n\nYou have to look somewhat carefully but you should find 7 of the 8 ‚Äúperfect‚Äù classifiers in there. And I haven‚Äôt checked for this particular example, but if the training set (randomly selected) did contain all the needed cases (probably did), this LCS should also almost cover for the missing classifier (11###0 0). Hint, the following would be the only one that would match for that missing classifier, so they would participate to recommend the action/class, and see how they all recommend class 0 (‚Ä¶):\n\n1####0 0\n#1#0#0 0\n##00#0 0\n##0#10 0\n\nSo in spite of missing one perfect rule (and that‚Äôs also depending on the random environment and non-deterministic nature of the LCS training‚Ä¶), it would work in all testing cases.\nLet‚Äôs move on to a (much) harder use-case.\n\n\n\nNow this was a stretch. the MNIST dataset is nothing like the dummy tests above, for sure. First, I don‚Äôt know how to manually write a perfect program manually for it (the above cases were trivial, comparatively).\nSecond, many trained neural nets on the MNIST dataset don‚Äôt get perfect record (but that‚Äôs understandable, if you spend enough time with that dataset).\nThird, and quite important, the ‚Äústates‚Äù here are numerical strings representing the shade (black-white) of 784 pixels (28*28) integers between 0 and 255. With a simple binary transformation I could end up with my states represented each as 6272 binary strings (8 bits per pixel).\nAnd there are a few thousand entries (samples) per represented number.\nI knew upfront, doing thousands of exposures per sample to get anywhere would take forever.\nFair enough, and so I simplified the problem first. Here is what I did:\n\nCompress the data, from shades to 0-1 values per pixel. I used a threshold to ‚Äúsharpen‚Äù the dataset, so only if the value was &gt; 100 (out of 255) I would set my new pixel to 1, otherwise I set it to 0.\nCompress further, from 28*28 to 7*7 pixels. Each original 4-pixels-square is encoded as only 1 pixel, with value 1 if any of the 4*4 subsquare was one, 0 otherwise.\nThe above gives me 7*7 binary strings, so my states are now 49 bits long.\n\n\n\nI ‚Äúcompress‚Äù the MNIST data before training my LCS\n\n\nClass stays the same, but I also will do a simpler exercise. My LCS should distinguish between classes 0 and 1 only. (This is not an issue, it‚Äôs a choice. I just choose to keep things simple, that‚Äôs all, but the value of the approach is the same, think of it as a one-versus-rest approach if you want). This is in part to make things faster, and in (big) part because the code so far only allows two-classes-output only.\n\nLet me skip directly to the results here:\n\n\n\nShowing a couple of runs of an LCS SL on MNIST simplified dataset\n\n\n(BTW, I meant to write ‚Äúconfusion matrix‚Äù, not ‚Äúcontention table‚Äù above, obviously‚Ä¶ Apologies, I hadn‚Äôt slept much yesterday‚Ä¶)\nI just want to make this clear:\n\nTraining on a total 500 random (sampled) training inputs only (that‚Äôs the size of my environment here), so roughly 250 examples of pictures of Zero and 250 of One\nTraining on these 500 examples takes me between 7.4 and 9.3 minutes (in the above example)\nIt generalizes very well: I end up with an LCS that correctly classified 96 to 97+% of the 3799 sample tests.\n\n\n\n\nOne thing that has worried me the past few days, something I actually knew was a concern with LCS, was performance. I mean speed, here.\nTraining requires exposing the LCS to sufficient training instances to ‚Äúrepresent‚Äù the overall data. Here I believe, in LCS in particular, too many training instances would hinder training because of the speed of processing power needed. I truly believe better chosen training instances are more important than more training instances. Kinda contrary of what Deep Learning would have you think. Although, this belief is, right now, just that: A belief.\nLCS on the other hand, for each training instance, require a lot of ‚Äúepochs‚Äù, so seeing the same data quite a few times. That is because after covering, the GA kicks in and that happens with choosing what best rules are available, which are evolved over time and where ‚Äúbest‚Äù depends on how many matches, how general but specific enough a rule is, whether a rule not only matches but also returns the correct action‚Ä¶ The point is, ideally, you want to train your LCS on a dataset, but circle over that dataset many times. I‚Äôm talking, thousands of times ideally - for each entry.\nThe other aspect of it is, of course, choosing R as a programming language. As much as I am comfortable with it, it is a slow language, if you consider compiled alternatives and such.\nI wanted to dive a bit into the details of what in my current (basic) implementation I could do, and so I ran the thing through ‚Äúprofvis‚Äù quite a few times, separate functions at separate times, then overall, with larger problems, etc.\nOne thing I do a lot, because I‚Äôm using lists for everything right now, is use ‚Äúlapply()‚Äù (and al.). I have tried as much as I could to not use dependencies if I could avoid it. So much so, I believe the only actual dependency I have is the plyr package for the rbind() function, and that‚Äôs for printing stuff‚Ä¶\nNot having too many dependencies is partly motivated by my end goal of producing a package, which I‚Äôd like to make ‚Äúlight‚Äù as much as possible.\nAnyhow, so I use lapply() a lot, but I have also used %in% quite a few times. And in some cases, I mix both and check quite a few instances, quite a few times!\nMatching, which happens a lot, for instance, can have an impact:\n\n\n\nProfiling run-times of mono-thread R interpreted code with LOTS of iterations in there‚Ä¶\n\n\n\n\n\nYou might know this by now: I like to parallelize stuff over my CPU cores/threads. It‚Äôs just a thing I think about when I see my processing times are‚Ä¶ Long. Even if long is a few seconds. And here, we‚Äôre talking many iterations, which on bigger datasets/longer states means minutes.\n(Actually, before I decided to simplify to 49 bits the states of the MNIST exercise, I was working with 784 bits states, and well, it would NOT converge after several minutes‚Ä¶)\nWell, I have to keep working on this, but the cool thing is, an LCS can be pre-trained, and then re-trained.\nSo the LCS (in supervised learning setting for now) is nothing but a set of classifiers, which are rules learnt from examples. You can improve it by exposing it, simply, to more examples. Or let it run more iterations over the same examples!\nEither are valid approaches.\nNow‚Ä¶ What if I ‚Äúsharded‚Äù my data? Say, if I have 7 CPU cores‚Ä¶\nI could do one shorter run over all the data to generate a first ruleset. I could then use at the same time that pretrained LCS, and what if I trained 7 sub-LCS on 7 subsets of the data for more iterations (quite a few more epochs now, but in parallel, each on smaller data samples)?\nWhat if then I loop over that, with some sort of ‚Äúcompaction‚Äù of the 7 newly re-trained sub-LCS and generate a new single base LCS, to then re-distribute to 7 sub processes.\nWhat if I did that a few times?\nI still have to think (seriously, and hard) through all the implications of the simple ‚Äúalgorithm‚Äù I just proposed above. I came up with it quite independently, mind you. And maybe it‚Äôs a very bad idea. (not showing all the training examples hinders the selection and then generalization of classifiers, for one‚Ä¶ So maybe it‚Äôs a stupid idea‚Ä¶ I just haven‚Äôt thought it through yet. For now I do think maybe it does in fact kinda make sense.)\nBUT, I have done it already! One version of my code allows for parallel processing like just described.\nAnd well, in (quite a few) tests with the MNIST example above, for roughly the same overall runtimes (and ‚Äúcompaction‚Äù is costly!) I get a gain of 1-2% of correctly classified samples.\nFrom 96% to 97+%. (It might sound marginal, and indeed I‚Äôm talking about a LOT more processing, but the same runtimes with marginal gains in such near-100% ranges, sounds like potentially valuable).\nWell, indeed, I‚Äôve done that too:\n\n\n\nCPU-based parallel training of my LCS\n\n\n\n\n\nSo I‚Äôve got all the pieces of the puzzle. And it works. And I have validated some marvellous (to me) results. All in a few days.\nWell, not a ‚Äúfew days‚Äù. See, I‚Äôve coded for only a few hours maybe, but I‚Äôve been thinking about this for a long time. And I also think it‚Äôd be unfair to say I was fast: Coding time per-se doesn‚Äôt account for waking up in the middle of the night coming up with my own design to approach the MNIST example. Waking up in the middle of the night, when I have a project like this, somehow happens more often. I have a bit of insomnia, but these projects make it worse, although they also make me more‚Ä¶ Productive.\nI guess what I‚Äôm saying is: coding time might not have been too many hours. But thinking time, or ‚Äúobsessing‚Äù (rather) did account for much more than 4 or 5 days (in 4 to 8h/day). I mean, I have designed everything in between the days of coding, and that started long before.\nAnyhow, to the next step: Moving from a few functions and examples to an actual Package!\nThat‚Äôs what I‚Äôll be up to when I next have time to dedicate to this.\n\n\n\nWell, that is, indeed, when I next have the time. I‚Äôll be disconnecting for a couple of weeks during January. I simply have other personal priorities (all great).\nSo I‚Äôll take this where I left it maybe a bit later. No matter. I have gone through half the book of packages, and I actually am more convinced than ever that this is the perfect opportunity to create a package for me.\n\n\n\nWell, I am just so‚Ä¶ Proud of this thing already!\nSee I had only ever read about the idea until‚Ä¶ Well, basically a week ago. Thanks to the holiday season, and long week-end hours, I can now say I have a working LCS in R.\nNot only that:\n\nI know it‚Äôs already not too bad in terms of what you could expect about performance. I know (from profiling) where I could try to go RCpp. I also have ideas to run it in more ‚Äúhighly‚Äù parallel setups. With more cores on a machine, or‚Ä¶ More machines! (plumbeR, here I come‚Ä¶ Well, later though, that‚Äôs not urgent)\nBut I also know, if I can ‚Äúencode‚Äù a problem into a binary string for binary classification, it turns out LCS are a very valid idea to consider! Just as good as a Neural Network! Heck, in some cases, better!\nI have done some testthat() already, I have several separate functions, very few (almost none) dependencies, the thing is somewhat organized‚Ä¶ So the next step comes rather naturally.\n\nAnyhow, overall, I am happy to report, I do believe this (future) package can prove very valuable to the community!\nAnd at this stage, I already hope I can explain that in future forums - I will convince people, I‚Äôm sure of it.\nSo this is turning out to be as great a project as I had (unreasonably) imagined already a long time ago. Which, let me tell you, is very satisfying at a very personal level.\n\n\n\nAgain, if some keywords above are confusing, the how of the algorithm is neatly explained in this 12‚Äô video, which I highly recommend."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#intro-imperfect-but-very-cool",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#intro-imperfect-but-very-cool",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Version ‚Äú0‚Äù is done and working. And I will say this, it is already showing some of its power. Let me show you."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#whats-in-it",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#whats-in-it",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Alright so this is what I have so far:\n\nA basic, fully functional, Michigan-style LCS for Supervised Learning\nA wrapper makes it easier to call the thing for training\nGA (tournament-based parents selection, one-point cross over reproduction, simple mutation) and Covering for rules discovery\nDeletion was somewhat fixed\nAccuracy and other stats work\nPrinting support functions\nNew: It includes subsumption. But calling subsumption affects performance ‚Äì both ways ‚Äì depending on the when/where/how, a known fact. But when used ‚Äì and that‚Äôs an important running decision, by the way ‚Äì, it condensates the relevant information encoded in the system‚Ä¶ Making it, when applicable, much better!\n\n\n\nsubsumption and deletion are costly, but effective to contain the size of the system\n\n\nNew too: Testing can be called now too, which is very helpful to validate the value of the LCS\nThis LCS for SL accepts an environment that, importantly, currently supports only:\n\nBinary classes/actions (so 0 or 1)\nBinary strings as input/states (no more no less) (and I mean, strings)\nAll states must be of equal length (whatever that is)\n\n\nThat‚Äôs on the plus side. On the not-so-great, well:\n\nLittle-to-no error control in there yet\nNext-to-zero documentation so far\nAnd I‚Äôll make a note on performance later in this post.\nImperfect/still-a-bit-disorganized code is probably an understatement.\n\nBut that‚Äôs just what needs to happen next, I guess. Now on to what you can do with this thing."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-1-not-bit-4",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-1-not-bit-4",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "So I‚Äôve already shown that one, but it wasn‚Äôt ‚Äúperfect‚Äù. Here the new version and a few tricks allow me to show how the LCS can be used for data mining.\nSo I give it 70% of the sample space, and it comes up with the following ‚ÄúClassifiers Set‚Äù:\n\n\n\nUsing LCS to discover the hidden rules in the dataset\n\n\nNotice how this is quite exactly what the LCS was supposed to try and discover. And also how it indeed tells us what that particular ‚Äúenvironment‚Äù (dataset and its classes) is all about.\n(Oh, and in this particular exercise, I really did not need to run so many epochs, it‚Äôs just my default hyperparameter setting, but after a hundred or so epochs, it was already done.)\nLet‚Äôs move to a more interesting example."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-2-mux6",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-2-mux6",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "The ‚ÄúIntroduction to Learning Classifier Systems‚Äù book ‚Äì referenced in my first post on LCS ‚Äì explains the algorithm with (among much more explanations) one particular example, called a ‚Äú6-bit multiplexer‚Äù.\nThe rules of that particular example are like so:\n\nyou get a string of 6 bits as input\nthe first two bits point to an address in the resting 4 bits\nthe ‚Äúclass‚Äù of your classifier should be whatever the bit is at the designated address.\n\nA couple of examples:\n\n‚Äú010000‚Äù says ‚ÄúBit 2 of the last 4 bits is the class, so 0‚Äù\n‚Äú110001‚Äù says ‚ÄúBit 4 of the last 4 bits is the class, so 1‚Äù\n‚Äú101101‚Äù says ‚ÄúBit 3 of the last 4 bits is the class, so 0‚Äù\n‚Ä¶\n\nYou get the idea. One aspect of this is meant to show that the LCS SL can somehow recognize things that are interrelated in the data, here how two different parts interact. They call this ‚Äúepistasis‚Äù. For now, suffice to say, it‚Äôs a bit more interesting use-case and we hope our LCS can discover relevant rules.\nAgain, with 70% of the whole dataset (64 entries total, for 6 bits), we train our LCS and hope to identify important rules (ideally, up to 8 perfect rules in this case ‚Äì but that‚Äôs not guaranteed). Here I show one such trained Classifier Set (aka ‚ÄúLCS‚Äù or ‚ÄúLearning Classifier System‚Äù, where the S stands for ‚ÄúSystem‚Äù, implying more than one classifier working together‚Ä¶ but I digress) that gets it almost perfect:\n\n\n\nAlmost perfect MUX6 LCS\n\n\nYou have to look somewhat carefully but you should find 7 of the 8 ‚Äúperfect‚Äù classifiers in there. And I haven‚Äôt checked for this particular example, but if the training set (randomly selected) did contain all the needed cases (probably did), this LCS should also almost cover for the missing classifier (11###0 0). Hint, the following would be the only one that would match for that missing classifier, so they would participate to recommend the action/class, and see how they all recommend class 0 (‚Ä¶):\n\n1####0 0\n#1#0#0 0\n##00#0 0\n##0#10 0\n\nSo in spite of missing one perfect rule (and that‚Äôs also depending on the random environment and non-deterministic nature of the LCS training‚Ä¶), it would work in all testing cases.\nLet‚Äôs move on to a (much) harder use-case."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-3-mnist-with-tricks",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#test-3-mnist-with-tricks",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Now this was a stretch. the MNIST dataset is nothing like the dummy tests above, for sure. First, I don‚Äôt know how to manually write a perfect program manually for it (the above cases were trivial, comparatively).\nSecond, many trained neural nets on the MNIST dataset don‚Äôt get perfect record (but that‚Äôs understandable, if you spend enough time with that dataset).\nThird, and quite important, the ‚Äústates‚Äù here are numerical strings representing the shade (black-white) of 784 pixels (28*28) integers between 0 and 255. With a simple binary transformation I could end up with my states represented each as 6272 binary strings (8 bits per pixel).\nAnd there are a few thousand entries (samples) per represented number.\nI knew upfront, doing thousands of exposures per sample to get anywhere would take forever.\nFair enough, and so I simplified the problem first. Here is what I did:\n\nCompress the data, from shades to 0-1 values per pixel. I used a threshold to ‚Äúsharpen‚Äù the dataset, so only if the value was &gt; 100 (out of 255) I would set my new pixel to 1, otherwise I set it to 0.\nCompress further, from 28*28 to 7*7 pixels. Each original 4-pixels-square is encoded as only 1 pixel, with value 1 if any of the 4*4 subsquare was one, 0 otherwise.\nThe above gives me 7*7 binary strings, so my states are now 49 bits long.\n\n\n\nI ‚Äúcompress‚Äù the MNIST data before training my LCS\n\n\nClass stays the same, but I also will do a simpler exercise. My LCS should distinguish between classes 0 and 1 only. (This is not an issue, it‚Äôs a choice. I just choose to keep things simple, that‚Äôs all, but the value of the approach is the same, think of it as a one-versus-rest approach if you want). This is in part to make things faster, and in (big) part because the code so far only allows two-classes-output only.\n\nLet me skip directly to the results here:\n\n\n\nShowing a couple of runs of an LCS SL on MNIST simplified dataset\n\n\n(BTW, I meant to write ‚Äúconfusion matrix‚Äù, not ‚Äúcontention table‚Äù above, obviously‚Ä¶ Apologies, I hadn‚Äôt slept much yesterday‚Ä¶)\nI just want to make this clear:\n\nTraining on a total 500 random (sampled) training inputs only (that‚Äôs the size of my environment here), so roughly 250 examples of pictures of Zero and 250 of One\nTraining on these 500 examples takes me between 7.4 and 9.3 minutes (in the above example)\nIt generalizes very well: I end up with an LCS that correctly classified 96 to 97+% of the 3799 sample tests."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#performance",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#performance",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "One thing that has worried me the past few days, something I actually knew was a concern with LCS, was performance. I mean speed, here.\nTraining requires exposing the LCS to sufficient training instances to ‚Äúrepresent‚Äù the overall data. Here I believe, in LCS in particular, too many training instances would hinder training because of the speed of processing power needed. I truly believe better chosen training instances are more important than more training instances. Kinda contrary of what Deep Learning would have you think. Although, this belief is, right now, just that: A belief.\nLCS on the other hand, for each training instance, require a lot of ‚Äúepochs‚Äù, so seeing the same data quite a few times. That is because after covering, the GA kicks in and that happens with choosing what best rules are available, which are evolved over time and where ‚Äúbest‚Äù depends on how many matches, how general but specific enough a rule is, whether a rule not only matches but also returns the correct action‚Ä¶ The point is, ideally, you want to train your LCS on a dataset, but circle over that dataset many times. I‚Äôm talking, thousands of times ideally - for each entry.\nThe other aspect of it is, of course, choosing R as a programming language. As much as I am comfortable with it, it is a slow language, if you consider compiled alternatives and such.\nI wanted to dive a bit into the details of what in my current (basic) implementation I could do, and so I ran the thing through ‚Äúprofvis‚Äù quite a few times, separate functions at separate times, then overall, with larger problems, etc.\nOne thing I do a lot, because I‚Äôm using lists for everything right now, is use ‚Äúlapply()‚Äù (and al.). I have tried as much as I could to not use dependencies if I could avoid it. So much so, I believe the only actual dependency I have is the plyr package for the rbind() function, and that‚Äôs for printing stuff‚Ä¶\nNot having too many dependencies is partly motivated by my end goal of producing a package, which I‚Äôd like to make ‚Äúlight‚Äù as much as possible.\nAnyhow, so I use lapply() a lot, but I have also used %in% quite a few times. And in some cases, I mix both and check quite a few instances, quite a few times!\nMatching, which happens a lot, for instance, can have an impact:\n\n\n\nProfiling run-times of mono-thread R interpreted code with LOTS of iterations in there‚Ä¶"
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#nicos-trick-parallelizing",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#nicos-trick-parallelizing",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "You might know this by now: I like to parallelize stuff over my CPU cores/threads. It‚Äôs just a thing I think about when I see my processing times are‚Ä¶ Long. Even if long is a few seconds. And here, we‚Äôre talking many iterations, which on bigger datasets/longer states means minutes.\n(Actually, before I decided to simplify to 49 bits the states of the MNIST exercise, I was working with 784 bits states, and well, it would NOT converge after several minutes‚Ä¶)\nWell, I have to keep working on this, but the cool thing is, an LCS can be pre-trained, and then re-trained.\nSo the LCS (in supervised learning setting for now) is nothing but a set of classifiers, which are rules learnt from examples. You can improve it by exposing it, simply, to more examples. Or let it run more iterations over the same examples!\nEither are valid approaches.\nNow‚Ä¶ What if I ‚Äúsharded‚Äù my data? Say, if I have 7 CPU cores‚Ä¶\nI could do one shorter run over all the data to generate a first ruleset. I could then use at the same time that pretrained LCS, and what if I trained 7 sub-LCS on 7 subsets of the data for more iterations (quite a few more epochs now, but in parallel, each on smaller data samples)?\nWhat if then I loop over that, with some sort of ‚Äúcompaction‚Äù of the 7 newly re-trained sub-LCS and generate a new single base LCS, to then re-distribute to 7 sub processes.\nWhat if I did that a few times?\nI still have to think (seriously, and hard) through all the implications of the simple ‚Äúalgorithm‚Äù I just proposed above. I came up with it quite independently, mind you. And maybe it‚Äôs a very bad idea. (not showing all the training examples hinders the selection and then generalization of classifiers, for one‚Ä¶ So maybe it‚Äôs a stupid idea‚Ä¶ I just haven‚Äôt thought it through yet. For now I do think maybe it does in fact kinda make sense.)\nBUT, I have done it already! One version of my code allows for parallel processing like just described.\nAnd well, in (quite a few) tests with the MNIST example above, for roughly the same overall runtimes (and ‚Äúcompaction‚Äù is costly!) I get a gain of 1-2% of correctly classified samples.\nFrom 96% to 97+%. (It might sound marginal, and indeed I‚Äôm talking about a LOT more processing, but the same runtimes with marginal gains in such near-100% ranges, sounds like potentially valuable).\nWell, indeed, I‚Äôve done that too:\n\n\n\nCPU-based parallel training of my LCS"
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#next-steps-packaging",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#next-steps-packaging",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "So I‚Äôve got all the pieces of the puzzle. And it works. And I have validated some marvellous (to me) results. All in a few days.\nWell, not a ‚Äúfew days‚Äù. See, I‚Äôve coded for only a few hours maybe, but I‚Äôve been thinking about this for a long time. And I also think it‚Äôd be unfair to say I was fast: Coding time per-se doesn‚Äôt account for waking up in the middle of the night coming up with my own design to approach the MNIST example. Waking up in the middle of the night, when I have a project like this, somehow happens more often. I have a bit of insomnia, but these projects make it worse, although they also make me more‚Ä¶ Productive.\nI guess what I‚Äôm saying is: coding time might not have been too many hours. But thinking time, or ‚Äúobsessing‚Äù (rather) did account for much more than 4 or 5 days (in 4 to 8h/day). I mean, I have designed everything in between the days of coding, and that started long before.\nAnyhow, to the next step: Moving from a few functions and examples to an actual Package!\nThat‚Äôs what I‚Äôll be up to when I next have time to dedicate to this."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#a-few-days-off",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#a-few-days-off",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Well, that is, indeed, when I next have the time. I‚Äôll be disconnecting for a couple of weeks during January. I simply have other personal priorities (all great).\nSo I‚Äôll take this where I left it maybe a bit later. No matter. I have gone through half the book of packages, and I actually am more convinced than ever that this is the perfect opportunity to create a package for me."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#conclusion",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#conclusion",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Well, I am just so‚Ä¶ Proud of this thing already!\nSee I had only ever read about the idea until‚Ä¶ Well, basically a week ago. Thanks to the holiday season, and long week-end hours, I can now say I have a working LCS in R.\nNot only that:\n\nI know it‚Äôs already not too bad in terms of what you could expect about performance. I know (from profiling) where I could try to go RCpp. I also have ideas to run it in more ‚Äúhighly‚Äù parallel setups. With more cores on a machine, or‚Ä¶ More machines! (plumbeR, here I come‚Ä¶ Well, later though, that‚Äôs not urgent)\nBut I also know, if I can ‚Äúencode‚Äù a problem into a binary string for binary classification, it turns out LCS are a very valid idea to consider! Just as good as a Neural Network! Heck, in some cases, better!\nI have done some testthat() already, I have several separate functions, very few (almost none) dependencies, the thing is somewhat organized‚Ä¶ So the next step comes rather naturally.\n\nAnyhow, overall, I am happy to report, I do believe this (future) package can prove very valuable to the community!\nAnd at this stage, I already hope I can explain that in future forums - I will convince people, I‚Äôm sure of it.\nSo this is turning out to be as great a project as I had (unreasonably) imagined already a long time ago. Which, let me tell you, is very satisfying at a very personal level."
  },
  {
    "objectID": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#references",
    "href": "posts/2024-12-29_RLCS_fully_functional_v000/index.html#references",
    "title": "RLCS Day 4.5 - Fully Functional v0 and New Tests",
    "section": "",
    "text": "Again, if some keywords above are confusing, the how of the algorithm is neatly explained in this 12‚Äô video, which I highly recommend."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kaizen-R.com new home",
    "section": "",
    "text": "RLCS Day 4.5 - Fully Functional v0 and New Tests\n\n\n\n\n\n\nML\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 29, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 2 - Full Rule Discovery\n\n\n\n\n\n\nML\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 24, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 1 - Part II: Basic Covering\n\n\n\n\n\n\nML\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nRLCS Day 1: Rules formatting, storage, and matching\n\n\n\n\n\n\nML\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nA new project\n\n\n\n\n\n\nML\n\n\nnews\n\n\nRLCS\n\n\n\n\n\n\n\n\n\nDec 8, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Linear Regression\n\n\n\n\n\n\nML\n\n\nmath\n\n\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying URLs\n\n\n\n\n\n\nML\n\n\ncode\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nEntropy - Identifying compressed files\n\n\n\n\n\n\nmath\n\n\ncode\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\nNico\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 8, 2024\n\n\nNico\n\n\n\n\n\n\nNo matching items"
  }
]